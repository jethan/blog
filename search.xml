<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[nginx安装与使用]]></title>
    <url>%2F2017%2F08%2F17%2Fnginx%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[nginx安装第一步，在/etc/yum.repos.d/目录下创建一个源配置文件nginx.repo： 12cd /etc/yum.repos.d/ vim nginx.repo 填写如下内容： 12345[nginx]name=nginx repo baseurl=http://nginx.org/packages/centos/$releasever/$basearch/ gpgcheck=0 enabled=1 保存，则会产生一个/etc/yum.repos.d/nginx.repo文件。 下面直接执行如下指令即可自动安装好Nginx： 1yum install nginx 安装完成，下面直接就可以启动Nginx了： 1/etc/init.d/nginx start 我是用：服务启动并设置开机启动 12345service nginx startchkconfig nginx on --level 35#指定配置文件启动/usr/sbin/nginx -c /etc/nginx/nginx.conf 启动成功如下 123456789[op@bogon init.d]$ ps aux | grep nginxroot 19210 0.0 0.0 46348 1192 ? Ss 14:57 0:00 nginx: master process /usr/sbin/nginx -c /etc/nginx/nginx.confnginx 19211 0.0 0.0 46740 1968 ? S 14:57 0:00 nginx: worker process nginx 19212 0.0 0.0 46740 1936 ? S 14:57 0:00 nginx: worker process nginx 19214 0.0 0.0 46740 1968 ? S 14:57 0:00 nginx: worker process nginx 19215 0.0 0.0 46740 1968 ? S 14:57 0:00 nginx: worker process nginx 19216 0.0 0.0 46740 1936 ? S 14:57 0:00 nginx: worker process nginx 19217 0.0 0.0 46740 1936 ? S 14:57 0:00 nginx: worker process op 19219 0.0 0.0 103328 872 pts/0 S+ 14:58 0:00 grep nginx 常用命令 123456789101112131415sudo nginx #启动nginxnginx -s reload|reopen|stop|quit #重新加载配置|重启|停止|退出 nginxnginx -t #测试配置是否有语法错误nginx [-?hvVtq] [-s signal] [-c filename] [-p prefix] [-g directives]-?,-h : 打开帮助信息-v : 显示版本信息并退出-V : 显示版本和配置选项信息，然后退出-t : 检测配置文件是否有语法错误，然后退出-q : 在检测配置文件期间屏蔽非错误信息-s signal : 给一个 nginx 主进程发送信号：stop（停止）, quit（退出）, reopen（重启）, reload（重新加载配置文件）-p prefix : 设置前缀路径（默认是：/usr/local/Cellar/nginx/1.2.6/）-c filename : 设置配置文件（默认是：/usr/local/etc/nginx/nginx.conf）-g directives : 设置配置文件外的全局指令 nginx 配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115user nginx;#启动进程,通常设置成和cpu的数量相等worker_processes 4;#全局错误日志及PID文件#error_log /data/nginx/logs/error.log warn;#error_log /data/nginx/logs/error.log notice;#error_log /data/nginx/logs/error.log info;#pid /data/nginx/pid/nginx.pid;#工作模式及连接数上限events &#123; #epoll是多路复用IO(I/O Multiplexing)中的一种方式, #仅用于linux2.6以上内核,可以大大提高nginx的性能 use epoll; #单个后台worker process进程的最大并发链接数 worker_connections 1024; # 并发总数是 worker_processes 和 worker_connections 的乘积 # 即 max_clients = worker_processes * worker_connections # 在设置了反向代理的情况下，max_clients = worker_processes * worker_connections / 4 为什么 # 为什么上面反向代理要除以4，应该说是一个经验值 # 根据以上条件，正常情况下的Nginx Server可以应付的最大连接数为：4 * 8000 = 32000 # worker_connections 值的设置跟物理内存大小有关 # 因为并发受IO约束，max_clients的值须小于系统可以打开的最大文件数 # 而系统可以打开的最大文件数和内存大小成正比，一般1GB内存的机器上可以打开的文件数大约是10万左右 # 我们来看看360M内存的VPS可以打开的文件句柄数是多少： # $ cat /proc/sys/fs/file-max # 输出 34336 # 32000 &lt; 34336，即并发连接总数小于系统可以打开的文件句柄总数，这样就在操作系统可以承受的范围之内 # 所以，worker_connections 的值需根据 worker_processes 进程数目和系统可以打开的最大文件总数进行适当地进行设置 # 使得并发总数小于操作系统可以打开的最大文件数目 # 其实质也就是根据主机的物理CPU和内存进行配置 # 当然，理论上的并发总数可能会和实际有所偏差，因为主机还有其他的工作进程需要消耗系统资源。 # ulimit -SHn 65535&#125;http &#123; #设定mime类型,类型由mime.type文件定义 include mime.types; default_type application/octet-stream; #设定日志格式 log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log logs/access.log main; #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件， #对于普通应用，必须设为 on, #如果用来进行下载等应用磁盘IO重负载应用，可设置为 off， #以平衡磁盘与网络I/O处理速度，降低系统的uptime. sendfile on; #tcp_nopush on; #连接超时时间 #keepalive_timeout 0; keepalive_timeout 65; tcp_nodelay on; #开启gzip压缩 gzip on; gzip_disable &quot;MSIE [1-6].&quot;; #设定请求缓冲 client_header_buffer_size 128k; large_client_header_buffers 4 128k; #设定虚拟主机配置 server &#123; #侦听80端口 listen 80; #定义使用 www.nginx.cn访问 server_name www.nginx.cn; #定义服务器的默认网站根目录位置 root html; #设定本虚拟主机的访问日志 access_log logs/nginx.access.log main; #默认请求 location / &#123; #定义首页索引文件的名称 index index.php index.html index.htm; &#125; # 定义错误提示页面 error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; #静态文件，nginx自己处理 location ~ ^/(images|javascript|js|css|flash|media|static)/ &#123; #过期30天，静态文件不怎么更新，过期可以设大一点， #如果频繁更新，则可以设置得小一点。 expires 30d; &#125; #PHP 脚本请求全部转发到 FastCGI处理. 使用FastCGI默认配置. location ~ .php$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125; #禁止访问 .htxxx 文件 location ~ /.ht &#123; deny all; &#125; &#125;&#125; 访问nginx 502错误,而通过服务器地址:原始端口号(8080)可以访问查看/var/log/nginx/error.log显示为 failed (13: Permission denied)命令行临时关闭selinux确认是否由此设置引起的 12$ getenforce #查看selinux状态$ setenforce 0 然后测试是否可以访问如果可以则证明是selinux的问题，于是先关掉selinux nginx拒绝或允许指定IP,是使用模块HTTP访问控制模块（HTTP Access）. 控制规则按照声明的顺序进行检查，首条匹配IP的访问规则将被启用。 123456location / &#123; deny 192.168.1.1; allow 192.168.1.0/24; allow 10.1.1.0/16; deny all;&#125; 上面的例子中仅允许192.168.1.0/24和10.1.1.0/16网络段访问这个location字段，但192.168.1.1是个例外。注意规则的匹配顺序，如果你使用过apache你可能会认为你可以随意控制规则的顺序并且他们能够正常的工作，但实际上不行。 下面的这个例子将拒绝掉所有的连接： 12345678location / &#123; #这里将永远输出403错误。 deny all; #这些指令不会被启用，因为到达的连接在第一条已经被拒绝 deny 192.168.1.1; allow 192.168.1.0/24; allow 10.1.1.0/1&#125;]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis安装及使用]]></title>
    <url>%2F2017%2F08%2F17%2Fredis%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[序言最近公司一台主要的redis服务器出现了异常，无限制的启动很多进程，导致系统资源耗尽，ssh很卡，redis及其他定时异常，想办法杀死了僵尸进程，但是最终还有一千六百多个crond进程和python进程处于D状态无法kill掉，庆幸的是进程数没有暴增了，可以继续使用，但是特别卡机。所以只能决定重启服务器，不过担心重启后起不来的情况，即使起来了所有实时数据都丢失，因为redis没开启持久化和主从读写分离备份，而且公司业务数据实时性要求非常高，最终办法是重新开启一台服务器多实例运行redis，两个原有端口不变先进行程序写入测试，另两个端口则设置从库从原有服务器对应端口实例同步数据，并且将现有redis和其他crontab定时迁移过去，并且开启数据持久化，让其他所有往这台服务器写数据的程序都同时重写一份进新服务器，读取还是从原有服务器，因为数据是按当天实时的，所以等待一天后，新服务器的数据就同步了，再将读也切换到新服务器，重启旧服务器，问题解决，吸取教训，重新配置主从和开启从库持久化，下面将整个过程介绍一下。 安装一、在线源安装 12345678910111213[op@bogon yum.repos.d]$ yum install redisLoaded plugins: fastestmirrorLoading mirror speeds from cached hostfile* base: mirrors.btte.net* extras: mirrors.btte.net* updates: mirrors.btte.netbase | 3.7 kB 00:00extras | 3.5 kB 00:00updates | 3.5 kB 00:00updates/primary_db | 4.6 MB 00:25Setting up Install ProcessNo package redis available.Error: Nothing to do 实际上redia位于第三方的yum源里面，不在centos官方yum源里面，如何解决呢？ 1、去下面的网站下载EPEL对应的版本：（epel是fedora维护的yum源，里面软件众多） 1http://fedoraproject.org/wiki/EPEL 2、我下载的是这个： 1wget http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm 3、安装epel： 1234rpm -ivh epel-release-6-8.noarch.rpmwarning: epel-release-6-8.noarch.rpm: Header V3 RSA/SHA256 Signature, key ID 0608b895: NOKEYPreparing... ########################################### [100%] 1:epel-release ########################################### [100%] 4、安装redis： 123456789101112131415161718192021222324252627[op@bogon yum.repos.d]$ yum install redisLoaded plugins: fastestmirrorLoading mirror speeds from cached hostfileepel/metalink | 4.1 kB 00:00* base: mirrors.btte.net* epel: mirrors.sohu.com* extras: mirrors.btte.net* updates: mirrors.btte.netepel | 4.3 kB 00:00epel/primary_db | 5.0 MB 00:43Setting up Install ProcessResolving Dependencies--&gt; Running transaction check---&gt; Package redis.x86_64 0:2.4.10-1.el6 will be installed--&gt; Finished Dependency ResolutionDependencies Resolved================================================================================Package Arch Version Repository Size================================================================================Installing:redis x86_64 2.4.10-1.el6 epel 213 kTransaction Summary================================================================================Install 1 Package(s)Total download size: 213 kInstalled size: 668 kIs this ok [y/N]:y 查看版本 12[op@bogon yum.repos.d]$ redis-server -vRedis server version 2.4.10 (00000000:0) 二、软件包安装 1) 下载redis安装包 可去官网 下载，也可通过wget命令， 1wget http://download.redis.io/redis-stable.tar.gz 2) 解压 1tar –zxvf redis-stable.tar.gz 3) 编译、安装 12cd redis-stablemake&amp;&amp;make install 如果提示gcc command不识别，请自行安装gcc: 12yum install gcc -yyum install gcc-g++ -y 如果提示couldn’t execute tcl : no such file or dicrectory，请自行安装tcl;如果提示: erroo:jmalloc/jemalloc.h:no such file or dicrectory请执行make distclean，然后再make 注意：若此时执行redis-server –v (查看版本命令)，若提示redis-server command not found，查看环境变量：echo $PATH，使用whereis redis-server查看redis-server命令目录，使用ln -s redis-server命令目录/redis-server 环境变量bin目录/redis-server创建软链接，客户端命令相同； 如 12sudo ln -s /usr/local/bin/redis-server /usr/sbin/redis-serversudo ln -s /usr/local/bin/redis-cli /usr/sbin/redis-cli /usr/sbin/redis-server环境变量中的命令，不存在/usr/local/bin/redis-server是make install后创建的 结果 12[op@bogon ~]$ ll /usr/sbin/redis-serverlrwxrwxrwx. 1 root root 27 Aug 18 15:17 /usr/sbin/redis-server -&gt; /usr/local/bin/redis-server 或者直接将/usr/local/bin目录加到环境变量，如何添加，此处不做详细介绍，可查看修改/etc/profile。 二．配置redis多实例环境 创建配置文件目录，dump file 目录，进程pid目录，log目录等 这里配置多实例环境 12cd /datamkdir -p redis/conf redis/log redis/pid redis/dump 注意各个目录的权限和所属用户及用户组,否则启动会报错dump和pid两个目录必须属于redis 12345678[op@bogon redis]$ lltotal 20drwxrwxr-x. 2 op op 4096 Aug 18 11:52 confdrwxr-xr-x. 2 redis root 4096 Aug 18 11:26 dumpdrwxr-xr-x. 2 op op 4096 Aug 18 11:25 logs-rw-------. 1 root root 0 Aug 18 11:52 nohup.outdrwxr-xr-x. 2 redis root 4096 Aug 18 11:52 pid-rwxr-xr-x. 1 op op 171 Aug 18 11:50 start.sh 修改配置文件，配置参数 软件源安装配置文件在/etc/redis.conf软件包安装配置文件在redis-stable/redis.conf 12cp /etc/redis.conf /data/redis/conf/redis-6380.confcp /etc/redis.conf /data/redis/conf/redis-6381.conf 建立日志文件 12vi redis/log/redis-6380.log //建立日志空文件并保存vi redis/log/redis-6381.log 这里以端口6380为例进行配置 打开redis-6380.conf文件修改端口(默认6379) 123# Accept connections on the specified port, default is 6379.# If port 0 is specified Redis will not listen on a TCP socket.port 6380 修改pid目录为新建目录 123# When running daemonized, Redis writes a pid file in /var/run/redis.pid by# default. You can specify a custom pid file location here.pidfile /data/redis/pid/redis-6380.pid 修改dump目录为新建目录及文件名 123456789# The working directory.## The DB will be written inside this directory, with the filename specified# above using the &apos;dbfilename&apos; configuration directive.## Also the Append Only File will be created inside this directory.## Note that you must specify a directory here, not a file name.dir /data/redis/dump/ 12# The filename where to dump the DBdbfilename dump-6380.rdb 修改log存储目录为新建目录 1234# Specify the log file name. Also &apos;stdout&apos; can be used to force# Redis to log on the standard output. Note that if you use standard# output for logging but daemonize, logs will be sent to /dev/nulllogfile /data/redis/logs/redis-6380.log 修改redis后台运行 123# By default Redis does not run as a daemon. Use &apos;yes&apos; if you need it.# Note that Redis will write a pid file in /var/run/redis.pid when daemonized.daemonize yes 持久化 默认rdb，可选择是否开启aof，若开启，修改配置文件appendonly 编写启动脚本，一次性启动 1vi start.sh 脚本内容 123#!/bin/bashnohup redis-server /data/redis/conf/redis-6380.conf &amp;nohup redis-server /data/redis/conf/redis-6381.conf &amp; 启动redis，查看各目录下文件 查看进程 1234[root@bogon conf]# ps aux | grep redisroot 22900 0.0 0.0 39944 2632 ? Ssl Aug14 0:24 redis-server /data/redis/conf/redis-6381.confroot 22901 0.0 0.0 39944 3748 ? Ssl Aug14 0:25 redis-server /data/redis/conf/redis-6380.confroot 39320 0.0 0.0 103332 876 pts/0 S+ 15:41 0:00 grep redis 关闭redis服务 1[root@bogon conf]# redis-cli shutdown 查看dump信息 1ls -al /data/redis/dump 若配置了aof持久化方式，data目录下还会有aof的相关文件，后面会详细介绍 客户端连接redis 本机连接，不指定则连接默认端口6379 1redis-cli 其他客户机连接，需要指定ip和要连接的端口 1redis-cli -h 192.168.132.25 -p 6380 如若是拒绝连接，则是因为redis配置默认是只允许本机连接的，所以要开启其他客户机访问，就将所有bind信息注释掉 12345# If you want you can bind a single interface, if the bind option is not# specified all the interfaces will listen for incoming connections.##bind 127.0.0.1#bind 192.168.132.25 若是没有路由，则是防火墙问题，防火墙添加路由，或者直接关闭防火墙 12sudo service iptables status #查看防火墙状态sudo service iptables stop #关闭防火墙服务 数据备份与恢复前面的配置提到了两种持久化方式，接下来详细介绍 RDB方式(默认)RDB方式的持久化是通过快照（snapshotting）完成的，当符合一定条件时Redis会自动将内存中的所有数据进行快照并存储在硬盘上。进行快照的条件可以由用户在配置文件中自定义，由两个参数构成：时间和改动的键的个数。当在指定的时间内被更改的键的个数大于指定的数值时就会进行快照。RDB是redis默认采用的持久化方式，在配置文件中已经预置了3个条件： 123save 900 1 # 900秒内有至少1个键被更改则进行快照save 300 10 # 300秒内有至少10个键被更改则进行快照save 60 10000 # 60秒内有至少10000个键被更改则进行快照 可以存在多个条件，条件之间是“或”的关系，只要满足其中一个条件，就会进行快照。 如果想要禁用自动快照，只需要将所有的save参数删除即可。 Redis默认会将快照文件存储在/var/lib/redis/目录(可CONFIG GET dir来查看)的dump.rdb文件中，可以通过配置dir和dbfilename两个参数分别指定快照文件的存储路径和文件名。 Redis实现快照的过程 Redis使用fork函数复制一份当前进程（父进程）的副本（子进程）；父进程继续接收并处理客户端发来的命令，而子进程开始将内存中的数据写入硬盘中的临时文件；当子进程写入完所有数据后会用该临时文件替换旧的RDB文件，至此一次快照操作完成。在执行fork的时候操作系统（类Unix操作系统）会使用写时复制（copy-on-write）策略，即fork函数发生的一刻父子进程共享同一内存数据，当父进程要更改其中某片数据时（如执行一个写命令 ），操作系统会将该片数据复制一份以保证子进程的数据不受影响，所以新的RDB文件存储的是执行fork一刻的内存数据。 Redis在进行快照的过程中不会修改RDB文件，只有快照结束后才会将旧的文件替换成新的，也就是说任何时候RDB文件都是完整的。这使得我们可以通过定时备份RDB文件来实 现Redis数据库备份。RDB文件是经过压缩（可以配置rdbcompression参数以禁用压缩节省CPU占用）的二进制格式，所以占用的空间会小于内存中的数据大小，更加利于传输。 除了自动快照，还可以手动发送SAVE或BGSAVE命令让Redis执行快照，两个命令的区别在于，前者是由主进程进行快照操作，会阻塞住其他请求，后者会通过fork子进程进行快照操作。 Redis启动后会读取RDB快照文件，将数据从硬盘载入到内存。根据数据量大小与结构和服务器性能不同，这个时间也不同。通常将一个记录一千万个字符串类型键、大小为1GB的快照文件载入到内 存中需要花费20～30秒钟。 通过RDB方式实现持久化，一旦Redis异常退出，就会丢失最后一次快照以后更改的所有数据。这就需要开发者根据具体的应用场合，通过组合设置自动快照条件的方式来将可能发生的数据损失控制在能够接受的范围。如果数据很重要以至于无法承受任何损失，则可以考虑使用AOF方式进行持久化。 手动备份与恢复 12345redis 127.0.0.1:6379&gt; SAVE #redis 备份目录中创建dump.rdb文件redis 127.0.0.1:6379&gt; CONFIG GET dir #获取rdb存放目录1) &quot;dir&quot;2) &quot;/data/redis/dump/&quot; 恢复，将备份文件dump.rdb放到对应的dir目录，重启redis服务即可恢复rdb数据 AOF方式默认情况下Redis没有开启AOF(append only file)方式的持久化，可以在redis.conf中通过appendonly参数开启： 1appendonly yes 在启动时Redis会逐个执行AOF文件中的命令来将硬盘中的数据载入到内存中，载入的速度相较RDB会慢一些 开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是appendonly.aof，可以通过appendfilename参数修改： 1appendfilename appendonly.aof 配置redis自动重写AOF文件的条件 123456auto-aof-rewrite-percentage 100 # 当目前的AOF文件大小超过上一次重写时的AOF文件大小的百分之多少时会再次进行重写，如果之前没有重写过，则以启动时的AOF文件大小为依据auto-aof-rewrite-min-size 64mb # 允许重写的最小AOF文件大小配置写入AOF文件后，要求系统刷新硬盘缓存的机制# appendfsync always # 每次执行写入都会执行同步，最安全也最慢appendfsync everysec # 每秒执行一次同步操作# appendfsync no # 不主动进行同步操作，而是完全交由操作系统来做（即每30秒一次），最快也最不 Redis允许同时开启AOF和RDB，既保证了数据安全又使得进行备份等操作十分容易。此时重新启动Redis后Redis会使用AOF文件来恢复数据，因为AOF方式的持久化可能丢失的数据更少 主从同步(复制)通过持久化功能，Redis保证了即使在服务器重启的情况下也不会损失（或少量损失）数据。但是由于数据是存储在一台服务器上的，如果这台服务器的硬盘出现故障，也会导致数据丢失。为了避免单点故障，我们希望将数据库复制多个副本以部署在不同的服务器上，即使有一台服务器出现故障其他服务器依然可以继续提供服务。这就要求当一台服务器上的数据库更新后，可以自动将更新的数据同步到其他服务器上，Redis提供了复制（replication）功能可以自动实现同步的过程。 配置方法 通过配置文件 从数据库的配置文件中加入slaveof master-ip master-port，主数据库无需配置 通过命令行参数 启动redis-server的时候，使用命令行参数--slaveof master-ip master port 1redis-server --port 6380 --slaveof 192.168.133.25 6379 从数据库启动以后再设置 1slaveof master-ip master-port 如 12192.168.133.24:6380&gt; slaveof 192.168.133.25 6379OK 查看从库状态 1info 从库info 1234567891011121314151617181920212223242526192.168.133.24:6380&gt; info# Serverredis_version:2.8.19redis_git_sha1:00000000redis_git_dirty:0redis_build_id:4a607fa14f74d354redis_mode:standaloneos:Linux 2.6.32-358.el6.x86_64 x86_64arch_bits:64...# Replicationrole:slave #角色是从master_host:192.168.133.25master_port:6379master_link_status:up #状态是upmaster_last_io_seconds_ago:0master_sync_in_progress:0slave_repl_offset:1323763642slave_priority:100slave_read_only:1connected_slaves:0master_repl_offset:0repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0 查看主库状态 12345678910111213141516171819192.168.133.25:6379&gt; info# Serverredis_version:2.8.19redis_git_sha1:00000000redis_git_dirty:0redis_build_id:4a607fa14f74d354redis_mode:standaloneos:Linux 2.6.32-358.el6.x86_64 x86_64arch_bits:64...# Replicationrole:masterconnected_slaves:1slave0:ip=192.168.133.25,port=6380,state=online,offset=1426459508,lag=0master_repl_offset:1426478361repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1425429786repl_backlog_histlen:1048576 查看数据同步情况 12345192.168.133.24:6380&gt; dbsize(integer) 58562192.168.133.25:6379&gt; dbsize(integer) 58562 从数据库停止接收其他数据库的同步转主数据库 1SLAVEOF NO ONE 如 12192.168.133.24:6380&gt; slaveof no oneOK 结果如下 12345678# Replicationrole:masterconnected_slaves:0master_repl_offset:1722534164repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0 优点及应用场景 读写分离 通过复制可以实现读写分离以提高服务器的负载能力。在常见的场景中，读的频率大于写，当单机的Redis无法应付大量的读请求时（尤其是较耗资源的请求，比如SORT命令等）可以通过复制功能建立多个从数据库，主数据库只进行写操作，而从数据库负责读操作。 从数据库持久化 持久化通常相对比较耗时，为了提高性能，可以通过复制功能建立一个（或若干个）从数据库，并在从数据库中启用持久化，同时在主数据库禁用持久化。当从数据库崩溃时重启后主数据库会自动将数据同步过来，所以无需担心数据丢失。而当主数据库崩溃时，需要在从数据库中使用SLAVEOF NO ONE命令将从数据库提升成主数据库继续服务，并在原来的主数据库启动后使用SLAVEOF命令将其设置成新的主数据库的从数据库，即可将数据同步回来。 集群配置更多资料查看]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>nosql</tag>
        <tag>cache</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[solr安装与使用]]></title>
    <url>%2F2017%2F08%2F16%2Fsolr%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[solr+tomcat单节点Solr6部署在Tomcat8环境下 solr下载 在之前版本的Solr安装包中，存在solr.war文件，但是Solr6已经没有这个war包了，它已经被解压到了.\solr-6.0.0\server\solr-webapp文件夹下，将该文件夹复制到.\apache-tomcat-8.5.5\webapps下，并将其重命名为solr。 日志处理：将Solr安装包中.\solr-6.0.0\server\lib\ext内的5个jar包复制到.\apache-tomcat-8.5.5\webapps\solr\WEB-INF\lib下。将.\solr-6.0.0\server\resources下的log4j.properties文件复制到.\apache-tomcat-8.5.5\webapps\solr\WEB-INF\classes中，这里的classes目录需要自己新建。log4j.properties文件中有一行log4j.appender.file.File=${solr.log}/solr.log指定log文件的存放路径，可以指定到特定的目录。配置solr_home：在磁盘任意位置新建目录，取名solr_home,把.\solr-6.0.0\server\solr下的整个solr文件夹复制到solr_home，编辑.\apache-tomcat-8.5.5\webapps\solr\WEB-INF下的web.xml文件。将web.xml文件注释去掉，&lt;env-entry-value&gt;中填刚才新建的solr_home路径 12345&lt;env-entry&gt; &lt;env-entry-name&gt;solr/home&lt;/env-entry-name&gt; &lt;env-entry-value&gt;/home/jet/workspace/github/bigdata/solr/solr_home&lt;/env-entry-value&gt; &lt;env-entry-type&gt;java.lang.String&lt;/env-entry-type&gt;&lt;/env-entry&gt; 这个solr_home里面的内容是复制.\solr-6.0.0\server\solr\下的内容，然后在该目录下新建文件夹core0，把 .\solr-6.0.0\server\solr\configsets\basic_configs\下的所有文件复制进来。 运行的话，直接双击startup.sh 访问http://localhost:8080/solr/index.html，可以看到solr管理界面，但是我们的sore还是空的，需要手动创建。在管理界面，点击No cores available选项，在弹出的窗口刚才新建的文件夹的名字。Add core这样，最简单的Solr就搭建完成了。 【注意事项】solr6以上必须要求jdk1.8以上版本，不然访问会报404,而且tomcat日志不会报任何错误信息且访问路径是localhost:8080/solr/index.html solrcloud6配置hosts192.168.40.200 jet.solr.com192.168.40.2 hadoop02.hadoop.com192.168.40.3 hadoop03.hadoop.com 关闭防火墙(可以只执行第二步：推荐)1) 永久关闭防火墙: vi /etc/selinux/config，将其中的SELinux设置：SELINUX=disabled 2) 关闭防火墙 : systemctl disable firewalld.service #禁用 3) 关闭packagekit: vi /etc/yum/pluginconf.d/langpacks.conf，将enabled设为 0 配置tomcat（各个solr节点一样）启动与关闭 启动：到bin目录下./startup.sh 验证：http://192.168.40.200:8080 关闭：到bin目录下./shutdown.sh 配置zookeeper（各个zookeeper节点上面）(1) 解压 1tar -zxvf zookeeper-3.4.10.tar.gz (2)创建data和logs目录 创建目录并赋于写权限 指定zookeeper的数据存放目录/hadoop/zookeeper/data和日志目录/hadoop/zookeeper/logs (3)拷贝zookeeper配制文件zoo_sample.cfg，文件在conf目录下 拷贝zookeeper配制文件zoo_sample.cfg并重命名zoo.cfg (4) 修改zoo.cfg 123456789101112131415161718192021222324252627282930313233### Licensed to the Apache Software Foundation (ASF) under one# or more contributor license agreements. See the NOTICE file# distributed with this work for additional information# regarding copyright ownership. The ASF licenses this file# to you under the Apache License, Version 2.0 (the# &quot;License&quot;); you may not use this file except in compliance# with the License. You may obtain a copy of the License at## http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing,# software distributed under the License is distributed on an# &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY# KIND, either express or implied. See the License for the# specific language governing permissions and limitations# under the License.###clientPort=2181initLimit=10autopurge.purgeInterval=24syncLimit=5tickTime=3000dataDir=/hadoop/zookeeper/data #上面创建的数据目录dataLogDir=/hadoop/zookeeper/logs #上面创建的日志目录autopurge.snapRetainCount=30server.1=hadoop02.hadoop.com:2888:3888server.2=hadoop03.hadoop.com:2888:3888 (5)进入data文件夹建立对应的myid文件 1vi /hadoop/zookeeper/data/myid (6)拷贝zookeeper 文件夹到其他机器,进行相同配置 配置solr（各个solr节点一样）和上面单节点一样 配置solr服务(1) 在solr下，上传相关信息至zookeeper 在/home/jet/workspace/github/bigdata/solr/solr-6.0.0/server/scripts/cloud-scripts目录下执行 1./zkcli.sh -zkhost 192.168.40.2:2181,192.168.40.3:2181 -cmd upconfig -confdir /home/jet/workspace/github/bigdata/solr/solr_home/core0/conf -confname solrconfig.xml (2) 每一台solr和zookeeper关联 修改每一台solr的tomcat 的 bin目录下catalina.sh文件中加入DzkHost指定zookeeper服务器地址： 在JAVA_OPTS添加zookeepre地址 1JAVA_OPTS=&quot;-DzkHost=192.168.40.2:2181,192.168.40.3:2181&quot; (3) 启动每一台solr服务器进入对应tomcat bin目录启动 1sh startup.sh (4) 查看tomcat日志 1tail -fn 100 catalina.out 如下信息 110035261 INFO (zkCallback-4-thread-34-processing-n:192.168.40.200:8080_solr-EventThread) [ ] o.a.s.c.c.ConnectionManager Watcher org.apache.solr.common.cloud.ConnectionManager@6edf2d5f name:ZooKeeperConnection Watcher:192.168.40.2:2181,192.168.40.3:2181 got event WatchedEvent state:SyncConnected type:None path:null path:null type:None (5) 修改solr启动端口（各个节点的配置一样） 在solrhome下，有一个solr.xml文件，修改其中的内容为： 123$&#123;host:192.168.40.200&#125;$&#123;jetty.port:8080&#125; 然后访问地址 1http://192.168.40.200:8080/solr/index.html#/ 如下 solr全文检索原理solr全文检索实现原理]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>solr</tag>
        <tag>bigdata</tag>
        <tag>搜索引擎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据平台-ambari]]></title>
    <url>%2F2017%2F08%2F15%2F%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0-ambari%2F</url>
    <content type="text"><![CDATA[前言Ambari 跟 Hadoop 等开源软件一样，也是 Apache Software Foundation 中的一个项目，并且是顶级项目。 Ambari 就是创建、管理、监视 Hadoop 的集群，但是这里的 Hadoop 是广义，指的是 Hadoop 整个生态圈（例如 Hive，Hbase，Sqoop，Zookeeper 等 详见），而并不仅是特指 Hadoop。用一句话来说，Ambari 就是为了让 Hadoop 以及相关的大数据软件更容易使用的一个工具。Ambari 现在所支持的平台组件也越来越多，例如流行的 Spark，Storm 等计算框架，以及资源调度平台 YARN 等，我们都能轻松地通过 Ambari 来进行部署。Ambari 自身也是一个分布式架构的软件，主要由两部分组成：Ambari Server 和 Ambari Agent。简单来说，用户通过 Ambari Server 通知 Ambari Agent 安装对应的软件；Agent 会定时地发送各个机器每个软件模块的状态给 Ambari Server，最终这些状态信息会呈现在 Ambari 的 GUI，方便用户了解到集群的各种状态，并进行相应的维护。 目前Ambari最新的发布版本是 2.5.1，下面的配置操作都是在centos7下进行的 安装ambari-server执行yum list ambari-server查看是否有ambari源，如果没有则在/etc/yum.repo.d/目录下，创建ambari源文件ambari.repo，并填写以下内容： 123456789#VERSION_NUMBER=2.5.1[Updates-ambari-2.5.1.0]name=ambari-2.5.1.0 - Updatesbaseurl=http://public-repo-1.hortonworks.com/ambari/centos6/2.x/updates/2.5.1.0gpgcheck=1gpgkey=http://public-repo-1.hortonworks.com/ambari/centos6/RPM-GPG-KEY/RPM-GPG-KEY-Jenkinsenabled=1priority=1 其中的版本号可以改成你想要安装的且官网中存在的版本号,执行yum update更新源 再执行yum list ambari-server查看结果如下： 12345678 [jet@ambari yum.repos.d]$ yum list ambari-serverLoaded plugins: fastestmirror, refresh-packagekit, securityLoading mirror speeds from cached hostfile * base: mirror.bit.edu.cn * extras: mirrors.163.com * updates: mirrors.neusoft.edu.cnAvailable Packagesambari-server.x86_64 2.5.1.0-159 Updates-ambari-2.5.1.0 执行命令sudo yum install ambari-server开始安装 设置并启动ambari-server设置ambari-server，根据自己需要修改默认配置，注意如果选择postgresql数据库，不要选择4，要选择1，不然后面start的时候会报错，拒绝连接，没找到原因 1ambari-server setup 启动ambari-server： 1ambari-server start 由于我之前安装过2.2.2版本，这次运行时出错了，log文件里面错误如下： 1org.apache.ambari.server.AmbariException: Current database store version is not compatible with current server version, serverVersion=2.5.1.0, schemaVersion=2.2.2.0 运行下面的命令进行升级后重新启动，成功。 1ambari-server upgrade 集群部署通过http://localhost:8080访问ambari web管理界面默认用户名密码是:admin/admin 如下图所示： 多台计算无密码登录-ssh强烈建议使用root账户配置 1.安装ssh. yum install openssh-server 安装完成后会在~目录（当前用户主目录，即这里的/root）下产生一个隐藏文件夹.ssh（ls -al 可以查看隐藏文件）。如果没有这个文件，自己新建即可（mkdir .ssh） 123456789101112131415161718[root@ambari ~]# ls -altotal 60dr-xr-x---. 6 root root 269 Aug 22 17:26 .dr-xr-xr-x. 18 root root 236 Apr 14 12:51 ..-rw-------. 1 root root 1441 Apr 14 12:17 anaconda-ks.cfg-rw-------. 1 root root 13050 Aug 22 17:20 .bash_history-rw-r--r--. 1 root root 18 Dec 29 2013 .bash_logout-rw-r--r--. 1 root root 176 Dec 29 2013 .bash_profile-rw-r--r--. 1 root root 176 Dec 29 2013 .bashrcdrwxr-xr-x. 3 root root 18 Apr 14 12:51 .cachedrwxr-xr-x. 3 root root 18 Apr 14 12:51 .config-rw-r--r--. 1 root root 100 Dec 29 2013 .cshrc-rw-r--r--. 1 root root 404 Aug 22 17:26 id_rsa.pubdrwxr-xr-x. 2 root root 40 Apr 20 14:27 .oracle_jre_usage-rw-------. 1 root root 247 Apr 17 18:38 .psql_history-rw-r--r--. 1 root root 6899 Aug 22 16:39 remove.sh-rw-------. 1 root root 1024 Apr 20 14:40 .rnddrwx------. 2 root root 80 Aug 22 17:27 .ssh 2.进入.ssh目录下面，在每台机器上执行：ssh-keygen -t rsa 之后一路回车，产生密钥； 1234[root@ambari .ssh]# lltotal 16-rw-------. 1 root root 1679 Aug 22 17:25 id_rsa-rw-r--r--. 1 root root 404 Aug 22 17:25 id_rsa.pub 3。完成第二步后会产生两个文件： id-rsa #私钥 id-rsa.pub #公钥 4.在第一台机器的目录.ssh下执行命令，cat id_rsa.pub &gt;&gt; authorized_keys；生成authorized_keys文件。 123[root@ambari .ssh]# lltotal 16-rw-r-----. 1 root root 404 Aug 22 17:26 authorized_keys 5.然后将第一台机器的.ssh目录下面的authorized_keys文件拷贝到第二台计算机的/root/.ssh目录下， 1scp authorized_keys root@hadoop02.hadoop.com:/root/.ssh/ 6.再转到第二台机器的.ssh目录下，会发现刚刚传输过来的文件authorized_keys，然后执行命令cat id-rsa.pub &gt;&gt; authorized_keys，将第二台计算机的公钥也加进来 7.将第二台计算机新生成的authorized_keys传输到第三台计算机，将第三台计算机的公钥id-rsa.pub添加到从第二台计算机传过来的authorized_keys里面。 8.依次类推，直至集群中的最后一台计算机。 9.在集群的最后一台计算机执行完添加后，生成的authorized_keys文件就包含集群中所有计算机的公钥，如果以后还有机器加进到集群中来，可以直接添加到文件authorized_keys。最后，将最后生成的authorized_keys复制到集群中的每一台计算机的.ssh目录下，覆盖掉之前的authorized_keys即可。 10.完成第九步后，就可以在集群中任意一台计算机上，免密码ssh登录到其他计算了。否则错误：Agent admitted failure to sign using the key解决：ssh-add ~/.ssh/id_rsa 如果需无密码登录到目标主机，只需要将自己的公钥id_rsa.pub添加到对应的目标主机的 .ssh/authorized_keys文件中即可，注意所属账户的.ssh,如以下是免密码登录到jet用户 1cat id_rsa.pub | ssh jet@10.111.24.144 &apos;cat - &gt;&gt; ~/.ssh/authorized_keys&apos; 一般以上几步就ok了，但我的仍要输入密码，用root用户登陆查看系统的日志文件：$ tail /var/log/secure -n 20 12345678…………Aug 22 10:26:43 MasterServer sshd[2734]: Authentication refused: bad ownership or modes for file /home/hadooper/.ssh/authorized_keysAug 22 10:26:48 MasterServer sshd[2734]: Accepted password for hadooper from ::1 port 37456 ssh2Aug 22 10:26:48 MasterServer sshd[2734]: pam_unix(sshd:session): session opened for user hadooper by (uid=0)Aug 22 10:36:30 MasterServer sshd[2809]: Accepted password for hadooper from 192.168.1.241 port 36257 ssh2Aug 22 10:36:30 MasterServer sshd[2809]: pam_unix(sshd:session): session opened for user hadooper by (uid=0)Aug 22 10:38:28 MasterServer sshd[2857]: Authentication refused: bad ownership or modes for directory /home/hadooper/.ssh………… 提示/home/root/.ssh和 /home/root/.ssh/authorized_keys权限不对，修改如下： 12chmod 700 /root/.sshchmod 640 /root/.ssh/authorized_keys 测试ssh root@hadoop02.hadoop.com第一次登录可能需要yes确认，之后就可以直接登录了。 下面是ambari界面安装添加集群过程，只介绍重要的可能遇到问题的部分 Install Options 【注意】1.Target Hosts 图中的hosts为各个客户机的hostname，一定要用域名的格式，配置方式如下两步： 集群中每台机器各自命名，最好添加ip号作为后缀，编辑/etc/sysconfig/network ambari-server192.168.40.112NETWORKING=yesHOSTNAME=ambari.hadoop.com ambari-agent192.168.40.212NETWORKING=yesHOSTNAME=hadoop02.hadoop.com ambari-agent192.168.40.312NETWORKING=yesHOSTNAME=hadoop03.hadoop.com 集群中每台机器都需要配置一样的，编辑文件/etc/hosts 192.168.40.1 192.168.40.2 192.168.40.3 ambari.hadoop.com12192.168.40.2 hadoop02.hadoop.com192.168.40.3 hadoop03.hadoop.com 2.Host Registration Information 注意这里是之前配置的免密码登录的用户的私钥 我前面是用root用户配置的，所以应该用/root/.ssh/id_rsa ssh user是root，ssh默认端口就是22 Hosts Check 一般就是图中的两个warning： 1.关闭防火墙 关闭防火墙 sudo service iptables stop 临时关闭命令关闭selinux 123456getenforcesetenforce 0[说明]setenforce 1 #设置SELinux 成为enforcing模式setenforce 0 #设置SELinux 成为permissive模式 或者直接修改配置文件关闭/etc/selinux/config(需要重启服务器) 1SELINUX=disabled 2.启动ntpd服务 12yum -y install ntpchkconfig ntpd on centos7服务模式变化 123/bin/systemctl start ntpd/bin/systemctl start chronyd/bin/systemctl stop firewalld 完成这两个操作以后，warning消失，如图 Choose Services选择需要安装的服务 Assign Masters分配主服务器 Assign slaves and Clients分配从服务器和客户端 控制面板 访问不了注意关闭防火墙 常见错误汇总错误信息123456789102017-08-22 21:09:18,495 - Skipping installation of existing package hdp-select2017-08-22 21:09:18,755 - Using hadoop conf dir: /usr/hdp/current/hadoop-client/conf2017-08-22 21:09:18,757 - checked_call[&apos;hostid&apos;] &#123;&#125;2017-08-22 21:09:18,761 - checked_call returned (0, &apos;a8c00228&apos;)2017-08-22 21:09:18,763 - Package[&apos;ambari-metrics-monitor&apos;] &#123;&apos;retry_on_repo_unavailability&apos;: False, &apos;retry_count&apos;: 5&#125;2017-08-22 21:09:18,829 - Skipping installation of existing package ambari-metrics-monitor2017-08-22 21:09:18,830 - Package[&apos;ambari-metrics-hadoop-sink&apos;] &#123;&apos;retry_on_repo_unavailability&apos;: False, &apos;retry_count&apos;: 5&#125;2017-08-22 21:09:18,839 - Skipping installation of existing package ambari-metrics-hadoop-sink2017-08-22 21:09:18,840 - Package[&apos;ambari-metrics-grafana&apos;] &#123;&apos;retry_on_repo_unavailability&apos;: False, &apos;retry_count&apos;: 5&#125;2017-08-22 21:09:18,849 - Installing package ambari-metrics-grafana (&apos;/usr/bin/yum -d 0 -e 0 -y install ambari-metrics-grafana&apos;) 手动安装即可参考 1234567yum install ambari-metrics-monitor hdp-select -yyum install slider_2_6_1_0_129 hdp-select -yyum install spark_2_6_1_0_129 hdp-select -yyum install mysql-connector-java hdp-select -yyum install tez_2_6_1_0_129 hdp-select -yyum install zookeeper_2_6_1_0_129 hdp-select -yyum install zookeeper_2_6_1_0_129-server hdp-select -y 此版本新增了自动启动服务功能，再也不用手动去挨个点击启动了 在admin-services auto start去enable对应的服务即可，太方便了]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>bigdata</tag>
        <tag>ambari</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式]]></title>
    <url>%2F2017%2F08%2F08%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[前言设计模式简介设计模式（Design pattern）代表了最佳的实践，通常被有经验的面向对象的软件开发人员所采用。设计模式是软件开发人员在软件开发过程中面临的一般问题的解决方案。这些解决方案是众多软件开发人员经过相当长的一段时间的试验和错误总结出来的。 设计模式是一套被反复使用的、多数人知晓的、经过分类编目的、代码设计经验的总结。使用设计模式是为了重用代码、让代码更容易被他人理解、保证代码可靠性。 毫无疑问，设计模式于己于他人于系统都是多赢的，设计模式使代码编制真正工程化，设计模式是软件工程的基石，如同大厦的一块块砖石一样。项目中合理地运用设计模式可以完美地解决很多问题，每种模式在现实中都有相应的原理来与之对应，每种模式都描述了一个在我们周围不断重复发生的问题，以及该问题的核心解决方案，这也是设计模式能被广泛应用的原因。什么是 GOF（四人帮，全拼 Gang of Four）？在 1994 年，由 Erich Gamma、Richard Helm、Ralph Johnson 和 John Vlissides 四人合著出版了一本名为 Design Patterns - Elements of Reusable Object-Oriented Software（中文译名：设计模式 - 可复用的面向对象软件元素） 的书，该书首次提到了软件开发中设计模式的概念。四位作者合称 GOF（四人帮，全拼 Gang of Four）。他们所提出的设计模式主要是基于以下的面向对象设计原则。对接口编程而不是对实现编程。优先使用对象组合而不是继承。设计模式的使用设计模式在软件开发中的两个主要用途。开发人员的共同平台设计模式提供了一个标准的术语系统，且具体到特定的情景。例如，单例设计模式意味着使用单个对象，这样所有熟悉单例设计模式的开发人员都能使用单个对象，并且可以通过这种方式告诉对方，程序使用的是单例模式。最佳的实践设计模式已经经历了很长一段时间的发展，它们提供了软件开发过程中面临的一般问题的最佳解决方案。学习这些模式有助于经验不足的开发人员通过一种简单快捷的方式来学习软件设计。设计模式的类型根据设计模式的参考书 Design Patterns - Elements of Reusable Object-Oriented Software（中文译名：设计模式 - 可复用的面向对象软件元素） 中所提到的，总共有 23 种设计模式。这些模式可以分为三大类：创建型模式（Creational Patterns）、结构型模式（Structural Patterns）、行为型模式（Behavioral Patterns）。当然，我们还会讨论另一类设计模式：J2EE 设计模式。 序号 模式&amp;描述 包含 1 创建型模式这些设计模式提供了一种在创建对象的同时隐藏创建逻辑的方式，而不是使用 new 运算符直接实例化对象。这使得程序在判断针对某个给定实例需要创建哪些对象时更加灵活。 工厂模式（Factory Pattern）抽象工厂模式（Abstract Factory Pattern）单例模式（Singleton Pattern）建造者模式（Builder Pattern）原型模式（Prototype Pattern） 2 结构型模式这些设计模式关注类和对象的组合。继承的概念被用来组合接口和定义组合对象获得新功能的方式。 适配器模式（Adapter Pattern）桥接模式（Bridge Pattern）过滤器模式（Filter、Criteria Pattern）组合模式（Composite Pattern）装饰器模式（Decorator Pattern）外观模式（Facade Pattern）享元模式（Flyweight Pattern）代理模式（Proxy Pattern） 3 行为型模式这些设计模式特别关注对象之间的通信。 责任链模式（Chain of Responsibility Pattern）命令模式（Command Pattern）解释器模式（Interpreter Pattern）迭代器模式（Iterator Pattern）中介者模式（Mediator Pattern）备忘录模式（Memento Pattern）观察者模式（Observer Pattern）状态模式（State Pattern）空对象模式（Null Object Pattern）策略模式（Strategy Pattern）模板模式（Template Pattern）访问者模式（Visitor Pattern） 4 J2EE 模式这些设计模式特别关注表示层。这些模式是由 Sun Java Center 鉴定的。 MVC 模式（MVC Pattern）业务代表模式（Business Delegate Pattern）组合实体模式（Composite Entity Pattern）数据访问对象模式（Data Access Object Pattern）前端控制器模式（Front Controller Pattern）拦截过滤器模式（Intercepting Filter Pattern）服务定位器模式（Service Locator Pattern）传输对象模式（Transfer Object Pattern） 下面用一个图片来整体描述一下设计模式之间的关系： 设计模式的六大原则 开闭原则（Open Close Principle）开闭原则的意思是：对扩展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。简言之，是为了使程序的扩展性好，易于维护和升级。想要达到这样的效果，我们需要使用接口和抽象类，后面的具体设计中我们会提到这点。 里氏代换原则（Liskov Substitution Principle）里氏代换原则是面向对象设计的基本原则之一。 里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。LSP 是继承复用的基石，只有当派生类可以替换掉基类，且软件单位的功能不受到影响时，基类才能真正被复用，而派生类也能够在基类的基础上增加新的行为。里氏代换原则是对开闭原则的补充。实现开闭原则的关键步骤就是抽象化，而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。 依赖倒转原则（Dependence Inversion Principle）这个原则是开闭原则的基础，具体内容：针对接口编程，依赖于抽象而不依赖于具体。 接口隔离原则（Interface Segregation Principle）这个原则的意思是：使用多个隔离的接口，比使用单个接口要好。它还有另外一个意思是：降低类之间的耦合度。由此可见，其实设计模式就是从大型软件架构出发、便于升级和维护的软件设计思想，它强调降低依赖，降低耦合。 迪米特法则，又称最少知道原则（Demeter Principle）最少知道原则是指：一个实体应当尽量少地与其他实体之间发生相互作用，使得系统功能模块相对独立。 合成复用原则（Composite Reuse Principle）合成复用原则是指：尽量使用合成/聚合的方式，而不是使用继承。 java常用设计模式通俗一点讲就是：一个程序员对设计模式的理解:“不懂”为什么要把很简单的东西搞得那么复杂。后来随着软件开发经验的增加才开始明白我所看到的“复杂”恰恰就是设计模式的精髓所在，我所理解的“简单”就是一把钥匙开一把锁的模式，目的仅仅是着眼于解决现在的问题，而设计模式的“复杂”就在于它是要构造一个“万能钥匙”，目的是提出一种对所有锁的开锁方案。在真正理解设计模式之前我一直在编写“简单”的代码.这个“简单”不是功能的简单，而是设计的简单。简单的设计意味着缺少灵活性，代码很钢硬，只在这个项目里有用，拿到其它的项目中就是垃圾，我将其称之为“一次性代码”。 要使代码可被反复使用,请用’设计模式’对你的代码进行设计。 很多我所认识的程序员在接触到设计模式之后，都有一种相见恨晚的感觉，有人形容学习了设计模式之后感觉自己好像已经脱胎换骨，达到了新的境界，还有人甚至把是否了解设计模式作为程序员划分水平的标准。我们也不能陷入模式的陷阱，为了使用模式而去套模式，那样会陷入形式主义。我们在使用模式的时候，一定要注意模式的意图（intent），而不要过多的去关注模式的实现细节，因为这些实现细节在特定情况下，可能会发生一些改变。不要顽固地认为设计模式一书中的类图或实现代码就代表了模式本身。 设计原则：(重要) 逻辑代码独立到单独的方法中，注重封装性—易读，易复用。不要在一个方法中，写下上百行的逻辑代码。把各小逻辑代码独立出来，写于其它方法中，易读其可重复调用。 写类，写方法，写功能时，应考虑其移植性，复用性：防止一次性代码！是否可以拿到其它同类事物中应该？是否可以拿到其它系统中应该？ 熟练运用继承的思想：找出应用中相同之处，且不容易发生变化的东西，把它们抽取到抽象类中，让子类去继承它们；继承的思想，也方便将自己的逻辑建立于别人的成果之上。如ImageField extends JTextField；熟练运用接口的思想：找出应用中可能需要变化之处，把它们独立出来，不要和那些不需要变化的代码混在一起。 把很简单的东西搞得那么复杂，一次性代码，设计模式优势的实例说明：（策略模式）说明：模拟鸭子游戏的应用程序，要求：游戏中会出现各种颜色外形的鸭子，一边游泳戏水，一边呱呱叫。1、 一次性代码 直接编写出各种鸭子的类：MallardDuck//野鸭，RedheadDuck//红头鸭，各类有三个方法：quack()：叫的方法swim()：游水的方法display()：外形的方法2、运用继承的特性，将其中共同的部分提升出来，避免重复编程。即：设计一个鸭子的超类（Superclass）,并让各种鸭子继承这个超类。 123456789public class Duck&#123; public void quack()&#123; //呱呱叫 System.out.println(&quot;呱呱叫&quot;); &#125; public void swim()&#123; //游泳 System.out.println(&quot; 游泳&quot;); &#125; public abstratact void display(); /*因为外观不一样，让子类自己去决定了。*/&#125; 对于它的子类只需简单的继承就可以了，并实现自己的display()方法。 123456789101112//野鸭 public class MallardDuck extends Duck&#123; public void display()&#123; System.out.println(&quot;野鸭的颜色...&quot;); &#125; &#125;//红头鸭 public class RedheadDuck extends Duck&#123; public void display()&#123; System.out.println(&quot;红头鸭的颜色...&quot;); &#125;&#125; 不幸的是，现在客户又提出了新的需求，想让鸭子飞起来。这个对于我们OO程序员，在简单不过了，在超类中在加一个方法就可以了。 123456789101112public class Duck&#123; public void quack()&#123; //呱呱叫 System.out.println(&quot;呱呱叫&quot;); &#125; public void swim()&#123; //游泳 System.out.println(&quot; 游泳&quot;); &#125; public abstract void display(); /*因为外观不一样，让子类自己去决定了。*/ public void fly()&#123; System.out.println(&quot;飞吧！鸭子&quot;); &#125;&#125; 对于不能飞的鸭子，在子类中只需简单的覆盖。 123456789//残废鸭 public class DisabledDuck extends Duck&#123; public void display()&#123; System.out.println(&quot;残废鸭的颜色...&quot;); &#125; public void fly()&#123; //覆盖，变成什么事都不做。 &#125;&#125; 其它会飞的鸭子不用覆盖。这样所有的继承这个超类的鸭子都会fly了。但是问题又出来了，客户又提出有的鸭子会飞，有的不能飞。 对于上面的设计，你可能发现一些弊端，如果超类有新的特性，子类都必须变动，这是我们开发最不喜欢看到的，一个类变让另一个类也跟着变，这有点不符合OO设计了。这样很显然的耦合了一起。利用继承—&gt;耦合度太高了. 3、用接口改进我们把容易引起变化的部分提取出来并封装之，来应付以后的变法。虽然代码量加大了，但可用性提高了，耦合度也降低了。我们把Duck中的fly方法和quack提取出来。 123456 public interface Flyable&#123; public void fly(); &#125; public interface Quackable&#123; public void quack();&#125; 最后Duck的设计成为： 123456public class Duck&#123; public void swim()&#123; //游泳 System.out.println(&quot; 游泳&quot;); &#125; public abstract void display(); /*因为外观不一样，让子类自 己去决定了。*/&#125; 而MallardDuck,RedheadDuck,DisabledDuck 就可以写成为： 123456789101112131415161718192021222324252627282930313233//野鸭 public class MallardDuck extends Duck implements Flyable,Quackable&#123; public void display()&#123; System.out.println(&quot;野鸭的颜色...&quot;); &#125; public void fly()&#123; //实现该方法 &#125; public void quack()&#123; //实现该方法 &#125; &#125;//红头鸭 public class RedheadDuck extends Duck implements Flyable,Quackable&#123; public void display()&#123; System.out.println(&quot;红头鸭的颜色...&quot;); &#125; public void fly()&#123; //实现该方法 &#125; public void quack()&#123; //实现该方法 &#125;&#125; //残废鸭 只实现Quackable（能叫不能飞） public class DisabledDuck extends Duck implements Quackable&#123; public void display()&#123; System.out.println(&quot;残废鸭的颜色...&quot;); &#125; public void quack()&#123; //实现该方法 &#125;&#125; 好处:这样已设计，我们的程序就降低了它们之间的耦合。不足:Flyable和 Quackable接口一开始似乎还挺不错的，解决了问题（只有会飞到鸭子才实现 Flyable），但是Java接口不具有实现代码，所以实现接口无法达到代码的复用。 继承的好处:让共同部分,可以复用.避免重复编程.继承的不好:耦合性高.一旦超类添加一个新方法,子类都继承,拥有此方法,若子类相当部分不实现此方法,则要进行大批量修改.继承时,子类就不可继承其它类了.接口的好处:解决了继承耦合性高的问题,且可让实现类,继承或实现其它类或接口.接口的不好:不能真正实现代码的复用.可用以下的策略模式来解决. strategy(策略模式)我们有一个设计原则：找出应用中相同之处，且不容易发生变化的东西，把它们抽取到抽象类中，让子类去继承它们；找出应用中可能需要变化之处，把它们独立出来，不要和那些不需要变化的代码混在一起。 现在，为了要分开“变化和不变化的部分”，我们准备建立两组类（完全远离Duck类），一个是”fly”相关的，另一个是“quack”相关的，每一组类将实现各自的动作。比方说，我们可能有一个类实现“呱呱叫”，另一个类实现“吱吱叫”，还有一个类实现“安静”。首先写两个接口。FlyBehavior(飞行行为)和QuackBehavior（叫的行为）. 123456public interface FlyBehavior&#123; public void fly(); &#125;public interface QuackBehavior&#123; public void quack();&#125; 我们在定义一些针对FlyBehavior的具体实现。 12345678910public class FlyWithWings implements FlyBehavior&#123; public void fly()&#123; //实现了所有有翅膀的鸭子飞行行为。 &#125; &#125;public class FlyNoWay implements FlyBehavior&#123; public void fly()&#123; //什么都不做，不会飞 &#125; &#125; 针对QuackBehavior的几种具体实现。 1234567891011121314151617public class Quack implements QuackBehavior&#123; public void quack()&#123; //实现呱呱叫的鸭子 &#125;&#125; public class Squeak implements QuackBehavior&#123; public void quack()&#123; //实现吱吱叫的鸭子 &#125;&#125; public class MuteQuack implements QuackBehavior&#123; public void quack()&#123; //什么都不做，不会叫 &#125;&#125; 点评一:这样的设计，可以让飞行和呱呱叫的动作被其他的对象复用，因为这些行为已经与鸭子类无关了。而我们增加一些新的行为，不会影响到既有的行为类，也不会影响“使用”到飞行行为的鸭子类。最后我们看看Duck 如何设计。 123456789101112131415public class Duck&#123; ---------&gt;在抽象类中,声明各接口,定义各接口对应的方法. FlyBehavior flyBehavior;//接口 QuackBehavior quackBehavior;//接口 public Duck()&#123;&#125; public abstract void display(); public void swim()&#123; //实现游泳的行为 &#125; public void performFly()&#123; flyBehavior.fly(); --&gt;由于是接口,会根据继承类实现的方式,而调用相应的方法. &#125; public void performQuack()&#123; quackBehavior.quack();(); &#125;&#125; 看看MallardDuck如何实现通过构造方法,生成’飞’,’叫’具体实现类的实例,从而指定’飞’,’叫’的具体属性 12345678910public class MallardDuck extends Duck&#123; public MallardDuck &#123; flyBehavior = new FlyWithWings (); quackBehavior = new Quack(); //因为MallardDuck 继承了Duck，所有具有flyBehavior 与quackBehavior 实例变量 &#125; public void display()&#123; //实现 &#125;&#125; 这样就满足了即可以飞，又可以叫，同时展现自己的颜色了。这样的设计我们可以看到是把flyBehavior ，quackBehavior 的实例化写在子类了。我们还可以动态的来决定。我们只需在Duck中加上两个方法。 在构造方法中对属性进行赋值与用属性的setter的区别：构造方法中对属性进行赋值：固定，不可变；用属性的setter，可以在实例化对象后，动态的变化，比较灵活。 12345678910public class Duck&#123; FlyBehavior flyBehavior;//接口 QuackBehavior quackBehavior;//接口 public void setFlyBehavior(FlyBehavior flyBehavior)&#123; this.flyBehavior = flyBehavior; &#125; public void setQuackBehavior(QuackBehavior quackBehavior &#123; this.quackBehavior= quackBehavior; &#125; &#125; 工厂模式工厂模式（Factory Pattern）是 Java 中最常用的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。在工厂模式中，我们在创建对象时不会对客户端暴露创建逻辑，并且是通过使用一个共同的接口来指向新创建的对象。意图：定义一个创建对象的接口，让其子类自己决定实例化哪一个工厂类，工厂模式使其创建过程延迟到子类进行。主要解决：主要解决接口选择的问题。何时使用：我们明确地计划不同条件下创建不同实例时。如何解决：让其子类实现工厂接口，返回的也是一个抽象的产品。关键代码：创建过程在其子类执行。应用实例： 1、您需要一辆汽车，可以直接从工厂里面提货，而不用去管这辆汽车是怎么做出来的，以及这个汽车里面的具体实现。 2、Hibernate 换数据库只需换方言和驱动就可以。优点： 1、一个调用者想创建一个对象，只要知道其名称就可以了。 2、扩展性高，如果想增加一个产品，只要扩展一个工厂类就可以。 3、屏蔽产品的具体实现，调用者只关心产品的接口。缺点：每次增加一个产品时，都需要增加一个具体类和对象实现工厂，使得系统中类的个数成倍增加，在一定程度上增加了系统的复杂度，同时也增加了系统具体类的依赖。这并不是什么好事。注意事项：作为一种创建类模式，在任何需要生成复杂对象的地方，都可以使用工厂方法模式。有一点需要注意的地方就是复杂对象适合使用工厂模式，而简单对象，特别是只需要通过 new 就可以完成创建的对象，无需使用工厂模式。如果使用工厂模式，就需要引入一个工厂类，会增加系统的复杂度。实现我们将创建一个 Shape 接口和实现 Shape 接口的实体类。下一步是定义工厂类 ShapeFactory。FactoryPatternDemo，我们的演示类使用 ShapeFactory 来获取 Shape 对象。它将向 ShapeFactory 传递信息（CIRCLE / RECTANGLE / SQUARE），以便获取它所需对象的类型。 步骤 1 创建一个接口: Shape.java 123public interface Shape &#123; void draw();&#125; 步骤 2 创建实现接口的实体类: Rectangle.java 1234567public class Rectangle implements Shape &#123; @Override public void draw() &#123; System.out.println(&quot;Inside Rectangle::draw() method.&quot;); &#125;&#125; Square.java 1234567public class Square implements Shape &#123; @Override public void draw() &#123; System.out.println(&quot;Inside Square::draw() method.&quot;); &#125;&#125; Circle.java 1234567public class Circle implements Shape &#123; @Override public void draw() &#123; System.out.println(&quot;Inside Circle::draw() method.&quot;); &#125;&#125; 步骤 3 创建一个工厂，生成基于给定信息的实体类的对象: ShapeFactory.java 1234567891011121314151617public class ShapeFactory &#123; //使用 getShape 方法获取形状类型的对象 public Shape getShape(String shapeType)&#123; if(shapeType == null)&#123; return null; &#125; if(shapeType.equalsIgnoreCase(&quot;CIRCLE&quot;))&#123; return new Circle(); &#125; else if(shapeType.equalsIgnoreCase(&quot;RECTANGLE&quot;))&#123; return new Rectangle(); &#125; else if(shapeType.equalsIgnoreCase(&quot;SQUARE&quot;))&#123; return new Square(); &#125; return null; &#125;&#125; 步骤 4 使用该工厂，通过传递类型信息来获取实体类的对象: FactoryPatternDemo.java 123456789101112131415161718192021222324public class FactoryPatternDemo &#123; public static void main(String[] args) &#123; ShapeFactory shapeFactory = new ShapeFactory(); //获取 Circle 的对象，并调用它的 draw 方法 Shape shape1 = shapeFactory.getShape(&quot;CIRCLE&quot;); //调用 Circle 的 draw 方法 shape1.draw(); //获取 Rectangle 的对象，并调用它的 draw 方法 Shape shape2 = shapeFactory.getShape(&quot;RECTANGLE&quot;); //调用 Rectangle 的 draw 方法 shape2.draw(); //获取 Square 的对象，并调用它的 draw 方法 Shape shape3 = shapeFactory.getShape(&quot;SQUARE&quot;); //调用 Square 的 draw 方法 shape3.draw(); &#125;&#125; 步骤 5 验证输出: 123Inside Circle::draw() method.Inside Rectangle::draw() method.Inside Square::draw() method. 抽象工厂模式抽象工厂模式（Abstract Factory Pattern）是围绕一个超级工厂创建其他工厂。该超级工厂又称为其他工厂的工厂。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。在抽象工厂模式中，接口是负责创建一个相关对象的工厂，不需要显式指定它们的类。每个生成的工厂都能按照工厂模式提供对象。介绍意图：提供一个创建一系列相关或相互依赖对象的接口，而无需指定它们具体的类。主要解决：主要解决接口选择的问题。何时使用：系统的产品有多于一个的产品族，而系统只消费其中某一族的产品。如何解决：在一个产品族里面，定义多个产品。关键代码：在一个工厂里聚合多个同类产品。应用实例：工作了，为了参加一些聚会，肯定有两套或多套衣服吧，比如说有商务装（成套，一系列具体产品）、时尚装（成套，一系列具体产品），甚至对于一个家庭来说，可能有商务女装、商务男装、时尚女装、时尚男装，这些也都是成套的，即一系列具体产品。假设一种情况（现实中是不存在的，要不然，没法进入共产主义了，但有利于说明抽象工厂模式），在您的家中，某一个衣柜（具体工厂）只能存放某一种这样的衣服（成套，一系列具体产品），每次拿这种成套的衣服时也自然要从这个衣柜中取出了。用 OO 的思想去理解，所有的衣柜（具体工厂）都是衣柜类的（抽象工厂）某一个，而每一件成套的衣服又包括具体的上衣（某一具体产品），裤子（某一具体产品），这些具体的上衣其实也都是上衣（抽象产品），具体的裤子也都是裤子（另一个抽象产品）。优点：当一个产品族中的多个对象被设计成一起工作时，它能保证客户端始终只使用同一个产品族中的对象。缺点：产品族扩展非常困难，要增加一个系列的某一产品，既要在抽象的 Creator 里加代码，又要在具体的里面加代码。使用场景： 1、QQ 换皮肤，一整套一起换。 2、生成不同操作系统的程序。注意事项：产品族难扩展，产品等级易扩展。实现我们将创建 Shape 和 Color 接口和实现这些接口的实体类。下一步是创建抽象工厂类 AbstractFactory。接着定义工厂类 ShapeFactory 和 ColorFactory，这两个工厂类都是扩展了 AbstractFactory。然后创建一个工厂创造器/生成器类 FactoryProducer。AbstractFactoryPatternDemo，我们的演示类使用 FactoryProducer 来获取 AbstractFactory 对象。它将向 AbstractFactory 传递形状信息 Shape（CIRCLE / RECTANGLE / SQUARE），以便获取它所需对象的类型。同时它还向 AbstractFactory 传递颜色信息 Color（RED / GREEN / BLUE），以便获取它所需对象的类型。 步骤 1 为形状创建一个接口。 Shape.java 123public interface Shape &#123; void draw();&#125; 步骤 2 创建实现接口的实体类。 Rectangle.java 1234567public class Rectangle implements Shape &#123; @Override public void draw() &#123; System.out.println(&quot;Inside Rectangle::draw() method.&quot;); &#125;&#125; Square.java 1234567public class Square implements Shape &#123; @Override public void draw() &#123; System.out.println(&quot;Inside Square::draw() method.&quot;); &#125;&#125; Circle.java 1234567public class Circle implements Shape &#123; @Override public void draw() &#123; System.out.println(&quot;Inside Circle::draw() method.&quot;); &#125;&#125; 步骤 3 为颜色创建一个接口。 Color.java 123public interface Color &#123; void fill();&#125; 步骤4 创建实现接口的实体类。 Red.java 1234567public class Red implements Color &#123; @Override public void fill() &#123; System.out.println(&quot;Inside Red::fill() method.&quot;); &#125;&#125; Green.java 1234567public class Green implements Color &#123; @Override public void fill() &#123; System.out.println(&quot;Inside Green::fill() method.&quot;); &#125;&#125; Blue.java 1234567public class Blue implements Color &#123; @Override public void fill() &#123; System.out.println(&quot;Inside Blue::fill() method.&quot;); &#125;&#125; 步骤 5 为 Color 和 Shape 对象创建抽象类来获取工厂。 12345AbstractFactory.javapublic abstract class AbstractFactory &#123; abstract Color getColor(String color); abstract Shape getShape(String shape) ;&#125; 步骤 6 创建扩展了 AbstractFactory 的工厂类，基于给定的信息生成实体类的对象。 ShapeFactory.java 12345678910111213141516171819202122public class ShapeFactory extends AbstractFactory &#123; @Override public Shape getShape(String shapeType)&#123; if(shapeType == null)&#123; return null; &#125; if(shapeType.equalsIgnoreCase(&quot;CIRCLE&quot;))&#123; return new Circle(); &#125; else if(shapeType.equalsIgnoreCase(&quot;RECTANGLE&quot;))&#123; return new Rectangle(); &#125; else if(shapeType.equalsIgnoreCase(&quot;SQUARE&quot;))&#123; return new Square(); &#125; return null; &#125; @Override Color getColor(String color) &#123; return null; &#125;&#125; ColorFactory.java 12345678910111213141516171819202122public class ColorFactory extends AbstractFactory &#123; @Override public Shape getShape(String shapeType)&#123; return null; &#125; @Override Color getColor(String color) &#123; if(color == null)&#123; return null; &#125; if(color.equalsIgnoreCase(&quot;RED&quot;))&#123; return new Red(); &#125; else if(color.equalsIgnoreCase(&quot;GREEN&quot;))&#123; return new Green(); &#125; else if(color.equalsIgnoreCase(&quot;BLUE&quot;))&#123; return new Blue(); &#125; return null; &#125;&#125; 步骤 7 创建一个工厂创造器/生成器类，通过传递形状或颜色信息来获取工厂。 FactoryProducer.java 12345678910public class FactoryProducer &#123; public static AbstractFactory getFactory(String choice)&#123; if(choice.equalsIgnoreCase(&quot;SHAPE&quot;))&#123; return new ShapeFactory(); &#125; else if(choice.equalsIgnoreCase(&quot;COLOR&quot;))&#123; return new ColorFactory(); &#125; return null; &#125;&#125; 步骤 8 使用 FactoryProducer 来获取 AbstractFactory，通过传递类型信息来获取实体类的对象。 AbstractFactoryPatternDemo.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class AbstractFactoryPatternDemo &#123; public static void main(String[] args) &#123; //获取形状工厂 AbstractFactory shapeFactory = FactoryProducer.getFactory(&quot;SHAPE&quot;); //获取形状为 Circle 的对象 Shape shape1 = shapeFactory.getShape(&quot;CIRCLE&quot;); //调用 Circle 的 draw 方法 shape1.draw(); //获取形状为 Rectangle 的对象 Shape shape2 = shapeFactory.getShape(&quot;RECTANGLE&quot;); //调用 Rectangle 的 draw 方法 shape2.draw(); //获取形状为 Square 的对象 Shape shape3 = shapeFactory.getShape(&quot;SQUARE&quot;); //调用 Square 的 draw 方法 shape3.draw(); //获取颜色工厂 AbstractFactory colorFactory = FactoryProducer.getFactory(&quot;COLOR&quot;); //获取颜色为 Red 的对象 Color color1 = colorFactory.getColor(&quot;RED&quot;); //调用 Red 的 fill 方法 color1.fill(); //获取颜色为 Green 的对象 Color color2 = colorFactory.getColor(&quot;Green&quot;); //调用 Green 的 fill 方法 color2.fill(); //获取颜色为 Blue 的对象 Color color3 = colorFactory.getColor(&quot;BLUE&quot;); //调用 Blue 的 fill 方法 color3.fill(); &#125;&#125; 步骤 9 验证输出。 123456Inside Circle::draw() method.Inside Rectangle::draw() method.Inside Square::draw() method.Inside Red::fill() method.Inside Green::fill() method.Inside Blue::fill() method. 单例模式单例模式（Singleton Pattern）是 Java 中最简单的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。注意：1、单例类只能有一个实例。2、单例类必须自己创建自己的唯一实例。3、单例类必须给所有其他对象提供这一实例。意图：保证一个类仅有一个实例，并提供一个访问它的全局访问点。主要解决：一个全局使用的类频繁地创建与销毁。何时使用：当您想控制实例数目，节省系统资源的时候。如何解决：判断系统是否已经有这个单例，如果有则返回，如果没有则创建。关键代码：构造函数是私有的。优点： 1、在内存里只有一个实例，减少了内存的开销，尤其是频繁的创建和销毁实例（比如管理学院首页页面缓存）。 2、避免对资源的多重占用（比如写文件操作）。缺点：没有接口，不能继承，与单一职责原则冲突，一个类应该只关心内部逻辑，而不关心外面怎么样来实例化。使用场景： 1、要求生产唯一序列号。 2、WEB 中的计数器，不用每次刷新都在数据库里加一次，用单例先缓存起来。 3、创建的一个对象需要消耗的资源过多，比如 I/O 与数据库的连接等。注意事项：getInstance() 方法中需要使用同步锁 synchronized (Singleton.class) 防止多线程同时进入造成 instance 被多次实例化。实现我们将创建一个 SingleObject 类。SingleObject 类有它的私有构造函数和本身的一个静态实例。SingleObject 类提供了一个静态方法，供外界获取它的静态实例。SingletonPatternDemo，我们的演示类使用 SingleObject 类来获取 SingleObject 对象。 步骤 1 创建一个 Singleton 类。 SingleObject.java 1234567891011121314151617public class SingleObject &#123; //创建 SingleObject 的一个对象 private static SingleObject instance = new SingleObject(); //让构造函数为 private，这样该类就不会被实例化 private SingleObject()&#123;&#125; //获取唯一可用的对象 public static SingleObject getInstance()&#123; return instance; &#125; public void showMessage()&#123; System.out.println(&quot;Hello World!&quot;); &#125;&#125; 步骤 2 从 singleton 类获取唯一的对象。 SingletonPatternDemo.java 1234567891011121314public class SingletonPatternDemo &#123; public static void main(String[] args) &#123; //不合法的构造函数 //编译时错误：构造函数 SingleObject() 是不可见的 //SingleObject object = new SingleObject(); //获取唯一可用的对象 SingleObject object = SingleObject.getInstance(); //显示消息 object.showMessage(); &#125;&#125; 步骤 3 验证输出。 1Hello World! 单例模式的几种实现方式单例模式的实现有多种方式，如下所示：1、懒汉式，线程不安全是否 Lazy 初始化：是是否多线程安全：否实现难度：易描述：这种方式是最基本的实现方式，这种实现最大的问题就是不支持多线程。因为没有加锁 synchronized，所以严格意义上它并不算单例模式。这种方式 lazy loading 很明显，不要求线程安全，在多线程不能正常工作。代码实例： 1234567891011public class Singleton &#123; private static Singleton instance; private Singleton ()&#123;&#125; public static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; &#125; 接下来介绍的几种实现方式都支持多线程，但是在性能上有所差异。 2、懒汉式，线程安全是否 Lazy 初始化：是是否多线程安全：是实现难度：易描述：这种方式具备很好的 lazy loading，能够在多线程中很好的工作，但是，效率很低，99% 情况下不需要同步。优点：第一次调用才初始化，避免内存浪费。缺点：必须加锁 synchronized 才能保证单例，但加锁会影响效率。getInstance() 的性能对应用程序不是很关键（该方法使用不太频繁）。代码实例： 12345678910public class Singleton &#123; private static Singleton instance; private Singleton ()&#123;&#125; public static synchronized Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; &#125; 3、饿汉式是否 Lazy 初始化：否是否多线程安全：是实现难度：易描述：这种方式比较常用，但容易产生垃圾对象。优点：没有加锁，执行效率会提高。缺点：类加载时就初始化，浪费内存。它基于 classloder 机制避免了多线程的同步问题，不过，instance 在类装载时就实例化，虽然导致类装载的原因有很多种，在单例模式中大多数都是调用 getInstance 方法， 但是也不能确定有其他的方式（或者其他的静态方法）导致类装载，这时候初始化 instance 显然没有达到 lazy loading 的效果。代码实例： 1234567public class Singleton &#123; private static Singleton instance = new Singleton(); private Singleton ()&#123;&#125; public static Singleton getInstance() &#123; return instance; &#125; &#125; 4、双检锁/双重校验锁（DCL，即 double-checked locking）JDK 版本：JDK1.5 起是否 Lazy 初始化：是是否多线程安全：是实现难度：较复杂描述：这种方式采用双锁机制，安全且在多线程情况下能保持高性能。getInstance() 的性能对应用程序很关键。代码实例： 1234567891011121314public class Singleton &#123; private volatile static Singleton singleton; private Singleton ()&#123;&#125; public static Singleton getSingleton() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125; &#125; 5、登记式/静态内部类是否 Lazy 初始化：是是否多线程安全：是实现难度：一般描述：这种方式能达到双检锁方式一样的功效，但实现更简单。对静态域使用延迟初始化，应使用这种方式而不是双检锁方式。这种方式只适用于静态域的情况，双检锁方式可在实例域需要延迟初始化时使用。这种方式同样利用了 classloder 机制来保证初始化 instance 时只有一个线程，它跟第 3 种方式不同的是：第 3 种方式只要 Singleton 类被装载了，那么 instance 就会被实例化（没有达到 lazy loading 效果），而这种方式是 Singleton 类被装载了，instance 不一定被初始化。因为 SingletonHolder 类没有被主动使用，只有显示通过调用 getInstance 方法时，才会显示装载 SingletonHolder 类，从而实例化 instance。想象一下，如果实例化 instance 很消耗资源，所以想让它延迟加载，另外一方面，又不希望在 Singleton 类加载时就实例化，因为不能确保 Singleton 类还可能在其他的地方被主动使用从而被加载，那么这个时候实例化 instance 显然是不合适的。这个时候，这种方式相比第 3 种方式就显得很合理。代码实例： 123456789public class Singleton &#123; private static class SingletonHolder &#123; private static final Singleton INSTANCE = new Singleton(); &#125; private Singleton ()&#123;&#125; public static final Singleton getInstance() &#123; return SingletonHolder.INSTANCE; &#125; &#125; 6、枚举JDK 版本：JDK1.5 起是否 Lazy 初始化：否是否多线程安全：是实现难度：易描述：这种实现方式还没有被广泛采用，但这是实现单例模式的最佳方法。它更简洁，自动支持序列化机制，绝对防止多次实例化。这种方式是 Effective Java 作者 Josh Bloch 提倡的方式，它不仅能避免多线程同步问题，而且还自动支持序列化机制，防止反序列化重新创建新的对象，绝对防止多次实例化。不过，由于 JDK1.5 之后才加入 enum 特性，用这种方式写不免让人感觉生疏，在实际工作中，也很少用。不能通过 reflection attack 来调用私有构造方法。代码实例： 12345public enum Singleton &#123; INSTANCE; public void whateverMethod() &#123; &#125; &#125; 经验之谈：一般情况下，不建议使用第 1 种和第 2 种懒汉方式，建议使用第 3 种饿汉方式。只有在要明确实现 lazy loading 效果时，才会使用第 5 种登记方式。如果涉及到反序列化创建对象时，可以尝试使用第 6 种枚举方式。如果有其他特殊的需求，可以考虑使用第 4 种双检锁方式。 建造者模式建造者模式（Builder Pattern）使用多个简单的对象一步一步构建成一个复杂的对象。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。一个 Builder 类会一步一步构造最终的对象。该 Builder 类是独立于其他对象的。意图：将一个复杂的构建与其表示相分离，使得同样的构建过程可以创建不同的表示。主要解决：主要解决在软件系统中，有时候面临着”一个复杂对象”的创建工作，其通常由各个部分的子对象用一定的算法构成；由于需求的变化，这个复杂对象的各个部分经常面临着剧烈的变化，但是将它们组合在一起的算法却相对稳定。何时使用：一些基本部件不会变，而其组合经常变化的时候。如何解决：将变与不变分离开。关键代码：建造者：创建和提供实例，导演：管理建造出来的实例的依赖关系。应用实例： 1、去肯德基，汉堡、可乐、薯条、炸鸡翅等是不变的，而其组合是经常变化的，生成出所谓的”套餐”。 2、JAVA 中的 StringBuilder。优点： 1、建造者独立，易扩展。 2、便于控制细节风险。缺点： 1、产品必须有共同点，范围有限制。 2、如内部变化复杂，会有很多的建造类。使用场景： 1、需要生成的对象具有复杂的内部结构。 2、需要生成的对象内部属性本身相互依赖。注意事项：与工厂模式的区别是：建造者模式更加关注与零件装配的顺序。实现我们假设一个快餐店的商业案例，其中，一个典型的套餐可以是一个汉堡（Burger）和一杯冷饮（Cold drink）。汉堡（Burger）可以是素食汉堡（Veg Burger）或鸡肉汉堡（Chicken Burger），它们是包在纸盒中。冷饮（Cold drink）可以是可口可乐（coke）或百事可乐（pepsi），它们是装在瓶子中。我们将创建一个表示食物条目（比如汉堡和冷饮）的 Item 接口和实现 Item 接口的实体类，以及一个表示食物包装的 Packing 接口和实现 Packing 接口的实体类，汉堡是包在纸盒中，冷饮是装在瓶子中。然后我们创建一个 Meal 类，带有 Item 的 ArrayList 和一个通过结合 Item 来创建不同类型的 Meal 对象的 MealBuilder。BuilderPatternDemo，我们的演示类使用 MealBuilder 来创建一个 Meal。 步骤 1 创建一个表示食物条目和食物包装的接口。 Item.java 12345public interface Item &#123; public String name(); public Packing packing(); public float price(); &#125; Packing.java 123public interface Packing &#123; public String pack();&#125; 步骤 2 创建实现 Packing 接口的实体类。 Wrapper.java 1234567public class Wrapper implements Packing &#123; @Override public String pack() &#123; return &quot;Wrapper&quot;; &#125;&#125; Bottle.java 1234567public class Bottle implements Packing &#123; @Override public String pack() &#123; return &quot;Bottle&quot;; &#125;&#125; 步骤 3 创建实现 Item 接口的抽象类，该类提供了默认的功能。 Burger.java 12345678910public abstract class Burger implements Item &#123; @Override public Packing packing() &#123; return new Wrapper(); &#125; @Override public abstract float price();&#125; ColdDrink.java 12345678910public abstract class ColdDrink implements Item &#123; @Override public Packing packing() &#123; return new Bottle(); &#125; @Override public abstract float price();&#125; 步骤 4 创建扩展了 Burger 和 ColdDrink 的实体类。 VegBurger.java 123456789101112public class VegBurger extends Burger &#123; @Override public float price() &#123; return 25.0f; &#125; @Override public String name() &#123; return &quot;Veg Burger&quot;; &#125;&#125; ChickenBurger.java 123456789101112public class ChickenBurger extends Burger &#123; @Override public float price() &#123; return 50.5f; &#125; @Override public String name() &#123; return &quot;Chicken Burger&quot;; &#125;&#125; Coke.java 123456789101112public class Coke extends ColdDrink &#123; @Override public float price() &#123; return 30.0f; &#125; @Override public String name() &#123; return &quot;Coke&quot;; &#125;&#125; Pepsi.java 123456789101112public class Pepsi extends ColdDrink &#123; @Override public float price() &#123; return 35.0f; &#125; @Override public String name() &#123; return &quot;Pepsi&quot;; &#125;&#125; 步骤 5 创建一个 Meal 类，带有上面定义的 Item 对象。 Meal.java 1234567891011121314151617181920212223242526import java.util.ArrayList;import java.util.List;public class Meal &#123; private List&lt;Item&gt; items = new ArrayList&lt;Item&gt;(); public void addItem(Item item)&#123; items.add(item); &#125; public float getCost()&#123; float cost = 0.0f; for (Item item : items) &#123; cost += item.price(); &#125; return cost; &#125; public void showItems()&#123; for (Item item : items) &#123; System.out.print(&quot;Item : &quot;+item.name()); System.out.print(&quot;, Packing : &quot;+item.packing().pack()); System.out.println(&quot;, Price : &quot;+item.price()); &#125; &#125; &#125; 步骤 6 创建一个 MealBuilder 类，实际的 builder 类负责创建 Meal 对象。 MealBuilder.java 12345678910111213141516public class MealBuilder &#123; public Meal prepareVegMeal ()&#123; Meal meal = new Meal(); meal.addItem(new VegBurger()); meal.addItem(new Coke()); return meal; &#125; public Meal prepareNonVegMeal ()&#123; Meal meal = new Meal(); meal.addItem(new ChickenBurger()); meal.addItem(new Pepsi()); return meal; &#125;&#125; 步骤 7 BuiderPatternDemo 使用 MealBuider 来演示建造者模式（Builder Pattern）。 BuilderPatternDemo.java 123456789101112131415public class BuilderPatternDemo &#123; public static void main(String[] args) &#123; MealBuilder mealBuilder = new MealBuilder(); Meal vegMeal = mealBuilder.prepareVegMeal(); System.out.println(&quot;Veg Meal&quot;); vegMeal.showItems(); System.out.println(&quot;Total Cost: &quot; +vegMeal.getCost()); Meal nonVegMeal = mealBuilder.prepareNonVegMeal(); System.out.println(&quot;\n\nNon-Veg Meal&quot;); nonVegMeal.showItems(); System.out.println(&quot;Total Cost: &quot; +nonVegMeal.getCost()); &#125;&#125; 步骤 8 验证输出。 123456789Veg MealItem : Veg Burger, Packing : Wrapper, Price : 25.0Item : Coke, Packing : Bottle, Price : 30.0Total Cost: 55.0Non-Veg MealItem : Chicken Burger, Packing : Wrapper, Price : 50.5Item : Pepsi, Packing : Bottle, Price : 35.0Total Cost: 85.5 原型模式原型模式（Prototype Pattern）是用于创建重复的对象，同时又能保证性能。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。这种模式是实现了一个原型接口，该接口用于创建当前对象的克隆。当直接创建对象的代价比较大时，则采用这种模式。例如，一个对象需要在一个高代价的数据库操作之后被创建。我们可以缓存该对象，在下一个请求时返回它的克隆，在需要的时候更新数据库，以此来减少数据库调用。意图：用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。主要解决：在运行期建立和删除原型。何时使用： 1、当一个系统应该独立于它的产品创建，构成和表示时。 2、当要实例化的类是在运行时刻指定时，例如，通过动态装载。 3、为了避免创建一个与产品类层次平行的工厂类层次时。 4、当一个类的实例只能有几个不同状态组合中的一种时。建立相应数目的原型并克隆它们可能比每次用合适的状态手工实例化该类更方便一些。如何解决：利用已有的一个原型对象，快速地生成和原型对象一样的实例。关键代码： 1、实现克隆操作，在 JAVA 继承 Cloneable，重写 clone()，在 .NET 中可以使用 Object 类的 MemberwiseClone() 方法来实现对象的浅拷贝或通过序列化的方式来实现深拷贝。 2、原型模式同样用于隔离类对象的使用者和具体类型（易变类）之间的耦合关系，它同样要求这些”易变类”拥有稳定的接口。应用实例： 1、细胞分裂。 2、JAVA 中的 Object clone() 方法。优点： 1、性能提高。 2、逃避构造函数的约束。缺点： 1、配备克隆方法需要对类的功能进行通盘考虑，这对于全新的类不是很难，但对于已有的类不一定很容易，特别当一个类引用不支持串行化的间接对象，或者引用含有循环结构的时候。 2、必须实现 Cloneable 接口。 3、逃避构造函数的约束。使用场景： 1、资源优化场景。 2、类初始化需要消化非常多的资源，这个资源包括数据、硬件资源等。 3、性能和安全要求的场景。 4、通过 new 产生一个对象需要非常繁琐的数据准备或访问权限，则可以使用原型模式。 5、一个对象多个修改者的场景。 6、一个对象需要提供给其他对象访问，而且各个调用者可能都需要修改其值时，可以考虑使用原型模式拷贝多个对象供调用者使用。 7、在实际项目中，原型模式很少单独出现，一般是和工厂方法模式一起出现，通过 clone 的方法创建一个对象，然后由工厂方法提供给调用者。原型模式已经与 Java 融为浑然一体，大家可以随手拿来使用。注意事项：与通过对一个类进行实例化来构造新对象不同的是，原型模式是通过拷贝一个现有对象生成新对象的。浅拷贝实现 Cloneable，重写，深拷贝是通过实现 Serializable 读取二进制流。实现 我们将创建一个抽象类 Shape 和扩展了 Shape 类的实体类。下一步是定义类 ShapeCache，该类把 shape 对象存储在一个 Hashtable 中，并在请求的时候返回它们的克隆。PrototypPatternDemo，我们的演示类使用 ShapeCache 类来获取 Shape 对象 步骤 1 创建一个实现了 Clonable 接口的抽象类。 Shape.java 1234567891011121314151617181920212223242526272829public abstract class Shape implements Cloneable &#123; private String id; protected String type; abstract void draw(); public String getType()&#123; return type; &#125; public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125; public Object clone() &#123; Object clone = null; try &#123; clone = super.clone(); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; return clone; &#125;&#125; 步骤 2 创建扩展了上面抽象类的实体类。 Rectangle.java 1234567891011public class Rectangle extends Shape &#123; public Rectangle()&#123; type = &quot;Rectangle&quot;; &#125; @Override public void draw() &#123; System.out.println(&quot;Inside Rectangle::draw() method.&quot;); &#125;&#125; Square.java 1234567891011public class Square extends Shape &#123; public Square()&#123; type = &quot;Square&quot;; &#125; @Override public void draw() &#123; System.out.println(&quot;Inside Square::draw() method.&quot;); &#125;&#125; Circle.java 1234567891011public class Circle extends Shape &#123; public Circle()&#123; type = &quot;Circle&quot;; &#125; @Override public void draw() &#123; System.out.println(&quot;Inside Circle::draw() method.&quot;); &#125;&#125; 步骤 3 创建一个类，从数据库获取实体类，并把它们存储在一个 Hashtable 中。 ShapeCache.java 1234567891011121314151617181920212223242526272829import java.util.Hashtable;public class ShapeCache &#123; private static Hashtable&lt;String, Shape&gt; shapeMap = new Hashtable&lt;String, Shape&gt;(); public static Shape getShape(String shapeId) &#123; Shape cachedShape = shapeMap.get(shapeId); return (Shape) cachedShape.clone(); &#125; // 对每种形状都运行数据库查询，并创建该形状 // shapeMap.put(shapeKey, shape); // 例如，我们要添加三种形状 public static void loadCache() &#123; Circle circle = new Circle(); circle.setId(&quot;1&quot;); shapeMap.put(circle.getId(),circle); Square square = new Square(); square.setId(&quot;2&quot;); shapeMap.put(square.getId(),square); Rectangle rectangle = new Rectangle(); rectangle.setId(&quot;3&quot;); shapeMap.put(rectangle.getId(),rectangle); &#125;&#125; 步骤 4 PrototypePatternDemo 使用 ShapeCache 类来获取存储在 Hashtable 中的形状的克隆。 PrototypePatternDemo.java 1234567891011121314public class PrototypePatternDemo &#123; public static void main(String[] args) &#123; ShapeCache.loadCache(); Shape clonedShape = (Shape) ShapeCache.getShape(&quot;1&quot;); System.out.println(&quot;Shape : &quot; + clonedShape.getType()); Shape clonedShape2 = (Shape) ShapeCache.getShape(&quot;2&quot;); System.out.println(&quot;Shape : &quot; + clonedShape2.getType()); Shape clonedShape3 = (Shape) ShapeCache.getShape(&quot;3&quot;); System.out.println(&quot;Shape : &quot; + clonedShape3.getType()); &#125;&#125; 步骤 5 验证输出。 123Shape : CircleShape : SquareShape : Rectangle 适配器模式适配器模式（Adapter Pattern）是作为两个不兼容的接口之间的桥梁。这种类型的设计模式属于结构型模式，它结合了两个独立接口的功能。这种模式涉及到一个单一的类，该类负责加入独立的或不兼容的接口功能。举个真实的例子，读卡器是作为内存卡和笔记本之间的适配器。您将内存卡插入读卡器，再将读卡器插入笔记本，这样就可以通过笔记本来读取内存卡。我们通过下面的实例来演示适配器模式的使用。其中，音频播放器设备只能播放 mp3 文件，通过使用一个更高级的音频播放器来播放 vlc 和 mp4 文件。意图：将一个类的接口转换成客户希望的另外一个接口。适配器模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。主要解决：主要解决在软件系统中，常常要将一些”现存的对象”放到新的环境中，而新环境要求的接口是现对象不能满足的。何时使用： 1、系统需要使用现有的类，而此类的接口不符合系统的需要。 2、想要建立一个可以重复使用的类，用于与一些彼此之间没有太大关联的一些类，包括一些可能在将来引进的类一起工作，这些源类不一定有一致的接口。 3、通过接口转换，将一个类插入另一个类系中。（比如老虎和飞禽，现在多了一个飞虎，在不增加实体的需求下，增加一个适配器，在里面包容一个虎对象，实现飞的接口。）如何解决：继承或依赖（推荐）。关键代码：适配器继承或依赖已有的对象，实现想要的目标接口。应用实例： 1、美国电器 110V，中国 220V，就要有一个适配器将 110V 转化为 220V。 2、JAVA JDK 1.1 提供了 Enumeration 接口，而在 1.2 中提供了 Iterator 接口，想要使用 1.2 的 JDK，则要将以前系统的 Enumeration 接口转化为 Iterator 接口，这时就需要适配器模式。 3、在 LINUX 上运行 WINDOWS 程序。 4、JAVA 中的 jdbc。优点： 1、可以让任何两个没有关联的类一起运行。 2、提高了类的复用。 3、增加了类的透明度。 4、灵活性好。缺点： 1、过多地使用适配器，会让系统非常零乱，不易整体进行把握。比如，明明看到调用的是 A 接口，其实内部被适配成了 B 接口的实现，一个系统如果太多出现这种情况，无异于一场灾难。因此如果不是很有必要，可以不使用适配器，而是直接对系统进行重构。 2.由于 JAVA 至多继承一个类，所以至多只能适配一个适配者类，而且目标类必须是抽象类。使用场景：有动机地修改一个正常运行的系统的接口，这时应该考虑使用适配器模式。注意事项：适配器不是在详细设计时添加的，而是解决正在服役的项目的问题。实现我们有一个 MediaPlayer 接口和一个实现了 MediaPlayer 接口的实体类 AudioPlayer。默认情况下，AudioPlayer 可以播放 mp3 格式的音频文件。我们还有另一个接口 AdvancedMediaPlayer 和实现了 AdvancedMediaPlayer 接口的实体类。该类可以播放 vlc 和 mp4 格式的文件。我们想要让 AudioPlayer 播放其他格式的音频文件。为了实现这个功能，我们需要创建一个实现了 MediaPlayer 接口的适配器类 MediaAdapter，并使用 AdvancedMediaPlayer 对象来播放所需的格式。AudioPlayer 使用适配器类 MediaAdapter 传递所需的音频类型，不需要知道能播放所需格式音频的实际类。AdapterPatternDemo，我们的演示类使用 AudioPlayer 类来播放各种格式。 步骤 1 为媒体播放器和更高级的媒体播放器创建接口。 MediaPlayer.java 12345678public interface MediaPlayer &#123; public void play(String audioType, String fileName);&#125;AdvancedMediaPlayer.javapublic interface AdvancedMediaPlayer &#123; public void playVlc(String fileName); public void playMp4(String fileName);&#125; 步骤 2 创建实现了 AdvancedMediaPlayer 接口的实体类。 VlcPlayer.java 1234567891011public class VlcPlayer implements AdvancedMediaPlayer&#123; @Override public void playVlc(String fileName) &#123; System.out.println(&quot;Playing vlc file. Name: &quot;+ fileName); &#125; @Override public void playMp4(String fileName) &#123; //什么也不做 &#125;&#125; Mp4Player.java 123456789101112public class Mp4Player implements AdvancedMediaPlayer&#123; @Override public void playVlc(String fileName) &#123; //什么也不做 &#125; @Override public void playMp4(String fileName) &#123; System.out.println(&quot;Playing mp4 file. Name: &quot;+ fileName); &#125;&#125; 步骤 3 创建实现了 MediaPlayer 接口的适配器类。 MediaAdapter.java 123456789101112131415161718192021public class MediaAdapter implements MediaPlayer &#123; AdvancedMediaPlayer advancedMusicPlayer; public MediaAdapter(String audioType)&#123; if(audioType.equalsIgnoreCase(&quot;vlc&quot;) )&#123; advancedMusicPlayer = new VlcPlayer(); &#125; else if (audioType.equalsIgnoreCase(&quot;mp4&quot;))&#123; advancedMusicPlayer = new Mp4Player(); &#125; &#125; @Override public void play(String audioType, String fileName) &#123; if(audioType.equalsIgnoreCase(&quot;vlc&quot;))&#123; advancedMusicPlayer.playVlc(fileName); &#125;else if(audioType.equalsIgnoreCase(&quot;mp4&quot;))&#123; advancedMusicPlayer.playMp4(fileName); &#125; &#125;&#125; 步骤 4 创建实现了 MediaPlayer 接口的实体类。 AudioPlayer.java 12345678910111213141516171819202122public class AudioPlayer implements MediaPlayer &#123; MediaAdapter mediaAdapter; @Override public void play(String audioType, String fileName) &#123; //播放 mp3 音乐文件的内置支持 if(audioType.equalsIgnoreCase(&quot;mp3&quot;))&#123; System.out.println(&quot;Playing mp3 file. Name: &quot;+ fileName); &#125; //mediaAdapter 提供了播放其他文件格式的支持 else if(audioType.equalsIgnoreCase(&quot;vlc&quot;) || audioType.equalsIgnoreCase(&quot;mp4&quot;))&#123; mediaAdapter = new MediaAdapter(audioType); mediaAdapter.play(audioType, fileName); &#125; else&#123; System.out.println(&quot;Invalid media. &quot;+ audioType + &quot; format not supported&quot;); &#125; &#125; &#125; 步骤 5 使用 AudioPlayer 来播放不同类型的音频格式。 AdapterPatternDemo.java 12345678910public class AdapterPatternDemo &#123; public static void main(String[] args) &#123; AudioPlayer audioPlayer = new AudioPlayer(); audioPlayer.play(&quot;mp3&quot;, &quot;beyond the horizon.mp3&quot;); audioPlayer.play(&quot;mp4&quot;, &quot;alone.mp4&quot;); audioPlayer.play(&quot;vlc&quot;, &quot;far far away.vlc&quot;); audioPlayer.play(&quot;avi&quot;, &quot;mind me.avi&quot;); &#125;&#125; 步骤 6 验证输出。 1234Playing mp3 file. Name: beyond the horizon.mp3Playing mp4 file. Name: alone.mp4Playing vlc file. Name: far far away.vlcInvalid media. avi format not supported 桥接模式桥接（Bridge）是用于把抽象化与实现化解耦，使得二者可以独立变化。这种类型的设计模式属于结构型模式，它通过提供抽象化和实现化之间的桥接结构，来实现二者的解耦。这种模式涉及到一个作为桥接的接口，使得实体类的功能独立于接口实现类。这两种类型的类可被结构化改变而互不影响。我们通过下面的实例来演示桥接模式（Bridge Pattern）的用法。其中，可以使用相同的抽象类方法但是不同的桥接实现类，来画出不同颜色的圆。意图：将抽象部分与实现部分分离，使它们都可以独立的变化。主要解决：在有多种可能会变化的情况下，用继承会造成类爆炸问题，扩展起来不灵活。何时使用：实现系统可能有多个角度分类，每一种角度都可能变化。如何解决：把这种多角度分类分离出来，让它们独立变化，减少它们之间耦合。关键代码：抽象类依赖实现类。应用实例： 1、猪八戒从天蓬元帅转世投胎到猪，转世投胎的机制将尘世划分为两个等级，即：灵魂和肉体，前者相当于抽象化，后者相当于实现化。生灵通过功能的委派，调用肉体对象的功能，使得生灵可以动态地选择。 2、墙上的开关，可以看到的开关是抽象的，不用管里面具体怎么实现的。优点： 1、抽象和实现的分离。 2、优秀的扩展能力。 3、实现细节对客户透明。缺点：桥接模式的引入会增加系统的理解与设计难度，由于聚合关联关系建立在抽象层，要求开发者针对抽象进行设计与编程。使用场景： 1、如果一个系统需要在构件的抽象化角色和具体化角色之间增加更多的灵活性，避免在两个层次之间建立静态的继承联系，通过桥接模式可以使它们在抽象层建立一个关联关系。 2、对于那些不希望使用继承或因为多层次继承导致系统类的个数急剧增加的系统，桥接模式尤为适用。 3、一个类存在两个独立变化的维度，且这两个维度都需要进行扩展。注意事项：对于两个独立变化的维度，使用桥接模式再适合不过了。实现 我们有一个作为桥接实现的 DrawAPI 接口和实现了 DrawAPI 接口的实体类 RedCircle、GreenCircle。Shape 是一个抽象类，将使用 DrawAPI 的对象。BridgePatternDemo，我们的演示类使用 Shape 类来画出不同颜色的圆。 步骤 1 创建桥接实现接口。 DrawAPI.java 123public interface DrawAPI &#123; public void drawCircle(int radius, int x, int y);&#125; 步骤 2 创建实现了 DrawAPI 接口的实体桥接实现类。 RedCircle.java 1234567public class RedCircle implements DrawAPI &#123; @Override public void drawCircle(int radius, int x, int y) &#123; System.out.println(&quot;Drawing Circle[ color: red, radius: &quot; + radius +&quot;, x: &quot; +x+&quot;, &quot;+ y +&quot;]&quot;); &#125;&#125; GreenCircle.java 1234567public class GreenCircle implements DrawAPI &#123; @Override public void drawCircle(int radius, int x, int y) &#123; System.out.println(&quot;Drawing Circle[ color: green, radius: &quot; + radius +&quot;, x: &quot; +x+&quot;, &quot;+ y +&quot;]&quot;); &#125;&#125; 步骤 3 使用 DrawAPI 接口创建抽象类 Shape。 Shape.java 1234567public abstract class Shape &#123; protected DrawAPI drawAPI; protected Shape(DrawAPI drawAPI)&#123; this.drawAPI = drawAPI; &#125; public abstract void draw(); &#125; 步骤 4 创建实现了 Shape 接口的实体类。 Circle.java 1234567891011121314public class Circle extends Shape &#123; private int x, y, radius; public Circle(int x, int y, int radius, DrawAPI drawAPI) &#123; super(drawAPI); this.x = x; this.y = y; this.radius = radius; &#125; public void draw() &#123; drawAPI.drawCircle(radius,x,y); &#125;&#125; 步骤 5 使用 Shape 和 DrawAPI 类画出不同颜色的圆。 BridgePatternDemo.java 123456789public class BridgePatternDemo &#123; public static void main(String[] args) &#123; Shape redCircle = new Circle(100,100, 10, new RedCircle()); Shape greenCircle = new Circle(100,100, 10, new GreenCircle()); redCircle.draw(); greenCircle.draw(); &#125;&#125; 步骤 6 验证输出。 12Drawing Circle[ color: red, radius: 10, x: 100, 100]Drawing Circle[ color: green, radius: 10, x: 100, 100] 过滤器模式过滤器模式（Filter Pattern）或标准模式（Criteria Pattern）是一种设计模式，这种模式允许开发人员使用不同的标准来过滤一组对象，通过逻辑运算以解耦的方式把它们连接起来。这种类型的设计模式属于结构型模式，它结合多个标准来获得单一标准。实现我们将创建一个 Person 对象、Criteria 接口和实现了该接口的实体类，来过滤 Person 对象的列表。CriteriaPatternDemo，我们的演示类使用 Criteria 对象，基于各种标准和它们的结合来过滤 Person 对象的列表。 步骤 1 创建一个类，在该类上应用标准。 Person.java 12345678910111213141516171819202122public class Person &#123; private String name; private String gender; private String maritalStatus; public Person(String name,String gender,String maritalStatus)&#123; this.name = name; this.gender = gender; this.maritalStatus = maritalStatus; &#125; public String getName() &#123; return name; &#125; public String getGender() &#123; return gender; &#125; public String getMaritalStatus() &#123; return maritalStatus; &#125; &#125; 步骤 2 为标准（Criteria）创建一个接口。 Criteria.java 12345import java.util.List;public interface Criteria &#123; public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons);&#125; 步骤 3 创建实现了 Criteria 接口的实体类。 CriteriaMale.java 12345678910111213141516import java.util.ArrayList;import java.util.List;public class CriteriaMale implements Criteria &#123; @Override public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons) &#123; List&lt;Person&gt; malePersons = new ArrayList&lt;Person&gt;(); for (Person person : persons) &#123; if(person.getGender().equalsIgnoreCase(&quot;MALE&quot;))&#123; malePersons.add(person); &#125; &#125; return malePersons; &#125;&#125; CriteriaFemale.java 12345678910111213141516import java.util.ArrayList;import java.util.List;public class CriteriaFemale implements Criteria &#123; @Override public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons) &#123; List&lt;Person&gt; femalePersons = new ArrayList&lt;Person&gt;(); for (Person person : persons) &#123; if(person.getGender().equalsIgnoreCase(&quot;FEMALE&quot;))&#123; femalePersons.add(person); &#125; &#125; return femalePersons; &#125;&#125; CriteriaSingle.java 12345678910111213141516import java.util.ArrayList;import java.util.List;public class CriteriaSingle implements Criteria &#123; @Override public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons) &#123; List&lt;Person&gt; singlePersons = new ArrayList&lt;Person&gt;(); for (Person person : persons) &#123; if(person.getMaritalStatus().equalsIgnoreCase(&quot;SINGLE&quot;))&#123; singlePersons.add(person); &#125; &#125; return singlePersons; &#125;&#125; AndCriteria.java 123456789101112131415161718import java.util.List;public class AndCriteria implements Criteria &#123; private Criteria criteria; private Criteria otherCriteria; public AndCriteria(Criteria criteria, Criteria otherCriteria) &#123; this.criteria = criteria; this.otherCriteria = otherCriteria; &#125; @Override public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons) &#123; List&lt;Person&gt; firstCriteriaPersons = criteria.meetCriteria(persons); return otherCriteria.meetCriteria(firstCriteriaPersons); &#125;&#125; OrCriteria.java 12345678910111213141516171819202122232425import java.util.List;public class OrCriteria implements Criteria &#123; private Criteria criteria; private Criteria otherCriteria; public OrCriteria(Criteria criteria, Criteria otherCriteria) &#123; this.criteria = criteria; this.otherCriteria = otherCriteria; &#125; @Override public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons) &#123; List&lt;Person&gt; firstCriteriaItems = criteria.meetCriteria(persons); List&lt;Person&gt; otherCriteriaItems = otherCriteria.meetCriteria(persons); for (Person person : otherCriteriaItems) &#123; if(!firstCriteriaItems.contains(person))&#123; firstCriteriaItems.add(person); &#125; &#125; return firstCriteriaItems; &#125;&#125; 步骤4 使用不同的标准（Criteria）和它们的结合来过滤 Person 对象的列表。 CriteriaPatternDemo.java 123456789101112131415161718192021222324252627282930313233343536373839404142import java.util.ArrayList; import java.util.List;public class CriteriaPatternDemo &#123; public static void main(String[] args) &#123; List&lt;Person&gt; persons = new ArrayList&lt;Person&gt;(); persons.add(new Person(&quot;Robert&quot;,&quot;Male&quot;, &quot;Single&quot;)); persons.add(new Person(&quot;John&quot;,&quot;Male&quot;, &quot;Married&quot;)); persons.add(new Person(&quot;Laura&quot;,&quot;Female&quot;, &quot;Married&quot;)); persons.add(new Person(&quot;Diana&quot;,&quot;Female&quot;, &quot;Single&quot;)); persons.add(new Person(&quot;Mike&quot;,&quot;Male&quot;, &quot;Single&quot;)); persons.add(new Person(&quot;Bobby&quot;,&quot;Male&quot;, &quot;Single&quot;)); Criteria male = new CriteriaMale(); Criteria female = new CriteriaFemale(); Criteria single = new CriteriaSingle(); Criteria singleMale = new AndCriteria(single, male); Criteria singleOrFemale = new OrCriteria(single, female); System.out.println(&quot;Males: &quot;); printPersons(male.meetCriteria(persons)); System.out.println(&quot;\nFemales: &quot;); printPersons(female.meetCriteria(persons)); System.out.println(&quot;\nSingle Males: &quot;); printPersons(singleMale.meetCriteria(persons)); System.out.println(&quot;\nSingle Or Females: &quot;); printPersons(singleOrFemale.meetCriteria(persons)); &#125; public static void printPersons(List&lt;Person&gt; persons)&#123; for (Person person : persons) &#123; System.out.println(&quot;Person : [ Name : &quot; + person.getName() +&quot;, Gender : &quot; + person.getGender() +&quot;, Marital Status : &quot; + person.getMaritalStatus() +&quot; ]&quot;); &#125; &#125; &#125; 步骤 5 验证输出。 123456789101112131415161718192021Males: Person : [ Name : Robert, Gender : Male, Marital Status : Single ]Person : [ Name : John, Gender : Male, Marital Status : Married ]Person : [ Name : Mike, Gender : Male, Marital Status : Single ]Person : [ Name : Bobby, Gender : Male, Marital Status : Single ]Females: Person : [ Name : Laura, Gender : Female, Marital Status : Married ]Person : [ Name : Diana, Gender : Female, Marital Status : Single ]Single Males: Person : [ Name : Robert, Gender : Male, Marital Status : Single ]Person : [ Name : Mike, Gender : Male, Marital Status : Single ]Person : [ Name : Bobby, Gender : Male, Marital Status : Single ]Single Or Females: Person : [ Name : Robert, Gender : Male, Marital Status : Single ]Person : [ Name : Diana, Gender : Female, Marital Status : Single ]Person : [ Name : Mike, Gender : Male, Marital Status : Single ]Person : [ Name : Bobby, Gender : Male, Marital Status : Single ]Person : [ Name : Laura, Gender : Female, Marital Status : Married ] 组合模式组合模式（Composite Pattern），又叫部分整体模式，是用于把一组相似的对象当作一个单一的对象。组合模式依据树形结构来组合对象，用来表示部分以及整体层次。这种类型的设计模式属于结构型模式，它创建了对象组的树形结构。这种模式创建了一个包含自己对象组的类。该类提供了修改相同对象组的方式。我们通过下面的实例来演示组合模式的用法。实例演示了一个组织中员工的层次结构。意图：将对象组合成树形结构以表示”部分-整体”的层次结构。组合模式使得用户对单个对象和组合对象的使用具有一致性。主要解决：它在我们树型结构的问题中，模糊了简单元素和复杂元素的概念，客户程序可以向处理简单元素一样来处理复杂元素，从而使得客户程序与复杂元素的内部结构解耦。何时使用： 1、您想表示对象的部分-整体层次结构（树形结构）。 2、您希望用户忽略组合对象与单个对象的不同，用户将统一地使用组合结构中的所有对象。如何解决：树枝和叶子实现统一接口，树枝内部组合该接口。关键代码：树枝内部组合该接口，并且含有内部属性 List，里面放 Component。应用实例： 1、算术表达式包括操作数、操作符和另一个操作数，其中，另一个操作符也可以是操作树、操作符和另一个操作数。 2、在 JAVA AWT 和 SWING 中，对于 Button 和 Checkbox 是树叶，Container 是树枝。优点： 1、高层模块调用简单。 2、节点自由增加。缺点：在使用组合模式时，其叶子和树枝的声明都是实现类，而不是接口，违反了依赖倒置原则。使用场景：部分、整体场景，如树形菜单，文件、文件夹的管理。注意事项：定义时为具体类。实现我们有一个类 Employee，该类被当作组合模型类。CompositePatternDemo，我们的演示类使用 Employee 类来添加部门层次结构，并打印所有员工。 步骤 1 创建 Employee 类，该类带有 Employee 对象的列表。 Employee.java 1234567891011121314151617181920212223242526272829303132333435import java.util.ArrayList;import java.util.List;public class Employee &#123; private String name; private String dept; private int salary; private List&lt;Employee&gt; subordinates; //构造函数 public Employee(String name,String dept, int sal) &#123; this.name = name; this.dept = dept; this.salary = sal; subordinates = new ArrayList&lt;Employee&gt;(); &#125; public void add(Employee e) &#123; subordinates.add(e); &#125; public void remove(Employee e) &#123; subordinates.remove(e); &#125; public List&lt;Employee&gt; getSubordinates()&#123; return subordinates; &#125; public String toString()&#123; return (&quot;Employee :[ Name : &quot;+ name +&quot;, dept : &quot;+ dept + &quot;, salary :&quot; + salary+&quot; ]&quot;); &#125; &#125; 步骤 2 使用 Employee 类来创建和打印员工的层次结构。 CompositePatternDemo.java 123456789101112131415161718192021222324252627282930313233public class CompositePatternDemo &#123; public static void main(String[] args) &#123; Employee CEO = new Employee(&quot;John&quot;,&quot;CEO&quot;, 30000); Employee headSales = new Employee(&quot;Robert&quot;,&quot;Head Sales&quot;, 20000); Employee headMarketing = new Employee(&quot;Michel&quot;,&quot;Head Marketing&quot;, 20000); Employee clerk1 = new Employee(&quot;Laura&quot;,&quot;Marketing&quot;, 10000); Employee clerk2 = new Employee(&quot;Bob&quot;,&quot;Marketing&quot;, 10000); Employee salesExecutive1 = new Employee(&quot;Richard&quot;,&quot;Sales&quot;, 10000); Employee salesExecutive2 = new Employee(&quot;Rob&quot;,&quot;Sales&quot;, 10000); CEO.add(headSales); CEO.add(headMarketing); headSales.add(salesExecutive1); headSales.add(salesExecutive2); headMarketing.add(clerk1); headMarketing.add(clerk2); //打印该组织的所有员工 System.out.println(CEO); for (Employee headEmployee : CEO.getSubordinates()) &#123; System.out.println(headEmployee); for (Employee employee : headEmployee.getSubordinates()) &#123; System.out.println(employee); &#125; &#125; &#125;&#125; 步骤 3 验证输出。 1234567Employee :[ Name : John, dept : CEO, salary :30000 ]Employee :[ Name : Robert, dept : Head Sales, salary :20000 ]Employee :[ Name : Richard, dept : Sales, salary :10000 ]Employee :[ Name : Rob, dept : Sales, salary :10000 ]Employee :[ Name : Michel, dept : Head Marketing, salary :20000 ]Employee :[ Name : Laura, dept : Marketing, salary :10000 ]Employee :[ Name : Bob, dept : Marketing, salary :10000 ] 装饰器模式装饰器模式（Decorator Pattern）允许向一个现有的对象添加新的功能，同时又不改变其结构。这种类型的设计模式属于结构型模式，它是作为现有的类的一个包装。这种模式创建了一个装饰类，用来包装原有的类，并在保持类方法签名完整性的前提下，提供了额外的功能。我们通过下面的实例来演示装饰器模式的用法。其中，我们将把一个形状装饰上不同的颜色，同时又不改变形状类。意图：动态地给一个对象添加一些额外的职责。就增加功能来说，装饰器模式相比生成子类更为灵活。主要解决：一般的，我们为了扩展一个类经常使用继承方式实现，由于继承为类引入静态特征，并且随着扩展功能的增多，子类会很膨胀。何时使用：在不想增加很多子类的情况下扩展类。如何解决：将具体功能职责划分，同时继承装饰者模式。关键代码： 1、Component 类充当抽象角色，不应该具体实现。 2、修饰类引用和继承 Component 类，具体扩展类重写父类方法。应用实例： 1、孙悟空有 72 变，当他变成”庙宇”后，他的根本还是一只猴子，但是他又有了庙宇的功能。 2、不论一幅画有没有画框都可以挂在墙上，但是通常都是有画框的，并且实际上是画框被挂在墙上。在挂在墙上之前，画可以被蒙上玻璃，装到框子里；这时画、玻璃和画框形成了一个物体。优点：装饰类和被装饰类可以独立发展，不会相互耦合，装饰模式是继承的一个替代模式，装饰模式可以动态扩展一个实现类的功能。缺点：多层装饰比较复杂。使用场景： 1、扩展一个类的功能。 2、动态增加功能，动态撤销。注意事项：可代替继承。实现我们将创建一个 Shape 接口和实现了 Shape 接口的实体类。然后我们创建一个实现了 Shape 接口的抽象装饰类 ShapeDecorator，并把 Shape 对象作为它的实例变量。RedShapeDecorator 是实现了 ShapeDecorator 的实体类。DecoratorPatternDemo，我们的演示类使用 RedShapeDecorator 来装饰 Shape 对象 步骤 1 创建一个接口。 Shape.java 123public interface Shape &#123; void draw();&#125; 步骤 2 创建实现接口的实体类。 Rectangle.java 1234567public class Rectangle implements Shape &#123; @Override public void draw() &#123; System.out.println(&quot;Shape: Rectangle&quot;); &#125;&#125; Circle.java 1234567public class Circle implements Shape &#123; @Override public void draw() &#123; System.out.println(&quot;Shape: Circle&quot;); &#125;&#125; 步骤 3 创建实现了 Shape 接口的抽象装饰类。 ShapeDecorator.java 1234567891011public abstract class ShapeDecorator implements Shape &#123; protected Shape decoratedShape; public ShapeDecorator(Shape decoratedShape)&#123; this.decoratedShape = decoratedShape; &#125; public void draw()&#123; decoratedShape.draw(); &#125; &#125; 步骤 4 创建扩展了 ShapeDecorator 类的实体装饰类。 RedShapeDecorator.java 12345678910111213141516public class RedShapeDecorator extends ShapeDecorator &#123; public RedShapeDecorator(Shape decoratedShape) &#123; super(decoratedShape); &#125; @Override public void draw() &#123; decoratedShape.draw(); setRedBorder(decoratedShape); &#125; private void setRedBorder(Shape decoratedShape)&#123; System.out.println(&quot;Border Color: Red&quot;); &#125;&#125; 步骤 5 使用 RedShapeDecorator 来装饰 Shape 对象。 DecoratorPatternDemo.java 123456789101112131415161718public class DecoratorPatternDemo &#123; public static void main(String[] args) &#123; Shape circle = new Circle(); Shape redCircle = new RedShapeDecorator(new Circle()); Shape redRectangle = new RedShapeDecorator(new Rectangle()); System.out.println(&quot;Circle with normal border&quot;); circle.draw(); System.out.println(&quot;\nCircle of red border&quot;); redCircle.draw(); System.out.println(&quot;\nRectangle of red border&quot;); redRectangle.draw(); &#125;&#125; 步骤 6 验证输出。 12345678910Circle with normal borderShape: CircleCircle of red borderShape: CircleBorder Color: RedRectangle of red borderShape: RectangleBorder Color: Red 外观模式外观模式（Facade Pattern）隐藏系统的复杂性，并向客户端提供了一个客户端可以访问系统的接口。这种类型的设计模式属于结构型模式，它向现有的系统添加一个接口，来隐藏系统的复杂性。这种模式涉及到一个单一的类，该类提供了客户端请求的简化方法和对现有系统类方法的委托调用。意图：为子系统中的一组接口提供一个一致的界面，外观模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。主要解决：降低访问复杂系统的内部子系统时的复杂度，简化客户端与之的接口。何时使用： 1、客户端不需要知道系统内部的复杂联系，整个系统只需提供一个”接待员”即可。 2、定义系统的入口。如何解决：客户端不与系统耦合，外观类与系统耦合。关键代码：在客户端和复杂系统之间再加一层，这一层将调用顺序、依赖关系等处理好。应用实例： 1、去医院看病，可能要去挂号、门诊、划价、取药，让患者或患者家属觉得很复杂，如果有提供接待人员，只让接待人员来处理，就很方便。 2、JAVA 的三层开发模式。优点： 1、减少系统相互依赖。 2、提高灵活性。 3、提高了安全性。缺点：不符合开闭原则，如果要改东西很麻烦，继承重写都不合适。使用场景： 1、为复杂的模块或子系统提供外界访问的模块。 2、子系统相对独立。 3、预防低水平人员带来的风险。注意事项：在层次化结构中，可以使用外观模式定义系统中每一层的入口。实现我们将创建一个 Shape 接口和实现了 Shape 接口的实体类。下一步是定义一个外观类 ShapeMaker。ShapeMaker 类使用实体类来代表用户对这些类的调用。FacadePatternDemo，我们的演示类使用 ShapeMaker 类来显示结果。 步骤 1 创建一个接口。 Shape.java 123public interface Shape &#123; void draw();&#125; 步骤 2 创建实现接口的实体类。 Rectangle.java 1234567public class Rectangle implements Shape &#123; @Override public void draw() &#123; System.out.println(&quot;Rectangle::draw()&quot;); &#125;&#125; Square.java 1234567public class Square implements Shape &#123; @Override public void draw() &#123; System.out.println(&quot;Square::draw()&quot;); &#125;&#125; Circle.java 1234567public class Circle implements Shape &#123; @Override public void draw() &#123; System.out.println(&quot;Circle::draw()&quot;); &#125;&#125; 步骤 3 创建一个外观类。 ShapeMaker.java 123456789101112131415161718192021public class ShapeMaker &#123; private Shape circle; private Shape rectangle; private Shape square; public ShapeMaker() &#123; circle = new Circle(); rectangle = new Rectangle(); square = new Square(); &#125; public void drawCircle()&#123; circle.draw(); &#125; public void drawRectangle()&#123; rectangle.draw(); &#125; public void drawSquare()&#123; square.draw(); &#125;&#125; 步骤 4 使用该外观类画出各种类型的形状。 FacadePatternDemo.java 123456789public class FacadePatternDemo &#123; public static void main(String[] args) &#123; ShapeMaker shapeMaker = new ShapeMaker(); shapeMaker.drawCircle(); shapeMaker.drawRectangle(); shapeMaker.drawSquare(); &#125;&#125; 步骤 5 验证输出。 123Circle::draw()Rectangle::draw()Square::draw() 享元模式享元模式（Flyweight Pattern）主要用于减少创建对象的数量，以减少内存占用和提高性能。这种类型的设计模式属于结构型模式，它提供了减少对象数量从而改善应用所需的对象结构的方式。享元模式尝试重用现有的同类对象，如果未找到匹配的对象，则创建新对象。我们将通过创建 5 个对象来画出 20 个分布于不同位置的圆来演示这种模式。由于只有 5 种可用的颜色，所以 color 属性被用来检查现有的 Circle 对象。意图：运用共享技术有效地支持大量细粒度的对象。主要解决：在有大量对象时，有可能会造成内存溢出，我们把其中共同的部分抽象出来，如果有相同的业务请求，直接返回在内存中已有的对象，避免重新创建。何时使用： 1、系统中有大量对象。 2、这些对象消耗大量内存。 3、这些对象的状态大部分可以外部化。 4、这些对象可以按照内蕴状态分为很多组，当把外蕴对象从对象中剔除出来时，每一组对象都可以用一个对象来代替。 5、系统不依赖于这些对象身份，这些对象是不可分辨的。如何解决：用唯一标识码判断，如果在内存中有，则返回这个唯一标识码所标识的对象。关键代码：用 HashMap 存储这些对象。应用实例： 1、JAVA 中的 String，如果有则返回，如果没有则创建一个字符串保存在字符串缓存池里面。 2、数据库的数据池。优点：大大减少对象的创建，降低系统的内存，使效率提高。缺点：提高了系统的复杂度，需要分离出外部状态和内部状态，而且外部状态具有固有化的性质，不应该随着内部状态的变化而变化，否则会造成系统的混乱。使用场景： 1、系统有大量相似对象。 2、需要缓冲池的场景。注意事项： 1、注意划分外部状态和内部状态，否则可能会引起线程安全问题。 2、这些类必须有一个工厂对象加以控制。实现我们将创建一个 Shape 接口和实现了 Shape 接口的实体类 Circle。下一步是定义工厂类 ShapeFactory。ShapeFactory 有一个 Circle 的 HashMap，其中键名为 Circle 对象的颜色。无论何时接收到请求，都会创建一个特定颜色的圆。ShapeFactory 检查它的 HashMap 中的 circle 对象，如果找到 Circle 对象，则返回该对象，否则将创建一个存储在 hashmap 中以备后续使用的新对象，并把该对象返回到客户端。FlyWeightPatternDemo，我们的演示类使用 ShapeFactory 来获取 Shape 对象。它将向 ShapeFactory 传递信息（red / green / blue/ black / white），以便获取它所需对象的颜色。 步骤 1 创建一个接口。 Shape.java 123public interface Shape &#123; void draw();&#125; 步骤 2 创建实现接口的实体类。 Circle.java 12345678910111213141516171819202122232425262728public class Circle implements Shape &#123; private String color; private int x; private int y; private int radius; public Circle(String color)&#123; this.color = color; &#125; public void setX(int x) &#123; this.x = x; &#125; public void setY(int y) &#123; this.y = y; &#125; public void setRadius(int radius) &#123; this.radius = radius; &#125; @Override public void draw() &#123; System.out.println(&quot;Circle: Draw() [Color : &quot; + color +&quot;, x : &quot; + x +&quot;, y :&quot; + y +&quot;, radius :&quot; + radius); &#125;&#125; 步骤 3 创建一个工厂，生成基于给定信息的实体类的对象。 ShapeFactory.java 12345678910111213141516import java.util.HashMap;public class ShapeFactory &#123; private static final HashMap&lt;String, Shape&gt; circleMap = new HashMap(); public static Shape getCircle(String color) &#123; Circle circle = (Circle)circleMap.get(color); if(circle == null) &#123; circle = new Circle(color); circleMap.put(color, circle); System.out.println(&quot;Creating circle of color : &quot; + color); &#125; return circle; &#125;&#125; 步骤 4 使用该工厂，通过传递颜色信息来获取实体类的对象。 FlyweightPatternDemo.java 123456789101112131415161718192021222324public class FlyweightPatternDemo &#123; private static final String colors[] = &#123; &quot;Red&quot;, &quot;Green&quot;, &quot;Blue&quot;, &quot;White&quot;, &quot;Black&quot; &#125;; public static void main(String[] args) &#123; for(int i=0; i &lt; 20; ++i) &#123; Circle circle = (Circle)ShapeFactory.getCircle(getRandomColor()); circle.setX(getRandomX()); circle.setY(getRandomY()); circle.setRadius(100); circle.draw(); &#125; &#125; private static String getRandomColor() &#123; return colors[(int)(Math.random()*colors.length)]; &#125; private static int getRandomX() &#123; return (int)(Math.random()*100 ); &#125; private static int getRandomY() &#123; return (int)(Math.random()*100); &#125;&#125; 步骤 5 验证输出。 12345678910111213141516171819202122232425Creating circle of color : BlackCircle: Draw() [Color : Black, x : 36, y :71, radius :100Creating circle of color : GreenCircle: Draw() [Color : Green, x : 27, y :27, radius :100Creating circle of color : WhiteCircle: Draw() [Color : White, x : 64, y :10, radius :100Creating circle of color : RedCircle: Draw() [Color : Red, x : 15, y :44, radius :100Circle: Draw() [Color : Green, x : 19, y :10, radius :100Circle: Draw() [Color : Green, x : 94, y :32, radius :100Circle: Draw() [Color : White, x : 69, y :98, radius :100Creating circle of color : BlueCircle: Draw() [Color : Blue, x : 13, y :4, radius :100Circle: Draw() [Color : Green, x : 21, y :21, radius :100Circle: Draw() [Color : Blue, x : 55, y :86, radius :100Circle: Draw() [Color : White, x : 90, y :70, radius :100Circle: Draw() [Color : Green, x : 78, y :3, radius :100Circle: Draw() [Color : Green, x : 64, y :89, radius :100Circle: Draw() [Color : Blue, x : 3, y :91, radius :100Circle: Draw() [Color : Blue, x : 62, y :82, radius :100Circle: Draw() [Color : Green, x : 97, y :61, radius :100Circle: Draw() [Color : Green, x : 86, y :12, radius :100Circle: Draw() [Color : Green, x : 38, y :93, radius :100Circle: Draw() [Color : Red, x : 76, y :82, radius :100Circle: Draw() [Color : Blue, x : 95, y :82, radius :100 代理模式在代理模式（Proxy Pattern）中，一个类代表另一个类的功能。这种类型的设计模式属于结构型模式。在代理模式中，我们创建具有现有对象的对象，以便向外界提供功能接口。意图：为其他对象提供一种代理以控制对这个对象的访问。主要解决：在直接访问对象时带来的问题，比如说：要访问的对象在远程的机器上。在面向对象系统中，有些对象由于某些原因（比如对象创建开销很大，或者某些操作需要安全控制，或者需要进程外的访问），直接访问会给使用者或者系统结构带来很多麻烦，我们可以在访问此对象时加上一个对此对象的访问层。何时使用：想在访问一个类时做一些控制。如何解决：增加中间层。关键代码：实现与被代理类组合。应用实例： 1、Windows 里面的快捷方式。 2、猪八戒去找高翠兰结果是孙悟空变的，可以这样理解：把高翠兰的外貌抽象出来，高翠兰本人和孙悟空都实现了这个接口，猪八戒访问高翠兰的时候看不出来这个是孙悟空，所以说孙悟空是高翠兰代理类。 3、买火车票不一定在火车站买，也可以去代售点。 4、一张支票或银行存单是账户中资金的代理。支票在市场交易中用来代替现金，并提供对签发人账号上资金的控制。 5、spring aop。优点： 1、职责清晰。 2、高扩展性。 3、智能化。缺点： 1、由于在客户端和真实主题之间增加了代理对象，因此有些类型的代理模式可能会造成请求的处理速度变慢。 2、实现代理模式需要额外的工作，有些代理模式的实现非常复杂。使用场景：按职责来划分，通常有以下使用场景： 1、远程代理。 2、虚拟代理。 3、Copy-on-Write 代理。 4、保护（Protect or Access）代理。 5、Cache代理。 6、防火墙（Firewall）代理。 7、同步化（Synchronization）代理。 8、智能引用（Smart Reference）代理。注意事项： 1、和适配器模式的区别：适配器模式主要改变所考虑对象的接口，而代理模式不能改变所代理类的接口。 2、和装饰器模式的区别：装饰器模式为了增强功能，而代理模式是为了加以控制。实现我们将创建一个 Image 接口和实现了 Image 接口的实体类。ProxyImage 是一个代理类，减少 RealImage 对象加载的内存占用。ProxyPatternDemo，我们的演示类使用 ProxyImage 来获取要加载的 Image 对象，并按照需求进行显示。 步骤 1 创建一个接口。 Image.java 123public interface Image &#123; void display();&#125; 步骤 2 创建实现接口的实体类。 RealImage.java 123456789101112131415161718public class RealImage implements Image &#123; private String fileName; public RealImage(String fileName)&#123; this.fileName = fileName; loadFromDisk(fileName); &#125; @Override public void display() &#123; System.out.println(&quot;Displaying &quot; + fileName); &#125; private void loadFromDisk(String fileName)&#123; System.out.println(&quot;Loading &quot; + fileName); &#125;&#125; ProxyImage.java 1234567891011121314151617public class ProxyImage implements Image&#123; private RealImage realImage; private String fileName; public ProxyImage(String fileName)&#123; this.fileName = fileName; &#125; @Override public void display() &#123; if(realImage == null)&#123; realImage = new RealImage(fileName); &#125; realImage.display(); &#125;&#125; 步骤 3 当被请求时，使用 ProxyImage 来获取 RealImage 类的对象。 ProxyPatternDemo.java 123456789101112public class ProxyPatternDemo &#123; public static void main(String[] args) &#123; Image image = new ProxyImage(&quot;test_10mb.jpg&quot;); //图像将从磁盘加载 image.display(); System.out.println(&quot;&quot;); //图像将无法从磁盘加载 image.display(); &#125;&#125; 步骤 4 验证输出。 1234Loading test_10mb.jpgDisplaying test_10mb.jpgDisplaying test_10mb.jpg 责任链模式顾名思义，责任链模式（Chain of Responsibility Pattern）为请求创建了一个接收者对象的链。这种模式给予请求的类型，对请求的发送者和接收者进行解耦。这种类型的设计模式属于行为型模式。在这种模式中，通常每个接收者都包含对另一个接收者的引用。如果一个对象不能处理该请求，那么它会把相同的请求传给下一个接收者，依此类推。意图：避免请求发送者与接收者耦合在一起，让多个对象都有可能接收请求，将这些对象连接成一条链，并且沿着这条链传递请求，直到有对象处理它为止。主要解决：职责链上的处理者负责处理请求，客户只需要将请求发送到职责链上即可，无须关心请求的处理细节和请求的传递，所以职责链将请求的发送者和请求的处理者解耦了。何时使用：在处理消息的时候以过滤很多道。如何解决：拦截的类都实现统一接口。关键代码：Handler 里面聚合它自己，在 HanleRequest 里判断是否合适，如果没达到条件则向下传递，向谁传递之前 set 进去。应用实例： 1、红楼梦中的”击鼓传花”。 2、JS 中的事件冒泡。 3、JAVA WEB 中 Apache Tomcat 对 Encoding 的处理，Struts2 的拦截器，jsp servlet 的 Filter。优点： 1、降低耦合度。它将请求的发送者和接收者解耦。 2、简化了对象。使得对象不需要知道链的结构。 3、增强给对象指派职责的灵活性。通过改变链内的成员或者调动它们的次序，允许动态地新增或者删除责任。 4、增加新的请求处理类很方便。缺点： 1、不能保证请求一定被接收。 2、系统性能将受到一定影响，而且在进行代码调试时不太方便，可能会造成循环调用。 3、可能不容易观察运行时的特征，有碍于除错。使用场景： 1、有多个对象可以处理同一个请求，具体哪个对象处理该请求由运行时刻自动确定。 2、在不明确指定接收者的情况下，向多个对象中的一个提交一个请求。 3、可动态指定一组对象处理请求。注意事项：在 JAVA WEB 中遇到很多应用。实现 我们创建抽象类 AbstractLogger，带有详细的日志记录级别。然后我们创建三种类型的记录器，都扩展了 AbstractLogger。每个记录器消息的级别是否属于自己的级别，如果是则相应地打印出来，否则将不打印并把消息传给下一个记录器。 步骤 1 创建抽象的记录器类。 AbstractLogger.java 1234567891011121314151617181920212223242526public abstract class AbstractLogger &#123; public static int INFO = 1; public static int DEBUG = 2; public static int ERROR = 3; protected int level; //责任链中的下一个元素 protected AbstractLogger nextLogger; public void setNextLogger(AbstractLogger nextLogger)&#123; this.nextLogger = nextLogger; &#125; public void logMessage(int level, String message)&#123; if(this.level &lt;= level)&#123; write(message); &#125; if(nextLogger !=null)&#123; nextLogger.logMessage(level, message); &#125; &#125; abstract protected void write(String message); &#125; 步骤 2 创建扩展了该记录器类的实体类。 ConsoleLogger.java 1234567891011public class ConsoleLogger extends AbstractLogger &#123; public ConsoleLogger(int level)&#123; this.level = level; &#125; @Override protected void write(String message) &#123; System.out.println(&quot;Standard Console::Logger: &quot; + message); &#125;&#125; ErrorLogger.java 1234567891011public class ErrorLogger extends AbstractLogger &#123; public ErrorLogger(int level)&#123; this.level = level; &#125; @Override protected void write(String message) &#123; System.out.println(&quot;Error Console::Logger: &quot; + message); &#125;&#125; FileLogger.java 1234567891011public class FileLogger extends AbstractLogger &#123; public FileLogger(int level)&#123; this.level = level; &#125; @Override protected void write(String message) &#123; System.out.println(&quot;File::Logger: &quot; + message); &#125;&#125; 步骤 3 创建不同类型的记录器。赋予它们不同的错误级别，并在每个记录器中设置下一个记录器。每个记录器中的下一个记录器代表的是链的一部分。 ChainPatternDemo.java 123456789101112131415161718192021222324252627public class ChainPatternDemo &#123; private static AbstractLogger getChainOfLoggers()&#123; AbstractLogger errorLogger = new ErrorLogger(AbstractLogger.ERROR); AbstractLogger fileLogger = new FileLogger(AbstractLogger.DEBUG); AbstractLogger consoleLogger = new ConsoleLogger(AbstractLogger.INFO); errorLogger.setNextLogger(fileLogger); fileLogger.setNextLogger(consoleLogger); return errorLogger; &#125; public static void main(String[] args) &#123; AbstractLogger loggerChain = getChainOfLoggers(); loggerChain.logMessage(AbstractLogger.INFO, &quot;This is an information.&quot;); loggerChain.logMessage(AbstractLogger.DEBUG, &quot;This is an debug level information.&quot;); loggerChain.logMessage(AbstractLogger.ERROR, &quot;This is an error information.&quot;); &#125;&#125; 步骤 4 验证输出。 123456Standard Console::Logger: This is an information.File::Logger: This is an debug level information.Standard Console::Logger: This is an debug level information.Error Console::Logger: This is an error information.File::Logger: This is an error information.Standard Console::Logger: This is an error information. 命令模式命令模式（Command Pattern）是一种数据驱动的设计模式，它属于行为型模式。请求以命令的形式包裹在对象中，并传给调用对象。调用对象寻找可以处理该命令的合适的对象，并把该命令传给相应的对象，该对象执行命令。意图：将一个请求封装成一个对象，从而使您可以用不同的请求对客户进行参数化。主要解决：在软件系统中，行为请求者与行为实现者通常是一种紧耦合的关系，但某些场合，比如需要对行为进行记录、撤销或重做、事务等处理时，这种无法抵御变化的紧耦合的设计就不太合适。何时使用：在某些场合，比如要对行为进行”记录、撤销/重做、事务”等处理，这种无法抵御变化的紧耦合是不合适的。在这种情况下，如何将”行为请求者”与”行为实现者”解耦？将一组行为抽象为对象，可以实现二者之间的松耦合。如何解决：通过调用者调用接受者执行命令，顺序：调用者→接受者→命令。关键代码：定义三个角色：1、received 真正的命令执行对象 2、Command 3、invoker 使用命令对象的入口应用实例：struts 1 中的 action 核心控制器 ActionServlet 只有一个，相当于 Invoker，而模型层的类会随着不同的应用有不同的模型类，相当于具体的 Command。优点： 1、降低了系统耦合度。 2、新的命令可以很容易添加到系统中去。缺点：使用命令模式可能会导致某些系统有过多的具体命令类。使用场景：认为是命令的地方都可以使用命令模式，比如： 1、GUI 中每一个按钮都是一条命令。 2、模拟 CMD。注意事项：系统需要支持命令的撤销(Undo)操作和恢复(Redo)操作，也可以考虑使用命令模式，见命令模式的扩展。实现我们首先创建作为命令的接口 Order，然后创建作为请求的 Stock 类。实体命令类 BuyStock 和 SellStock，实现了 Order 接口，将执行实际的命令处理。创建作为调用对象的类 Broker，它接受订单并能下订单。Broker 对象使用命令模式，基于命令的类型确定哪个对象执行哪个命令。CommandPatternDemo，我们的演示类使用 Broker 类来演示命令模式。 步骤 1 创建一个命令接口。 Order.java 123public interface Order &#123; void execute();&#125; 步骤 2 创建一个请求类。 Stock.java 1234567891011121314public class Stock &#123; private String name = &quot;ABC&quot;; private int quantity = 10; public void buy()&#123; System.out.println(&quot;Stock [ Name: &quot;+name+&quot;, Quantity: &quot; + quantity +&quot; ] bought&quot;); &#125; public void sell()&#123; System.out.println(&quot;Stock [ Name: &quot;+name+&quot;, Quantity: &quot; + quantity +&quot; ] sold&quot;); &#125;&#125; 步骤 3 创建实现了 Order 接口的实体类。 BuyStock.java 1234567891011public class BuyStock implements Order &#123; private Stock abcStock; public BuyStock(Stock abcStock)&#123; this.abcStock = abcStock; &#125; public void execute() &#123; abcStock.buy(); &#125;&#125; SellStock.java 1234567891011public class SellStock implements Order &#123; private Stock abcStock; public SellStock(Stock abcStock)&#123; this.abcStock = abcStock; &#125; public void execute() &#123; abcStock.sell(); &#125;&#125; 步骤 4 创建命令调用类。 Broker.java 1234567891011121314151617import java.util.ArrayList;import java.util.List; public class Broker &#123; private List&lt;Order&gt; orderList = new ArrayList&lt;Order&gt;(); public void takeOrder(Order order)&#123; orderList.add(order); &#125; public void placeOrders()&#123; for (Order order : orderList) &#123; order.execute(); &#125; orderList.clear(); &#125;&#125; 步骤 5 使用 Broker 类来接受并执行命令。 CommandPatternDemo.java 1234567891011121314public class CommandPatternDemo &#123; public static void main(String[] args) &#123; Stock abcStock = new Stock(); BuyStock buyStockOrder = new BuyStock(abcStock); SellStock sellStockOrder = new SellStock(abcStock); Broker broker = new Broker(); broker.takeOrder(buyStockOrder); broker.takeOrder(sellStockOrder); broker.placeOrders(); &#125;&#125; 步骤 6 验证输出。 12Stock [ Name: ABC, Quantity: 10 ] boughtStock [ Name: ABC, Quantity: 10 ] sold 解释器模式解释器模式（Interpreter Pattern）提供了评估语言的语法或表达式的方式，它属于行为型模式。这种模式实现了一个表达式接口，该接口解释一个特定的上下文。这种模式被用在 SQL 解析、符号处理引擎等。意图：给定一个语言，定义它的文法表示，并定义一个解释器，这个解释器使用该标识来解释语言中的句子。主要解决：对于一些固定文法构建一个解释句子的解释器。何时使用：如果一种特定类型的问题发生的频率足够高，那么可能就值得将该问题的各个实例表述为一个简单语言中的句子。这样就可以构建一个解释器，该解释器通过解释这些句子来解决该问题。 如何解决：构件语法树，定义终结符与非终结符。 关键代码：构件环境类，包含解释器之外的一些全局信息，一般是 HashMap。 应用实例：编译器、运算表达式计算。 优点： 1、可扩展性比较好，灵活。 2、增加了新的解释表达式的方式。 3、易于实现简单文法。 缺点： 1、可利用场景比较少。 2、对于复杂的文法比较难维护。 3、解释器模式会引起类膨胀。 4、解释器模式采用递归调用方法。 使用场景： 1、可以将一个需要解释执行的语言中的句子表示为一个抽象语法树。 2、一些重复出现的问题可以用一种简单的语言来进行表达。 3、一个简单语法需要解释的场景。注意事项：可利用场景比较少，JAVA 中如果碰到可以用 expression4J 代替。 实现 **我们将创建一个接口 Expression 和实现了 Expression 接口的实体类。定义作为上下文中主要解释器的 TerminalExpression 类。其他的类 OrExpression、AndExpression 用于创建组合式表达式。InterpreterPatternDemo，我们的演示类使用 Expression 类创建规则和演示表达式的解析。 步骤 1 创建一个表达式接口。 Expression.java 123public interface Expression &#123; public boolean interpret(String context);&#125; 步骤 2 创建实现了上述接口的实体类。 TerminalExpression.java 12345678910111213141516public class TerminalExpression implements Expression &#123; private String data; public TerminalExpression(String data)&#123; this.data = data; &#125; @Override public boolean interpret(String context) &#123; if(context.contains(data))&#123; return true; &#125; return false; &#125;&#125; OrExpression.java 123456789101112131415public class OrExpression implements Expression &#123; private Expression expr1 = null; private Expression expr2 = null; public OrExpression(Expression expr1, Expression expr2) &#123; this.expr1 = expr1; this.expr2 = expr2; &#125; @Override public boolean interpret(String context) &#123; return expr1.interpret(context) || expr2.interpret(context); &#125;&#125; AndExpression.java 123456789101112131415public class AndExpression implements Expression &#123; private Expression expr1 = null; private Expression expr2 = null; public AndExpression(Expression expr1, Expression expr2) &#123; this.expr1 = expr1; this.expr2 = expr2; &#125; @Override public boolean interpret(String context) &#123; return expr1.interpret(context) &amp;&amp; expr2.interpret(context); &#125;&#125; 步骤 3InterpreterPatternDemo 使用 Expression 类来创建规则，并解析它们。 InterpreterPatternDemo.java 12345678910111213141516171819202122232425public class InterpreterPatternDemo &#123; //规则：Robert 和 John 是男性 public static Expression getMaleExpression()&#123; Expression robert = new TerminalExpression(&quot;Robert&quot;); Expression john = new TerminalExpression(&quot;John&quot;); return new OrExpression(robert, john); &#125; //规则：Julie 是一个已婚的女性 public static Expression getMarriedWomanExpression()&#123; Expression julie = new TerminalExpression(&quot;Julie&quot;); Expression married = new TerminalExpression(&quot;Married&quot;); return new AndExpression(julie, married); &#125; public static void main(String[] args) &#123; Expression isMale = getMaleExpression(); Expression isMarriedWoman = getMarriedWomanExpression(); System.out.println(&quot;John is male? &quot; + isMale.interpret(&quot;John&quot;)); System.out.println(&quot;Julie is a married women? &quot; + isMarriedWoman.interpret(&quot;Married Julie&quot;)); &#125;&#125; 步骤 4 验证输出。 12John is male? trueJulie is a married women? true 迭代器模式迭代器模式（Iterator Pattern）是 Java 和 .Net 编程环境中非常常用的设计模式。这种模式用于顺序访问集合对象的元素，不需要知道集合对象的底层表示。迭代器模式属于行为型模式。意图：提供一种方法顺序访问一个聚合对象中各个元素, 而又无须暴露该对象的内部表示。主要解决：不同的方式来遍历整个整合对象。何时使用：遍历一个聚合对象。如何解决：把在元素之间游走的责任交给迭代器，而不是聚合对象。关键代码：定义接口：hasNext, next。应用实例：JAVA 中的 iterator。优点： 1、它支持以不同的方式遍历一个聚合对象。 2、迭代器简化了聚合类。 3、在同一个聚合上可以有多个遍历。 4、在迭代器模式中，增加新的聚合类和迭代器类都很方便，无须修改原有代码。缺点：由于迭代器模式将存储数据和遍历数据的职责分离，增加新的聚合类需要对应增加新的迭代器类，类的个数成对增加，这在一定程度上增加了系统的复杂性。使用场景： 1、访问一个聚合对象的内容而无须暴露它的内部表示。 2、需要为聚合对象提供多种遍历方式。 3、为遍历不同的聚合结构提供一个统一的接口。注意事项：迭代器模式就是分离了集合对象的遍历行为，抽象出一个迭代器类来负责，这样既可以做到不暴露集合的内部结构，又可让外部代码透明地访问集合内部的数据。实现我们将创建一个叙述导航方法的 Iterator 接口和一个返回迭代器的 Container 接口。实现了 Container 接口的实体类将负责实现 Iterator 接口。IteratorPatternDemo，我们的演示类使用实体类 NamesRepository 来打印 NamesRepository 中存储为集合的 Names。 步骤 1 创建接口。 Iterator.java 1234public interface Iterator &#123; public boolean hasNext(); public Object next();&#125; Container.java 123public interface Container &#123; public Iterator getIterator();&#125; 步骤 2 创建实现了 Container 接口的实体类。该类有实现了 Iterator 接口的内部类 NameIterator。 NameRepository.java 1234567891011121314151617181920212223242526272829public class NameRepository implements Container &#123; public String names[] = &#123;&quot;Robert&quot; , &quot;John&quot; ,&quot;Julie&quot; , &quot;Lora&quot;&#125;; @Override public Iterator getIterator() &#123; return new NameIterator(); &#125; private class NameIterator implements Iterator &#123; int index; @Override public boolean hasNext() &#123; if(index &lt; names.length)&#123; return true; &#125; return false; &#125; @Override public Object next() &#123; if(this.hasNext())&#123; return names[index++]; &#125; return null; &#125; &#125;&#125; 步骤 3 使用 NameRepository 来获取迭代器，并打印名字。 IteratorPatternDemo.java 1234567891011public class IteratorPatternDemo &#123; public static void main(String[] args) &#123; NameRepository namesRepository = new NameRepository(); for(Iterator iter = namesRepository.getIterator(); iter.hasNext();)&#123; String name = (String)iter.next(); System.out.println(&quot;Name : &quot; + name); &#125; &#125;&#125; 步骤 4 验证输出。 1234Name : RobertName : JohnName : JulieName : Lora 中介者模式中介者模式（Mediator Pattern）是用来降低多个对象和类之间的通信复杂性。这种模式提供了一个中介类，该类通常处理不同类之间的通信，并支持松耦合，使代码易于维护。中介者模式属于行为型模式。意图：用一个中介对象来封装一系列的对象交互，中介者使各对象不需要显式地相互引用，从而使其耦合松散，而且可以独立地改变它们之间的交互。主要解决：对象与对象之间存在大量的关联关系，这样势必会导致系统的结构变得很复杂，同时若一个对象发生改变，我们也需要跟踪与之相关联的对象，同时做出相应的处理。何时使用：多个类相互耦合，形成了网状结构。如何解决：将上述网状结构分离为星型结构。关键代码：对象 Colleague 之间的通信封装到一个类中单独处理。应用实例： 1、中国加入 WTO 之前是各个国家相互贸易，结构复杂，现在是各个国家通过 WTO 来互相贸易。 2、机场调度系统。 3、MVC 框架，其中C（控制器）就是 M（模型）和 V（视图）的中介者。优点： 1、降低了类的复杂度，将一对多转化成了一对一。 2、各个类之间的解耦。 3、符合迪米特原则。缺点：中介者会庞大，变得复杂难以维护。使用场景： 1、系统中对象之间存在比较复杂的引用关系，导致它们之间的依赖关系结构混乱而且难以复用该对象。 2、想通过一个中间类来封装多个类中的行为，而又不想生成太多的子类。注意事项：不应当在职责混乱的时候使用。实现我们通过聊天室实例来演示中介者模式。实例中，多个用户可以向聊天室发送消息，聊天室向所有的用户显示消息。我们将创建两个类 ChatRoom 和 User。User 对象使用 ChatRoom 方法来分享他们的消息。MediatorPatternDemo，我们的演示类使用 User 对象来显示他们之间的通信。 步骤 1 创建中介类。 ChatRoom.java 12345678import java.util.Date;public class ChatRoom &#123; public static void showMessage(User user, String message)&#123; System.out.println(new Date().toString() + &quot; [&quot; + user.getName() +&quot;] : &quot; + message); &#125;&#125; 步骤 2 创建 user 类。 User.java 12345678910111213141516171819public class User &#123; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public User(String name)&#123; this.name = name; &#125; public void sendMessage(String message)&#123; ChatRoom.showMessage(this,message); &#125;&#125; 步骤 3 使用 User 对象来显示他们之间的通信。 MediatorPatternDemo.java 123456789public class MediatorPatternDemo &#123; public static void main(String[] args) &#123; User robert = new User(&quot;Robert&quot;); User john = new User(&quot;John&quot;); robert.sendMessage(&quot;Hi! John!&quot;); john.sendMessage(&quot;Hello! Robert!&quot;); &#125;&#125; 步骤 4 验证输出。 12Thu Jan 31 16:05:46 IST 2013 [Robert] : Hi! John!Thu Jan 31 16:05:46 IST 2013 [John] : Hello! Robert! 备忘录模式备忘录模式（Memento Pattern）保存一个对象的某个状态，以便在适当的时候恢复对象。备忘录模式属于行为型模式。意图：在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。主要解决：所谓备忘录模式就是在不破坏封装的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，这样可以在以后将对象恢复到原先保存的状态。何时使用：很多时候我们总是需要记录一个对象的内部状态，这样做的目的就是为了允许用户取消不确定或者错误的操作，能够恢复到他原先的状态，使得他有”后悔药”可吃。如何解决：通过一个备忘录类专门存储对象状态。关键代码：客户不与备忘录类耦合，与备忘录管理类耦合。应用实例： 1、后悔药。 2、打游戏时的存档。 3、Windows 里的 ctri + z。 4、IE 中的后退。 4、数据库的事务管理。优点： 1、给用户提供了一种可以恢复状态的机制，可以使用户能够比较方便地回到某个历史的状态。 2、实现了信息的封装，使得用户不需要关心状态的保存细节。缺点：消耗资源。如果类的成员变量过多，势必会占用比较大的资源，而且每一次保存都会消耗一定的内存。使用场景： 1、需要保存/恢复数据的相关状态场景。 2、提供一个可回滚的操作。注意事项： 1、为了符合迪米特原则，还要增加一个管理备忘录的类。 2、为了节约内存，可使用原型模式+备忘录模式。实现备忘录模式使用三个类 Memento、Originator 和 CareTaker。Memento 包含了要被恢复的对象的状态。 Originator 创建并在 Memento 对象中存储状态。Caretaker 对象负责从 Memento 中恢复对象的状态。MementoPatternDemo，我们的演示类使用 CareTaker 和 Originator 对象来显示对象的状态恢复。 步骤 1 创建 Memento 类。 Memento.java 1234567891011public class Memento &#123; private String state; public Memento(String state)&#123; this.state = state; &#125; public String getState()&#123; return state; &#125; &#125; 步骤 2 创建 Originator 类。 Originator.java 12345678910111213141516171819public class Originator &#123; private String state; public void setState(String state)&#123; this.state = state; &#125; public String getState()&#123; return state; &#125; public Memento saveStateToMemento()&#123; return new Memento(state); &#125; public void getStateFromMemento(Memento Memento)&#123; state = Memento.getState(); &#125;&#125; 步骤 3 创建 CareTaker 类。 CareTaker.java 1234567891011121314import java.util.ArrayList;import java.util.List;public class CareTaker &#123; private List&lt;Memento&gt; mementoList = new ArrayList&lt;Memento&gt;(); public void add(Memento state)&#123; mementoList.add(state); &#125; public Memento get(int index)&#123; return mementoList.get(index); &#125;&#125; 步骤 4 使用 CareTaker 和 Originator 对象。 MementoPatternDemo.java 123456789101112131415161718public class MementoPatternDemo &#123; public static void main(String[] args) &#123; Originator originator = new Originator(); CareTaker careTaker = new CareTaker(); originator.setState(&quot;State #1&quot;); originator.setState(&quot;State #2&quot;); careTaker.add(originator.saveStateToMemento()); originator.setState(&quot;State #3&quot;); careTaker.add(originator.saveStateToMemento()); originator.setState(&quot;State #4&quot;); System.out.println(&quot;Current State: &quot; + originator.getState()); originator.getStateFromMemento(careTaker.get(0)); System.out.println(&quot;First saved State: &quot; + originator.getState()); originator.getStateFromMemento(careTaker.get(1)); System.out.println(&quot;Second saved State: &quot; + originator.getState()); &#125;&#125; 步骤 5 验证输出。 123Current State: State #4First saved State: State #2Second saved State: State #3 观察者模式当对象间存在一对多关系时，则使用观察者模式（Observer Pattern）。比如，当一个对象被修改时，则会自动通知它的依赖对象。观察者模式属于行为型模式。意图：定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。主要解决：一个对象状态改变给其他对象通知的问题，而且要考虑到易用和低耦合，保证高度的协作。何时使用：一个对象（目标对象）的状态发生改变，所有的依赖对象（观察者对象）都将得到通知，进行广播通知。如何解决：使用面向对象技术，可以将这种依赖关系弱化。关键代码：在抽象类里有一个 ArrayList 存放观察者们。应用实例： 1、拍卖的时候，拍卖师观察最高标价，然后通知给其他竞价者竞价。 2、西游记里面悟空请求菩萨降服红孩儿，菩萨洒了一地水招来一个老乌龟，这个乌龟就是观察者，他观察菩萨洒水这个动作。优点： 1、观察者和被观察者是抽象耦合的。 2、建立一套触发机制。缺点： 1、如果一个被观察者对象有很多的直接和间接的观察者的话，将所有的观察者都通知到会花费很多时间。 2、如果在观察者和观察目标之间有循环依赖的话，观察目标会触发它们之间进行循环调用，可能导致系统崩溃。 3、观察者模式没有相应的机制让观察者知道所观察的目标对象是怎么发生变化的，而仅仅只是知道观察目标发生了变化。使用场景： 1、有多个子类共有的方法，且逻辑相同。 2、重要的、复杂的方法，可以考虑作为模板方法。注意事项： 1、JAVA 中已经有了对观察者模式的支持类。 2、避免循环引用。 3、如果顺序执行，某一观察者错误会导致系统卡壳，一般采用异步方式。实现观察者模式使用三个类 Subject、Observer 和 Client。Subject 对象带有绑定观察者到 Client 对象和从 Client 对象解绑观察者的方法。我们创建 Subject 类、Observer 抽象类和扩展了抽象类 Observer 的实体类。ObserverPatternDemo，我们的演示类使用 Subject 和实体类对象来演示观察者模式。 步骤 1 创建 Subject 类。 Subject.java 12345678910111213141516171819202122232425262728import java.util.ArrayList;import java.util.List;public class Subject &#123; private List&lt;Observer&gt; observers = new ArrayList&lt;Observer&gt;(); private int state; public int getState() &#123; return state; &#125; public void setState(int state) &#123; this.state = state; notifyAllObservers(); &#125; public void attach(Observer observer)&#123; observers.add(observer); &#125; public void notifyAllObservers()&#123; for (Observer observer : observers) &#123; observer.update(); &#125; &#125; &#125; 步骤 2 创建 Observer 类。 Observer.java 1234public abstract class Observer &#123; protected Subject subject; public abstract void update();&#125; 步骤 3 创建实体观察者类。 BinaryObserver.java 12345678910111213public class BinaryObserver extends Observer&#123; public BinaryObserver(Subject subject)&#123; this.subject = subject; this.subject.attach(this); &#125; @Override public void update() &#123; System.out.println( &quot;Binary String: &quot; + Integer.toBinaryString( subject.getState() ) ); &#125;&#125; OctalObserver.java 12345678910111213public class OctalObserver extends Observer&#123; public OctalObserver(Subject subject)&#123; this.subject = subject; this.subject.attach(this); &#125; @Override public void update() &#123; System.out.println( &quot;Octal String: &quot; + Integer.toOctalString( subject.getState() ) ); &#125;&#125; HexaObserver.java 12345678910111213public class HexaObserver extends Observer&#123; public HexaObserver(Subject subject)&#123; this.subject = subject; this.subject.attach(this); &#125; @Override public void update() &#123; System.out.println( &quot;Hex String: &quot; + Integer.toHexString( subject.getState() ).toUpperCase() ); &#125;&#125; 步骤 4 使用 Subject 和实体观察者对象。 ObserverPatternDemo.java 1234567891011121314public class ObserverPatternDemo &#123; public static void main(String[] args) &#123; Subject subject = new Subject(); new HexaObserver(subject); new OctalObserver(subject); new BinaryObserver(subject); System.out.println(&quot;First state change: 15&quot;); subject.setState(15); System.out.println(&quot;Second state change: 10&quot;); subject.setState(10); &#125;&#125; 步骤 5 验证输出。 12345678First state change: 15Hex String: FOctal String: 17Binary String: 1111Second state change: 10Hex String: AOctal String: 12Binary String: 1010 状态模式在状态模式（State Pattern）中，类的行为是基于它的状态改变的。这种类型的设计模式属于行为型模式。在状态模式中，我们创建表示各种状态的对象和一个行为随着状态对象改变而改变的 context 对象。介绍意图：允许对象在内部状态发生改变时改变它的行为，对象看起来好像修改了它的类。主要解决：对象的行为依赖于它的状态（属性），并且可以根据它的状态改变而改变它的相关行为。何时使用：代码中包含大量与对象状态有关的条件语句。如何解决：将各种具体的状态类抽象出来。关键代码：通常命令模式的接口中只有一个方法。而状态模式的接口中有一个或者多个方法。而且，状态模式的实现类的方法，一般返回值，或者是改变实例变量的值。也就是说，状态模式一般和对象的状态有关。实现类的方法有不同的功能，覆盖接口中的方法。状态模式和命令模式一样，也可以用于消除 if…else 等条件选择语句。应用实例： 1、打篮球的时候运动员可以有正常状态、不正常状态和超常状态。 2、曾侯乙编钟中，’钟是抽象接口’,’钟A’等是具体状态，’曾侯乙编钟’是具体环境（Context）。优点： 1、封装了转换规则。 2、枚举可能的状态，在枚举状态之前需要确定状态种类。 3、将所有与某个状态有关的行为放到一个类中，并且可以方便地增加新的状态，只需要改变对象状态即可改变对象的行为。 4、允许状态转换逻辑与状态对象合成一体，而不是某一个巨大的条件语句块。 5、可以让多个环境对象共享一个状态对象，从而减少系统中对象的个数。缺点： 1、状态模式的使用必然会增加系统类和对象的个数。 2、状态模式的结构与实现都较为复杂，如果使用不当将导致程序结构和代码的混乱。 3、状态模式对”开闭原则”的支持并不太好，对于可以切换状态的状态模式，增加新的状态类需要修改那些负责状态转换的源代码，否则无法切换到新增状态，而且修改某个状态类的行为也需修改对应类的源代码。使用场景： 1、行为随状态改变而改变的场景。 2、条件、分支语句的代替者。注意事项：在行为受状态约束的时候使用状态模式，而且状态不超过 5 个。实现我们将创建一个 State 接口和实现了 State 接口的实体状态类。Context 是一个带有某个状态的类。StatePatternDemo，我们的演示类使用 Context 和状态对象来演示 Context 在状态改变时的行为变化。 步骤 1 创建一个接口。 State.java 123public interface State &#123; public void doAction(Context context);&#125; 步骤 2 创建实现接口的实体类。 StartState.java 1234567891011public class StartState implements State &#123; public void doAction(Context context) &#123; System.out.println(&quot;Player is in start state&quot;); context.setState(this); &#125; public String toString()&#123; return &quot;Start State&quot;; &#125;&#125; StopState.java 1234567891011public class StopState implements State &#123; public void doAction(Context context) &#123; System.out.println(&quot;Player is in stop state&quot;); context.setState(this); &#125; public String toString()&#123; return &quot;Stop State&quot;; &#125;&#125; 步骤 3 创建 Context 类。 Context.java 123456789101112131415public class Context &#123; private State state; public Context()&#123; state = null; &#125; public void setState(State state)&#123; this.state = state; &#125; public State getState()&#123; return state; &#125;&#125; 步骤 4 使用 Context 来查看当状态 State 改变时的行为变化。 StatePatternDemo.java 123456789101112131415public class StatePatternDemo &#123; public static void main(String[] args) &#123; Context context = new Context(); StartState startState = new StartState(); startState.doAction(context); System.out.println(context.getState().toString()); StopState stopState = new StopState(); stopState.doAction(context); System.out.println(context.getState().toString()); &#125;&#125; 步骤 5 验证输出。 1234Player is in start stateStart StatePlayer is in stop stateStop State 空对象模式在空对象模式（Null Object Pattern）中，一个空对象取代 NULL 对象实例的检查。Null 对象不是检查空值，而是反应一个不做任何动作的关系。这样的 Null 对象也可以在数据不可用的时候提供默认的行为。在空对象模式中，我们创建一个指定各种要执行的操作的抽象类和扩展该类的实体类，还创建一个未对该类做任何实现的空对象类，该空对象类将无缝地使用在需要检查空值的地方。实现我们将创建一个定义操作（在这里，是客户的名称）的 AbstractCustomer 抽象类，和扩展了 AbstractCustomer 类的实体类。工厂类 CustomerFactory 基于客户传递的名字来返回 RealCustomer 或 NullCustomer 对象。NullPatternDemo，我们的演示类使用 CustomerFactory 来演示空对象模式的用法。 步骤 1 创建一个抽象类。 AbstractCustomer.java 12345public abstract class AbstractCustomer &#123; protected String name; public abstract boolean isNil(); public abstract String getName();&#125; 步骤 2 创建扩展了上述类的实体类。 RealCustomer.java 12345678910111213141516public class RealCustomer extends AbstractCustomer &#123; public RealCustomer(String name) &#123; this.name = name; &#125; @Override public String getName() &#123; return name; &#125; @Override public boolean isNil() &#123; return false; &#125;&#125; NullCustomer.java 123456789101112public class NullCustomer extends AbstractCustomer &#123; @Override public String getName() &#123; return &quot;Not Available in Customer Database&quot;; &#125; @Override public boolean isNil() &#123; return true; &#125;&#125; 步骤 3 创建 CustomerFactory 类。 CustomerFactory.java 12345678910111213public class CustomerFactory &#123; public static final String[] names = &#123;&quot;Rob&quot;, &quot;Joe&quot;, &quot;Julie&quot;&#125;; public static AbstractCustomer getCustomer(String name)&#123; for (int i = 0; i &lt; names.length; i++) &#123; if (names[i].equalsIgnoreCase(name))&#123; return new RealCustomer(name); &#125; &#125; return new NullCustomer(); &#125;&#125; 步骤 4 使用 CustomerFactory，基于客户传递的名字，来获取 RealCustomer 或 NullCustomer 对象。 NullPatternDemo.java 123456789101112131415public class NullPatternDemo &#123; public static void main(String[] args) &#123; AbstractCustomer customer1 = CustomerFactory.getCustomer(&quot;Rob&quot;); AbstractCustomer customer2 = CustomerFactory.getCustomer(&quot;Bob&quot;); AbstractCustomer customer3 = CustomerFactory.getCustomer(&quot;Julie&quot;); AbstractCustomer customer4 = CustomerFactory.getCustomer(&quot;Laura&quot;); System.out.println(&quot;Customers&quot;); System.out.println(customer1.getName()); System.out.println(customer2.getName()); System.out.println(customer3.getName()); System.out.println(customer4.getName()); &#125;&#125; 步骤 5 验证输出。 12345CustomersRobNot Available in Customer DatabaseJulieNot Available in Customer Database 策略模式在策略模式（Strategy Pattern）中，一个类的行为或其算法可以在运行时更改。这种类型的设计模式属于行为型模式。在策略模式中，我们创建表示各种策略的对象和一个行为随着策略对象改变而改变的 context 对象。策略对象改变 context 对象的执行算法。意图：定义一系列的算法,把它们一个个封装起来, 并且使它们可相互替换。主要解决：在有多种算法相似的情况下，使用 if…else 所带来的复杂和难以维护。何时使用：一个系统有许多许多类，而区分它们的只是他们直接的行为。如何解决：将这些算法封装成一个一个的类，任意地替换。关键代码：实现同一个接口。应用实例： 1、诸葛亮的锦囊妙计，每一个锦囊就是一个策略。 2、旅行的出游方式，选择骑自行车、坐汽车，每一种旅行方式都是一个策略。 3、JAVA AWT 中的 LayoutManager。优点： 1、算法可以自由切换。 2、避免使用多重条件判断。 3、扩展性良好。缺点： 1、策略类会增多。 2、所有策略类都需要对外暴露。使用场景： 1、如果在一个系统里面有许多类，它们之间的区别仅在于它们的行为，那么使用策略模式可以动态地让一个对象在许多行为中选择一种行为。 2、一个系统需要动态地在几种算法中选择一种。 3、如果一个对象有很多的行为，如果不用恰当的模式，这些行为就只好使用多重的条件选择语句来实现。注意事项：如果一个系统的策略多于四个，就需要考虑使用混合模式，解决策略类膨胀的问题。实现 我们将创建一个定义活动的 Strategy 接口和实现了 Strategy 接口的实体策略类。Context 是一个使用了某种策略的类。StrategyPatternDemo，我们的演示类使用 Context 和策略对象来演示 Context 在它所配置或使用的策略改变时的行为变化。 步骤 1 创建一个接口。 Strategy.java 123public interface Strategy &#123; public int doOperation(int num1, int num2);&#125; 步骤 2 创建实现接口的实体类。 OperationAdd.java 123456public class OperationAdd implements Strategy&#123; @Override public int doOperation(int num1, int num2) &#123; return num1 + num2; &#125;&#125; OperationSubstract.java 123456public class OperationSubstract implements Strategy&#123; @Override public int doOperation(int num1, int num2) &#123; return num1 - num2; &#125;&#125; OperationMultiply.java 123456public class OperationMultiply implements Strategy&#123; @Override public int doOperation(int num1, int num2) &#123; return num1 * num2; &#125;&#125; 步骤 3 创建 Context 类。 Context.java 1234567891011public class Context &#123; private Strategy strategy; public Context(Strategy strategy)&#123; this.strategy = strategy; &#125; public int executeStrategy(int num1, int num2)&#123; return strategy.doOperation(num1, num2); &#125;&#125; 步骤 4 使用 Context 来查看当它改变策略 Strategy 时的行为变化。 StrategyPatternDemo.java 123456789101112public class StrategyPatternDemo &#123; public static void main(String[] args) &#123; Context context = new Context(new OperationAdd()); System.out.println(&quot;10 + 5 = &quot; + context.executeStrategy(10, 5)); context = new Context(new OperationSubstract()); System.out.println(&quot;10 - 5 = &quot; + context.executeStrategy(10, 5)); context = new Context(new OperationMultiply()); System.out.println(&quot;10 * 5 = &quot; + context.executeStrategy(10, 5)); &#125;&#125; 步骤 5 验证输出。 12310 + 5 = 1510 - 5 = 510 * 5 = 50 模板模式在模板模式（Template Pattern）中，一个抽象类公开定义了执行它的方法的方式/模板。它的子类可以按需要重写方法实现，但调用将以抽象类中定义的方式进行。这种类型的设计模式属于行为型模式。意图：定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。主要解决：一些方法通用，却在每一个子类都重新写了这一方法。何时使用：有一些通用的方法。如何解决：将这些通用算法抽象出来。关键代码：在抽象类实现，其他步骤在子类实现。应用实例： 1、在造房子的时候，地基、走线、水管都一样，只有在建筑的后期才有加壁橱加栅栏等差异。 2、西游记里面菩萨定好的 81 难，这就是一个顶层的逻辑骨架。 3、spring 中对 Hibernate 的支持，将一些已经定好的方法封装起来，比如开启事务、获取 Session、关闭 Session 等，程序员不重复写那些已经规范好的代码，直接丢一个实体就可以保存。优点： 1、封装不变部分，扩展可变部分。 2、提取公共代码，便于维护。 3、行为由父类控制，子类实现。缺点：每一个不同的实现都需要一个子类来实现，导致类的个数增加，使得系统更加庞大。使用场景： 1、有多个子类共有的方法，且逻辑相同。 2、重要的、复杂的方法，可以考虑作为模板方法。注意事项：为防止恶意操作，一般模板方法都加上 final 关键词。实现我们将创建一个定义操作的 Game 抽象类，其中，模板方法设置为 final，这样它就不会被重写。Cricket 和 Football 是扩展了 Game 的实体类，它们重写了抽象类的方法。TemplatePatternDemo，我们的演示类使用 Game 来演示模板模式的用法。 步骤 1 创建一个抽象类，它的模板方法被设置为 final。 Game.java 123456789101112131415161718public abstract class Game &#123; abstract void initialize(); abstract void startPlay(); abstract void endPlay(); //模板 public final void play()&#123; //初始化游戏 initialize(); //开始游戏 startPlay(); //结束游戏 endPlay(); &#125;&#125; 步骤 2 创建扩展了上述类的实体类。 Cricket.java 1234567891011121314151617public class Cricket extends Game &#123; @Override void endPlay() &#123; System.out.println(&quot;Cricket Game Finished!&quot;); &#125; @Override void initialize() &#123; System.out.println(&quot;Cricket Game Initialized! Start playing.&quot;); &#125; @Override void startPlay() &#123; System.out.println(&quot;Cricket Game Started. Enjoy the game!&quot;); &#125;&#125; Football.java 1234567891011121314151617public class Football extends Game &#123; @Override void endPlay() &#123; System.out.println(&quot;Football Game Finished!&quot;); &#125; @Override void initialize() &#123; System.out.println(&quot;Football Game Initialized! Start playing.&quot;); &#125; @Override void startPlay() &#123; System.out.println(&quot;Football Game Started. Enjoy the game!&quot;); &#125;&#125; 步骤 3 使用 Game 的模板方法 play() 来演示游戏的定义方式。 TemplatePatternDemo.java 12345678910public class TemplatePatternDemo &#123; public static void main(String[] args) &#123; Game game = new Cricket(); game.play(); System.out.println(); game = new Football(); game.play(); &#125;&#125; 步骤 4 验证输出。 1234567Cricket Game Initialized! Start playing.Cricket Game Started. Enjoy the game!Cricket Game Finished!Football Game Initialized! Start playing.Football Game Started. Enjoy the game!Football Game Finished! 访问者模式在访问者模式（Visitor Pattern）中，我们使用了一个访问者类，它改变了元素类的执行算法。通过这种方式，元素的执行算法可以随着访问者改变而改变。这种类型的设计模式属于行为型模式。根据模式，元素对象已接受访问者对象，这样访问者对象就可以处理元素对象上的操作。意图：主要将数据结构与数据操作分离。 主要解决： 稳定的数据结构和易变的操作耦合问题。 何时使用： 需要对一个对象结构中的对象进行很多不同的并且不相关的操作，而需要避免让这些操作”污染”这些对象的类，使用访问者模式将这些封装到类中。 如何解决： 在被访问的类里面加一个对外提供接待访问者的接口。 关键代码： 在数据基础类里面有一个方法接受访问者，将自身引用传入访问者。 应用实例： 您在朋友家做客，您是访问者，朋友接受您的访问，您通过朋友的描述，然后对朋友的描述做出一个判断，这就是访问者模式。 优点： 1、符合单一职责原则。 2、优秀的扩展性。 3、灵活性。 缺点： 1、具体元素对访问者公布细节，违反了迪米特原则。 2、具体元素变更比较困难。 3、违反了依赖倒置原则，依赖了具体类，没有依赖抽象。 使用场景： 1、对象结构中对象对应的类很少改变，但经常需要在此对象结构上定义新的操作。 2、需要对一个对象结构中的对象进行很多不同的并且不相关的操作，而需要避免让这些操作”污染”这些对象的类，也不希望在增加新操作时修改这些类。 注意事项： 访问者可以对功能进行统一，可以做报表、UI、拦截器与过滤器。 实现我们将创建一个定义接受操作的 ComputerPart 接口。Keyboard、Mouse、Monitor 和 Computer 是实现了 ComputerPart 接口的实体类。我们将定义另一个接口 ComputerPartVisitor，它定义了访问者类的操作。Computer 使用实体访问者来执行相应的动作。VisitorPatternDemo，我们的演示类使用 Computer、ComputerPartVisitor 类来演示访问者模式的用法。 步骤 1 定义一个表示元素的接口。 ComputerPart.java 123public interface ComputerPart &#123; public void accept(ComputerPartVisitor computerPartVisitor);&#125; 步骤 2 创建扩展了上述类的实体类。 Keyboard.java 1234567public class Keyboard implements ComputerPart &#123; @Override public void accept(ComputerPartVisitor computerPartVisitor) &#123; computerPartVisitor.visit(this); &#125;&#125; Monitor.java 1234567public class Monitor implements ComputerPart &#123; @Override public void accept(ComputerPartVisitor computerPartVisitor) &#123; computerPartVisitor.visit(this); &#125;&#125; Mouse.java 1234567public class Mouse implements ComputerPart &#123; @Override public void accept(ComputerPartVisitor computerPartVisitor) &#123; computerPartVisitor.visit(this); &#125;&#125; Computer.java 1234567891011121314151617public class Computer implements ComputerPart &#123; ComputerPart[] parts; public Computer()&#123; parts = new ComputerPart[] &#123;new Mouse(), new Keyboard(), new Monitor()&#125;; &#125; @Override public void accept(ComputerPartVisitor computerPartVisitor) &#123; for (int i = 0; i &lt; parts.length; i++) &#123; parts[i].accept(computerPartVisitor); &#125; computerPartVisitor.visit(this); &#125;&#125; 步骤 3 定义一个表示访问者的接口。 ComputerPartVisitor.java 123456public interface ComputerPartVisitor &#123; public void visit(Computer computer); public void visit(Mouse mouse); public void visit(Keyboard keyboard); public void visit(Monitor monitor);&#125; 步骤 4 创建实现了上述类的实体访问者。 ComputerPartDisplayVisitor.java 12345678910111213141516171819202122public class ComputerPartDisplayVisitor implements ComputerPartVisitor &#123; @Override public void visit(Computer computer) &#123; System.out.println(&quot;Displaying Computer.&quot;); &#125; @Override public void visit(Mouse mouse) &#123; System.out.println(&quot;Displaying Mouse.&quot;); &#125; @Override public void visit(Keyboard keyboard) &#123; System.out.println(&quot;Displaying Keyboard.&quot;); &#125; @Override public void visit(Monitor monitor) &#123; System.out.println(&quot;Displaying Monitor.&quot;); &#125;&#125; 步骤 5 使用 ComputerPartDisplayVisitor 来显示 Computer 的组成部分。 VisitorPatternDemo.java 1234567public class VisitorPatternDemo &#123; public static void main(String[] args) &#123; ComputerPart computer = new Computer(); computer.accept(new ComputerPartDisplayVisitor()); &#125;&#125; 步骤 6 验证输出。 1234Displaying Mouse.Displaying Keyboard.Displaying Monitor.Displaying Computer. MVC 模式MVC 模式代表 Model-View-Controller（模型-视图-控制器） 模式。这种模式用于应用程序的分层开发。Model（模型） - 模型代表一个存取数据的对象或 JAVA POJO。它也可以带有逻辑，在数据变化时更新控制器。View（视图） - 视图代表模型包含的数据的可视化。Controller（控制器） - 控制器作用于模型和视图上。它控制数据流向模型对象，并在数据变化时更新视图。它使视图与模型分离开。实现我们将创建一个作为模型的 Student 对象。StudentView 是一个把学生详细信息输出到控制台的视图类，StudentController 是负责存储数据到 Student 对象中的控制器类，并相应地更新视图 StudentView。MVCPatternDemo，我们的演示类使用 StudentController 来演示 MVC 模式的用法。 步骤 1 创建模型。 Student.java 12345678910111213141516public class Student &#123; private String rollNo; private String name; public String getRollNo() &#123; return rollNo; &#125; public void setRollNo(String rollNo) &#123; this.rollNo = rollNo; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 步骤 2 创建视图。 StudentView.java 1234567public class StudentView &#123; public void printStudentDetails(String studentName, String studentRollNo)&#123; System.out.println(&quot;Student: &quot;); System.out.println(&quot;Name: &quot; + studentName); System.out.println(&quot;Roll No: &quot; + studentRollNo); &#125;&#125; 步骤 3 创建控制器。 StudentController.java 1234567891011121314151617181920212223242526272829public class StudentController &#123; private Student model; private StudentView view; public StudentController(Student model, StudentView view)&#123; this.model = model; this.view = view; &#125; public void setStudentName(String name)&#123; model.setName(name); &#125; public String getStudentName()&#123; return model.getName(); &#125; public void setStudentRollNo(String rollNo)&#123; model.setRollNo(rollNo); &#125; public String getStudentRollNo()&#123; return model.getRollNo(); &#125; public void updateView()&#123; view.printStudentDetails(model.getName(), model.getRollNo()); &#125; &#125; 步骤 4 使用 StudentController 方法来演示 MVC 设计模式的用法。 MVCPatternDemo.java 1234567891011121314151617181920212223242526public class MVCPatternDemo &#123; public static void main(String[] args) &#123; //从数据可获取学生记录 Student model = retriveStudentFromDatabase(); //创建一个视图：把学生详细信息输出到控制台 StudentView view = new StudentView(); StudentController controller = new StudentController(model, view); controller.updateView(); //更新模型数据 controller.setStudentName(&quot;John&quot;); controller.updateView(); &#125; private static Student retriveStudentFromDatabase()&#123; Student student = new Student(); student.setName(&quot;Robert&quot;); student.setRollNo(&quot;10&quot;); return student; &#125;&#125; 步骤 5 验证输出。 123456Student: Name: RobertRoll No: 10Student: Name: JohnRoll No: 10 业务代表模式业务代表模式（Business Delegate Pattern）用于对表示层和业务层解耦。它基本上是用来减少通信或对表示层代码中的业务层代码的远程查询功能。在业务层中我们有以下实体。客户端（Client） - 表示层代码可以是 JSP、servlet 或 UI java 代码。业务代表（Business Delegate） - 一个为客户端实体提供的入口类，它提供了对业务服务方法的访问。查询服务（LookUp Service） - 查找服务对象负责获取相关的业务实现，并提供业务对象对业务代表对象的访问。业务服务（Business Service） - 业务服务接口。实现了该业务服务的实体类，提供了实际的业务实现逻辑。实现我们将创建 Client、BusinessDelegate、BusinessService、LookUpService、JMSService 和 EJBService 来表示业务代表模式中的各种实体。BusinessDelegatePatternDemo，我们的演示类使用 BusinessDelegate 和 Client 来演示业务代表模式的用法。 步骤 1 创建 BusinessService 接口。 BusinessService.java 123public interface BusinessService &#123; public void doProcessing();&#125; 步骤 2 创建实体服务类。 EJBService.java 1234567public class EJBService implements BusinessService &#123; @Override public void doProcessing() &#123; System.out.println(&quot;Processing task by invoking EJB Service&quot;); &#125;&#125; JMSService.java 1234567public class JMSService implements BusinessService &#123; @Override public void doProcessing() &#123; System.out.println(&quot;Processing task by invoking JMS Service&quot;); &#125;&#125; 步骤 3 创建业务查询服务。 BusinessLookUp.java 123456789public class BusinessLookUp &#123; public BusinessService getBusinessService(String serviceType)&#123; if(serviceType.equalsIgnoreCase(&quot;EJB&quot;))&#123; return new EJBService(); &#125;else &#123; return new JMSService(); &#125; &#125;&#125; 步骤 4 创建业务代表。 BusinessDelegate.java 1234567891011121314public class BusinessDelegate &#123; private BusinessLookUp lookupService = new BusinessLookUp(); private BusinessService businessService; private String serviceType; public void setServiceType(String serviceType)&#123; this.serviceType = serviceType; &#125; public void doTask()&#123; businessService = lookupService.getBusinessService(serviceType); businessService.doProcessing(); &#125;&#125; 步骤 5 创建客户端。 Client.java 123456789101112public class Client &#123; BusinessDelegate businessService; public Client(BusinessDelegate businessService)&#123; this.businessService = businessService; &#125; public void doTask()&#123; businessService.doTask(); &#125;&#125; 步骤 6 使用 BusinessDelegate 和 Client 类来演示业务代表模式。 BusinessDelegatePatternDemo.java 1234567891011121314public class BusinessDelegatePatternDemo &#123; public static void main(String[] args) &#123; BusinessDelegate businessDelegate = new BusinessDelegate(); businessDelegate.setServiceType(&quot;EJB&quot;); Client client = new Client(businessDelegate); client.doTask(); businessDelegate.setServiceType(&quot;JMS&quot;); client.doTask(); &#125;&#125; 步骤 7 验证输出。 12Processing task by invoking EJB ServiceProcessing task by invoking JMS Service 组合实体模式组合实体模式（Composite Entity Pattern）用在 EJB 持久化机制中。一个组合实体是一个 EJB 实体 bean，代表了对象的图解。当更新一个组合实体时，内部依赖对象 beans 会自动更新，因为它们是由 EJB 实体 bean 管理的。以下是组合实体 bean 的参与者。组合实体（Composite Entity） - 它是主要的实体 bean。它可以是粗粒的，或者可以包含一个粗粒度对象，用于持续生命周期。粗粒度对象（Coarse-Grained Object） - 该对象包含依赖对象。它有自己的生命周期，也能管理依赖对象的生命周期。依赖对象（Dependent Object） - 依赖对象是一个持续生命周期依赖于粗粒度对象的对象。策略（Strategies） - 策略表示如何实现组合实体。实现我们将创建作为组合实体的 CompositeEntity 对象。CoarseGrainedObject 是一个包含依赖对象的类。CompositeEntityPatternDemo，我们的演示类使用 Client 类来演示组合实体模式的用法。 步骤 1 创建依赖对象。 DependentObject1.java 123456789101112public class DependentObject1 &#123; private String data; public void setData(String data)&#123; this.data = data; &#125; public String getData()&#123; return data; &#125;&#125; DependentObject2.java 123456789101112public class DependentObject2 &#123; private String data; public void setData(String data)&#123; this.data = data; &#125; public String getData()&#123; return data; &#125;&#125; 步骤 2 创建粗粒度对象。 CoarseGrainedObject.java 12345678910111213public class CoarseGrainedObject &#123; DependentObject1 do1 = new DependentObject1(); DependentObject2 do2 = new DependentObject2(); public void setData(String data1, String data2)&#123; do1.setData(data1); do2.setData(data2); &#125; public String[] getData()&#123; return new String[] &#123;do1.getData(),do2.getData()&#125;; &#125;&#125; 步骤 3 创建组合实体。 CompositeEntity.java 1234567891011public class CompositeEntity &#123; private CoarseGrainedObject cgo = new CoarseGrainedObject(); public void setData(String data1, String data2)&#123; cgo.setData(data1, data2); &#125; public String[] getData()&#123; return cgo.getData(); &#125;&#125; 步骤 4 创建使用组合实体的客户端类。 Client.java 12345678910111213public class Client &#123; private CompositeEntity compositeEntity = new CompositeEntity(); public void printData()&#123; for (int i = 0; i &lt; compositeEntity.getData().length; i++) &#123; System.out.println(&quot;Data: &quot; + compositeEntity.getData()[i]); &#125; &#125; public void setData(String data1, String data2)&#123; compositeEntity.setData(data1, data2); &#125;&#125; 步骤 5 使用 Client 来演示组合实体设计模式的用法。 CompositeEntityPatternDemo.java 123456789public class CompositeEntityPatternDemo &#123; public static void main(String[] args) &#123; Client client = new Client(); client.setData(&quot;Test&quot;, &quot;Data&quot;); client.printData(); client.setData(&quot;Second Test&quot;, &quot;Data1&quot;); client.printData(); &#125;&#125; 步骤 6 验证输出。 1234Data: TestData: DataData: Second TestData: Data1 数据访问对象模式数据访问对象模式（Data Access Object Pattern）或 DAO 模式用于把低级的数据访问 API 或操作从高级的业务服务中分离出来。以下是数据访问对象模式的参与者。数据访问对象接口（Data Access Object Interface） - 该接口定义了在一个模型对象上要执行的标准操作。数据访问对象实体类（Data Access Object concrete class） - 该类实现了上述的接口。该类负责从数据源获取数据，数据源可以是数据库，也可以是 xml，或者是其他的存储机制。模型对象/数值对象（Model Object/Value Object） - 该对象是简单的 POJO，包含了 get/set 方法来存储通过使用 DAO 类检索到的数据。实现 我们将创建一个作为模型对象或数值对象的 Student 对象。StudentDao 是数据访问对象接口。StudentDaoImpl 是实现了数据访问对象接口的实体类。DaoPatternDemo，我们的演示类使用 StudentDao 来演示数据访问对象模式的用法。 步骤 1 创建数值对象。 Student.java 12345678910111213141516171819202122232425public class Student &#123; private String name; private int rollNo; Student(String name, int rollNo)&#123; this.name = name; this.rollNo = rollNo; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getRollNo() &#123; return rollNo; &#125; public void setRollNo(int rollNo) &#123; this.rollNo = rollNo; &#125;&#125; 步骤 2 创建数据访问对象接口。 StudentDao.java 12345678import java.util.List;public interface StudentDao &#123; public List&lt;Student&gt; getAllStudents(); public Student getStudent(int rollNo); public void updateStudent(Student student); public void deleteStudent(Student student);&#125; 步骤 3 创建实现了上述接口的实体类。 StudentDaoImpl.java 12345678910111213141516171819202122232425262728293031323334353637383940import java.util.ArrayList;import java.util.List;public class StudentDaoImpl implements StudentDao &#123; //列表是当作一个数据库 List&lt;Student&gt; students; public StudentDaoImpl()&#123; students = new ArrayList&lt;Student&gt;(); Student student1 = new Student(&quot;Robert&quot;,0); Student student2 = new Student(&quot;John&quot;,1); students.add(student1); students.add(student2); &#125; @Override public void deleteStudent(Student student) &#123; students.remove(student.getRollNo()); System.out.println(&quot;Student: Roll No &quot; + student.getRollNo() +&quot;, deleted from database&quot;); &#125; //从数据库中检索学生名单 @Override public List&lt;Student&gt; getAllStudents() &#123; return students; &#125; @Override public Student getStudent(int rollNo) &#123; return students.get(rollNo); &#125; @Override public void updateStudent(Student student) &#123; students.get(student.getRollNo()).setName(student.getName()); System.out.println(&quot;Student: Roll No &quot; + student.getRollNo() +&quot;, updated in the database&quot;); &#125;&#125; 步骤 4 使用 StudentDao 来演示数据访问对象模式的用法。 CompositeEntityPatternDemo.java 12345678910111213141516171819202122public class DaoPatternDemo &#123; public static void main(String[] args) &#123; StudentDao studentDao = new StudentDaoImpl(); //输出所有的学生 for (Student student : studentDao.getAllStudents()) &#123; System.out.println(&quot;Student: [RollNo : &quot; +student.getRollNo()+&quot;, Name : &quot;+student.getName()+&quot; ]&quot;); &#125; //更新学生 Student student =studentDao.getAllStudents().get(0); student.setName(&quot;Michael&quot;); studentDao.updateStudent(student); //获取学生 studentDao.getStudent(0); System.out.println(&quot;Student: [RollNo : &quot; +student.getRollNo()+&quot;, Name : &quot;+student.getName()+&quot; ]&quot;); &#125;&#125; 步骤 5 验证输出。 1234Student: [RollNo : 0, Name : Robert ]Student: [RollNo : 1, Name : John ]Student: Roll No 0, updated in the databaseStudent: [RollNo : 0, Name : Michael ] 前端控制器模式前端控制器模式（Front Controller Pattern）是用来提供一个集中的请求处理机制，所有的请求都将由一个单一的处理程序处理。该处理程序可以做认证/授权/记录日志，或者跟踪请求，然后把请求传给相应的处理程序。以下是这种设计模式的实体。前端控制器（Front Controller） - 处理应用程序所有类型请求的单个处理程序，应用程序可以是基于 web 的应用程序，也可以是基于桌面的应用程序。调度器（Dispatcher） - 前端控制器可能使用一个调度器对象来调度请求到相应的具体处理程序。视图（View） - 视图是为请求而创建的对象。实现 我们将创建 FrontController、Dispatcher 分别当作前端控制器和调度器。HomeView 和 StudentView 表示各种为前端控制器接收到的请求而创建的视图。FrontControllerPatternDemo，我们的演示类使用 FrontController 来演示前端控制器设计模式。 步骤 1 创建视图。 HomeView.java 12345public class HomeView &#123; public void show()&#123; System.out.println(&quot;Displaying Home Page&quot;); &#125;&#125; StudentView.java 12345public class StudentView &#123; public void show()&#123; System.out.println(&quot;Displaying Student Page&quot;); &#125;&#125; 步骤 2 创建调度器 Dispatcher。 Dispatcher.java 12345678910111213141516public class Dispatcher &#123; private StudentView studentView; private HomeView homeView; public Dispatcher()&#123; studentView = new StudentView(); homeView = new HomeView(); &#125; public void dispatch(String request)&#123; if(request.equalsIgnoreCase(&quot;STUDENT&quot;))&#123; studentView.show(); &#125;else&#123; homeView.show(); &#125; &#125;&#125; 步骤 3 创建前端控制器 FrontController。 Context.java 1234567891011121314151617181920212223242526public class FrontController &#123; private Dispatcher dispatcher; public FrontController()&#123; dispatcher = new Dispatcher(); &#125; private boolean isAuthenticUser()&#123; System.out.println(&quot;User is authenticated successfully.&quot;); return true; &#125; private void trackRequest(String request)&#123; System.out.println(&quot;Page requested: &quot; + request); &#125; public void dispatchRequest(String request)&#123; //记录每一个请求 trackRequest(request); //对用户进行身份验证 if(isAuthenticUser())&#123; dispatcher.dispatch(request); &#125; &#125;&#125; 步骤 4 使用 FrontController 来演示前端控制器设计模式。 FrontControllerPatternDemo.java 1234567public class FrontControllerPatternDemo &#123; public static void main(String[] args) &#123; FrontController frontController = new FrontController(); frontController.dispatchRequest(&quot;HOME&quot;); frontController.dispatchRequest(&quot;STUDENT&quot;); &#125;&#125; 步骤 5 验证输出。 123456Page requested: HOMEUser is authenticated successfully.Displaying Home PagePage requested: STUDENTUser is authenticated successfully.Displaying Student Page 拦截过滤器模式拦截过滤器模式（Intercepting Filter Pattern）用于对应用程序的请求或响应做一些预处理/后处理。定义过滤器，并在把请求传给实际目标应用程序之前应用在请求上。过滤器可以做认证/授权/记录日志，或者跟踪请求，然后把请求传给相应的处理程序。以下是这种设计模式的实体。过滤器（Filter） - 过滤器在请求处理程序执行请求之前或之后，执行某些任务。过滤器链（Filter Chain） - 过滤器链带有多个过滤器，并在 Target 上按照定义的顺序执行这些过滤器。Target - Target 对象是请求处理程序。过滤管理器（Filter Manager） - 过滤管理器管理过滤器和过滤器链。客户端（Client） - Client 是向 Target 对象发送请求的对象。实现我们将创建 FilterChain、FilterManager、Target、Client 作为表示实体的各种对象。AuthenticationFilter 和 DebugFilter 表示实体过滤器。InterceptingFilterDemo，我们的演示类使用 Client 来演示拦截过滤器设计模式。 步骤 1 创建过滤器接口 Filter。 Filter.java 123public interface Filter &#123; public void execute(String request);&#125; 步骤 2 创建实体过滤器。 AuthenticationFilter.java 12345public class AuthenticationFilter implements Filter &#123; public void execute(String request)&#123; System.out.println(&quot;Authenticating request: &quot; + request); &#125;&#125; DebugFilter.java 12345public class DebugFilter implements Filter &#123; public void execute(String request)&#123; System.out.println(&quot;request log: &quot; + request); &#125;&#125; 步骤 3 创建 Target。 Target.java 12345public class Target &#123; public void execute(String request)&#123; System.out.println(&quot;Executing request: &quot; + request); &#125;&#125; 步骤 4 创建过滤器链。 FilterChain.java 12345678910111213141516171819202122import java.util.ArrayList;import java.util.List;public class FilterChain &#123; private List&lt;Filter&gt; filters = new ArrayList&lt;Filter&gt;(); private Target target; public void addFilter(Filter filter)&#123; filters.add(filter); &#125; public void execute(String request)&#123; for (Filter filter : filters) &#123; filter.execute(request); &#125; target.execute(request); &#125; public void setTarget(Target target)&#123; this.target = target; &#125;&#125; 步骤 5 创建过滤管理器。 FilterManager.java 123456789101112131415public class FilterManager &#123; FilterChain filterChain; public FilterManager(Target target)&#123; filterChain = new FilterChain(); filterChain.setTarget(target); &#125; public void setFilter(Filter filter)&#123; filterChain.addFilter(filter); &#125; public void filterRequest(String request)&#123; filterChain.execute(request); &#125;&#125; 步骤 6 创建客户端 Client。 Client.java 1234567891011public class Client &#123; FilterManager filterManager; public void setFilterManager(FilterManager filterManager)&#123; this.filterManager = filterManager; &#125; public void sendRequest(String request)&#123; filterManager.filterRequest(request); &#125;&#125; 步骤 7 使用 Client 来演示拦截过滤器设计模式。 FrontControllerPatternDemo.java 1234567891011public class InterceptingFilterDemo &#123; public static void main(String[] args) &#123; FilterManager filterManager = new FilterManager(new Target()); filterManager.setFilter(new AuthenticationFilter()); filterManager.setFilter(new DebugFilter()); Client client = new Client(); client.setFilterManager(filterManager); client.sendRequest(&quot;HOME&quot;); &#125;&#125; 步骤 8 验证输出。 123Authenticating request: HOMErequest log: HOMEExecuting request: HOME 服务定位器模式服务定位器模式（Service Locator Pattern）用在我们想使用 JNDI 查询定位各种服务的时候。考虑到为某个服务查找 JNDI 的代价很高，服务定位器模式充分利用了缓存技术。在首次请求某个服务时，服务定位器在 JNDI 中查找服务，并缓存该服务对象。当再次请求相同的服务时，服务定位器会在它的缓存中查找，这样可以在很大程度上提高应用程序的性能。以下是这种设计模式的实体。服务（Service） - 实际处理请求的服务。对这种服务的引用可以在 JNDI 服务器中查找到。Context / 初始的 Context - JNDI Context 带有对要查找的服务的引用。服务定位器（Service Locator） - 服务定位器是通过 JNDI 查找和缓存服务来获取服务的单点接触。缓存（Cache） - 缓存存储服务的引用，以便复用它们。客户端（Client） - Client 是通过 ServiceLocator 调用服务的对象。实现我们将创建 ServiceLocator、InitialContext、Cache、Service 作为表示实体的各种对象。Service1 和 Service2 表示实体服务。ServiceLocatorPatternDemo，我们的演示类在这里是作为一个客户端，将使用 ServiceLocator 来演示服务定位器设计模式。 步骤 1 创建服务接口 Service。 Service.java 1234public interface Service &#123; public String getName(); public void execute();&#125; 步骤 2 创建实体服务。 Service1.java 12345678910public class Service1 implements Service &#123; public void execute()&#123; System.out.println(&quot;Executing Service1&quot;); &#125; @Override public String getName() &#123; return &quot;Service1&quot;; &#125;&#125; Service2.java 12345678910public class Service2 implements Service &#123; public void execute()&#123; System.out.println(&quot;Executing Service2&quot;); &#125; @Override public String getName() &#123; return &quot;Service2&quot;; &#125;&#125; 步骤 3 为 JNDI 查询创建 InitialContext。 InitialContext.java 123456789101112public class InitialContext &#123; public Object lookup(String jndiName)&#123; if(jndiName.equalsIgnoreCase(&quot;SERVICE1&quot;))&#123; System.out.println(&quot;Looking up and creating a new Service1 object&quot;); return new Service1(); &#125;else if (jndiName.equalsIgnoreCase(&quot;SERVICE2&quot;))&#123; System.out.println(&quot;Looking up and creating a new Service2 object&quot;); return new Service2(); &#125; return null; &#125;&#125; 步骤 4 创建缓存 Cache。 Cache.java 123456789101112131415161718192021222324252627282930313233import java.util.ArrayList;import java.util.List;public class Cache &#123; private List&lt;Service&gt; services; public Cache()&#123; services = new ArrayList&lt;Service&gt;(); &#125; public Service getService(String serviceName)&#123; for (Service service : services) &#123; if(service.getName().equalsIgnoreCase(serviceName))&#123; System.out.println(&quot;Returning cached &quot;+serviceName+&quot; object&quot;); return service; &#125; &#125; return null; &#125; public void addService(Service newService)&#123; boolean exists = false; for (Service service : services) &#123; if(service.getName().equalsIgnoreCase(newService.getName()))&#123; exists = true; &#125; &#125; if(!exists)&#123; services.add(newService); &#125; &#125;&#125; 步骤 5 创建服务定位器。 ServiceLocator.java 123456789101112131415161718192021public class ServiceLocator &#123; private static Cache cache; static &#123; cache = new Cache(); &#125; public static Service getService(String jndiName)&#123; Service service = cache.getService(jndiName); if(service != null)&#123; return service; &#125; InitialContext context = new InitialContext(); Service service1 = (Service)context.lookup(jndiName); cache.addService(service1); return service1; &#125;&#125; 步骤 6 使用 ServiceLocator 来演示服务定位器设计模式。 ServiceLocatorPatternDemo.java 123456789101112public class ServiceLocatorPatternDemo &#123; public static void main(String[] args) &#123; Service service = ServiceLocator.getService(&quot;Service1&quot;); service.execute(); service = ServiceLocator.getService(&quot;Service2&quot;); service.execute(); service = ServiceLocator.getService(&quot;Service1&quot;); service.execute(); service = ServiceLocator.getService(&quot;Service2&quot;); service.execute(); &#125;&#125; 步骤 7 验证输出。 12345678Looking up and creating a new Service1 objectExecuting Service1Looking up and creating a new Service2 objectExecuting Service2Returning cached Service1 objectExecuting Service1Returning cached Service2 objectExecuting Service2 传输对象模式传输对象模式（Transfer Object Pattern）用于从客户端向服务器一次性传递带有多个属性的数据。传输对象也被称为数值对象。传输对象是一个具有 getter/setter 方法的简单的 POJO 类，它是可序列化的，所以它可以通过网络传输。它没有任何的行为。服务器端的业务类通常从数据库读取数据，然后填充 POJO，并把它发送到客户端或按值传递它。对于客户端，传输对象是只读的。客户端可以创建自己的传输对象，并把它传递给服务器，以便一次性更新数据库中的数值。以下是这种设计模式的实体。业务对象（Business Object） - 为传输对象填充数据的业务服务。传输对象（Transfer Object） - 简单的 POJO，只有设置/获取属性的方法。客户端（Client） - 客户端可以发送请求或者发送传输对象到业务对象。实现我们将创建一个作为业务对象的 StudentBO 和作为传输对象的 StudentVO，它们都代表了我们的实体。TransferObjectPatternDemo，我们的演示类在这里是作为一个客户端，将使用 StudentBO 和 Student 来演示传输对象设计模式。 步骤 1 创建传输对象。 StudentVO.java 12345678910111213141516171819202122232425public class StudentVO &#123; private String name; private int rollNo; StudentVO(String name, int rollNo)&#123; this.name = name; this.rollNo = rollNo; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getRollNo() &#123; return rollNo; &#125; public void setRollNo(int rollNo) &#123; this.rollNo = rollNo; &#125;&#125; 步骤 2 创建业务对象。 StudentBO.java 123456789101112131415161718192021222324252627282930313233343536import java.util.ArrayList;import java.util.List;public class StudentBO &#123; //列表是当作一个数据库 List&lt;StudentVO&gt; students; public StudentBO()&#123; students = new ArrayList&lt;StudentVO&gt;(); StudentVO student1 = new StudentVO(&quot;Robert&quot;,0); StudentVO student2 = new StudentVO(&quot;John&quot;,1); students.add(student1); students.add(student2); &#125; public void deleteStudent(StudentVO student) &#123; students.remove(student.getRollNo()); System.out.println(&quot;Student: Roll No &quot; + student.getRollNo() +&quot;, deleted from database&quot;); &#125; //从数据库中检索学生名单 public List&lt;StudentVO&gt; getAllStudents() &#123; return students; &#125; public StudentVO getStudent(int rollNo) &#123; return students.get(rollNo); &#125; public void updateStudent(StudentVO student) &#123; students.get(student.getRollNo()).setName(student.getName()); System.out.println(&quot;Student: Roll No &quot; + student.getRollNo() +&quot;, updated in the database&quot;); &#125;&#125; 步骤 3 使用 StudentBO 来演示传输对象设计模式。 TransferObjectPatternDemo.java 123456789101112131415161718192021public class TransferObjectPatternDemo &#123; public static void main(String[] args) &#123; StudentBO studentBusinessObject = new StudentBO(); //输出所有的学生 for (StudentVO student : studentBusinessObject.getAllStudents()) &#123; System.out.println(&quot;Student: [RollNo : &quot; +student.getRollNo()+&quot;, Name : &quot;+student.getName()+&quot; ]&quot;); &#125; //更新学生 StudentVO student =studentBusinessObject.getAllStudents().get(0); student.setName(&quot;Michael&quot;); studentBusinessObject.updateStudent(student); //获取学生 studentBusinessObject.getStudent(0); System.out.println(&quot;Student: [RollNo : &quot; +student.getRollNo()+&quot;, Name : &quot;+student.getName()+&quot; ]&quot;); &#125;&#125; 步骤 4 验证输出。 1234Student: [RollNo : 0, Name : Robert ]Student: [RollNo : 1, Name : John ]Student: Roll No 0, updated in the databaseStudent: [RollNo : 0, Name : Michael ] 相关资料本章列出了设计模式相关的网站、书籍和文章。 设计模式相关的网站 Wiki Page for Design Patterns) - 以一种非常通用的方式检查设计模式。Java Programming/Design Patterns - 一篇关于设计模式的好文章。The JavaTM Tutorials - 该 Java 教程是为那些想用 Java 编程语言创建应用程序的编程人员提供的实用指南。JavaTM 2 SDK, Standard Edition - JavaTM 2 SDK, Standard Edition 的官网。Java DesignPatterns - 关于设计模式的短文。 Java 设计模式有用的书籍Java Design PatternsHead First Design PatternsJava Design Pattern EssentialsDesign Patterns: Elements of Reusable Object-Oriented SoftwareDesign Patterns in Java(TM)Design Patterns Java Workbook 原文地址]]></content>
      <categories>
        <category>design patterns</category>
      </categories>
      <tags>
        <tag>Singleton Pattern</tag>
        <tag>Factory Pattern</tag>
        <tag>Proxy Pattern</tag>
        <tag>MVC Pattern</tag>
        <tag>Intercepting Filter Pattern</tag>
        <tag>Iterator Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发编程之线程池ThreadPoolExecutor]]></title>
    <url>%2F2017%2F08%2F06%2F%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E7%BA%BF%E7%A8%8B%E6%B1%A0ThreadPoolExecutor%2F</url>
    <content type="text"><![CDATA[ThreadPoolExecutor当前越来越多的系统使用多线程来处理任务，但是为每一个任务创建线程并不是合理的方案，原因有2点：一是创建线程的开销很大，一个任务一个线程的方式会有性能上的损失；二是可能导致线程数量的膨胀，不但不易于线程的管理，还可能导致内存被消耗完，导致out of memory（OOM）,从而使系统崩溃。为了解决这个问题，线程池应运而生。线程池有两个作用：一个是限制线程的数量，不会导致线程的膨胀；二是线程复用，线程执行完一个人任务之后，可以接着执行下一个任务，减少了创建线程的开销。 java中一个运用非常普遍的线程池是ThreadPoolExecutor。下面来探究下ThreadPoolExecutor的功能和实现原理。ThreadPoolExecutor的功能 自定义线程池的核心线程数和最大线程数。如果当前池中的线程数小于核心线程数，则直接为任务创建新线程来执行，如果前池中的线程数大于核心线程数，则把任务放入任务队列中，等待线程池中已有的线程去执行。如果任务队列满了，但是池中的线程数小于最大线程数，则创建新线程执行任务。如果任务队列满了，池中的线程数等于最大线程数，那么执行拒绝任务策略。 可配置拒绝任务策略，ThreadPoolExecutor自带了四种拒绝策略：丢弃当前将要加入队列的任务本身（DiscardPolicy），丢弃任务队列中最旧任务（DiscardOldestPolicy），抛出异常的方式（AbortPolicy），将任务交由调用者线程去执行（CallerRunsPolicy），除了自带的策略之外，用户还可以自定义策略。 线程声明周期管理。如果线程空闲时间超过了配置的时间keepAliveTime，则线程将被销毁。 配置线程工厂，用户可以自定义创建线程的工厂。 配置阻塞队列类型。 线程池生命周期管理。可以强制shutdown线程池，也可以优雅shutdown线程池。 为了实现上面的配置管理。ThreadPoolExecutor提供了不同的创建线程池的构造方法，用户可以根据自身实际情况选择。 ThreadPoolExecutor实现原理 ThreadPoolExecutor的属性 属性名 属性说明 volatile int runState runState主要提供了生命周期的控制，下面是主要的状态：RUNNING：0。接收新任务以及处理队列中的任务SHUTDOWN：1。不再接收新任务，但是处理队列中的任务STOP：2。不再接收新任务，也不处理队列中的任务，同时中断正在执行的任务TERMINATED：3。跟STOP相同，同时所有的线程都终止了。 BlockingQueue workQueue 任务队列 ReentrantLock mainLock 为poolSize, corePoolSize,maximumPoolSize, runState, and workers属性的set提供同步。 HashSet workers 保存线程池中所有的工作线程，只有获得mainLock锁才能访问 volatile long keepAliveTime 空闲线程的最大存活时间 volatile boolean allowCoreThreadTimeOut 核心线程是否也支持最大存活时间管理 volatile int corePoolSize 线程池核心线程数 volatile int maximumPoolSize 线程池最大线程数 volatile int poolSize 线程池当前线程数 int largestPoolSize 线程池峰值线程数 long completedTaskCount 线程池总共处理的任务数 volatile RejectedExecutionHandler handler 任务拒绝策略 volatile ThreadFactory threadFactory 创建线程工厂 ThreadPoolExecutor的属性，基本上大部分都是构造函数中可配置的，也说明了ThreadPoolExecutor的灵活性。不过通过上面的表大家可能会有点疑惑：怎么没有保存Thread对象集合的属性？不要急，大家应该发现了里面有个HashSet workers属性。这个集合里Worker对象是ThreadPoolExecutor定义的一个内部类，它包含了thread对象。现在我们来看下Worker对象包含的属性。 Worker对象的属性 属性名称 属性说明 inal ReentrantLock runLock 这个锁的作用是保护取消worker线程的中断，而不是中断正在执行的任务。 Runnable firstTask 由于线程池创建现在的时候都是为某个任务创建，所以该属性就是记录该刚线程创建时执行的任务 long completedTasks 这个线程执行的任务数 Thread thread 本worker运行的线程 volatile boolean hasRun 本worker对象运行的线程是否执行过该worker的run方法。只有hasRun为true时worker的线程才能被中断。 ThreadPoolExecutor的任务处理流程 前面介绍了ThreadPoolExecutor的属性以及需要用到的内部类，素材有了，那么下面来看看是如何来把素材加工成成品的吧。在用户创建完线程池之后，需要把任务提交给线程池，线程池提供了submit和execute方法来提交任务，而submit方法最终还是调用的execute方法，它只是把任务封装成futuretask，以便获得任务的返回值。对于没有返回值的任务直接用execute提交就可以了，如果有返回值的任务，用submit提交更好。所以提交任务的核心还是execute方法。现在就来看看execute的实现代码： 1.public void execute(Runnable command) { 2. if (command == null) 3. throw new NullPointerException(); 4. if (poolSize &gt;= corePoolSize || !addIfUnderCorePoolSize(command)) { 5. if (runState == RUNNING &amp;&amp; workQueue.offer(command)) { 6. if (runState != RUNNING || poolSize == 0) 7. ensureQueuedTaskHandled(command); 8. } 9. else if (!addIfUnderMaximumPoolSize(command)) 10. reject(command); // is shutdown or saturated 11. } 12. } 这段代码的主要逻辑如下： 1.如果当选线程数大于等于核心线程数，则直接把任务放到任务队列里，等待已有的线程去执行它。如果当前选线程数小于核心线程数，则为该任务创建新的线程去执行它，这个的功能的实现方法是addIfUnderCorePoolSize(command)如下： 123456789101112private boolean addIfUnderCorePoolSize(Runnable firstTask) &#123; Thread t = null; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; if (poolSize &lt; corePoolSize &amp;&amp; runState == RUNNING) t = addThread(firstTask); &#125; finally &#123; mainLock.unlock(); &#125; return t != null; &#125; 可以发现，这段源码是如果发现小于corePoolSize就会调用addThread()方法创建一个新的线程，并且调用线程的start()方法将线程运行起来。只有没有创建成功Thread才会返回false，也就是当当前的poolSize &gt; corePoolSize的时候，或线程池已经不是在running状态的时候才会出现。execute对poolSize和corePoolSize的比较只是粗略判断，而addIfUnderCorePoolSize（）内部是加锁后判定的，以得到更为准确的结果，而外部初步判定如果是大于了，就没有必要进入这段有锁的代码了。 2.如果addIfUnderCorePoolSize返回false，说明没有为任务创建线程（原因可能是线程池不是RUNNING状态，或者poolsize大于corepoolsize了）。则需要把任务存放到任务队列中。 3.在任务放到队列之前，先初步判断下此时线程池的状态。如果是running才接受新任务，否则addIfUnderMaximumPoolSize方法精确线程池状态。 4.如果任务可以添加到任务队列，则判调用队列的offer方法，往队列末尾加入任务。由于队列是一个自定义的阻塞队列，可以是有界也可以是无界的。如果加入队列成功，还有先判断下runState != RUNNING || poolSize == 0。前面判断了状态之后为什么还要判断呢？这是因为有时间差，状态随时可以发生改变。记住了这一点在看这样一堆状态判断就不会难以理解了。好了，如果线程池不是RUNNING状态或线程池里没有线程了，则执行ensureQueuedTaskHandled方法处理任务如下： 12345678910111213141516171819private void ensureQueuedTaskHandled(Runnable command) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); boolean reject = false; Thread t = null; try &#123; int state = runState; if (state != RUNNING &amp;&amp; workQueue.remove(command)) reject = true; else if (state &lt; STOP &amp;&amp; poolSize &lt; Math.max(corePoolSize, 1) &amp;&amp; !workQueue.isEmpty()) t = addThread(null); &#125; finally &#123; mainLock.unlock(); &#125; if (reject) reject(command); &#125; 这段代码是处理拒绝任务的。这里也会加锁来锁定当前的状态和工作队列。如果状态确实不等于running，则把任务从任务列表中移除并执行拒绝策略。如果任务remove失败，并且当前状态为running和shutdown状态，任务队列不为空，并且poolSize小于Math.max(corePoolSize, 1)。则调用addThread为线程池创建一个新线程。但是这个任务并没有直接给新线程执行。为什么要判断poolSize小于Math.max(corePoolSize, 1)，因为corePoolSize可以设置为0.当corePoolSize=0时，需要至少有1个线程去执行任务。前面的几个方法中出现了几次创建addThread的方法，现在来看看这个方法做了哪些事情： 1234567891011121314151617181920212223private Thread addThread(Runnable firstTask) &#123; Worker w = new Worker(firstTask); Thread t = threadFactory.newThread(w); boolean workerStarted = false; if (t != null) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); w.thread = t; workers.add(w); int nt = ++poolSize; if (nt &gt; largestPoolSize) largestPoolSize = nt; try &#123; t.start(); workerStarted = true; &#125; finally &#123; if (!workerStarted) workers.remove(w); &#125; &#125; return t; &#125; 这个方法的参数名firstTask可能比较难理解。这里详细说明一下：首先在线程池中，一个新线程的创建大多数情况都是为执行某个任务而创建的，这个任务不会加入任务队列，而是通过firstTask传给为他而建的新线程去执行。所以这个任务也就是这个线程执行的第一个任务。如果firstTask设为null，那么线程将去执行任务队列中的任务。下面来分析这个方法的功能，首先先创建一个worker对象，把firstTask初始化这个worker对象。然后通过线程工厂创建一个线程，并检查这个线程的状态，同时跟新线程池的峰值线程数的值。需要注意的是，这个线程不是属于某个具体任务的，而是属于这个worker的，即该线程不是执行某个任务的run，而是执行这个worker的run。最后把worker对象添加到worker队列里面。所以发到这里可以明白了ThreadPoolExecutor为什么没有thread的集合属性了。5.第4点阐述了任务加入队列成功的情况，但是如果队列满了加入队列也可能失败。这时候会去尝试创建新线程来执行该任务。即执行addIfUnderMaximumPoolSize方法。这个方法与addIfUnderCorePoolSize基本一致，只是后者是拿poolSize跟corePoolSize比较，而前者是拿poolSize跟maximumPoolSize比较。如果addIfUnderMaximumPoolSize方法为任务创建线程失败，则执行拒绝策略来处理这个任务。到目前为止，前面讲的5个步骤将了一个任务提交给线程池之后是如何处理的。但是细心的用户可能发现，里面缺失了非常重要的一个功能：任务被添加到任务队列之后是如何被线程池处理掉的？线程处理完它的首个任务之后是如何获取新任务的呢？线程池是不是有类似Timer一样的守护进程不断扫描线程队列和等待队列？还是利用某种锁机制，实现类似wait和notify实现的？ 别急。下面来揭开它的神秘面纱。前面提到了ThreadPoolExecutor的内部类Worker，也在介绍addThread方法的时候提到了线程池的线程是和Worker对象绑定在一起的。所以现在来看看Worker类做了什么事情？通过代码发现Worker的定义也是一个Runnable。addthread方法中调用了这个Worker的start()方法，也就是线程的启动方法，其实也就是调用了Worker的run()方法。现在来看看worker的run方法做了什么事情： 1234567891011121314public void run() &#123; try &#123; hasRun = true; Runnable task = firstTask; firstTask = null; while (task != null || (task = getTask()) != null) &#123; runTask(task); task = null; &#125; &#125; finally &#123; workerDone(this); &#125; &#125; &#125; woker的run方法主要是通过while循环不断调用getTask()方法去获取任务。然后执行runTask(task)方法来执行任务，最后调用workerDone()方法来执行一些清除操作。 runTask(task)其实做的事情很简单：它的核心就是调用任务的run方法来执行真正的用户任务，除此之外还执行了任务执行前后需要的一些操作，以及统计一下这个worker完成的任务数。这个方法不需要深究，代码也比较简单： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556private void runTask(Runnable task) &#123; final ReentrantLock runLock = this.runLock; runLock.lock(); try &#123; if ((runState &gt;= STOP || (Thread.interrupted() &amp;&amp; runState &gt;= STOP)) &amp;&amp; hasRun) thread.interrupt(); boolean ran = false; beforeExecute(thread, task); try &#123; task.run(); ran = true; afterExecute(task, null); ++completedTasks; &#125; catch (RuntimeException ex) &#123; if (!ran) afterExecute(task, ex); throw ex; &#125; &#125; finally &#123; runLock.unlock(); &#125; &#125; ``` worker的润方法真正的核心是如果不断获取任务的。所以这里必须认真解读下getTask()方法，下面是getTask()的代码： ``` Runnable getTask() &#123; for (;;) &#123; try &#123; int state = runState; if (state &gt; SHUTDOWN) return null; Runnable r; if (state == SHUTDOWN) // Help drain queue r = workQueue.poll(); else if (poolSize &gt; corePoolSize || allowCoreThreadTimeOut) r = workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS); else r = workQueue.take(); if (r != null) return r; if (workerCanExit()) &#123; if (runState &gt;= SHUTDOWN) // Wake up others interruptIdleWorkers(); return null; &#125; // Else retry &#125; catch (InterruptedException ie) &#123; // On interruption, re-check runState &#125; &#125; &#125; 你会发现getTask()方法是从workQueue队列中，也就是等待队列中获取一个任务出来并返回！如果没有获得任务，则通过 interruptIdleWorkers()方法去关闭空闲时间超过阈值的空闲线程。 至此，完整的ThreadPoolExecutor线程池处理任务的原理就解读完毕了。其他的一些诸如关闭线程池和获取线程池的状态和统计信息等的接口都比较简单，这里就不一一解释了。 常见线程池1. newSingleThreadExecutor。只有一个线程的线程池，即corePoolSize和maximumPoolSize都等于1。2. newCachedThreadPool创建一个可根据需要创建新线程的线程池，但是在以前构造的线程可用时将重用它们。对于执行很多短期异步任务的程序而言，这些线程池通常可提高程序性能。调用 execute 将重用以前构造的线程（如果线程可用）。如果现有线程没有可用的，则创建一个新线程并添加到池中。终止并从缓存中移除那些已有 60 秒钟未被使用的线程。因此，长时间保持空闲的线程池不会使用任何资源。在newCachedThreadPool构造参数中，corePoolSize=0，maximumPoolSize=Integer.MAX_VALUE，即可与无限制的创建线程。但是它使用的是阻塞队列是SynchronousQueue。这个队列比较奇葩，虽然他是无界的，但是里面只能有一个元素。在添加一个任务的时候，必须要有一个线程正在等待一个任务。即通过这个阻塞队列，既可以保证任务能够马上得到线程去运行，同时又能重用已有的空闲线程。3. newFixedThreadPool线程数固定的线程池，即corePoolSize=maximumPoolSize。当线程数达到了corePoolSize时，不能创建新的线程了，所以新的任务只能放到任务队列中，因此这个线程池用的阻塞队列是无界队列LinkedBlockingQueue。4. ScheduledThreadPoolExecutor可以执行延迟固定时间的任务，也可以执行定时任务的线程池。ScheduledThreadPoolExecutor的底层不是基于ThreadPoolExecutor实现的，它有一个自己的实现类。 其实我们的要求很简单，希望线程池能跟连接池一样，能设置最小线程数、最大线程数，当最小数&lt;任务&lt;最大数时，应该分配新的线程处理；当任务&gt;最大数时，应该等待有空闲线程再处理该任务。但线程池的设计思路是，任务应该放到Queue中，当Queue放不下时再考虑用新线程处理，如果Queue满且无法派生新线程，就拒绝该任务。设计导致“先放等执行”、“放不下再执行”、“拒绝不等待”。所以，根据不同的Queue参数，要提高吞吐量不能一味地增大maximumPoolSize。当然，要达到我们的目标，必须对线程池进行一定的封装，幸运的是ThreadPoolExecutor中留了足够的自定义接口以帮助我们达到目标。我们封装的方式是： 以SynchronousQueue作为参数，使maximumPoolSize发挥作用，以防止线程被无限制的分配，同时可以通过提高maximumPoolSize来提高系统吞吐量 自定义一个RejectedExecutionHandler，当线程数超过maximumPoolSize时进行处理，处理方式为隔一段时间检查线程池是否可以执行新Task，如果可以把拒绝的Task重新放入到线程池，检查的时间依赖keepAliveTime的大小。 线程池的两个核心队列 线程等待池，即线程队列BlockingQueue。 任务处理池（PoolWorker），即正在工作的Thread列表（HashSet）。线程池的核心参数： 核心池大小（corePoolSize），即固定大小，设定好之后，线程池的稳定峰值，达到这个值之后池的线程数大小不会释放。 最大处理线程池数（maximumPoolSize），当线程池里面的线程数超过corePoolSize，小于maximumPoolSize时会动态创建与回收线程池里面的线程池资源。 线程池的运行机制： 举个例子。假如有一个工厂，工厂里面有10个人，每个工人同时只能做一件事情。因此只要当10个工人中有工人是空闲的，来了任务就分配给空闲的工人做；当10个工人都有任务时，如果还来任务，就把任务进行排队等待。如果说新任务数目增长的速度远远大于工作做任务的速度，那么此时工厂的主管可能就需要采取补救措施了，比如重新招4个工人进来；然后就将任务分配给这4个刚招进来的工人处理。如果说这14个工人做任务的速度还是不够，此时工厂主管就要考虑不再接受新的任务或者抛弃前面的一些任务了。当这14个工人当中有人空闲时，而新任务增长的速度又比较缓慢，工厂主管就要考虑辞掉4个临时工了，只保持原来10个工人，比较额外的工人是需要花费的。而这个例子中永远等待干活的10个工人机制就是workerQueue。这个栗子中的corePoolSize就是10，而maximumPoolSize就是14（10+4）。也就是说corePoolSize就是线程池的大小，maximumPoolSize在我看来就是一种线程池任务超过负荷的一种补救措施，即任务量突然过大时的一种补救措施。再看看下面图好好理解一下。工人永远在等待干活，就像workerQueue永远在循环干活一样，除非，整个线程池停止了。 线程池里面的线程的时序图如下图所示： 自定义线程池与ExecutorService自定义线程池需要用到ThreadFactory，本节将通过创建一个线程的例子对ExecutorService及其参数进行详细讲解。1.认识ExecutorService家族 ExecutorService家族成员如下所示： 上图中主要元素说明如下：Executor：线程池的顶级接口，但是严格意义上讲Executor并不是一个线程池，而只是一个执行线程的工具。ExecutorService：真正线程池接口。这个接口继承了Executor接口，并声明了一些方法：submit、invokeAll、invokeAny以及shutDown等。ThreadPoolExecutor：ExecutorService的默认实现，继承了类AbstractExecutorService。ScheduledExecutorService：与Timer/TimerTask类似，解决那些需要任务重复执行的问题。ScheduledThreadPoolExecutor：继承ThreadPoolExecutor的ScheduledExecutorService接口实现，周期性任务调度的类实现。Executors是个线程工厂类，方便我们快速地创建线程池。 2.利用ThreadFactory创建一个线程Java.util.concurrent.ThreadFactory提供了一个创建线程的工厂的接口。ThreadFactory源码如下： 1234public interface ThreadFactory&#123; @override public Thread newThread(Runnable r);&#125; 我们可以看到上面的接口类中有一个newThread()的方法，为此我们自己手动定义一个线程工厂类，有木有激动啊，呵呵，下面我们就手动写一个自己的线程工厂类吧！ 123456public class MyThreadFactory implements ThreadFactory&#123; @Override public Thread newThread(Runnable r)&#123; return new Thread(r); &#125;&#125; 上面已经创建好了我们自己的线程工厂类，但是啥都没有做，就是直接new了一个Thread就返回回去了，我们一般在创建线程的时候，都需要定义其线程的名字，因为我们在定义了线程的名字之后就能在出现问题的时候根据监视工具来查找错误的来源，所以我们来看下官方实现的ThreadFactory吧！这个类在java.util.concurrent.Executors类中的静态类中DefaultThreadFactory 12345678910111213141516171819202122/*** The default thread factory*/static class DefaultThreadFactory implements ThreadFactory&#123; private static final AtomicInteger poolNumber=new AtomicInteger(1); private final ThreadGroup group; private final AtomicInteger threadNumber=new AtomicInteger(1); private final String namePrefix; DefaultThreadFactory()&#123; SecurityManager s=System.getSecurityManager(); group=(s!=null)?s.getThreadGroup():Thread.currentThread().getThreadGroup(); namePrefix=&quot;pool-&quot;+poolNumber.getAndIncrement()+&quot;-thread-&quot;; &#125; public Thread newThread(Runnable r)&#123; Thread t=new Thread(group,r,namePrefix+threadNumber.getAndIncrement(),0); if((t.isDaemon()) t.setDaemon(false); if(t.getPriority()!=Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; &#125;&#125; 3.了解线程池的拒绝策略(RejectExecutionHandler)当调用ThreadPoolExecutor的execute方法时，而此时线程池处于一个饱和的状态，并且任务队列也已经满了那么就需要做丢弃处理，RejectExecutionHandler就是这样的一个处理接口类。 12345678910111213141516171819public interface RejectedExecutionHandler &#123; /** * Method that may be invoked by a &#123;@link ThreadPoolExecutor&#125; when * &#123;@link ThreadPoolExecutor#execute execute&#125; cannot accept a * task. This may occur when no more threads or queue slots are * available because their bounds would be exceeded, or upon * shutdown of the Executor. * * &lt;p&gt;In the absence of other alternatives, the method may throw * an unchecked &#123;@link RejectedExecutionException&#125;, which will be * propagated to the caller of &#123;@code execute&#125;. * * @param r the runnable task requested to be executed * @param executor the executor attempting to execute this task * @throws RejectedExecutionException if there is no remedy */ void rejectedExecution(Runnable r, ThreadPoolExecutor executor);&#125; 在JDK里面有4种拒绝策略，如下图所示： AbortPolicy：一言不合就抛异常（默认使用策略）。 CallerRunsPolicy：只用调用者所在线程来运行任务。 DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。 DiscardPolicy：不处理，直接丢弃。 来看下源码吧： 123456789101112131415161718192021222324AbortPolicy : 一言不合就抛异常的 /** * A handler for rejected tasks that throws a * &#123;@code RejectedExecutionException&#125;. */ public static class AbortPolicy implements RejectedExecutionHandler &#123; /** * Creates an &#123;@code AbortPolicy&#125;. */ public AbortPolicy() &#123; &#125; /** * Always throws RejectedExecutionException. * * @param r the runnable task requested to be executed * @param e the executor attempting to execute this task * @throws RejectedExecutionException always. */ public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; throw new RejectedExecutionException(&quot;Task &quot; + r.toString() + &quot; rejected from &quot; + e.toString()); &#125; &#125; CallerRunsPolicy：调用者所在线程来运行任务 12345678910111213141516171819202122232425/** * A handler for rejected tasks that runs the rejected task * directly in the calling thread of the &#123;@code execute&#125; method, * unless the executor has been shut down, in which case the task * is discarded. */public static class CallerRunsPolicy implements RejectedExecutionHandler &#123; /** * Creates a &#123;@code CallerRunsPolicy&#125;. */ public CallerRunsPolicy() &#123; &#125; /** * Executes task r in the caller&apos;s thread, unless the executor * has been shut down, in which case the task is discarded. * * @param r the runnable task requested to be executed * @param e the executor attempting to execute this task */ public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; r.run(); &#125; &#125;&#125; DiscardOldestPolicy :丢弃队列里面最近的一个任务,并执行当前任务 123456789101112131415161718192021222324252627/** * A handler for rejected tasks that discards the oldest unhandled * request and then retries &#123;@code execute&#125;, unless the executor * is shut down, in which case the task is discarded. */public static class DiscardOldestPolicy implements RejectedExecutionHandler &#123; /** * Creates a &#123;@code DiscardOldestPolicy&#125; for the given executor. */ public DiscardOldestPolicy() &#123; &#125; /** * Obtains and ignores the next task that the executor * would otherwise execute, if one is immediately available, * and then retries execution of task r, unless the executor * is shut down, in which case task r is instead discarded. * * @param r the runnable task requested to be executed * @param e the executor attempting to execute this task */ public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; e.getQueue().poll(); e.execute(r); &#125; &#125;&#125; DiscardPolicy : 不处理，直接丢弃 12345678910111213141516171819/** * A handler for rejected tasks that silently discards the * rejected task. */ public static class DiscardPolicy implements RejectedExecutionHandler &#123; /** * Creates a &#123;@code DiscardPolicy&#125;. */ public DiscardPolicy() &#123; &#125; /** * Does nothing, which has the effect of discarding task r. * * @param r the runnable task requested to be executed * @param e the executor attempting to execute this task */ public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; &#125; &#125; 思考问题：为什么有任务拒绝的情况发生呢：这里先假设有一个前提：线程池里面有一个任务队列，用于缓存所有待处理的任务，正在处理的任务将从任务队列中移除。因此，在任务队列长度有限的情况下，就会出现现任务的拒绝情况，需要一种策略来处理发生这种已满无法加入的情况。另外，在线程池关闭的时候，也需要对任务加入队列操作进行额外的协调处理。 4.ThreadPoolExecutor详解 ThreadPoolExecutor类是线程池中最核心的一个类，因此如果要想透彻的了解Java线程池，必须先了解这个大BOSS，下面来看下其源码： 4种构造方法： 12345678910111213141516171819202122232425262728public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,Executors.defaultThreadFactory(), defaultHandler);&#125;public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,threadFactory, defaultHandler);&#125;public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), handler);&#125;public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory,RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; 通过源码我们清楚的看到，最终构造函数调用了最后一个构造函数，后面的那个构造函数才是真正的构造函数，接下来研究一下参数。 int corePoolSize：核心池大小，这个参数跟后面讲的线程池原理有很大的关系。在创建了线程池之后，默认情况下，线程池中并没有任何线程，而是等待所有的任务到来之时才进行创建线程去执行任务，除非调用了prestartAllCoreThreads()或者prestartCoreThread()方法 ，从这个两个方法的名字可以知道是预创建线程的意思，即在没有任务来临之前先创建好corePoolSize个线程或者一个线程。默认情况下，在创建好线程池之后，线程池中的线程数为0，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数量达到corePoolSize后，就会把达到的任务放到缓存队列中去。 int maximumPoolSize：线程池最大线程数量，这是个非常重要的参数，它表示在线程池中最多能创建线程的数量；在corePoolSize和maximumPoolSize的线程数会被自动释放，而小于corePoolSize的则不会。 long keepAliveTime：表示线程没有执行任务时最多保持多久时间会终止。默认情况下，只有当线程池中的线程数大于corePoolSize时，keepAliveTime才会生效,直到线程池数量不大于corePoolSize，即只有当线程池数量大于corePoolSize数量，超出这个数量的线程一旦到达keepAliveTime就会终止。但是如果调用了allowCoreThreadTimeout(boolean)方法，即使线程池的线程数量不大于corePoolSize，线程也会在keepAliveTime之后就终止，知道线程池的数量为0为止。 TimeUnit unit：参数keepAliveTime的时间单位，一个时间单位枚举类。 BlockingQueue workQueue：一个阻塞队列，用来存储等待执行任务的队列，这个参数选择也很重要，会对线程池的运行过程产生重大影响，一般来说，这里的阻塞队列就是（ArrayBlockingQueue、LinkedBlockingQueue、SynchronousQueue；）。 ThreadFactory ThreadFactory：线程工厂，主要用来创建线程；可以是一个自定义的线程工厂，默认就是Executors.defaultThreadFactory()。用来在线程池中创建线程。 RejectedExecutionHandler handler：表示当拒绝处理任务时的策略，也是可以自定义的，默认是我们前面的4种取值： ThreadPoolExecutor.AbortPolicy（默认的，一言不合即抛异常的） ThreadPoolExecutor.DiscardPolicy（一言不合就丢弃任务） ThreadPoolExecutor.DiscardOldestPolicy（一言不合就把最近的任务给抛弃，然后执行当前任务） ThreadPoolExecutor.CallerRunsPolicy（由调用者所在线程来执行任务）所以想自定义线程池就可以从上面的几个参数入手。接下来具体看下代码,了解一下实现原理： // 默认异常处理机制 private static final RejectedExecutionHandler defaultHandler = new AbortPolicy(); //任务缓存队列，用来存放等待执行的任务 private final BlockingQueue workQueue; //线程池的主要状态锁，对线程状态（比如线程大小、runState等）的改变都需要这个锁 private final ReentrantLock mainLock = new ReentrantLock(); //用来存放工作集 private final HashSet workers = new HashSet(); //volatile 可变变量关键字，写的时候用mainLock做锁，读的时候无锁，高性能 private volatile long keepAliveTime; //是否允许核心线程超时 private volatile boolean allowCoreThreadTimeOut; //核心线程数量 private volatile int corePoolSize; //线程最大线程数量 private volatile int maximumPoolSize; //任务拒绝策略 private volatile RejectedExcutionHandler handler;结合之前的知识，大概就能猜出里面是怎么实现的了，具体可以参考一下JDK的源代码，这样我们就能做到了解原理又会用了。 5.自定义实现一个简单的Web请求连接池我们来自定义一个简单的Web请求线程池。模仿Web服务的需求场景说明如下： 服务器可容纳的最小请求数是多少。 可以动态扩充的请求数大小是多少。 多久回收多余线程数即请求数。 用户访问量打了怎么处理。 线程队列机制采取有优先级的排队的执行机制。根据上面的场景，看下这个线程池如何编写？ 1234567public class MyExecutors extends Executors&#123; //利用默认线程工厂和PriorityBlockingQueue队列机制，当然了，我们还可以自定义ThreadFactory和继承queue进行自定义扩展 public static ExecutorService newMyWebThreadPool(int minSpareThreads,int maxThreads,int maxIdleTime)&#123; return new ThreadPoolExecutor(minSpareThread,maxThreads,maxIdleTime,TimeUnit.MILLISECONDS， new PriorityBlockingQueue&lt;Runnable&gt;()); &#125;&#125; 6.线程池在工作中的错误使用(1)分不清楚线程是单例还是多对象。(2)线程池数量设置很大。(3)注意死锁问题 连接池（org.apache.commons.dbcp.BasicDataSource）在使用org.apache.commons.dbcp.BasicDataSource的时候，因为之前采用了默认配置，所以当访问量大时，通过JMX观察到很多Tomcat线程都阻塞在BasicDataSource使用的Apache ObjectPool的锁上，直接原因当时是因为BasicDataSource连接池的最大连接数设置的太小，默认的BasicDataSource配置，仅使用8个最大连接。我还观察到一个问题，当较长的时间不访问系统，比如2天，DB上的Mysql会断掉所以的连接，导致连接池中缓存的连接不能用。为了解决这些问题，我们充分研究了BasicDataSource，发现了一些优化的点： Mysql默认支持100个链接，所以每个连接池的配置要根据集群中的机器数进行，如有2台服务器，可每个设置为60 initialSize：参数是一直打开的连接数 minEvictableIdleTimeMillis：该参数设置每个连接的空闲时间，超过这个时间连接将被关闭 timeBetweenEvictionRunsMillis：后台线程的运行周期，用来检测过期连接 maxActive：最大能分配的连接数 maxIdle：最大空闲数，当连接使用完毕后发现连接数大于maxIdle，连接将被直接关闭。只有initialSize &lt; x &lt; maxIdle的连接将被定期检测是否超期。这个参数主要用来在峰值访问时提高吞吐量。 initialSize是如何保持的？经过研究代码发现，BasicDataSource会关闭所有超期的连接，然后再打开initialSize数量的连接，这个特性与minEvictableIdleTimeMillis、timeBetweenEvictionRunsMillis一起保证了所有超期的initialSize连接都会被重新连接，从而避免了Mysql长时间无动作会断掉连接的问题。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>thread pool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程的实现方式]]></title>
    <url>%2F2017%2F08%2F05%2F%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[线程实现方式 继承java.lang.Thread类 实现java.lang.Runnable接口 区别：第一种是继承，第二种是实现好处： 在实际开发中通常以实现Runnable接口为主，因为实现Runnable接口相比继承Thread类可以避免继承的局限，一个类可以继承多个接口，适合于资源的共享示例1：1234567891011121314151617181920212223241.class ThreadTest extends Thread&#123; 2. public void run()&#123; 3. private int tickets = 100; 4. while(true)&#123; 5. if(ticket &gt; 0)&#123; 6. System.out.println(Thread.currentThread().getName() + 7. &quot;is saling ticket&quot; + ticket--); 8. &#125;else&#123; 9. break; 10. &#125; 11. &#125; 12. &#125; 13.&#125; #main测试类: 1.public class ThreadDome1&#123; 2. public static void main(String[] args)&#123; 3. ThreadTest t = new ThreadTest(); 4. t.start(); 5. t.start(); 6. t.start(); 7. t.start(); 8. &#125; 9.&#125; 【说明】一个线程对象只能启动一个线程，无论你调用多少遍start()方法，结果只有一个线程。 示例2：123456789101112131415161718192021221.public class ThreadDemo1&#123; 2. public static void main(String[] args)&#123; 3. new ThreadTest().start(); 4. new ThreadTest().start(); 5. new ThreadTest().start(); 6. new ThreadTest().start(); 7. &#125; 8.&#125; 1.class ThreadTest extends Thread&#123; 2. public void run()&#123; 3. private int tickets = 100; 4. while(true)&#123; 5. if(ticket &gt; 0)&#123; 6. System.out.println(Thread.currentThread().getName() + 7. &quot; is saling ticket&quot; + ticket--); 8. &#125;else&#123; 9. break; 10. &#125; 11. &#125; 12. &#125; 13.&#125; 【说明】创建了四个ThreadTest对象，就等于创建了四个资源，每个资源都有100张票，每个线程都在独自处理各自的资源。 示例4： 1234567891011121314151617181920211.public class ThreadDemo1&#123; 2. public static void main(String[] args)&#123; 3. ThreadTest t = new ThreadTest(); 4. new Thread(t).start(); 5. new Thread(t).start(); 6. new Thread(t).start(); 7. new Thread(t).start(); 8. &#125; 9.&#125; 1.class ThreadTest implements Runnable&#123; 2. public void run()&#123; 3. private int tickets = 100; //局部变量，如果是成员变量，则所有线程则共享它，会出现问题 4. while(true)&#123; 5. if(tickets &gt; 0)&#123; 6. System.out.println(Thread.currentThread().getName() + 7. &quot; is saling ticket &quot; + tickets--); 8. &#125; 9. &#125; 10. &#125; 11.&#125; 【注意】创建了四个线程，每个线程调用的是同一个ThreadTest对象中的run()方法，访问的是同一个对象中的变量（tickets）的实例 如果一个变量是成员变量，那么多个线程对同一个对象的成员变量进行操作时，它们对该成员变量是彼此影响的，也就是说一个线程对成员变量的改变会影响到另一个线程。 如果一个变量是局部变量，那么每个线程都会有一个该局部变量的拷贝（即便是同一个对象中的方法的局部变量，也会对每一个线程有一个拷贝），一个线程对该局部变量的改变不会影响到其他线程。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>thread</tag>
        <tag>runnable</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm调优]]></title>
    <url>%2F2017%2F08%2F05%2Fjvm%E8%B0%83%E4%BC%98%2F</url>
    <content type="text"><![CDATA[JVM内存模型1.根据Java虚拟机规范，JVM将内存划分为：New（年轻代）Tenured（年老代）永久代（Perm） 其中New和Tenured属于堆内存，堆内存会从JVM启动参数（-Xmx:3G）指定的内存中分配，Perm不属于堆内存，有虚拟机直接分配，但可以通过-XX:PermSize -XX:MaxPermSize 等参数调整其大小。 年轻代（New）：年轻代用来存放JVM刚分配的Java对象年老代（Tenured)：年轻代中经过垃圾回收没有回收掉的对象将被Copy到年老代永久代（Perm）：永久代存放Class、Method元信息，其大小跟项目的规模、类、方法的量有关，一般设置为128M就足够，设置原则是预留30%的空间。 New又分为几个部分：Eden：Eden用来存放JVM刚分配的对象Survivor1Survivro2：两个Survivor空间一样大，当Eden中的对象经过垃圾回收没有被回收掉时，会在两个Survivor之间来回Copy，当满足某个条件，比如Copy次数，就会被Copy到Tenured。显然，Survivor只是增加了对象在年轻代中的逗留时间，增加了被垃圾回收的可能性。 各代如何设置比例堆大小设置JVM 中最大堆大小有三方面限制：相关操作系统的数据模型（32-bt还是64-bit）限制；系统的可用虚拟内存限制；系统的可用物理内存限制。32位系统下，一般限制在1.5G~2G；64为操作系统对内存无限制。我在Windows Server 2003 系统，3.5G物理内存，JDK5.0下测试，最大可设置为1478m。典型设置：- java -Xmx3550m -Xms3550m -Xmn2g -Xss128k- -Xmx3550m：设置JVM最大可用内存为3550M。- -Xms3550m：设置JVM促使内存为3550m。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。- -Xmn2g：设置年轻代大小为2G。整个JVM内存大小=年轻代大小 + 年老代大小 + 持久代大小。持久代一般固定大小为64m，所以增大年轻代后，将会减小年老代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的3/8。- -Xss128k：设置每个线程的堆栈大小。JDK5.0以后每个线程堆栈大小为1M，以前每个线程堆栈大小为256K。更具应用的线程所需内存大小进行调整。在相同物理内存下，减小这个值能生成更多的线程。但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右。- java -Xmx3550m -Xms3550m -Xss128k -XX:NewRatio=4 -XX:SurvivorRatio=4 -XX:MaxPermSize=16m -XX:MaxTenuringThreshold=0- -XX:NewRatio=4:设置年轻代（包括Eden和两个Survivor区）与年老代的比值（除去持久代）。设置为4，则年轻代与年老代所占比值为1：4，年轻代占整个堆栈的1/5- -XX:SurvivorRatio=4：设置年轻代中Eden区与Survivor区的大小比值。设置为4，则两个Survivor区与一个Eden区的比值为2:4，一个Survivor区占整个年轻代的1/6- -XX:MaxPermSize=16m:设置持久代大小为16m。- -XX:MaxTenuringThreshold=0：设置垃圾最大年龄。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概论。 垃圾回收算法垃圾回收算法可以分为三类，都基于标记-清除（复制）算法：Serial算法（单线程）并行算法并发算法JVM会根据机器的硬件配置对每个内存代选择适合的回收算法，比如，如果机器多于1个核，会对年轻代选择并行算法，关于选择细节请参考JVM调优文档。 稍微解释下的是，并行算法是用多线程进行垃圾回收，回收期间会暂停程序的执行，而并发算法，也是多线程回收，但期间不停止应用执行。所以，并发算法适用于交互性高的一些程序。经过观察，并发算法会减少年轻代的大小，其实就是使用了一个大的年老代，这反过来跟并行算法相比吞吐量相对较低。 还有一个问题是，垃圾回收动作何时执行？ 当年轻代内存满时，会引发一次普通GC，该GC仅回收年轻代。需要强调的时，年轻代满是指Eden代满，Survivor满不会引发GC 当年老代满时会引发Full GC，Full GC将会同时回收年轻代、年老代 当永久代满时也会引发Full GC，会导致Class、Method元信息的卸载另一个问题是，何时会抛出OutOfMemoryException，并不是内存被耗空的时候才抛出 JVM98%的时间都花费在内存回收 每次回收的内存小于2%满足这两个条件将触发OutOfMemoryException，这将会留给系统一个微小的间隙以做一些Down之前的操作，比如手动打印Heap Dump。 内存泄漏及解决方法1.系统崩溃前的一些现象： 每次垃圾回收的时间越来越长，由之前的10ms延长到50ms左右，FullGC的时间也有之前的0.5s延长到4、5s FullGC的次数越来越多，最频繁时隔不到1分钟就进行一次FullGC 年老代的内存越来越大并且每次FullGC后年老代没有内存被释放之后系统会无法响应新的请求，逐渐到达OutOfMemoryError的临界值。 2.生成堆的dump文件 通过JMX的MBean生成当前的Heap信息，大小为一个3G（整个堆的大小）的hprof文件，如果没有启动JMX可以通过Java的jmap命令来生成该文件。 3.分析dump文件 下面要考虑的是如何打开这个3G的堆信息文件，显然一般的Window系统没有这么大的内存，必须借助高配置的Linux。当然我们可以借助X-Window把Linux上的图形导入到Window。我们考虑用下面几种工具打开该文件： Visual VM IBM HeapAnalyzer JDK 自带的Hprof工具 使用这些工具时为了确保加载速度，建议设置最大内存为6G。使用后发现，这些工具都无法直观地观察到内存泄漏，Visual VM虽能观察到对象大小，但看不到调用堆栈；HeapAnalyzer虽然能看到调用堆栈，却无法正确打开一个3G的文件。因此，我们又选用了Eclipse专门的静态内存分析工具：Mat。 4.分析内存泄漏 通过Mat我们能清楚地看到，哪些对象被怀疑为内存泄漏，哪些对象占的空间最大及对象的调用关系。针对本案，在ThreadLocal中有很多的JbpmContext实例，经过调查是JBPM的Context没有关闭所致。 另，通过Mat或JMX我们还可以分析线程状态，可以观察到线程被阻塞在哪个对象上，从而判断系统的瓶颈。 5.回归问题 Q：为什么崩溃前垃圾回收的时间越来越长？ A:根据内存模型和垃圾回收算法，垃圾回收分两部分：内存标记、清除（复制），标记部分只要内存大小固定时间是不变的，变的是复制部分，因为每次垃圾回收都有一些回收不掉的内存，所以增加了复制量，导致时间延长。所以，垃圾回收的时间也可以作为判断内存泄漏的依据 Q：为什么Full GC的次数越来越多？ A：因此内存的积累，逐渐耗尽了年老代的内存，导致新对象分配没有更多的空间，从而导致频繁的垃圾回收 Q:为什么年老代占用的内存越来越大？ A:因为年轻代的内存无法被回收，越来越多地被Copy到年老代 性能调优 除了上述内存泄漏外，我们还发现CPU长期不足3%，系统吞吐量不够，针对8core×16G、64bit的Linux服务器来说，是严重的资源浪费。 在CPU负载不足的同时，偶尔会有用户反映请求的时间过长，我们意识到必须对程序及JVM进行调优。从以下几个方面进行： 线程池：解决用户响应时间长的问题 连接池 JVM启动参数：调整各代的内存比例和垃圾回收算法，提高吞吐量 程序算法：改进程序逻辑算法提高性能]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web.xml加载顺序]]></title>
    <url>%2F2017%2F08%2F05%2Fweb-xml%E5%8A%A0%E8%BD%BD%E9%A1%BA%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[web.xml 的加载顺序:ServletContext-&gt; context-param -&gt;listener -&gt; filter -&gt; servlet，而同个类型之间的实际程序调用的时候的顺序是根据对应的 mapping 的顺序进行调用的。ServletContext即Servlet上下文对象，该对象表示当前的web应用环境信息，一个Web应用只会创建一个ServletContext对象。 Web容器启动的时候，它会为每个Web应用程序都创建一个对应的ServletContext对象，它代表当前的web应用。[注意]由于一个Web应用中的所有Servlet共享一个ServletContext对象，所以多个Servlet通过ServletContext对象实现数据共享，ServletContext对象通常称为Context域对象。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sping之IOC，AOP]]></title>
    <url>%2F2017%2F08%2F05%2Fsping%E4%B9%8BIOC%EF%BC%8CAOP%2F</url>
    <content type="text"><![CDATA[前言Spring AOP和IOC个人理解IOC inversion of control 控制反转将new对象的权力由调用者转移到spring容器（即xml文件），Struts2与Spring整合（scope=”prototype”）由spring来维护struts的生命周期，在启动web容器时spring容器创建action实例对象，又分两种方式：第一种xml方式 需要set方法为被调用的属性赋值，xml中需要ref注入被调要的对象。第二种注解方式 不需要set方法为被调用属性赋值，但需要在action层service层dao层的类上对应写上@Controller,@Service,@Repository通过在属性上加上@Resource(name=&quot;&quot;)来为属性赋值，这一步相当于xml方式的ref。事务管理器 123&lt;bean id=&quot;txManager&quot;class=&quot;org.springframework.orm.hibernate3.HibernateTransactionManager&quot;&gt; &lt;property name=&quot;sessionFactory&quot; ref=&quot;sessionFactory&quot;&gt;&lt;/property&gt; &lt;/bean&gt; 相当于切面需要注入sessionFactory AOP Aspect Oriented Programming 面向切面编程通过代理的方式在需要的时候通过切入点给指定位置的程序添加逻辑代码或功能。声明事务处理分为两种方式：第一种xml方式: 需要在xml中配置事务的通知&lt;tx:advice&gt;里面放增删改查等方法的isolation=&quot;DEFAULT&quot; propagation=&quot;REQUIRED&quot; read-only=&quot;false&quot;&lt;/tx:advice&gt;）用切面关联通知，然后再用通知关联切入点&lt;aop:config&gt;（即事务操作业务层）切入地点是所有service 包及其子包下类的所有方法。第二种注解方式: 使用注解的方式配置声明式事务处理，在Service层类中，@Transcational(事务处理的) &lt;tx:annotation-driven transaction-manager=&quot;txManager&quot;/&gt;不需要关联通知也不需要通知关联切入点 spring的基本框架主要包含六大模块：DAO、ORM、AOP、JEE、WEB、CORE Spring DAO：Spring提供了对JDBC的操作支持：JdbcTemplate模板工具类 。Spring ORM：Spring可以与ORM框架整合。例如Spring整合Hibernate框架，其中Spring还提供 HibernateDaoSupport工具类，简化了Hibernate的操作 。Spring WEB：Spring提供了对Struts、Springmvc的支持，支持WEB开发。与此同时Spring自身也提供了基于MVC的解决方案 。Spring AOP：Spring提供面向切面的编程，可以给某一层提供事务管理，例如在Service层添加事物控制 。Spring JEE：J2EE开发规范的支持，例如EJB 。8Spring Core：提供IOC容器对象的创建和处理依赖对象关系 。 Spring下IOC容器和DI(依赖注入Dependency injection) IOC容器：就是具有依赖注入功能的容器，是可以创建对象的容器，IOC容器负责实例化、定位、配置应用程序中的对象及建立这些对象间的依赖。通常new一个实例，控制权由程序员控制，而”控制反转”是指new实例工作不由程序员来做而是交给Spring容器来做。。在Spring中BeanFactory是IOC容器的实际代表者。 DI(依赖注入Dependency injection) ：在容器创建对象后，处理对象的依赖关系。依赖注入spring的注入方式： set注入方式静态工厂注入方式构造方法注入方式基于注解的方式 1、 set注入方式：控制层代码：1234private OrderServiceImp orderService; public void setOrderService(OrderServiceImp orderService) &#123; this.orderService = orderService;&#125; Spring配置XML文件：其中配置声明OrderAction类存在属性orderService。程式运行时候，会将已经实例化的orderService对象调用setOrderService方式注入。1234&lt;bean name=&quot;orderAction&quot; class=&quot;com.pec.action.OrderAction&quot;&gt; &lt;property name=&quot;orderService&quot; ref=&quot;orderService&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean name=&quot;orderService&quot; class=&quot;com.pec.service.imp.OrderServiceImp&quot;&gt;&lt;/bean&gt; 2、 构造器注入方式：控制层代码：1234private OrderServiceImp orderService; public OrderAction(OrderServiceImp orderService) &#123; this.orderService = orderService; &#125; Spring配置XML文件：1234&lt;bean name=&quot;orderAction&quot; class=&quot;com.pec.action.OrderAction&quot;&gt; &lt;constructor-arg ref=&quot;orderService&quot;&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;&lt;bean name=&quot;orderService&quot; class=&quot;com.pec.service.imp.OrderServiceImp&quot;&gt;&lt;/bean&gt; 3、基于注解的方式 （推荐使用，比较便捷少配置）控制层代码：1@Autowired //@Resourceprivate OrderServiceImp orderService; 服务层代码： @Service(&quot;orderService&quot;) public class OrderServiceImp implements IOrderService { @Autowired private JavaOrderMDaoImp javaOrderMDao; @Autowired private JavaOrderDDaoImp javaOrderDDao; @Override public List&lt;JavaOrderMList&gt; findOrderM(OrderSearch search) { return javaOrderMDao.findJavaOrderM(search); } @Override public List&lt;JavaOrderDList&gt; findOrderD(OrderSearch search) { return javaOrderDDao.findJavaOrderD(search); } } DAO层代码：1234@Repository(&quot;javaOrderMDao&quot;)public class JavaOrderMDaoImp extends BaseHibernateDAO&lt;JavaOrderM, Serializable&gt; implements IJavaOrderMDao &#123;...&#125;@Repository(&quot;javaOrderDDao&quot;)public class JavaOrderDDaoImp extendsBaseHibernateDAO&lt;JavaOrderD, Serializable&gt; implements IJavaOrderDDao &#123;...&#125; 【注意点】⑴ 持久层DAO层注解Repository中规定了名称，在Service层中声明名称必须一致。⑵ 服务层Service层注解Service中规定了名称，在控制层中声明的名称必须一致。⑶ 注解方式注入依赖注解： @Component 把对象加入ioc容器，对象引用名称是类名，第一个字母小写@Component(“name”) 把指定名称的对象，加入ioc容器@Repository 主要用于标识加入容器的对象是一个持久层的组件(类)@Service 主要用于标识加入容器的对象是一个业务逻辑层的组件@Controller 主要用于标识加入容器的对象是一个控制层的组件@Resource 注入属性(DI), 会从容器中找对象注入到@Resource修饰的对象上@Autowired 注入属性(DI), 会从容器中找对象注入到@Autowired修饰的对象上 开启注解&lt;mvc:annotation-driven/&gt;静态资源由WEB服务器默认的Servlet来处理 ，必须和一起&lt;mvc:default-servlet-handler/&gt;包扫描路径&lt;context:component-scan base-package=&quot;com.fh.controller&quot; /&gt; 注解可以简化配置，提升开发效率，但是也不利于后期维护。 @Autowired与@Resource都可以用来装配bean. 都可以写在字段上,或写在setter方法上。 @Autowired默认按类型装配（这个注解是属业spring的），默认情况下必须要求依赖对象必须存在，如果要允许null 值，可以设置它的required属性为false，如：@Autowired(required=false) ，如果我们想使用名称装配可以结合@Qualifier注解进行使用，如下： 12@Autowired() @Qualifier(&quot;baseDao&quot;) private BaseDao baseDao; @Resource（这个注解属于J2EE的），默认安照名称进行装配，名称可以通过name属性进行指定，如果没有指定name属性，当注解写在字段上时，默认取字段名进行按照名称查找，如果注解写在setter方法上默认取属性名进行装配。 当找不到与名称匹配的bean时才按照类型进行装配。但是需要注意的是，如果name属性一旦指定，就只会按照名称进行装配。 12@Resource(name=&quot;baseDao&quot;) private BaseDao baseDao; 我喜欢用 @Resource注解在字段上，且这个注解是属于J2EE的，减少了与spring的耦合。最重要的这样代码看起就比较优雅。 Spring面向切面编程(AOP)和事务管理配置AOP就是纵向的编程，如业务1和业务2都需要一个共同的操作，与其往每个业务中都添加同样的代码，不如写一遍代码，让两个业务共同使用这段代码。在日常有订单管理、商品管理、资金管理、库存管理等业务，都会需要到类似日志记录、事务控制、权限控制、性能统计、异常处理及事务处理等。AOP把所有共有代码全部抽取出来，放置到某个地方集中管理，然后在具体运行时，再由容器动态织入这些共有代码。 AOP涉及名称：切面（Aspect）：其实就是共有功能的实现。如日志切面、权限切面、事务切面等。在实际应用中通常是一个存放共有功能实现的普通Java类，之所以能被AOP容器识别成切面，是在配置中指定的。通知（Advice）：是切面的具体实现。以目标方法为参照点，根据放置的地方不同，可分为前置通知（Before）、后置通知（AfterReturning）、异常通知（AfterThrowing）、最终通知（After）与环绕通知（Around）5种。在实际应用中通常是切面类中的一个方法，具体属于哪类通知，同样是在配置中指定的。连接点（Joinpoint）：就是程序在运行过程中能够插入切面的地点。例如，方法调用、异常抛出或字段修改等，但Spring只支持方法级的连接点。切入点（Pointcut）：用于定义通知应该切入到哪些连接点上。不同的通知通常需要切入到不同的连接点上，这种精准的匹配是由切入点的正则表达式来定义的。目标对象（Target）：就是那些即将切入切面的对象，也就是那些被通知的对象。这些对象中已经只剩下干干净净的核心业务逻辑代码了，所有的共有功能代码等待AOP容器的切入。代理对象（Proxy）：将通知应用到目标对象之后被动态创建的对象。可以简单地理解为，代理对象的功能等于目标对象的核心业务逻辑功能加上共有功能。代理对象对于使用者而言是透明的，是程序运行过程中的产物。织入（Weaving）：将切面应用到目标对象从而创建一个新的代理对象的过程。这个过程可以发生在编译期、类装载期及运行期，当然不同的发生点有着不同的前提条件。譬如发生在编译期的话，就要求有一个支持这种AOP实现的特殊编译器；发生在类装载期，就要求有一个支持AOP实现的特殊类装载器；只有发生在运行期，则可直接通过Java语言的反射机制与动态代理机制来动态实现。 Spring配置文件中关于事务配置总是由三个组成部分，分别是DataSource、TransactionManager和代理机制这三部分，无论哪种配置方式，一般变化的只是代理机制这部分。 DataSource、TransactionManager这两部分只是会根据数据访问方式有所变化，比如使用hibernate进行数据访问时，DataSource实际为SessionFactory，TransactionManager的实现为HibernateTransactionManager。根据代理机制的不同，总结了五种Spring事务的配置方式，配置文件如下：第一种方式：每个Bean都有一个代理 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-2.5.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-2.5.xsd&quot;&gt; &lt;bean id=&quot;sessionFactory&quot; class=&quot;org.springframework.orm.hibernate3.LocalSessionFactoryBean&quot;&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:hibernate.cfg.xml&quot; /&gt; &lt;property name=&quot;configurationClass&quot; value=&quot;org.hibernate.cfg.AnnotationConfiguration&quot; /&gt; &lt;/bean&gt; &lt;!-- 定义事务管理器（声明式的事务） --&gt; &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.orm.hibernate3.HibernateTransactionManager&quot;&gt; &lt;property name=&quot;sessionFactory&quot; ref=&quot;sessionFactory&quot; /&gt; &lt;/bean&gt; &lt;!-- 配置DAO --&gt; &lt;bean id=&quot;userDaoTarget&quot; class=&quot;com.bluesky.spring.dao.UserDaoImpl&quot;&gt; &lt;property name=&quot;sessionFactory&quot; ref=&quot;sessionFactory&quot; /&gt; &lt;/bean&gt; &lt;bean id=&quot;userDao&quot; class=&quot;org.springframework.transaction.interceptor.TransactionProxyFactoryBean&quot;&gt; &lt;!-- 配置事务管理器 --&gt; &lt;property name=&quot;transactionManager&quot; ref=&quot;transactionManager&quot; /&gt; &lt;property name=&quot;target&quot; ref=&quot;userDaoTarget&quot; /&gt; &lt;property name=&quot;proxyInterfaces&quot; value=&quot;com.bluesky.spring.dao.GeneratorDao&quot; /&gt; &lt;!-- 配置事务属性 --&gt; &lt;property name=&quot;transactionAttributes&quot;&gt; &lt;props&gt; &lt;prop key=&quot;*&quot;&gt;PROPAGATION_REQUIRED&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/beans&gt; 第二种方式：所有Bean共享一个代理基类 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-2.5.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-2.5.xsd&quot;&gt; &lt;bean id=&quot;sessionFactory&quot; class=&quot;org.springframework.orm.hibernate3.LocalSessionFactoryBean&quot;&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:hibernate.cfg.xml&quot; /&gt; &lt;property name=&quot;configurationClass&quot; value=&quot;org.hibernate.cfg.AnnotationConfiguration&quot; /&gt; &lt;/bean&gt; &lt;!-- 定义事务管理器（声明式的事务） --&gt; &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.orm.hibernate3.HibernateTransactionManager&quot;&gt; &lt;property name=&quot;sessionFactory&quot; ref=&quot;sessionFactory&quot; /&gt; &lt;/bean&gt; &lt;bean id=&quot;transactionBase&quot; class=&quot;org.springframework.transaction.interceptor.TransactionProxyFactoryBean&quot; lazy-init=&quot;true&quot; abstract=&quot;true&quot;&gt; &lt;!-- 配置事务管理器 --&gt; &lt;property name=&quot;transactionManager&quot; ref=&quot;transactionManager&quot; /&gt; &lt;!-- 配置事务属性 --&gt; &lt;property name=&quot;transactionAttributes&quot;&gt; &lt;props&gt; &lt;prop key=&quot;*&quot;&gt;PROPAGATION_REQUIRED&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置DAO --&gt; &lt;bean id=&quot;userDaoTarget&quot; class=&quot;com.bluesky.spring.dao.UserDaoImpl&quot;&gt; &lt;property name=&quot;sessionFactory&quot; ref=&quot;sessionFactory&quot; /&gt; &lt;/bean&gt; &lt;bean id=&quot;userDao&quot; parent=&quot;transactionBase&quot; &gt; &lt;property name=&quot;target&quot; ref=&quot;userDaoTarget&quot; /&gt; &lt;/bean&gt; &lt;/beans&gt; 第三种方式：使用拦截器 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-2.5.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-2.5.xsd&quot;&gt; &lt;bean id=&quot;sessionFactory&quot; class=&quot;org.springframework.orm.hibernate3.LocalSessionFactoryBean&quot;&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:hibernate.cfg.xml&quot; /&gt; &lt;property name=&quot;configurationClass&quot; value=&quot;org.hibernate.cfg.AnnotationConfiguration&quot; /&gt; &lt;/bean&gt; &lt;!-- 定义事务管理器（声明式的事务） --&gt; &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.orm.hibernate3.HibernateTransactionManager&quot;&gt; &lt;property name=&quot;sessionFactory&quot; ref=&quot;sessionFactory&quot; /&gt; &lt;/bean&gt; &lt;bean id=&quot;transactionInterceptor&quot; class=&quot;org.springframework.transaction.interceptor.TransactionInterceptor&quot;&gt; &lt;property name=&quot;transactionManager&quot; ref=&quot;transactionManager&quot; /&gt; &lt;!-- 配置事务属性 --&gt; &lt;property name=&quot;transactionAttributes&quot;&gt; &lt;props&gt; &lt;prop key=&quot;*&quot;&gt;PROPAGATION_REQUIRED&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean class=&quot;org.springframework.aop.framework.autoproxy.BeanNameAutoProxyCreator&quot;&gt; &lt;property name=&quot;beanNames&quot;&gt; &lt;list&gt; &lt;value&gt;*Dao&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;property name=&quot;interceptorNames&quot;&gt; &lt;list&gt; &lt;value&gt;transactionInterceptor&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置DAO --&gt; &lt;bean id=&quot;userDao&quot; class=&quot;com.bluesky.spring.dao.UserDaoImpl&quot;&gt; &lt;property name=&quot;sessionFactory&quot; ref=&quot;sessionFactory&quot; /&gt; &lt;/bean&gt; &lt;/beans&gt; 第四种方式：使用tx标签配置的拦截器 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-2.5.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-2.5.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-2.5.xsd&quot;&gt; &lt;context:annotation-config /&gt; &lt;context:component-scan base-package=&quot;com.bluesky&quot; /&gt; &lt;bean id=&quot;sessionFactory&quot; class=&quot;org.springframework.orm.hibernate3.LocalSessionFactoryBean&quot;&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:hibernate.cfg.xml&quot; /&gt; &lt;property name=&quot;configurationClass&quot; value=&quot;org.hibernate.cfg.AnnotationConfiguration&quot; /&gt; &lt;/bean&gt; &lt;!-- 定义事务管理器（声明式的事务） --&gt; &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.orm.hibernate3.HibernateTransactionManager&quot;&gt; &lt;property name=&quot;sessionFactory&quot; ref=&quot;sessionFactory&quot; /&gt; &lt;/bean&gt; &lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;transactionManager&quot;&gt; &lt;tx:attributes&gt; &lt;tx:method name=&quot;*&quot; propagation=&quot;REQUIRED&quot; /&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;aop:config&gt; &lt;aop:pointcut id=&quot;interceptorPointCuts&quot; expression=&quot;execution(* com.bluesky.spring.dao.*.*(..))&quot; /&gt; &lt;aop:advisor advice-ref=&quot;txAdvice&quot; pointcut-ref=&quot;interceptorPointCuts&quot; /&gt; &lt;/aop:config&gt; &lt;/beans&gt; 第五种方式：全注解 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-2.5.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-2.5.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-2.5.xsd&quot;&gt; &lt;context:annotation-config /&gt; &lt;context:component-scan base-package=&quot;com.bluesky&quot; /&gt; &lt;tx:annotation-driven transaction-manager=&quot;transactionManager&quot;/&gt; &lt;bean id=&quot;sessionFactory&quot; class=&quot;org.springframework.orm.hibernate3.LocalSessionFactoryBean&quot;&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:hibernate.cfg.xml&quot; /&gt; &lt;property name=&quot;configurationClass&quot; value=&quot;org.hibernate.cfg.AnnotationConfiguration&quot; /&gt; &lt;/bean&gt; &lt;!-- 定义事务管理器（声明式的事务） --&gt; &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.orm.hibernate3.HibernateTransactionManager&quot;&gt; &lt;property name=&quot;sessionFactory&quot; ref=&quot;sessionFactory&quot; /&gt; &lt;/bean&gt; &lt;/beans&gt; 此时在DAO上需加上@Transactional注解，如下： 123456789101112131415161718192021package com.bluesky.spring.dao;import java.util.List;import org.hibernate.SessionFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.orm.hibernate3.support.HibernateDaoSupport;import org.springframework.stereotype.Component;import com.bluesky.spring.domain.User;@Transactional@Component(&quot;userDao&quot;)public class UserDaoImpl extends HibernateDaoSupport implements UserDao &#123; public List&lt;User&gt; listUsers() &#123; return this.getSession().createQuery(&quot;from User&quot;).list(); &#125; &#125;]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>IOC</tag>
        <tag>AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring事务的传播属性和隔离级别]]></title>
    <url>%2F2017%2F08%2F05%2Fspring%E4%BA%8B%E5%8A%A1%E7%9A%84%E4%BC%A0%E6%92%AD%E5%B1%9E%E6%80%A7%E5%92%8C%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%2F</url>
    <content type="text"><![CDATA[spring事务传播属性Propagation（事务的传播属性） ：key属性确定代理应该给哪个方法增加事务行为。这样的属性最重要的部份是传播行为。有以下选项可供使用：PROPAGATION_REQUIRED—支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。PROPAGATION_SUPPORTS—支持当前事务，如果当前没有事务，就以非事务方式执行。PROPAGATION_MANDATORY—支持当前事务，如果当前没有事务，就抛出异常。PROPAGATION_REQUIRES_NEW—新建事务，如果当前存在事务，把当前事务挂起。PROPAGATION_NOT_SUPPORTED—以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。PROPAGATION_NEVER—以非事务方式执行，如果当前存在事务，则抛出异常。 PROPAGATION_REQUIRED加入当前正要执行的事务不在另外一个事务里，那么就起一个新的事务比如说，ServiceB.methodB的事务级别定义为PROPAGATION_REQUIRED, 那么由于执行ServiceA.methodA的时候，ServiceA.methodA已经起了事务，这时调用ServiceB.methodB，ServiceB.methodB看到自己已经运行在ServiceA.methodA的事务内部，就不再起新的事务。而假如ServiceA.methodA运行的时候发现自己没有在事务中，他就会为自己分配一个事务。这样，在ServiceA.methodA或者在ServiceB.methodB内的任何地方出现异常，事务都会被回滚。即使ServiceB.methodB的事务已经被提交，但是ServiceA.methodA在接下来fail要回滚，ServiceB.methodB也要回滚 PROPAGATION_SUPPORTS如果当前在事务中，即以事务的形式运行，如果当前不再一个事务中，那么就以非事务的形式运行 PROPAGATION_MANDATORY必须在一个事务中运行。也就是说，他只能被一个父事务调用。否则，他就要抛出异常 PROPAGATION_REQUIRES_NEW这个就比较绕口了。 比如我们设计ServiceA.methodA的事务级别为PROPAGATION_REQUIRED，ServiceB.methodB的事务级别为PROPAGATION_REQUIRES_NEW，那么当执行到ServiceB.methodB的时候，ServiceA.methodA所在的事务就会挂起，ServiceB.methodB会起一个新的事务，等待ServiceB.methodB的事务完成以后，他才继续执行。他与PROPAGATION_REQUIRED 的事务区别在于事务的回滚程度了。因为ServiceB.methodB是新起一个事务，那么就是存在两个不同的事务。如果ServiceB.methodB已经提交，那么ServiceA.methodA失败回滚，ServiceB.methodB是不会回滚的。如果ServiceB.methodB失败回滚，如果他抛出的异常被ServiceA.methodA捕获，ServiceA.methodA事务仍然可能提交。 PROPAGATION_NOT_SUPPORTED当前不支持事务。比如ServiceA.methodA的事务级别是PROPAGATION_REQUIRED ，而ServiceB.methodB的事务级别是PROPAGATION_NOT_SUPPORTED ，那么当执行到ServiceB.methodB时，ServiceA.methodA的事务挂起，而他以非事务的状态运行完，再继续ServiceA.methodA的事务。 PROPAGATION_NEVER不能在事务中运行。假设ServiceA.methodA的事务级别是PROPAGATION_REQUIRED， 而ServiceB.methodB的事务级别是PROPAGATION_NEVER ，那么ServiceB.methodB就要抛出异常了。 PROPAGATION_NESTED理解Nested的关键是savepoint。他与PROPAGATION_REQUIRES_NEW的区别是，PROPAGATION_REQUIRES_NEW另起一个事务，将会与他的父事务相互独立，而Nested的事务和他的父事务是相依的，他的提交是要等和他的父事务一块提交的。也就是说，如果父事务最后回滚，他也要回滚的。而Nested事务的好处是他有一个savepoint。 12345678910111213ServiceA &#123;/*** 事务属性配置为 PROPAGATION_REQUIRED*/void methodA() &#123;try &#123;//savepointServiceB.methodB(); //PROPAGATION_NESTED 级别&#125; catch (SomeException) &#123;// 执行其他业务, 如 ServiceC.methodC();&#125;&#125;&#125; 也就是说ServiceB.methodB失败回滚，那么ServiceA.methodA也会回滚到savepoint点上，ServiceA.methodA可以选择另外一个分支，比如ServiceC.methodC，继续执行，来尝试完成自己的事务。但是这个事务并没有在EJB标准中定义。 Spring事务的隔离级别 ISOLATION_DEFAULT： 这是一个PlatfromTransactionManager默认的隔离级别，使用数据库默认的事务隔离级别. 另外四个与JDBC的隔离级别相对应 ISOLATION_READ_UNCOMMITTED： 这是事务最低的隔离级别，它充许令外一个事务可以看到这个事务未提交的数据。 这种隔离级别会产生脏读，不可重复读和幻像读。 ISOLATION_READ_COMMITTED： 保证一个事务修改的数据提交后才能被另外一个事务读取。另外一个事务不能读取该事务未提交的数据 ISOLATION_REPEATABLE_READ： 这种事务隔离级别可以防止脏读，不可重复读。但是可能出现幻像读。 它除了保证一个事务不能读取另一个事务未提交的数据外，还保证了避免下面的情况产生(不可重复读)。 ISOLATION_SERIALIZABLE: 这是花费最高代价但是最可靠的事务隔离级别。事务被处理为顺序执行。 事务的四个特性 原子性（Atomicity） 原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚，这和前面两篇博客介绍事务的功能是一样的概念，因此事务的操作如果成功就必须要完全应用到数据库，如果操作失败则不能对数据库有任何影响。 一致性（Consistency） 一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。 拿转账来说，假设用户A和用户B两者的钱加起来一共是5000，那么不管A和B之间如何转账，转几次账，事务结束后两个用户的钱相加起来应该还得是5000，这就是事务的一致性。 隔离性（Isolation） 隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。 即要达到这么一种效果：对于任意两个并发的事务T1和T2，在事务T1看来，T2要么在T1开始之前就已经结束，要么在T1结束之后才开始，这样每个事务都感觉不到有其他事务在并发地执行。 关于事务的隔离性数据库提供了多种隔离级别，稍后会介绍到。 持久性（Durability） 持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。 例如我们在使用JDBC操作数据库时，在提交事务方法后，提示用户事务操作完成，当我们程序执行完成直到看到提示后，就可以认定事务以及正确提交，即使这时候数据库出现了问题，也必须要将我们的事务完全执行完成，否则就会造成我们看到提示事务处理完毕，但是数据库因为故障而没有执行事务的重大错误。 以上介绍完事务的四大特性(简称ACID)，现在重点来说明下事务的隔离性，当多个线程都开启事务操作数据库中的数据时，数据库系统要能进行隔离操作，以保证各个线程获取数据的准确性，在介绍数据库提供的各种隔离级别之前，我们先看看如果不考虑事务的隔离性，会发生的几种问题： 脏读: 指当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据， 那么另外一个事务读到的这个数据是脏数据，依据脏数据所做的操作可能是不正确的。 不可重复读: 指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的，因此称为是不可重复读。 幻觉读: 指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。 除了防止脏读，不可重复读外，还避免了幻像读，需要设置事务隔离级别]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>事务传播属性</tag>
        <tag>隔离级别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[乐观锁与悲观锁及应用举例]]></title>
    <url>%2F2017%2F08%2F05%2F%E4%B9%90%E8%A7%82%E9%94%81%E4%B8%8E%E6%82%B2%E8%A7%82%E9%94%81%E5%8F%8A%E5%BA%94%E7%94%A8%E4%B8%BE%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[悲观锁 正如其名，它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）的修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）。 以常用的mysql InnoDB存储引擎为例：加入商品表items表中有一个字段status，status=1表示该商品未被下单，status=2表示该商品已经被下单，那么我们对每个商品下单前必须确保此商品的status=1。假设有一件商品，其id为10000；如果不使用锁，那么操作方法如下: 123456//查出商品状态select status from items where id=10000;//根据商品信息生成订单insert into orders(id,item_id) values(null,10000);//修改商品状态为2update Items set status=2 where id=10000; 上述场景在高并发环境下可能出现问题：前面已经提到只有商品的status=1是才能对它进行下单操作，上面第一步操作中，查询出来的商品status为1。但是当我们执行第三步update操作的时候，有可能出现其他人先一步对商品下单把Item的status修改为2了，但是我们并不知道数据已经被修改了，这样就可能造成同一个商品被下单2次，使得数据不一致。所以说这种方式是不安全的。使用悲观锁来实现：在上面的场景中，商品信息从查询出来到修改，中间有一个处理订单的过程，使用悲观锁的原理就是，当我们在查询出items信息后就把当前的数据锁定，直到我们修改完毕后再解锁。那么在这个过程中，因为items被锁定了，就不会出现有第三者来对其进行修改了。注：要使用悲观锁，我们必须关闭mysql数据库的自动提交属性，因为MySQL默认使用autocommit模式，也就是说，当你执行一个更新操作后，MySQL会立刻将结果进行提交。我们可以使用命令设置MySQL为非autocommit模式：123456789101112set autocommit=0;设置完autocommit后，我们就可以执行我们的正常业务了。具体如下：//开始事务begin;/begin work;/start transaction; (三者选一就可以)//查询出商品信息select status from items where id=10000 for update;//根据商品信息生成订单insert into orders (id,item_id) values (null,10000);//修改商品status为2update items set status=2 where id=10000;//提交事务commit;/commit work; 注：上面的begin/commit为事务的开始和结束，因为在前一步我们关闭了mysql的autocommit，所以需要手动控制事务的提交，在这里就不细表了。上面的第一步我们执行了一次查询操作：select status from items where id=10000 for update;与普通查询不一样的是，我们使用了select…for update的方式，这样就通过数据库实现了悲观锁。此时在items表中，id为10000的 那条数据就被我们锁定了，其它的事务必须等本次事务提交之后才能执行。这样我们可以保证当前的数据不会被其它事务修改。注：需要注意的是，在事务中，只有SELECT … FOR UPDATE 或LOCK IN SHARE MODE 同一笔数据时会等待其它事务结束后才执行，一般SELECT … 则不受此影响。拿上面的实例来说，当我执行select status from items where id=10000 for update;后。我在另外的事务中如果再次执行select status from items where id=10000 for update;则第二个事务会一直等待第一个事务的提交，此时第二个查询处于阻塞的状态，但是如果我是在第二个事务中执行select status from items where id=10000;则能正常查询出数据，不会受第一个事务的影响。上面我们提到，使用select…for update会把数据给锁住，不过我们需要注意一些锁的级别，MySQL InnoDB默认Row-Level Lock，所以只有明确地指定主键，MySQL 才会执行Row lock (只锁住被选取的数据) ，否则MySQL 将会执行Table Lock (将整个数据表单给锁住)。除了主键外，使用索引也会影响数据库的锁定级别。悲观锁并不是适用于任何场景，它也有它存在的一些不足，因为悲观锁大多数情况下依靠数据库的锁机制实现，以保证操作最大程度的独占性。如果加锁的时间过长，其他用户长时间无法访问，影响了程序的并发访问性，同时这样对数据库性能开销影响也很大，特别是对长事务而言，这样的开销往往无法承受。 乐观锁（ Optimistic Locking ）相对悲观锁而言，乐观锁假设认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让返回用户错误的信息，让用户决定如何去做。那么我们如何实现乐观锁呢，一般来说有以下2种方式： 使用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式。何谓数据版本？即为数据增加一个版本标识，一般是通过为数据库表增加一个数字类型的 “version” 字段来实现。当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值+1。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的version值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据。如果更新操作顺序执行，则数据的版本（version）依次递增，不会产生冲突。但是如果发生有不同的业务操作对同一版本的数据进行修改，那么，先提交的操作（图中B）会把数据version更新为2，当A在B之后提交更新时发现数据的version已经被修改了，那么A的更新操作会失败。 乐观锁定的第二种实现方式和第一种差不多，同样是在需要乐观锁控制的table中增加一个字段，名称无所谓，字段类型使用时间戳（timestamp）, 和上面的version类似（其实不用新加字段，用需要修改的字段作为条件进行修改操作即可），也是在更新提交的时候检查当前数据库中数据的时间戳和自己更新前取到的时间戳进行对比，如果一致则OK，否则就是版本冲突。以mysql InnoDB存储引擎为例，还是拿之前的例子商品表items表中有一个字段status，status=1表示该商品未被下单，status=2表示该商品已经被下单，那么我们对每个商品下单前必须确保此商品的status=1。假设有一件商品，其id为10000；下单操作包括3步骤： 12345//查询出商品信息select (status,version) from items where id=#&#123;id&#125;//根据商品信息生成订单//修改商品status为2update items set status=2,version=version+1 where id=#&#123;id&#125; and version=#&#123;version&#125;; 为了使用乐观锁，我们需要首先修改items表，增加一个version字段，数据默认version可设为1；其实我们周围的很多产品都有乐观锁的使用，比如我们经常使用的分布式存储引擎Tair，Tair中存储的每个数据都有版本号，版本号在每次更新后都会递增，相应的，在Tair put接口中也有此version参数，这个参数是为了解决并发更新同一个数据而设置的，这其实就是乐观锁；很多情况下，更新数据是先get，修改get回来的数据，然后put回系统。如果有多个客户端get到同一份数据，都对其修改并保存，那么先保存的修改就会被后到达的修改覆盖，从而导致数据一致性问题,在大部分情况下应用能够接受，但在少量特殊情况下，这个是我们不希望发生的。比如系统中有一个值”1”, 现在A和B客户端同时都取到了这个值。之后A和B客户端都想改动这个值，假设A要改成12，B要改成13，如果不加控制的话，无论A和B谁先更新成功，它的更新都会被后到的更新覆盖。Tair引入的乐观锁机制避免了这样的问题。刚刚的例子中，假设A和B同时取到数据，当时版本号是10，A先更新，更新成功后，值为12，版本为11。当B更新的时候，由于其基于的版本号是10，此时服务器会拒绝更新，返回version error，从而避免A的更新被覆盖。B可以选择get新版本的value，然后在其基础上修改，也可以选择强行更新。当然了，乐观锁也是要精心挑选的，主要的目的就是避免锁的失败率过高又要规避ABA问题。关于锁力度太大导致接口操作失败率过高。商品库存扣减时，尤其是在秒杀、聚划算这种高并发的场景下，若采用version号作为乐观锁，则每次只有一个事务能更新成功，业务感知上就是大量操作失败。若挑选以库存数作为乐观锁123456update item set quantity=quantity-#sub_quantity# where item_id = #id# and quantity-#sub_quantity# &gt; 0 通过挑选乐观锁，可以减小锁力度，从而提升吞吐乐观锁需要灵活运用,现在互联网高并发的架构中，受到fail-fast思路的影响，悲观锁已经非常少见了。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>乐观锁</tag>
        <tag>悲观锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql事务隔离级别]]></title>
    <url>%2F2017%2F08%2F04%2Fmysql%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%2F</url>
    <content type="text"><![CDATA[mysql事务隔离级别第1级别：Read Uncommitted(读取未提交内容)1.所有事务都可以看到其他未提交事务的执行结果2.本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少3.该级别引发的问题是——脏读(Dirty Read)：读取到了未提交的数据 #首先，修改隔离级别 set tx_isolation=&#39;READ-UNCOMMITTED&#39;; select @@tx_isolation; | @@tx_isolation | | READ-UNCOMMITTED | #事务A：启动一个事务 start transaction; select * from tx; | id | num | | 1 | 1 | | 2 | 2 | | 3 | 3 | #事务B：也启动一个事务(那么两个事务交叉了) #在事务B中执行更新语句，且不提交 start transaction; update tx set num=10 where id=1; select * from tx; | id | num | | 1 | 10 | | 2 | 2 | | 3 | 3 | #事务A：那么这时候事务A能看到这个更新了的数据吗? select * from tx; | id | num | | 1 | 10 | ---&gt;可以看到！说明我们读到了事务B还没有提交的数据 | 2 | 2 | | 3 | 3 | #事务B：事务B回滚,仍然未提交 rollback; select * from tx; | id | num | | 1 | 1 | | 2 | 2 | | 3 | 3 | #事务A：在事务A里面看到的也是B没有提交的数据 select * from tx; | id | num | | 1 | 1 | ---&gt;脏读意味着我在这个事务中(A中)，事务B虽然没有提交，但它任何一条数据变化，我都可以看到！ | 2 | 2 | | 3 | 3 | 第2级别：Read Committed(读取提交内容)1.这是大多数数据库系统的默认隔离级别（但不是MySQL默认的）2.它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变3.这种隔离级别出现的问题是——不可重复读(Nonrepeatable Read)：不可重复读意味着我们在同一个事务中执行完全相同的select语句时可能看到不一样的结果。 ——&gt;导致这种情况的原因可能有： (1)有一个交叉的事务有新的commit，导致了数据的改变; (2)一个数据库被多个实例操作时,同一事务的其他实例在该实例处理其间可能会有新的commit #首先修改隔离级别 set tx_isolation=&#39;read-committed&#39;; select @@tx_isolation; | @@tx_isolation | | READ-COMMITTED | #事务A：启动一个事务 start transaction; select * from tx; | id | num | | 1 | 1 | | 2 | 2 | | 3 | 3 | #事务B：也启动一个事务(那么两个事务交叉了) #在这事务中更新数据，且未提交 start transaction; update tx set num=10 where id=1; select * from tx; | id | num | | 1 | 10 | | 2 | 2 | | 3 | 3 | #事务A：这个时候我们在事务A中能看到数据的变化吗? select * from tx; | id | num | | 1 | 1 |---&gt;并不能看到！ | 2 | 2 | | 3 | 3 | |——&gt;相同的select语句，结果却不一样 #事务B：如果提交了事务B呢? commit; #事务A: select * from tx; | id | num | | 1 | 10 |---&gt;因为事务B已经提交了，所以在A中我们看到了数据变化 | 2 | 2 | | 3 | 3 | 第3级别：Repeatable Read(可重读)1.这是MySQL的默认事务隔离级别2.它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行3.此级别可能出现的问题——幻读(Phantom Read)：当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行4.InnoDB和Falcon存储引擎通过多版本并发控制(MVCC，Multiversion Concurrency Control)机制解决了该问题 #首先，更改隔离级别 set tx_isolation=&#39;repeatable-read&#39;; select @@tx_isolation; | @@tx_isolation | +------+------+ | REPEATABLE-READ | +------+------+ #事务A：启动一个事务 start transaction; select * from tx; | id | num | +------+------+ | 1 | 1 | | 2 | 2 | | 3 | 3 | +------+------+ #事务B：开启一个新事务(那么这两个事务交叉了) #在事务B中更新数据，并提交 start transaction; update tx set num=10 where id=1; select * from tx; +------+------+ | id | num | +------+------+ | 1 | 10 | | 2 | 2 | | 3 | 3 | +------+------+ commit; #事务A：这时候即使事务B已经提交了,但A能不能看到数据变化？ select * from tx;+------+------+ | id | num | +------+------+ | 1 | 1 | ---&gt;还是看不到的！(这个级别2不一样，也说明级别3解决了不可重复读问题) | 2 | 2 | | 3 | 3 | +------+------+ #事务A：只有当事务A也提交了，它才能够看到数据变化 commit;select * from tx; +------+------+ | id | num | +------+------+ | 1 | 10 | | 2 | 2 | | 3 | 3 | +------+------+ 第4级别：Serializable(可串行化)1.这是最高的隔离级别2.它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之,它是在每个读的数据行上加上共享锁。3.在这个级别，可能导致大量的超时现象和锁竞争 #首先修改隔离界别 set tx_isolation=&#39;serializable&#39;; select @@tx_isolation; +----------------+ | @@tx_isolation | +----------------+ | SERIALIZABLE | +----------------+ #事务A：开启一个新事务 start transaction; #事务B：在A没有commit之前，这个交叉事务是不能更改数据的 start transaction; insert tx values(&#39;4&#39;,&#39;4&#39;); ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionupdate tx set num=10 where id=1;ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>事务隔离级别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[equals、==和hashCode]]></title>
    <url>%2F2017%2F08%2F01%2Fequals%E3%80%81-%E5%92%8ChashCode%2F</url>
    <content type="text"><![CDATA[引言equals：是否同一个对象实例。注意，是“实例”。比如String s = new String(“test”); s.equals(s), 这就是同一个对象实例的比较； 等号(==)：对比对象实例的内存地址（也即对象实例的ID），来判断是否是同一对象实例；又可以说是判断对象实例是否物理相等； Hashcode：我觉得可以这样理解：并不是对象的内存地址，而是利用hash算法，对对象实例的一种描述符（或者说对象存储位置的hash算法映射）——对象实例的哈希码。 ==比较的是对象的地址String重写的equals比较的是字符串的内容值String重写的hashCode已经不是对象内存地址的hash码，是根据内容产生的，因为a、b是两个完全不同的对象，也满足这条规律“equals相等的两个对象，hashCode也相等”。System.identityHashCode是未被重写的获取对象内存地址hash码的函数，new出来的String对象的内存地址是不一样的，所以hash值也不一样 示例12345678910111213141516171819202122232425public class Test &#123; public static void main(String[] args) &#123; String a=new String(&quot;foo&quot;); String b=new String(&quot;foo&quot;); String c=&quot;hello&quot;; String d=&quot;hello&quot;; System.out.println(&quot;memory address hashcode a:&quot;+System.identityHashCode(a)); System.out.println(&quot;memory address hashcode a:&quot;+System.identityHashCode(b)); System.out.println(&quot;String hashcode a: &quot;+a.hashCode()); System.out.println(&quot;String hashcode a: &quot;+b.hashCode()); System.out.println(&quot;a==b: &quot;+(a==b)); System.out.println(&quot;a.equals(b): &quot;+a.equals(b)); System.out.println(&quot;&quot;); System.out.println(&quot;memory address hashcode c:&quot;+System.identityHashCode(c)); System.out.println(&quot;memory address hashcode d:&quot;+System.identityHashCode(d)); System.out.println(&quot;String hashcode c: &quot;+c.hashCode()); System.out.println(&quot;String hashcode d: &quot;+d.hashCode()); System.out.println(&quot;c==d: &quot;+(c==d)); System.out.println(&quot;c.equals(d): &quot;+c.equals(d)); &#125;&#125; 结果：123456789101112memory address hashcode a:8222510memory address hashcode a:18581223String hashcode a: 101574String hashcode a: 101574a==b: falsea.equals(b): truememory address hashcode c:3526198memory address hashcode d:3526198String hashcode c: 99162322String hashcode d: 99162322c==d: truec.equals(d): true 从Java集合的常用需求为什么需要使用HashcodeJava中的集合（Collection）有两类，一类是List，再有一类是Set。前者集合内的元素是有序的，元素可以重复；后者元素无序，但元素不可重复。那么这里就有一个比较严重的问题了：要想保证元素不重复，可两个元素是否重复应该依据什么来判断呢？这就是 Object.equals方法了。但是，如果每增加一个元素就检查一次，那么当元素很多时，后添加到集合中的元素比较的次数就非常多了。也就是说，如果集合中现在已经有1000个元素，那么第1001个元素加入集合时，它就要调用1000次equals方法。这显然会大大降低效率。 于是，Java采用了哈希表的原理。哈希算法也称为散列算法，是将数据依特定算法直接指定到一个地址上。可以这样简单理解，hashCode方法实际上返回的就是对象存储位置的映像。 这样一来，当集合要添加新的元素时，先调用这个元素的hashCode方法，就能定位到它应该放置的bucket存储位置。如果这个位置上没有元素，它就可以直接存储在这个位置上，不用再进行任何比较了；如果这个位置上已经有元素了，就调用它的equals方法与新元素进行比较，相同的话就不存了，不相同就表示发生冲突了，散列表对于冲突有具体的解决办法，但最终还会将新元素保存在适当的位置。这样一来，实际调用equals方法的次数就大大降低了，几乎只需要一两次。 简单归纳，hashmap的深入理解： HashMap的数据结构是基于数组和链表的。（以数组存储元素，如有hash相同的元素，在数组结构中，创建链表结构，再把hash相同的元素放到链表的下一个节点） hashMap的结构类似这样 元素0—&gt;[hashCode=0, key.value=x1的数据] 元素1—&gt;[hashCode=1, key.value=y1的数据] 。。。。。。 元素n—&gt;[hashCode=n, key.value=z1的数据] 假设没有hashCode=1的元素加入，但是有两个hashCode=0的数据，它的结构就变成这样 元素0—&gt;[hashCode=0, key.value=x1的数据].next—&gt;[hashCode=0, key.value=x2的数据] 元素1—&gt;[null] …… 元素n—&gt;[hashCode=n, key.value=z1的数据] put和get都首先会调用hashcode方法，去查找相关的key，当有冲突时，再调用equals（这也是为什么刚开始就重温hashcode和equals的原因）！HashMap基于hashing原理，我们通过put()和get()方法储存和获取对象。当我们将键值对传递给put()方法时，它调用键对象的hashCode()方法来计算hashcode，让后找到bucket位置来储存值对象。当获取对象时，通过键对象的equals()方法找到正确的键值对，然后返回值对象。HashMap使用链表来解决碰撞问题，当发生碰撞了，对象将会储存在链表的下一个节点中。 HashMap在每个链表节点中储存键值对对象。 当两个不同的键对象的hashcode相同时会发生什么？ 它们会储存在同一个bucket位置的链表中。键对象的equals()方法用来找到键值对。 HashMap的工作原理HashMap基于hashing原理，我们通过put()和get()方法储存和获取对象。当我们将键值对传递给put()方法时，它调用键对象的hashCode()方法来计算hashcode，让后找到bucket位置来储存值对象。当获取对象时，通过键对象的equals()方法找到正确的键值对，然后返回值对象。HashMap使用链表来解决碰撞问题，当发生碰撞了，对象将会储存在链表的下一个节点中。 HashMap在每个链表节点中储存键值对对象。 当两个不同的键对象的hashcode相同时会发生什么？ 它们会储存在同一个bucket位置的链表中。键对象的equals()方法用来找到键值对。 重写 equals 的时候必须重写 hashCodeSUN官方的文档中规定”如果重定义equals方法，就必须重定义hashCode方法,以便用户可以将对象插入到散列(哈希)表中” 那么 SUN 公司是出于什么考虑做了这个规定呢？ 在集合框架中的HashSet，HashTable和HashMap都使用哈希表的形式存储数据，而hashCode计算出来的哈希码便是它们的身份证。哈希码的存在便可以： 快速定位对象，提高哈希表集合的性能。只有当哈希表中对象的索引即hashCode和对象的属性即equals同时相等时，才能够判断两个对象相等。从上面可以看出，哈希码主要是为哈希表服务的，其实如果不需要使用哈希表，也可以不重写hashCode。但是SUN公司应该是出于对程序扩展性的考虑（万一以后需要将对象放入哈希表集合中），才会规定重写equals的同时需要重写hashCode，以避免后续开发不必要的麻烦。 重写equals的注意事项 Java语言规范要求equals需要具有如下的特性： 自反性：对于任何非空引用 x，x.equals() 应该返回 true。对称性：对于任何引用 x 和 y，当且仅当 y.equals(x) 返回 true，x.equals(y) 也应该返回 true。传递性：对于任何引用 x、y 和 z，如果 x.equals(y)返回 true，y.equals(z) 也应返回同样的结果。一致性：如果 x 和 y 引用的对象没有发生变化，反复调用 x.equals(y) 应该返回同样的结果。对于任意非空引用 x，x.equals(null) 应该返回 false。在对象比较时，我们应该如何编写出一个符合特性的 equals 方法呢，《Core Java》中提出了如下建议： 显式参数命名为 otherObject，稍后将它转换成另一个叫做 other 的变量。检测 this 与 otherObject 是否引用同一个对象： if (this == otherObject) return true;计算这个等式可以避免一个个比较类中的域，实现优化。 检测 otherObject 是否为 null，如果为 null，返回 false。进行非空校验是十分重要的。 比较 this 与 otherObject 是否属于同一个类。 如果每个子类都重写了 equals，使用 getClass 检验：12if (getClass() != otherObject.getClass()) return false; 如果所有子类都使用同一个 equals，就用 instanceof 检验：12if (!(otherObject instanceof ClassName)) return false; 将 otherObject 转换为相应的类型变量。1ClassName other = (ClassName) otherObject; 现在可以对所有需要比较的域进行比较了。 基本类型使用 == 比较对象使用 equals 比较数组类型的域可以使用静态方法 Arrays.equals检测相应数组元素是否相等如果所有域匹配，则返回 true注意：子类重写父类 equals 方法时，必须完全覆盖父类方法，不能因为类型错误或者其他原因定义了一个完全无关的方法。可以使用 @Override 注解对覆盖父类的方法进行标记，这样编译器便会检测到覆盖过程中的错误。 重写 hashCode 的注意事项散列码（hash code）是由对象导出的一个整型值。散列码没有规律，在不同的对象中通过不同的算法生成，Java中生成 hashCode 的策略为（以下说明均摘自 Java API 8）： String 类的 hashCode 根据其字符串内容，使用算法计算后返回哈希码。1Returns a hash code for this string. The hash code for a String object is computed as s[0]*31^(n-1) + s[1]*31^(n-2) + ... + s[n-1] Integer 类返回的哈希码为其包含的整数数值。1Returns: a hash code value for this object, equal to the primitive int value represented by this Integer object. Object 类的 hashCode 返回对象的内存地址经过处理后的数值。1Returns a hash code value for the object. This method is supported for the benefit of hash tables such as those provided by HashMap. 在自己的类中想要重写 hashCode 的话一般怎么做呢？建议合理地组合实例域的散列码，让各个不同对象产生的散列码更加均匀。例如我们现在有一个 Cat 对象，它有 name、size 和 color 三个不同域，那么可以重写 hashCode 方法如下： 12345678910class Cat &#123; ...... public int hashCode() &#123; //hashCode是可以返回负值的 return 6 * name.hashCode() + 8 * new Double(size).hashCode() + 10 * color.hashCode(); &#125; ......&#125; 当然还有更好的做法，我们可以直接调用静态方法 Objects.hash 并提供多个参数。这个方法会对各个参数调用 Object.hashCode，并组合返回的散列码。故以上的方法可以缩写为：123public int hashCode() &#123; return Objects.hash(name, size, color);&#125; 【注意】 equals与hashCode的定义必须一致，两个对象equals为true，就必须有相同的hashCode。例如：如果定义的equals比较的是小猫的 name，那么hashCode就需要散列该 name，而不是小猫的 color 或 size。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap工作原理]]></title>
    <url>%2F2017%2F07%2F28%2FHashMap%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[引言HashMap的工作原理是近年来常见的Java面试题。几乎每个Java程序员都知道HashMap，都知道哪里要用HashMap，知道Hashtable和HashMap之间的区别，那么为何这道面试题如此特殊呢？是因为这道题考察的深度很深。这题经常出现在高级或中高级面试中。投资银行更喜欢问这个问题，甚至会要求你实现HashMap来考察你的编程能力。ConcurrentHashMap和其它同步集合的引入让这道题变得更加复杂。让我们开始探索的旅程吧！ HashMap“你用过HashMap吗？” “什么是HashMap？你为什么用到它？” 几乎每个人都会回答“是的”，然后回答HashMap的一些特性，譬如HashMap可以接受null键值和值，而Hashtable则不能；HashMap是非synchronized;HashMap很快；以及HashMap储存的是键值对等等。这显示出你已经用过HashMap，而且对它相当的熟悉。但是面试官来个急转直下，从此刻开始问出一些刁钻的问题，关于HashMap的更多基础的细节。面试官可能会问出下面的问题： “你知道HashMap的工作原理吗？” “你知道HashMap的get()方法的工作原理吗？”你也许会回答“我没有详查标准的Java API，你可以看看Java源代码或者Open JDK。”“我可以用Google找到答案。” 但一些面试者可能可以给出答案，“HashMap是基于hashing的原理，我们使用put(key, value)存储对象到HashMap中，使用get(key)从HashMap中获取对象。当我们给put()方法传递键和值时，我们先对键调用hashCode()方法，返回的hashCode用于找到bucket位置来储存Entry对象。”这里关键点在于指出，HashMap是在bucket中储存键对象和值对象，作为Map.Entry。这一点有助于理解获取对象的逻辑。如果你没有意识到这一点，或者错误的认为仅仅只在bucket中存储值的话，你将不会回答如何从HashMap中获取对象的逻辑。这个答案相当的正确，也显示出面试者确实知道hashing以及HashMap的工作原理。但是这仅仅是故事的开始，当面试官加入一些Java程序员每天要碰到的实际场景的时候，错误的答案频现。下个问题可能是关于HashMap中的碰撞探测(collision detection)以及碰撞的解决方法： “当两个对象的hashcode相同会发生什么？” 从这里开始，真正的困惑开始了，一些面试者会回答因为hashcode相同，所以两个对象是相等的，HashMap将会抛出异常，或者不会存储它们。然后面试官可能会提醒他们有equals()和hashCode()两个方法，并告诉他们两个对象就算hashcode相同，但是它们可能并不相等。一些面试者可能就此放弃，而另外一些还能继续挺进，他们回答“因为hashcode相同，所以它们的bucket位置相同，‘碰撞’会发生。因为HashMap使用链表存储对象，这个Entry(包含有键值对的Map.Entry对象)会存储在链表中。”这个答案非常的合理，虽然有很多种处理碰撞的方法，这种方法是最简单的，也正是HashMap的处理方法。但故事还没有完结，面试官会继续问： “如果两个键的hashcode相同，你如何获取值对象？” 面试者会回答：当我们调用get()方法，HashMap会使用键对象的hashcode找到bucket位置，然后获取值对象。面试官提醒他如果有两个值对象储存在同一个bucket，他给出答案:将会遍历链表直到找到值对象。面试官会问因为你并没有值对象去比较，你是如何确定确定找到值对象的？除非面试者直到HashMap在链表中存储的是键值对，否则他们不可能回答出这一题。 其中一些记得这个重要知识点的面试者会说，找到bucket位置之后，会调用keys.equals()方法去找到链表中正确的节点，最终找到要找的值对象。完美的答案！ 许多情况下，面试者会在这个环节中出错，因为他们混淆了hashCode()和equals()方法。因为在此之前hashCode()屡屡出现，而equals()方法仅仅在获取值对象的时候才出现。一些优秀的开发者会指出使用不可变的、声明作final的对象，并且采用合适的equals()和hashCode()方法的话，将会减少碰撞的发生，提高效率。不可变性使得能够缓存不同键的hashcode，这将提高整个获取对象的速度，使用String，Interger这样的wrapper类作为键是非常好的选择。 如果你认为到这里已经完结了，那么听到下面这个问题的时候，你会大吃一惊。“如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办？”除非你真正知道HashMap的工作原理，否则你将回答不出这道题。默认的负载因子大小为0.75，也就是说，当一个map填满了75%的bucket时候，和其它集合类(如ArrayList等)一样，将会创建原来HashMap大小的两倍的bucket数组，来重新调整map的大小，并将原来的对象放入新的bucket数组中。这个过程叫作rehashing，因为它调用hash方法找到新的bucket位置。 如果你能够回答这道问题，下面的问题来了：“你了解重新调整HashMap大小存在什么问题吗？”你可能回答不上来，这时面试官会提醒你当多线程的情况下，可能产生条件竞争(race condition)。 当重新调整HashMap大小的时候，确实存在条件竞争，因为如果两个线程都发现HashMap需要重新调整大小了，它们会同时试着调整大小。在调整大小的过程中，存储在链表中的元素的次序会反过来，因为移动到新的bucket位置的时候，HashMap并不会将元素放在链表的尾部，而是放在头部，这是为了避免尾部遍历(tail traversing)。如果条件竞争发生了，那么就死循环了。这个时候，你可以质问面试官，为什么这么奇怪，要在多线程的环境下使用HashMap呢？：） 为什么String, Interger这样的wrapper类适合作为键？ String, Interger这样的wrapper类作为HashMap的键是再适合不过了，而且String最为常用。因为String是不可变的，也是final的，而且已经重写了equals()和hashCode()方法了。其他的wrapper类也有这个特点。不可变性是必要的，因为为了要计算hashCode()，就要防止键值改变，如果键值在放入时和获取时返回不同的hashcode的话，那么就不能从HashMap中找到你想要的对象。不可变性还有其他的优点如线程安全。如果你可以仅仅通过将某个field声明成final就能保证hashCode是不变的，那么请这么做吧。因为获取对象的时候要用到equals()和hashCode()方法，那么键对象正确的重写这两个方法是非常重要的。如果两个不相等的对象返回不同的hashcode的话，那么碰撞的几率就会小些，这样就能提高HashMap的性能。我们可以使用自定义的对象作为键吗？ 这是前一个问题的延伸。当然你可能使用任何对象作为键，只要它遵守了equals()和hashCode()方法的定义规则，并且当对象插入到Map中之后将不会再改变了。如果这个自定义对象时不可变的，那么它已经满足了作为键的条件，因为当它创建之后就已经不能改变了。我们可以使用CocurrentHashMap来代替Hashtable吗？这是另外一个很热门的面试题，因为ConcurrentHashMap越来越多人用了。我们知道Hashtable是synchronized的，但是ConcurrentHashMap同步性能更好，因为它仅仅根据同步级别对map的一部分进行上锁。ConcurrentHashMap当然可以代替HashTable，但是HashTable提供更强的线程安全性。看看这篇博客查看Hashtable和ConcurrentHashMap的区别。我个人很喜欢这个问题，因为这个问题的深度和广度，也不直接的涉及到不同的概念。让我们再来看看这些问题设计哪些知识点： hashing的概念HashMap中解决碰撞的方法equals()和hashCode()的应用，以及它们在HashMap中的重要性不可变对象的好处HashMap多线程的条件竞争重新调整HashMap的大小 HashMap的工作原理HashMap基于hashing原理，我们通过put()和get()方法储存和获取对象。当我们将键值对传递给put()方法时，它调用键对象的hashCode()方法来计算hashcode，让后找到bucket位置来储存值对象。当获取对象时，通过键对象的equals()方法找到正确的键值对，然后返回值对象。HashMap使用链表来解决碰撞问题，当发生碰撞了，对象将会储存在链表的下一个节点中。 HashMap在每个链表节点中储存键值对对象。 当两个不同的键对象的hashcode相同时会发生什么？ 它们会储存在同一个bucket位置的链表中。键对象的equals()方法用来找到键值对。 因为HashMap的好处非常多，我曾经在电子商务的应用中使用HashMap作为缓存。因为金融领域非常多的运用Java，也出于性能的考虑，我们会经常用到HashMap和ConcurrentHashMap。 简单归纳，hashmap的深入理解： HashMap的数据结构是基于数组和链表的。（以数组存储元素，如有hash相同的元素，在数组结构中，创建链表结构，再把hash相同的元素放到链表的下一个节点） hashMap的结构类似这样 元素0—&gt;[hashCode=0, key.value=x1的数据] 元素1—&gt;[hashCode=1, key.value=y1的数据] 。。。。。。 元素n—&gt;[hashCode=n, key.value=z1的数据] 假设没有hashCode=1的元素加入，但是有两个hashCode=0的数据，它的结构就变成这样 元素0—&gt;[hashCode=0, key.value=x1的数据].next—&gt;[hashCode=0, key.value=x2的数据] 元素1—&gt;[null] …… 元素n—&gt;[hashCode=n, key.value=z1的数据] put和get都首先会调用hashcode方法，去查找相关的key，当有冲突时，再调用equals（这也是为什么刚开始就重温hashcode和equals的原因）！HashMap基于hashing原理，我们通过put()和get()方法储存和获取对象。当我们将键值对传递给put()方法时，它调用键对象的hashCode()方法来计算hashcode，让后找到bucket位置来储存值对象。当获取对象时，通过键对象的equals()方法找到正确的键值对，然后返回值对象。HashMap使用链表来解决碰撞问题，当发生碰撞了，对象将会储存在链表的下一个节点中。 HashMap在每个链表节点中储存键值对对象。 当两个不同的键对象的hashcode相同时会发生什么？ 它们会储存在同一个bucket位置的链表中。键对象的equals()方法用来找到键值对。 HashMap基于hashing原理，我们通过put()和get()方法储存和获取对象。当我们将键值对传递给put()方法时，它调用键对象的hashCode()方法来计算hashcode，让后找到bucket位置来储存值对象。当获取对象时，通过键对象的equals()方法找到正确的键值对，然后返回值对象。HashMap使用链表来解决碰撞问题，当发生碰撞了，对象将会储存在链表的下一个节点中。 HashMap在每个链表节点中储存键值对对象。 当两个不同的键对象的hashcode相同时会发生什么？ 它们会储存在同一个bucket位置的链表中。键对象的equals()方法用来找到键值对。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>hashmap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[volatile用法]]></title>
    <url>%2F2017%2F07%2F28%2Fvolatile%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[引言在Java中除了long和double类型的基本类型变量的赋值操作外都是原子操作，也就是说，对于变量值的简单读写操作没有必要进行同步。 vilatileJava中的原子操作包括：1）除long和double之外的基本类型的赋值操作2）所有引用reference的赋值操作3）java.concurrent.Atomic.* 包中所有类的一切操作。long和double占用的字节数都是8，也就是64bits。在32位操作系统上对64位的数据的读写要分两步完成，每一步取32位数据。这样对double和long的赋值操作就会有问题：如果有两个线程同时写一个变量内存，一个进程写低32位，而另一个写高32位，这样将导致获取的64位数据是失效的数据。因此需要使用volatile关键字来防止此类现象。volatile本身不保证获取和设置操作的原子性，仅仅保持修改的可见性。但是java的内存模型保证声明为volatile的long和double变量的get和set操作是原子的。 在当前的Java内存模型下，线程可以把变量保存在本地内存（比如机器的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成数据的不一致。 要解决这个问题，只需要像在本程序中的这样，把该变量声明为volatile（不稳定的）即可，这就指示JVM，这个变量是不稳定的，每次使用它都到主存中进行读取。一般说来，多任务环境下各任务间共享的标志都应该加volatile修饰。 Volatile修饰的成员变量在每次被线程访问时，都强迫从共享内存中重读该成员变量的值。而且，当成员变量发生变化时，强迫线程将变化值回写到共享内存。这样在任何时刻，两个不同的线程总是看到某个成员变量的同一个值。 Java语言规范中指出：为了获得最佳速度，允许线程保存共享成员变量的私有拷贝，而且只当线程进入或者离开同步代码块时才与共享成员变量的原始值对比。 这样当多个线程同时与某个对象交互时，就必须要注意到要让线程及时的得到共享成员变量的变化。 而volatile关键字就是提示VM：对于这个成员变量不能保存它的私有拷贝，而应直接与共享成员变量交互。 使用建议：在两个或者更多的线程访问的成员变量上使用volatile。当要访问的变量已在synchronized代码块中，或者为常量时，不必使用。 由于使用volatile屏蔽掉了VM中必要的代码优化，所以在效率上比较低，因此一定在必要时才使用此关键字。 示例public class UnatomicLong implements Runnable { private static long test = 0; private final long val; public UnatomicLong(long val) { this.val = val; } @Override public void run() { while (!Thread.interrupted()) { test = val; //两个线程都试图将自己的私有变量val赋值给类私有静态变量test } } public static void main(String[] args) { Thread t1 = new Thread(new UnatomicLong(-1)); Thread t2 = new Thread(new UnatomicLong(0)); System.out.println(Long.toBinaryString(-1)); System.out.println(pad(Long.toBinaryString(0), 64)); t1.start(); t2.start(); long val; while ((val = test) == -1 || val == 0) { //如果静态成员test的值是-1或0，说明两个线程操作没有交叉 } System.out.println(pad(Long.toBinaryString(val), 64)); System.out.println(val); t1.interrupt(); t2.interrupt(); } // prepend 0s to the string to make it the target length private static String pad(String s, int targetLength) { int n = targetLength - s.length(); for (int x = 0; x &lt; n; x++) { s = &quot;0&quot; + s; } return s; } } 运行发现程序在while循环时进入了死循环，这是因为使用的JVM是64bits。在64位JVM中double和long的赋值操作是原子操作。在eclipse中修改jre为一个32bit的JVM地址，则会有如下运行结果：111111111111111111111111111111111111111111111111111111111111111100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000011111111111111111111111111111111//很明显test的值被破坏了4294967295]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>volatile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java常量池]]></title>
    <url>%2F2017%2F07%2F28%2Fjava%E5%B8%B8%E9%87%8F%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[引言接上一篇文章继续探索string类牵带出的常量池 jvm程序计数器：1.在IDE上编译的Java代码运行时都会被转译成字节码。程序计数器的就是给编译好的字节码添加行号，这样这些字节码就以程序计数器的编号来作为调度时候的标识了。 2.在程序运行时，诸如循环，跳转，异常处理这些功能都必须依赖于字节码来完。 我的理解：字节码是二进制文件，所以识别起来很难，代表一个功能的字节码数量巨大。如果在编译的时候就将其在程序计数器上进行编号，则后期调用的时候就可以按照程序员在IDE上用高级语言编译时候的顺序进行分条执行了。栈：栈不灵活，但是很严格，是安全的，易于管理。因为只要上面的引用没有销毁，下面引用就一定还在，在大部分程序中，都是先定义的变量、引用先进栈，后定义的后进栈，同时，区块内部的变量、引用在进入区块时压栈，区块结束时出栈，理解了这种机制，我们就可以很方便地理解各种编程语言的作用域的概念了，同时这也是栈的优点——错误的引用逻辑在编译时就可以被发现，主要存放引用和基本数据类型。包括：&ensp;&ensp;&ensp;1.本地方法栈：是jvm调用操作系统方法所使用的栈。 &ensp;&ensp;&ensp;2.虚拟机栈：是jvm执行java代码所使用的栈。 方法区：存放了一些常量、静态变量、类信息等，可以理解成class文件在内存中的存放位置。 虚拟机堆：堆很灵活，但是不安全。对于对象，我们要动态地创建、销毁，不能说后创建的对象没有销毁，先前创建的对象就不能销毁，那样的话我们的程序就寸步难行，所以Java中用堆来存储对象。而一旦堆中的对象被销毁，我们继续引用这个对象的话，就会出现著名的 NullPointerException，这就是堆的缺点——错误的引用逻辑只有在运行时才会被发现。主要用来存放 new 出来的对象实例。 Java中的常量池：，实际上分为两种形态：静态常量池和运行时常量池。 &ensp;&ensp;&ensp;1.静态常量池：，即*.class文件中的常量池，class文件中的常量池不仅仅包含字符串(数字)字面量，还包含类、方法的信息，占用class文件绝大部分空间。 &ensp;&ensp;&ensp;2.运行时常量池：，则是jvm虚拟机在完成类装载操作后，将class文件中的常量池载入到内存中，并保存在方法区中，我们常说的常量池，就是指方法区中的运行时常量池。 接下来我们引用一些网络上流行的常量池例子，然后借以讲解。12345678910111213141516String s1 = &quot;Hello&quot;; String s2 = &quot;Hello&quot;; String s3 = &quot;Hel&quot; + &quot;lo&quot;; String s4 = &quot;Hel&quot; + new String(&quot;lo&quot;); String s5 = new String(&quot;Hello&quot;); String s6 = s5.intern(); String s7 = &quot;H&quot;; String s8 = &quot;ello&quot;; String s9 = s7 + s8; System.out.println(s1 == s2); // true System.out.println(s1 == s3); // true System.out.println(s1 == s4); // false System.out.println(s1 == s9); // false System.out.println(s4 == s5); // false System.out.println(s1 == s6); // true 在上节中提到，在java 中，直接使用==操作符，比较的是两个字符串的引用地址，并不是比较内容，比较内容请用equals()方法。 s1 == s2这个非常好理解，s1、s2在赋值时，均使用的字符串字面量，说白话点，就是直接把字符串写死，在编译期间，这种字面量会直接放入class文件的常量池中，从而实现复用，载入运行时常量池后，s1、s2指向的是同一个内存地址，所以相等。 s1 == s3这个地方有个坑，s3虽然是动态拼接出来的字符串，但是所有参与拼接的部分都是已知的字面量，在编译期间，这种拼接会被优化，编译器直接帮你拼好，因此String s3 = “Hel” + “lo”;在class文件中被优化成String s3 = “Hello”;，所以s1 == s3成立。 s1 == s4当然不相等，s4虽然也是拼接出来的，但new String(“lo”)这部分不是已知字面量，是一个不可预料的部分，编译器不会优化，必须等到运行时才可以确定结果，结合字符串不变定理，鬼知道s4被分配到哪去了，所以地址肯定不同。配上一张简图理清思路： s1 == s9也不相等，道理差不多，虽然s7、s8在赋值的时候使用的字符串字面量，但是拼接成s9的时候，s7、s8作为两个变量，都是不可预料的，编译器毕竟是编译器，不可能当解释器用，所以不做优化，等到运行时，s7、s8拼接成的新字符串，在堆中地址不确定，不可能与方法区常量池中的s1地址相同。 s4 == s5已经不用解释了，绝对不相等，二者都在堆中，但地址不同。 s1 == s6这两个相等完全归功于intern方法，s5在堆中，内容为Hello ，intern方法会尝试将Hello字符串添加到常量池中，并返回其在常量池中的地址，因为常量池中已经有了Hello字符串，所以intern方法直接返回地址；而s1在编译期就已经指向常量池了，因此s1和s6指向同一地址，相等。 至此，我们可以得出三个非常重要的结论： &ensp;&ensp;&ensp;必须要关注编译期的行为，才能更好的理解常量池。 &ensp;&ensp;&ensp;运行时常量池中的常量，基本来源于各个class文件中的常量池。 &ensp;&ensp;&ensp;程序运行时，除非手动向常量池中添加常量(比如调用intern方法)，否则jvm不会自动添加常量到常量池。 以上所讲仅涉及字符串常量池，实际上还有整型常量池、浮点型常量池等等，但都大同小异，只不过数值类型的常量池不可以手动添加常量，程序启动时常量池中的常量就已经确定了，比如整型常量池中的常量范围：-128~127，只有这个范围的数字可以用到常量池。 说了这么多理论，接下来让我们触摸一下真正的常量池。 前文提到过，class文件中存在一个静态常量池，这个常量池是由编译器生成的，用来存储java源文件中的字面量(本文仅仅关注字面量)，假设我们有如下java代码：1String s = &quot;hi&quot;; 为了方便起见，就这么简单，没错！将代码编译成class文件后，用UE打开二进制格式的class文件。如图： 在命令行我们通过javap工具来查看一个class文件的字节码。1javap -v test 如图所示： 简单讲解一下class文件的结构，开头的4个字节是class文件魔数，用来标识这是一个class文件，说白话点就是文件头，既：CA FE BA BE。 紧接着4个字节是java的版本号，这里的版本号是34，因为笔者是用jdk8编译的，版本号的高低和jdk版本的高低相对应，高版本可以兼容低版本，但低版本无法执行高版本。所以，如果哪天读者想知道别人的class文件是用什么jdk版本编译的，就可以看这4个字节，对应关系如下： jdk1.4 对应48 （00 30）,jdk1.5 对应49,（00 31）,jdk1.6 对应50,（00 32）,jdk1.7 对应51,（00 33）,jdk1.8 对应52,（00 34）, 接下来就是常量池入口，入口处用2个字节标识常量池常量数量，本例中数值为00 13，翻译成十进制是19，也就是有18个常量，其中第0个常量是特殊值，所以只有18个常量。 常量池中存放了各种类型的常量，他们都有自己的类型，并且都有自己的存储规范，本文只关注字符串常量 01 00 02 68 69 ，其中01代表的是“utf-8编码的字符串”，00 02代表的是这个字符串的长度是2个字节，68 69这2个字节代表的就是这个字符串的内容，因为是ascii码，每个字节对应一个字符，翻译过来就是hi 接下来再说说运行时常量池，由于运行时常量池在方法区中，我们可以通过jvm参数：-XX:PermSize、-XX:MaxPermSize来设置方法区大小，从而间接限制常量池大小。 假设jvm启动参数为：-XX:PermSize＝2M -XX:MaxPermSize＝2M，然后运行如下代码：123456789//保持引用，防止自动垃圾回收List&lt;String&gt; list = new ArrayList&lt;String&gt;(); int i = 0; while(true)&#123; //通过intern方法向常量池中手动添加常量 list.add(String.valueOf(i++).intern());&#125; 程序立刻会抛出：Exception in thread “main” java.lang.outOfMemoryError: PermGen space异常。PermGen space正是方法区，足以说明常量池在方法区中。 在jdk8中，移除了方法区，转而用Metaspace区域替代，所以我们需要使用新的jvm参数：-XX:MaxMetaspaceSize=2M，依然运行如上代码，抛出：java.lang.OutOfMemoryError: Metaspace异常。同理说明运行时常量池是划分在Metaspace区域中。具体关于Metaspace区域的知识，请读者自行搜索。 本文所有代码均在jdk7、jdk8下测试通过，其他版本jdk可能会略有差异，请读者自行探索。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>常量池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[string比较之‘’equals‘’和‘’==‘’]]></title>
    <url>%2F2017%2F07%2F28%2Fstring%E6%AF%94%E8%BE%83%E4%B9%8B%E2%80%98%E2%80%99equals%E2%80%98%E2%80%99%E5%92%8C%E2%80%98%E2%80%99%3D%3D%E2%80%98%E2%80%99%2F</url>
    <content type="text"><![CDATA[引言最近我发现了一个事情，那就是在面试笔试中，好多公司都喜欢在String字符串上出问题，涉及到方方面面的知识，包括其中的一些常用方法。在此，我总结下关于String类中的equals方法，以备应对以后的笔试面试。 equals和”==”string是一个final class，两种声明方法 :1.通过new关键字，创建一个新对象，分配一块新的、独立的内存堆String s1 = new String(“Hello”);2.直接赋值，创建一个”Hello”字符串放入字符串常量池里面,s2只是这个字符串的引用.String s2 = “Hello”; 这里s2属于字符串字面量，下一节会详细介绍 在java 中，string重写了equals和hashCode方法，都是以字符串内容复写的，直接使用”==”操作符，比较的是两个字符串的引用是否指向同一个对象，并不是比较内容，”equals”方法比较的是字符串内容，所以如果”==”返回true则”equals”一定为true,反之则不然。下面来看具体例子：1234567891011121314151617181920212223String s1 = new String(&quot;Hello&quot;);String s2 = new String(&quot;Hello&quot;);System.out.println(s1 == s2);// falseSystem.out.println(s1.equals(s2)); //trueString s3 = new String(&quot;Hello&quot;);String s4 = s3;System.out.println(s3 == s4);// trueSystem.out.println(s3.equals(s4));// trueString s5 = &quot;Hello&quot;;String s6 = &quot;Hello&quot;;System.out.println(s5 == s6);// trueSystem.out.println(s5.equals(s6));// trueString s7 = &quot;Hello&quot;;String s8 = new String(&quot;Hello&quot;);System.out.println(s7 == s8);// false，System.out.println(s7.equals(s8));// trueString s9 = s3.intern();System.out.println(s7 == s9);// true，System.out.println(s7.equals(s9));// true intern方法会尝试将Hello字符串添加到常量池中，并返回其在常量池中的地址，因为常量池中已经有了Hello字符串，所以intern方法直接返回地址；而s7在编译期就已经指向常量池了，因此s7和s9指向同一地址，相等。 扩展假设有一个类，它有一个记录消息的方法，这个方法记录用户传来的消息(假设消息内容可能较大，并且重复率较高)，并且把消息按接收顺序记录在一个列表中。我想有些朋友会这样设计：1234567891011121314import java.util.*;public class Messages &#123;ArrayList messages = new ArrayList();public void record(String msg) &#123;messages.add(msg);&#125;public List getMessages() &#123;return messages;&#125;&#125; 这种设计方案好吗？假设我们重复的发送给record()方法同一个消息(消息来自不同的用户，所以可以视每个消息为一个new String(“…”))，并且消息内容较大，那么这个设计将会大大浪费内存空间，因为消息列表中记录的都是新创建的、独立的String对象，虽然它们的内容都相同。那么怎么样可以对其进行优化呢，其实很简单，请看如下优化后的示例：1234567891011121314import java.util.*;public class Messages &#123;ArrayList messages = new ArrayList();public void record(String msg) &#123;messages.add(msg.intern());&#125;public List getMessages() &#123;return messages;&#125;&#125; 正如你所看到的，原先record()方法中的messages.add(msg);代码段变成了messages.add(msg.intern());，仅仅对msg参数调用了intern()方法，这样将对重复的消息进行共享机制，从而降低了内存消耗，提高了性能。 自己写一个类MyString，里边有一个char[ ] value，实现里边的equalsString方法，要求可以比较两个MyString类的对象。相等返回0，大于返回1，小于返回-1，若比较的不是MyString类型的对象，则返回-100。 代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package cn.ywq.test; class MyString &#123; char[] value; public MyString(char[] value) &#123; this.value=value; //通过构造方法将字符传入 &#125; public int equalsString(Object obj) &#123; if(this==obj)&#123; return 0; &#125; //若该对象是MyString类型的 if(obj instanceof MyString)&#123; MyString string =(MyString) obj; int n=this.value.length; if (n&gt;string.value.length) &#123; //先判断长度的关系 return 1; &#125;else if(n&lt;string.value.length)&#123; return -1; &#125;else&#123; //若长度相等 char v1[] = this.value; char v2[] = string.value; int i = 0; while (n-- != 0) &#123; //按照数组的每一位进行比较 if (v1[i] &gt; v2[i])&#123; return 1; &#125;else if(v1[i] &lt; v2[i])&#123; return -1; &#125; i++; &#125; return 0; //若while循环正常结束，则说明相等，返回0 &#125; &#125; return -100; //若传入的不是MyString类型的对象 &#125; &#125; #测试代码：package cn.ywq.test; public class Test &#123; public static void main(String[] args) &#123; char[] value=&#123;&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;d&apos;&#125;; char[] value2=&#123;&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;d&apos;,&apos;e&apos;&#125;; char[] value3=&#123;&apos;c&apos;,&apos;b&apos;,&apos;c&apos;,&apos;d&apos;&#125;; char[] value4=&#123;&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&#125;; MyString myString = new MyString(value); MyString s=new MyString(value4); int i = myString.equalsString(s); System.out.println(i); &#125; &#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>string</tag>
        <tag>==</tag>
        <tag>equals</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring单例模式与线程安全]]></title>
    <url>%2F2017%2F07%2F26%2FSpring%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%2F</url>
    <content type="text"><![CDATA[引言Spring框架里的bean，或者说组件，获取实例的时候都是默认的单例模式，这是在多线程开发的时候要尤其注意的地方。 单例模式单例模式的意思就是只有一个实例。单例模式确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例。这个类称为单例类。当多用户同时请求一个服务时，容器会给每一个请求分配一个线程，这是多个线程会并发执行该请求多对应的业务逻辑（成员方法），此时就要注意了，如果该处理逻辑中有对该单列状态的修改（体现为该单列的成员属性），则必须考虑线程同步问题同步机制的比较 ThreadLocal和线程同步机制相比有什么优势呢？ThreadLocal和线程同步机制都是为了解决多线程中相同变量的访问冲突问题。 在同步机制中，通过对象的锁机制保证同一时间只有一个线程访问变量。这时该变量是多个线程共享的，使用同步机制要求程序慎密地分析什么时候对变量进行读写，什么时候需要锁定某个对象，什么时候释放对象锁等繁杂的问题，程序设计和编写难度相对较大。 而ThreadLocal则从另一个角度来解决多线程的并发访问。ThreadLocal会为每一个线程提供一个独立的变量副本，从而隔离了多个线程对数据的访问冲突。因为每一个线程都拥有自己的变量副本，从而也就没有必要对该变量进行同步了。ThreadLocal提供了线程安全的共享对象，在编写多线程代码时，可以把不安全的变量封装进ThreadLocal。 由于ThreadLocal中可以持有任何类型的对象，低版本JDK所提供的get()返回的是Object对象，需要强制类型转换。但JDK 5.0通过泛型很好的解决了这个问题，在一定程度地简化ThreadLocal的使用 概括起来说，对于多线程资源共享的问题，同步机制采用了“以时间换空间”的方式，而ThreadLocal采用了“以空间换时间”的方式。前者仅提供一份变量，让不同的线程排队访问，而后者为每一个线程都提供了一份变量，因此可以同时访问而互不影响。 线程安全 Spring使用ThreadLocal解决线程安全问题 我们知道在一般情况下，只有无状态的Bean才可以在多线程环境下共享，在Spring中，绝大部分Bean都可以声明为singleton作用域。就是因为Spring对一些Bean（如RequestContextHolder、TransactionSynchronizationManager、LocaleContextHolder等）中非线程安全状态采用ThreadLocal进行处理，让它们也成为线程安全的状态，因为有状态的Bean就可以在多线程中共享了。 一般的Web应用划分为展现层、服务层和持久层三个层次，在不同的层中编写对应的逻辑，下层通过接口向上层开放功能调用。在一般情况下，从接收请求到返回响应所经过的所有程序调用都同属于一个线程ThreadLocal是解决线程安全问题一个很好的思路，它通过为每个线程提供一个独立的变量副本解决了变量并发访问的冲突问题。在很多情况下，ThreadLocal比直接使用synchronized同步机制解决线程安全问题更简单，更方便，且结果程序拥有更高的并发性。如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。 或者说:一个类或者程序所提供的接口对于线程来说是原子操作或者多个线程之间的切换不会导致该接口的执行结果存在二义性,也就是说我们不用考虑同步的问题。 线程安全问题都是由全局变量及静态变量引起的。若每个线程中对全局变量、静态变量只有读操作，而无写操作，一般来说，这个全局变量是线程安全的；若有多个线程同时执行写操作，一般都需要考虑线程同步，否则就可能影响线程安全。1） 常量始终是线程安全的，因为只存在读操作。2）每次调用方法前都新建一个实例是线程安全的，因为不会访问共享的资源。3）局部变量是线程安全的。因为每执行一个方法，都会在独立的空间创建局部变量，它不是共享的资源。局部变量包括方法的参数变量和方法内变量。有状态就是有数据存储功能。有状态对象(Stateful Bean)，就是有实例变量的对象 ，可以保存数据，是非线程安全的。在不同方法调用间不保留任何状态。无状态就是一次操作，不能保存数据。无状态对象(Stateless Bean)，就是没有实例变量的对象 .不能保存数据，是不变类，是线程安全的。有状态对象:无状态的Bean适合用不变模式，技术就是单例模式，这样可以共享实例，提高性能。有状态的Bean，多线程环境下不安全，那么适合用Prototype原型模式。Prototype: 每次对bean的请求都会创建一个新的bean实例。Struts2默认的实现是Prototype模式。也就是每个请求都新生成一个Action实例，所以不存在线程安全问题。需要注意的是，如果由Spring管理action的生命周期， scope要配成prototype作用域。 线程安全案例SimpleDateFormat(下面简称sdf)类内部有一个Calendar对象引用,它用来储存和这个sdf相关的日期信息,例如sdf.parse(dateStr), sdf.format(date) 诸如此类的方法参数传入的日期相关String, Date等等, 都是交友Calendar引用来储存的.这样就会导致一个问题,如果你的sdf是个static的, 那么多个thread 之间就会共享这个sdf, 同时也是共享这个Calendar引用, 并且, 观察 sdf.parse() 方法,你会发现有如下的调用: Date parse() { calendar.clear(); // 清理calendar ... // 执行一些操作, 设置 calendar 的日期什么的 calendar.getTime(); // 获取calendar的时间 } 这里会导致的问题就是, 如果 线程A 调用了 sdf.parse(), 并且进行了 calendar.clear()后还未执行calendar.getTime()的时候,线程B又调用了sdf.parse(), 这时候线程B也执行了sdf.clear()方法, 这样就导致线程A的的calendar数据被清空了(实际上A,B的同时被清空了). 又或者当 A 执行了calendar.clear() 后被挂起, 这时候B 开始调用sdf.parse()并顺利i结束, 这样 A 的 calendar内存储的的date 变成了后来B设置的calendar的date这个问题背后隐藏着一个更为重要的问题—无状态：无状态方法的好处之一，就是它在各种环境下，都可以安全的调用。衡量一个方法是否是有状态的，就看它是否改动了其它的东西，比如全局变量，比如实例的字段。format方法在运行过程中改动了SimpleDateFormat的calendar字段，所以，它是有状态的。 这也同时提醒我们在开发和设计系统的时候注意下一下三点: 1.自己写公用类的时候，要对多线程调用情况下的后果在注释里进行明确说明2.对线程环境下，对每一个共享的可变变量都要注意其线程安全性3.我们的类和方法在做设计的时候，要尽量设计成无状态的 解决办法 需要的时候创建新实例： 说明：在需要用到SimpleDateFormat 的地方新建一个实例，不管什么时候，将有线程安全问题的对象由共享变为局部私有都能避免多线程问题，不过也加重了创建对象的负担。在一般情况下，这样其实对性能影响比不是很明显的。 使用同步：同步SimpleDateFormat对象 public class DateSyncUtil { private static SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); public static String formatDate(Date date)throws ParseException{ synchronized(sdf){ return sdf.format(date); } } public static Date parse(String strDate) throws ParseException{ synchronized(sdf){ return sdf.parse(strDate); } } } 说明：当线程较多时，当一个线程调用该方法时，其他想要调用此方法的线程就要block，多线程并发量大的时候会对性能有一定的影响。 使用ThreadLocal： public class ConcurrentDateUtil { private static ThreadLocal&lt;DateFormat&gt; threadLocal = new ThreadLocal&lt;DateFormat&gt;() { @Override protected DateFormat initialValue() { return new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); } }; public static Date parse(String dateStr) throws ParseException { return threadLocal.get().parse(dateStr); } public static String format(Date date) { return threadLocal.get().format(date); } } 或 public class ThreadLocalDateUtil { private static final String date_format = &quot;yyyy-MM-dd HH:mm:ss&quot;; private static ThreadLocal&lt;DateFormat&gt; threadLocal = new ThreadLocal&lt;DateFormat&gt;(); public static DateFormat getDateFormat() { DateFormat df = threadLocal.get(); if(df==null){ df = new SimpleDateFormat(date_format); threadLocal.set(df); } return df; } public static String formatDate(Date date) throws ParseException { return getDateFormat().format(date); } public static Date parse(String strDate) throws ParseException { return getDateFormat().parse(strDate); } } 说明：使用ThreadLocal, 也是将共享变量变为独享，线程独享肯定能比方法独享在并发环境中能减少不少创建对象的开销。如果对性能要求比较高的情况下，一般推荐使用这种方法。 抛弃JDK，使用其他类库中的时间格式化类： 1.使用Apache commons 里的FastDateFormat，宣称是既快又线程安全的SimpleDateFormat, 可惜它只能对日期进行format, 不能对日期串进行解析。 2.使用Joda-Time类库来处理时间相关问题 做一个简单的压力测试，方法一最慢，方法三最快，但是就算是最慢的方法一性能也不差，一般系统方法一和方法二就可以满足，所以说在这个点很难成为你系统的瓶颈所在。从简单的角度来说，建议使用方法一或者方法。 如果在必要的时候，追求那么一点性能提升的话，可以考虑用方法三，用ThreadLocal做缓存。Joda-Time类库对时间处理方式比较完美，建议使用。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring scope prototype与singleton]]></title>
    <url>%2F2017%2F07%2F26%2Fspring-scope-prototype%E4%B8%8Esingleton%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[singleton作用域 当一个bean的作用域设置为singleton, 那么Spring IOC容器中只会存在一个共享的bean实例，并且所有对bean的请求，只要id与该bean定义相匹配，则只会返回bean的同一实例。换言之，当把一个bean定义设置为singleton作用域时，Spring IOC容器只会创建该bean定义的唯一实例。这个单一实例会被存储到单例缓存（singleton cache）中，并且所有针对该bean的后续请求和引用都将返回被缓存的对象实例。 这里要注意的是singleton作用域和GOF设计模式中的单例是完全不同的，单例设计模式表示一个ClassLoader中只有一个class存在，而这里的singleton则表示一个容器对应一个bean，也就是说当一个bean被标识为singleton时候，spring的IOC容器中只会存在一个该bean。 prototype prototype作用域部署的bean，每一次请求（将其注入到另一个bean中，或者以程序的方式调用容器的getBean()方法）都会产生一个新的bean实例，相当与一个new的操作，对于prototype作用域的bean，有一点非常重要，那就是Spring不能对一个prototype bean的整个生命周期负责，容器在初始化、配置、装饰或者是装配完一个prototype实例后，将它交给客户端，随后就对该prototype实例不闻不问了。 不管何种作用域，容器都会调用所有对象的初始化生命周期回调方法，而对prototype而言，任何配置好的析构生命周期回调方法都将不会被调用。清除prototype作用域的对象并释放任何prototype bean所持有的昂贵资源，都是客户端代码的职责。（让Spring容器释放被singleton作用域bean占用资源的一种可行方式是，通过使用bean的后置处理器，该处理器持有要被清除的bean的引用。） scope=”prototype”没写的问题,项目中对一个表的增删该操作是用一个action，这个actionadd,update,delete,save这些方法， 添加和修改是共用一个页面，当页面得到id时代表进行的修改操作，反之是添加操作。因为在配置spring的bean是忘了写scope=”prototype” 所以每次添加时都显示最后一次访问过的记录,scope=”prototype” 会在该类型的对象被请求 时创建一个新的action对象。如果没有配置scope=prototype则添加的时候不会新建一个action，他任然会保留上次访问的过记录的信息 webwork的Action不是线程安全的，要求在多线程环境下必须是一个线程对应一个独立的实例，不能使用singleton。所以，我们在Spring配置Webwork Action Bean时，需要加上属性scope=”prototype”或singleton=”false”。 singleton模式指的是对某个对象的完全共享，包括代码空间和数据空间，说白了，如果一个类是singleton的，假如这个类有成员变量，那么这个成员变量的值是各个线程共享的（有点类似于static的样子了），当线程A往给变量赋了一个值以后，线程B就能读出这个值。 因此，对于前台Action，肯定不能使用singleton的模式，必须是一个线程请求对应一个独立的实例。推而广之，只要是带数据成员变量的类，为了防止多个线程混用数据，就不能使用singleton。对于我们用到的Service、Dao，之所以用了singleton，就是因为他们没有用到数据成员变量，如果谁的Service需要数据成员变量，请设置singleton=false。 有状态的bean都使用Prototype作用域，而对无状态的bean则应该使用singleton作用域。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>scope</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm内存模型]]></title>
    <url>%2F2017%2F07%2F20%2Fjvm%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[引言JVM定义了若干个程序执行期间使用的数据区域。这个区域里的一些数据在JVM启动的时候创建，在JVM退出的时候销毁。而其他的数据依赖于每一个线程，在线程创建时创建，在线程退出时销毁。 程序计数器程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。由于Java 虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。如果线程正在执行的是一个Java 方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Natvie 方法，这个计数器值则为空（Undefined）。此内存区域是唯一一个在Java 虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 虚拟机栈线程私有，它的生命周期与线程相同。虚拟机栈描述的是Java 方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。动画是由一帧一帧图片连续切换结果的结果而产生的，其实虚拟机的运行和动画也类似，每个在虚拟机中运行的程序也是由许多的帧的切换产生的结果，只是这些帧里面存放的是方法的局部变量，操作数栈，动态链接，方法返回地址和一些额外的附加信息组成。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 对于执行引擎来说，活动线程中，只有栈顶的栈帧是有效的，称为当前栈帧，这个栈帧所关联的方法称为当前方法。执行引擎所运行的所有字节码指令都只针对当前栈帧进行操作。局部变量表局部变量表是一组变量值存储空间，用于存放方法参数和方法内部定义的局部变量。在Java程序被编译成Class文件时，就在方法的Code属性的max_locals数据项中确定了该方法所需要分配的最大局部变量表的容量。局部变量表的容量以变量槽（Slot）为最小单位，32位虚拟机中一个Slot可以存放一个32位以内的数据类型（boolean、byte、char、short、int、float、reference和returnAddress八种）。reference类型虚拟机规范没有明确说明它的长度，但一般来说，虚拟机实现至少都应当能从此引用中直接或者间接地查找到对象在Java堆中的起始地址索引和方法区中的对象类型数据。returnAddress类型是为字节码指令jsr、jsr_w和ret服务的，它指向了一条字节码指令的地址。虚拟机是使用局部变量表完成参数值到参数变量列表的传递过程的，如果是实例方法（非static），那么局部变量表的第0位索引的Slot默认是用于传递方法所属对象实例的引用，在方法中通过this访问。 Slot是可以重用的，当Slot中的变量超出了作用域，那么下一次分配Slot的时候，将会覆盖原来的数据。Slot对对象的引用会影响GC（要是被引用，将不会被回收）。 系统不会为局部变量赋予初始值（实例变量和类变量都会被赋予初始值）。也就是说不存在类变量那样的准备阶段。 操作数栈和局部变量区一样，操作数栈也是被组织成一个以字长为单位的数组。但是和前者不同的是，它不是通过索引来访问，而是通过标准的栈操作——压栈和出栈—来访问的。比如，如果某个指令把一个值压入到操作数栈中，稍后另一个指令就可以弹出这个值来使用。虚拟机在操作数栈中存储数据的方式和在局部变量区中是一样的：如int、long、float、double、reference和returnType的存储。对于byte、short以及char类型的值在压入到操作数栈之前，也会被转换为int。虚拟机把操作数栈作为它的工作区——大多数指令都要从这里弹出数据，执行运算，然后把结果压回操作数栈。比如，iadd指令就要从操作数栈中弹出两个整数，执行加法运算，其结果又压回到操作数栈中，看看下面的示例，它演示了虚拟机是如何把两个int类型的局部变量相加，再把结果保存到第三个局部变量的：123456begin iload_0 // push the int in local variable 0 ontothe stack iload_1 //push the int in local variable 1 onto the stack iadd // pop two ints, add them, push result istore_2 // pop int, store into local variable 2 end 在这个字节码序列里，前两个指令iload_0和iload_1将存储在局部变量中索引为0和1的整数压入操作数栈中，其后iadd指令从操作数栈中弹出那两个整数相加，再将结果压入操作数栈。第四条指令istore_2则从操作数栈中弹出结果，并把它存储到局部变量区索引为2的位置。下图详细表述了这个过程中局部变量和操作数栈的状态变化，图中没有使用的局部变量区和操作数栈区域以空白表示。 动态连接虚拟机运行的时候,运行时常量池会保存大量的符号引用，这些符号引用可以看成是每个方法的间接引用。如果代表栈帧A的方法想调用代表栈帧B的方法，那么这个虚拟机的方法调用指令就会以B方法的符号引用作为参数，但是因为符号引用并不是直接指向代表B方法的内存位置，所以在调用之前还必须要将符号引用转换为直接引用，然后通过直接引用才可以访问到真正的方法。如果符号引用是在类加载阶段或者第一次使用的时候转化为直接应用，那么这种转换成为静态解析，如果是在运行期间转换为直接引用，那么这种转换就成为动态连接。 返回地址方法的返回分为两种情况，一种是正常退出，退出后会根据方法的定义来决定是否要传返回值给上层的调用者，一种是异常导致的方法结束，这种情况是不会传返回值给上层的调用方法。不过无论是那种方式的方法结束，在退出当前方法时都会跳转到当前方法被调用的位置，如果方法是正常退出的，则调用者的PC计数器的值就可以作为返回地址,，果是因为异常退出的，则是需要通过异常处理表来确定。方法的的一次调用就对应着栈帧在虚拟机栈中的一次入栈出栈操作，因此方法退出时可能做的事情包括：恢复上层方法的局部变量表以及操作数栈，如果有返回值的话，就把返回值压入到调用者栈帧的操作数栈中，还会把PC计数器的值调整为方法调用入口的下一条指令。异常在Java 虚拟机规范中，对虚拟机栈规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError 异常；如果虚拟机栈可以动态扩展（当前大部分的Java 虚拟机都可动态扩展，只不过Java 虚拟机规范中也允许固定长度的虚拟机栈），当扩展时无法申请到足够的内存时会抛出OutOfMemoryError 异常。 本地方法栈本地方法栈（Native MethodStacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java 方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native 方法服务。虚拟机规范中对本地方法栈中的方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。甚至有的虚拟机（譬如Sun HotSpot 虚拟机）直接就把本地方法栈和虚拟机栈合二为一。与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。 堆堆是Java 虚拟机所管理的内存中最大的一块。Java 堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。但是随着JIT 编译器的发展与逃逸分析技术的逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化发生，所有的对象都分配在堆上也渐渐变得不是那么“绝对”了。堆是垃圾收集器管理的主要区域，因此很多时候也被称做“GC 堆”。堆的大小可以通过-Xms(最小值)和-Xmx(最大值)参数设置，-Xms为JVM启动时申请的最小内存，默认为操作系统物理内存的1/64但小于1G，-Xmx为JVM可申请的最大内存，默认为物理内存的1/4但小于1G，默认当空余堆内存小于40%时，JVM会增大Heap到-Xmx指定的大小，可通过-XX:MinHeapFreeRation=来指定这个比列；当空余堆内存大于70%时，JVM会减小heap的大小到-Xms指定的大小，可通过XX:MaxHeapFreeRation=来指定这个比列，对于运行系统，为避免在运行时频繁调整Heap的大小，通常-Xms与-Xmx的值设成一样。 如果从内存回收的角度看，由于现在收集器基本都是采用的分代收集算法，所以Java 堆中还可以细分为：新生代和老年代；新生代：程序新创建的对象都是从新生代分配内存，新生代由Eden Space和两块相同大小的Survivor Space(通常又称S0和S1或From和To)构成，可通过-Xmn参数来指定新生代的大小，也可以通过-XX:SurvivorRation来调整Eden Space及SurvivorSpace的大小。老年代：用于存放经过多次新生代GC仍然存活的对象，例如缓存对象，新建的对象也有可能直接进入老年代，主要有两种情况：1、大对象，可通过启动参数设置-XX:PretenureSizeThreshold=1024(单位为字节，默认为0)来代表超过多大时就不在新生代分配，而是直接在老年代分配。2、大的数组对象，且数组中无引用外部对象。老年代所占的内存大小为-Xmx对应的值减去-Xmn对应的值。 如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError 异常。 方法区方法区在一个jvm实例的内部，类型信息被存储在一个称为方法区的内存逻辑区中。类型信息是由类加载器在类加载时从类文件中提取出来的。类(静态)变量也存储在方法区中。简单说方法区用来存储类型的元数据信息，一个.class文件是类被java虚拟机使用之前的表现形式，一旦这个类要被使用，java虚拟机就会对其进行装载、连接（验证、准备、解析）和初始化。而装载（后的结果就是由.class文件转变为方法区中的一段特定的数据结构。这个数据结构会存储如下信息： 类型信息 这个类型的全限定名 这个类型的直接超类的全限定名 这个类型是类类型还是接口类型 这个类型的访问修饰符 任何直接超接口的全限定名的有序列表 字段信息 字段名 字段类型 字段的修饰符 方法信息 方法名 方法返回类型 方法参数的数量和类型（按照顺序） 方法的修饰符 其他信息 除了常量以外的所有类（静态）变量 一个指向ClassLoader的指针 一个指向Class对象的指针 常量池（常量数据以及对其他类型的符号引用） JVM为每个已加载的类型都维护一个常量池。常量池就是这个类型用到的常量的一个有序集合，包括实际的常量(string,integer,和floating point常量)和对类型，域和方法的符号引用。池中的数据项象数组项一样，是通过索引访问的。 每个类的这些元数据，无论是在构建这个类的实例还是调用这个类某个对象的方法，都会访问方法区的这些元数据。构建一个对象时，JVM会在堆中给对象分配空间，这些空间用来存储当前对象实例属性以及其父类的实例属性（而这些属性信息都是从方法区获得），注意，这里并不是仅仅为当前对象的实例属性分配空间，还需要给父类的实例属性分配，到此其实我们就可以回答第一个问题了，即实例化父类的某个子类时，JVM也会同时构建父类的一个对象。从另外一个角度也可以印证这个问题：调用当前类的构造方法时，首先会调用其父类的构造方法直到Object，而构造方法的调用意味着实例的创建，所以子类实例化时，父类肯定也会被实例化。类变量被类的所有实例共享，即使没有类实例时你也可以访问它。这些变量只与类相关，所以在方法区中，它们成为类数据在逻辑上的一部分。在JVM使用一个类之前，它必须在方法区中为每个non-final类变量分配空间。 方法区主要有以下几个特点：1、方法区是线程安全的。由于所有的线程都共享方法区，所以，方法区里的数据访问必须被设计成线程安全的。例如，假如同时有两个线程都企图访问方法区中的同一个类，而这个类还没有被装入JVM，那么只允许一个线程去装载它，而其它线程必须等待2、方法区的大小不必是固定的，JVM可根据应用需要动态调整。同时，方法区也不一定是连续的，方法区可以在一个堆(甚至是JVM自己的堆)中自由分配。3、方法区也可被垃圾收集，当某个类不在被使用(不可触及)时，JVM将卸载这个类，进行垃圾收集 可以通过-XX:PermSize 和 -XX:MaxPermSize 参数限制方法区的大小。对于习惯在HotSpot 虚拟机上开发和部署程序的开发者来说，很多人愿意把方法区称为“永久代”（PermanentGeneration），本质上两者并不等价，仅仅是因为HotSpot 虚拟机的设计团队选择把GC 分代收集扩展至方法区，或者说使用永久代来实现方法区而已。对于其他虚拟机（如BEA JRockit、IBM J9 等）来说是不存在永久代的概念的。相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入了方法区就如永久代的名字一样“永久”存在了。这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载。当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。 总结 名称 特征 作用 配置参数 异常 程序计数器 占用内存小，线程私有，生命周期与线程相同 大致为字节码行号指示器 - - 虚拟机栈 线程私有，生命周期与线程相同，使用连续的内存空间 Java 方法执行的内存模型，存储局部变量表、操作栈、动态链接、方法出口等信息 -Xss StackOverflowError OutOfMemoryError java堆 线程共享，生命周期与虚拟机相同，可以不使用连续的内存地址 保存对象实例，所有对象实例（包括数组）都要在堆上分配 -Xms-Xsx-Xmn OutOfMemoryError 方法区 线程共享，生命周期与虚拟机相同，可以不使用连续的内存地址 存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据 -XX:PermSize:16M-XX:MaxPermSize64M OutOfMemoryError 运行时常量池 方法区的一部分，具有动态性 存放字面量及符号引用 - - 直接内存直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用，而且也可能导致OutOfMemoryError 异常出现，所以我们放到这里一起讲解。在JDK 1.4 中新加入了NIO（NewInput/Output）类，引入了一种基于通道（Channel）与缓冲区（Buffer）的I/O 方式，它可以使用Native 函数库直接分配堆外内存，然后通过一个存储在Java 堆里面的DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在Java 堆和Native 堆中来回复制数据。 堆与栈的对比经常有人把Java 内存区分为堆内存（Heap）和栈内存（Stack），这种分法比较粗糙，Java内存区域的划分实际上远比这复杂。这种划分方式的流行只能说明大多数程序员最关注的、与对象内存分配关系最密切的内存区域是这两块。堆很灵活，但是不安全。对于对象，我们要动态地创建、销毁，不能说后创建的对象没有销毁，先前创建的对象就不能销毁，那样的话我们的程序就寸步难行，所以Java中用堆来存储对象。而一旦堆中的对象被销毁，我们继续引用这个对象的话，就会出现著名的 NullPointerException，这就是堆的缺点——错误的引用逻辑只有在运行时才会被发现。栈不灵活，但是很严格，是安全的，易于管理。因为只要上面的引用没有销毁，下面引用就一定还在，在大部分程序中，都是先定义的变量、引用先进栈，后定义的后进栈，同时，区块内部的变量、引用在进入区块时压栈，区块结束时出栈，理解了这种机制，我们就可以很方便地理解各种编程语言的作用域的概念了，同时这也是栈的优点——错误的引用逻辑在编译时就可以被发现。 栈—主要存放引用和基本数据类型。 堆—用来存放 new 出来的对象实例。 内存溢出和内存泄漏内存溢出 out of memory，是指程序在申请内存时，没有足够的内存空间供其使用，出现out of memory；比如申请了一个integer，但给它存了long才能存下的数，那就是内存溢出。内存泄露 memory leak，是指程序在申请内存后，无法释放已申请的内存空间，一次内存泄露危害可以忽略，但内存泄露堆积后果很严重，无论多少内存,迟早会被占光。memory leak会最终会导致out ofmemory。 Java 堆内存的OutOfMemoryError异常是实际应用中最常见的内存溢出异常情况。出现Java 堆内存溢出时，异常堆栈信息“java.lang.OutOfMemoryError”会跟着进一步提示“Java heapspace”。要解决这个区域的异常，一般的手段是首先通过内存映像分析工具（如Eclipse Memory Analyzer）对dump 出来的堆转储快照进行分析，重点是确认内存中的对象是否是必要的，也就是要先分清楚到底是出现了内存泄漏（Memory Leak）还是内存溢出（Memory Overflow）。如果是内存泄漏，可进一步通过工具查看泄漏对象到GC Roots 的引用链。于是就能找到泄漏对象是通过怎样的路径与GC Roots 相关联并导致垃圾收集器无法自动回收它们的。掌握了泄漏对象的类型信息，以及GC Roots 引用链的信息，就可以比较准确地定位出泄漏代码的位置。如果不存在泄漏，换句话说就是内存中的对象确实都还必须存活着，那就应当检查虚拟机的堆参数（-Xmx 与-Xms），与机器物理内存对比看是否还可以调大，从代码上检查是否存在某些对象生命周期过长、持有状态时间过长的情况，尝试减少程序运行期的内存消耗。 内存分配过程1、JVM 会试图为相关Java对象在Eden Space中初始化一块内存区域。2、当Eden空间足够时，内存申请结束；否则到下一步。3、JVM 试图释放在Eden中所有不活跃的对象（这属于1或更高级的垃圾回收）。释放后若Eden空间仍然不足以放入新对象，则试图将部分Eden中活跃对象放入Survivor区。4、Survivor区被用来作为Eden及Old的中间交换区域，当Old区空间足够时，Survivor区的对象会被移到Old区，否则会被保留在Survivor区。5、当Old区空间不够时，JVM 会在Old区进行完全的垃圾收集（0级）。6、完全垃圾收集后，若Survivor及Old区仍然无法存放从Eden复制过来的部分对象，导致JVM无法在Eden区为新对象创建内存区域，则出现“outofmemory”错误。 对象访问对象访问在Java 语言中无处不在，是最普通的程序行为，但即使是最简单的访问，也会却涉及Java 栈、Java 堆、方法区这三个最重要内存区域之间的关联关系，如下面的这句代码： Object obj = newObject(); 假设这句代码出现在方法体中，那“Object obj”这部分的语义将会反映到Java 栈的本地变量表中，作为一个reference 类型数据出现。而“new Object()”这部分的语义将会反映到Java 堆中，形成一块存储了Object 类型所有实例数据值（Instance Data，对象中各个实例字段的数据）的结构化内存，根据具体类型以及虚拟机实现的对象内存布局（Object Memory Layout）的不同，这块内存的长度是不固定的。另外，在Java 堆中还必须包含能查找到此对象类型数据（如对象类型、父类、实现的接口、方法等）的地址信息，这些类型数据则存储在方法区中。由于reference 类型在Java 虚拟机规范里面只规定了一个指向对象的引用，并没有定义这个引用应该通过哪种方式去定位，以及访问到Java 堆中的对象的具体位置，因此不同虚拟机实现的对象访问方式会有所不同，主流的访问方式有两种：使用句柄和直接指针。如果使用句柄访问方式，Java 堆中将会划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据和类型数据各自的具体地址信息。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[crontab安装及使用]]></title>
    <url>%2F2017%2F07%2F16%2Fcrontab%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[引言经常有需求要在服务器定时执行各种脚本或者服务（shell脚本，python脚本等等），那么自然就会用到crontab 安装crontab:1[root@CentOS ~]# yum install vixie-cron 如下即安装成功 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172[root@bogon mysql]# yum install vixie-cronLoaded plugins: fastestmirror, securitySetting up Install ProcessLoading mirror speeds from cached hostfile * base: mirror.bit.edu.cn * extras: mirror.bit.edu.cn * updates: mirror.bit.edu.cnResolving Dependencies--&gt; Running transaction check---&gt; Package cronie.x86_64 0:1.4.4-16.el6_8.2 will be installed--&gt; Processing Dependency: dailyjobs for package: cronie-1.4.4-16.el6_8.2.x86_64--&gt; Processing Dependency: /usr/sbin/sendmail for package: cronie-1.4.4-16.el6_8.2.x86_64--&gt; Running transaction check---&gt; Package cronie-anacron.x86_64 0:1.4.4-16.el6_8.2 will be installed--&gt; Processing Dependency: crontabs for package: cronie-anacron-1.4.4-16.el6_8.2.x86_64---&gt; Package sendmail.x86_64 0:8.14.4-9.el6_8.1 will be installed--&gt; Processing Dependency: procmail for package: sendmail-8.14.4-9.el6_8.1.x86_64--&gt; Running transaction check---&gt; Package crontabs.noarch 0:1.10-33.el6 will be installed---&gt; Package procmail.x86_64 0:3.22-25.1.el6_5.1 will be installed--&gt; Finished Dependency ResolutionDependencies Resolved============================================================================================================================================================================ Package Arch Version Repository Size============================================================================================================================================================================Installing: cronie x86_64 1.4.4-16.el6_8.2 base 75 kInstalling for dependencies: cronie-anacron x86_64 1.4.4-16.el6_8.2 base 31 k crontabs noarch 1.10-33.el6 base 10 k procmail x86_64 3.22-25.1.el6_5.1 base 162 k sendmail x86_64 8.14.4-9.el6_8.1 base 717 kTransaction Summary============================================================================================================================================================================Install 5 Package(s)Total download size: 995 kInstalled size: 2.1 MIs this ok [y/N]: yDownloading Packages:(1/5): cronie-1.4.4-16.el6_8.2.x86_64.rpm | 75 kB 00:00 (2/5): cronie-anacron-1.4.4-16.el6_8.2.x86_64.rpm | 31 kB 00:00 (3/5): crontabs-1.10-33.el6.noarch.rpm | 10 kB 00:00 (4/5): procmail-3.22-25.1.el6_5.1.x86_64.rpm | 162 kB 00:00 (5/5): sendmail-8.14.4-9.el6_8.1.x86_64.rpm | 717 kB 00:00 ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------Total 788 kB/s | 995 kB 00:01 Running rpm_check_debugRunning Transaction TestTransaction Test SucceededRunning Transaction Installing : procmail-3.22-25.1.el6_5.1.x86_64 1/5 Installing : sendmail-8.14.4-9.el6_8.1.x86_64 2/5 Installing : cronie-1.4.4-16.el6_8.2.x86_64 3/5 Installing : crontabs-1.10-33.el6.noarch 4/5 Installing : cronie-anacron-1.4.4-16.el6_8.2.x86_64 5/5 Verifying : crontabs-1.10-33.el6.noarch 1/5 Verifying : procmail-3.22-25.1.el6_5.1.x86_64 2/5 Verifying : cronie-anacron-1.4.4-16.el6_8.2.x86_64 3/5 Verifying : sendmail-8.14.4-9.el6_8.1.x86_64 4/5 Verifying : cronie-1.4.4-16.el6_8.2.x86_64 5/5 Installed: cronie.x86_64 0:1.4.4-16.el6_8.2 Dependency Installed: cronie-anacron.x86_64 0:1.4.4-16.el6_8.2 crontabs.noarch 0:1.10-33.el6 procmail.x86_64 0:3.22-25.1.el6_5.1 sendmail.x86_64 0:8.14.4-9.el6_8.1 Complete! 说明：vixie-cron软件包是cron的主程序；crontabs软件包是用来安装、卸装、或列举用来驱动 cron 守护进程的表格的程序。 cron 是linux的内置服务，但它不自动起来，可以用以下的方法启动、关闭这个服务： 12345service crond start //启动服务service crond stop //关闭服务service crond restart //重启服务service crond reload //重新载入配置service crond status //查看服务状态 执行命令：ntsysv 查看开机启动的服务，tab键选择菜单 加入开机自动启动: 1chkconfig --level 35 crond on 使用crontab1.crontab命令 功能说明：设置计时器。 语 法：crontab [-u &lt;用户名称&gt;][配置文件] 或 crontab [-u &lt;用户名称&gt;][-elr] 补充说明：cron是一个常驻服务，它提供计时器的功能，让用户在特定的时间得以执行预设的指令或程序。只要用户会编辑计时器的配置文件，就可以使用计时器的功能。其配置文件格式如下：Minute Hour Day Month DayOFWeek Command 参 数： -e 编辑该用户的计时器设置。 -l 列出该用户的计时器设置。 -r 删除该用户的计时器设置。 -u&lt;用户名称&gt; 指定要设定计时器的用户名称。 2.crontab 格式 基本格式 : * * * * * command 分 时 日 月 周 命令 第1列表示分钟0～59 每分钟用*或者 */1表示第2列表示小时0～23（0表示0点）第3列表示日期1～31第4列表示月份1～12第5列标识号星期0～6（0表示星期天）第6列要运行的命令 示例： 每晚凌晨0点执行sql_backup.sh脚本，并将日志输出追加到backlog_date.log文件中，date是按天的时间2&gt;&amp;1表示将错误信息重定向至标准输出 10 0 * * * sh /home/backups/mysql/sql_backup.sh &gt;&gt; /home/logs/mysql_backup/backlog_`date +&quot;\%Y\%m\%d&quot;`.log 2&gt;&amp;1 每晚的21:30重启apache。130 21 * * * /usr/local/etc/rc.d/lighttpd restart 每月1、10、22日的4 : 45重启apache。 145 4 1,10,22 * * /usr/local/etc/rc.d/lighttpd restart 每周六、周日的1 : 10重启apache。 110 1 * * 6,0 /usr/local/etc/rc.d/lighttpd restart 每天18 : 00至23 : 00之间每隔30分钟重启apache。 10,30 18-23 * * * /usr/local/etc/rc.d/lighttpd restart 每星期六的23 : 00 pm重启apache。 10 23 * * 6 /usr/local/etc/rc.d/lighttpd restart 每一小时重启apache 1* */1 * * * /usr/local/etc/rc.d/lighttpd restart 晚上11点到早上7点之间，每隔一小时重启apache 1* 23-7/1 * * * /usr/local/etc/rc.d/lighttpd restart 每月的4号与每周一到周三的11点重启apache 10 11 4 * mon-wed /usr/local/etc/rc.d/lighttpd restart 一月一号的4点重启apache 10 4 1 jan * /usr/local/etc/rc.d/lighttpd restart 每分钟同步time.windows.com服务器时间 10-59/1 * * * * /usr/sbin/ntpdate time.windows.com 在以上任何值中，星号（*）可以用来代表所有有效的值。譬如，月份值中的星号意味着在满足其它制约条件后每月都执行该命令。 整数间的短线（-）指定一个整数范围。譬如，1-4 意味着整数 1、2、3、4。 用逗号（,）隔开的一系列值指定一个列表。譬如，3, 4, 6, 8 标明这四个指定的整数。 正斜线（/）可以用来指定间隔频率。在范围后加上 /&lt;integer&gt; 意味着在范围内可以跳过 integer。譬如，0-59/2 可以用来在分钟字段定义每两分钟。间隔频率值还可以和星号一起使用。例如，*/3 的值可以用在月份字段中表示每三个月运行一次任务。 开头为井号（#）的行是注释，不会被处理。 crontab命令主要有3个参数： -e ：编辑用户的crontab。 -l ：列出用户的crontab的内容。 -r ：删除用户的crontab的内容。 执行crontab -e，将自动打开编辑器，你可以编辑自己的crontab文件，语法和 /etc/crontab 文件一样，不同的只是，不必再指出执行的用户，编辑后保存即可。 crontab -l用来查看自己的crontab文件内能，crontab -r删除自己的crontab。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>crontab</tag>
        <tag>定时</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库之mysql(二)]]></title>
    <url>%2F2017%2F07%2F10%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B9%8Bmysql-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[mysql配置文件my.cnf详解1 mysqld程序：基本配置 basedir = path #使用给定目录作为根目录(安装目录)。 character-sets-dir = path #给出存放着字符集的目录。 datadir = path #从给定目录读取数据库文件。 pid-file = filename #为mysqld程序指定一个存放进程ID的文件(仅适用于UNIX/Linux系统); Init-V脚本需要使用这个文件里的进程ID结束mysqld进程。 socket = filename #为MySQL客户程序与服务器之间的本地通信指定一个套接字文件(仅适用于UNIX/Linux系统; 默认设置一般是/var/lib/mysql/mysql.sock文件)。在Windows环境下，如果MySQL客户与服务器是通过命名管道进行通信 的，–sock选项给出的将是该命名管道的名字(默认设置是MySQL)。 lower_case_table_name = 1/0 #新目录和数据表的名字是否只允许使用小写字母; 这个选项在Windows环境下的默认设置是1(只允许使用小写字母)。 mysqld程序：语言设置 character-sets-server = name #新数据库或数据表的默认字符集。为了与MySQL的早期版本保持兼容，这个字符集也可以用–default-character-set选项给出; 但这个选项已经显得有点过时了。 collation-server = name #新数据库或数据表的默认排序方式。 language = name #用指定的语言显示出错信息。 mysqld程序：通信、网络、信息安全 enable-named-pipes #允许Windows 2000/XP环境下的客户和服务器使用命名管道(named pipe)进行通信。这个命名管道的默认名字是MySQL，但可以用–socket选项来改变。 local-infile [=0] #允许/禁止使用LOAD DATA LOCAL语句来处理本地文件。 myisam-recover [=opt1, opt2, ...] 在启动时自动修复所有受损的MyISAM数据表。这个选项的可取值有4种:DEFAULT、BACKUP、QUICK和FORCE; 它们与myisamchk程序的同名选项作用相同。 old-passwords #使用MySQL 3.23和4.0版本中的老算法来加密mysql数据库里的密码(默认使用MySQL 4.1版本开始引入的新加密算法)。 port = n #为MySQL程序指定一个TCP/IP通信端口(通常是3306端口)。 safe-user-create #只有在mysql.user数据库表上拥有INSERT权限的用户才能使用GRANT命令; 这是一种双保险机制(此用户还必须具备GRANT权限才能执行GRANT命令)。 shared-memory #允许使用内存(shared memory)进行通信(仅适用于Windows)。 shared-memory-base-name = name #给共享内存块起一个名字(默认的名字是MySQL)。 skip-grant-tables #不使用mysql数据库里的信息来进行访问控制(警告:这将允许用户任何用户去修改任何数据库)。 skip-host-cache #不使用高速缓存区来存放主机名和IP地址的对应关系。 skip-name-resovle #不把IP地址解析为主机名; 与访问控制(mysql.user数据表)有关的检查全部通过IP地址行进。 skip-networking #只允许通过一个套接字文件(Unix/Linux系统)或通过命名管道(Windows系统)进行本地连接，不允许ICP/IP连接; 这提高了安全性，但阻断了来自网络的外部连接和所有的Java客户程序(Java客户即使在本地连接里也使用TCP/IP)。 user = name #mysqld程序在启动后将在给定UNIX/Linux账户下执行; mysqld必须从root账户启动才能在启动后切换到另一个账户下执行; mysqld_safe脚本将默认使用–user=mysql选项来启动mysqld程序。 mysqld程序：内存管理、优化、查询缓存区 bulk_insert_buffer_size = n #为一次插入多条新记录的INSERT命令分配的缓存区长度(默认设置是8M)。 key_buffer_size = n #用来存放索引区块的RMA值(默认设置是8M)。 join_buffer_size = n #在参加JOIN操作的数据列没有索引时为JOIN操作分配的缓存区长度(默认设置是128K)。 max_heap_table_size = n #HEAP数据表的最大长度(默认设置是16M); 超过这个长度的HEAP数据表将被存入一个临时文件而不是驻留在内存里。 max_connections = n #MySQL服务器同时处理的数据库连接的最大数量(默认设置是100)。 query_cache_limit = n #允许临时存放在查询缓存区里的查询结果的最大长度(默认设置是1M)。 query_cache_size = n #查询缓存区的最大长度(默认设置是0，不开辟查询缓存区)。 query_cache_type = 0/1/2 #查询缓存区的工作模式:0, 禁用查询缓存区; 1，启用查询缓存区(默认设置); 2，”按需分配”模式，只响应SELECT SQL_CACHE命令。 read_buffer_size = n #为从数据表顺序读取数据的读操作保留的缓存区的长度(默认设置是128KB); 这个选项的设置值在必要时可以用SQL命令SET SESSION read_buffer_size = n命令加以改变。 read_rnd_buffer_size = n #类似于read_buffer_size选项，但针对的是按某种特定顺序(比如使用了ORDER BY子句的查询)输出的查询结果(默认设置是256K)。 sore_buffer = n #为排序操作分配的缓存区的长度(默认设置是2M); 如果这个缓存区太小，则必须创建一个临时文件来进行排序。 table_cache = n #同时打开的数据表的数量(默认设置是64)。 tmp_table_size = n #临时HEAP数据表的最大长度(默认设置是32M); 超过这个长度的临时数据表将被转换为MyISAM数据表并存入一个临时文件。 mysqld程序：日志 log [= file] #把所有的连接以及所有的SQL命令记入日志(通用查询日志); 如果没有给出file参数，MySQL将在数据库目录里创建一个hostname.log文件作为这种日志文件(hostname是服务器的主机名)。 log-slow-queries [= file] #把执行用时超过long_query_time变量值的查询命令记入日志(慢查询日志); 如果没有给出file参数，MySQL将在数据库目录里创建一个hostname-slow.log文件作为这种日志文件(hostname是服务器主机 名)。 long_query_time = n #慢查询的执行用时上限(默认设置是10s)。 long_queries_not_using_indexs #把慢查询以及执行时没有使用索引的查询命令全都记入日志(其余同–log-slow-queries选项)。 log-bin [= filename] #把对数据进行修改的所有SQL命令(也就是INSERT、UPDATE和DELETE命令)以二进制格式记入日志(二进制变更日志，binary update log)。这种日志的文件名是filename.n或默认的hostname.n，其中n是一个6位数字的整数(日志文件按顺序编号)。 log-bin-index = filename #二进制日志功能的索引文件名。在默认情况下，这个索引文件与二进制日志文件的名字相同，但后缀名是.index而不是.nnnnnn。 max_binlog_size = n #二进制日志文件的最大长度(默认设置是1GB)。在前一个二进制日志文件里的信息量超过这个最大长度之前，MySQL服务器会自动提供一个新的二进制日志文件接续上。 binlog-do-db = dbname #只把给定数 据库里的变化情况记入二进制日志文件，其他数据库里的变化情况不记载。如果需要记载多个数据库里的变化情况，就必须在配置文件使用多个本选项来设置，每个数据库一行。 binlog-ignore-db = dbname #不把给定数据库里的变化情况记入二进制日志文件。 sync_binlog = n #每经过n次日志写操作就把日志文件写入硬盘一次(对日志信息进行一次同步)。n=1是最安全的做法，但效率最低。默认设置是n=0，意思是由操作系统来负责二进制日志文件的同步工作。 log-update [= file] #记载出错情况的日志文件名(出错日志)。这种日志功能无法禁用。如果没有给出file参数，MySQL会使用hostname.err作为种日志文件的名字。 mysqld程序：镜像(主控镜像服务器) server-id = n #给服务器分配一个独一无二的ID编号; n的取值范围是1~2的32次方启用二进制日志功能。 log-bin = name #启用二进制日志功能。这种日志的文件名是filename.n或默认的hostname.n，其中的n是一个6位数字的整数(日志文件顺序编号)。 binlog-do/ignore-db = dbname #只把给定数据库里的变化情况记入二进制日志文件/不把给定的数据库里的变化记入二进制日志文件。 mysqld程序：镜像(从属镜像服务器) server-id = n #给服务器分配一个唯一的ID编号 log-slave-updates #启用从属服务器上的日志功能，使这台计算机可以用来构成一个镜像链(A-&gt;B-&gt;C)。 master-host = hostname #主控服务器的主机名或IP地址。如果从属服务器上存在mater.info文件(镜像关系定义文件)，它将忽略此选项。 master-user = replicusername #从属服务器用来连接主控服务器的用户名。如果从属服务器上存在mater.info文件，它将忽略此选项。 master-password = passwd #从属服务器用来连接主控服务器的密码。如果从属服务器上存在mater.info文件，它将忽略此选项。 master-port = n #从属服务器用来连接主控服务器的TCP/IP端口(默认设置是3306端口)。 master-connect-retry = n #如果与主控服务器的连接没有成功，则等待n秒(s)后再进行管理方式(默认设置是60s)。如果从属服务器存在mater.info文件，它将忽略此选项。 master-ssl-xxx = xxx #对主、从服务器之间的SSL通信进行配置。 read-only = 0/1 #0: 允许从属服务器独立地执行SQL命令(默认设置); 1: 从属服务器只能执行来自主控服务器的SQL命令。 read-log-purge = 0/1 #1: 把处理完的SQL命令立刻从中继日志文件里删除(默认设置); 0: 不把处理完的SQL命令立刻从中继日志文件里删除。 replicate-do-table = dbname.tablename 与–replicate-do-table选项的含义和用法相同，但数据库和数据库表名字里允许出现通配符”%” (例如: test%.%–对名字以”test”开头的所有数据库里的所以数据库表进行镜像处理)。 replicate-do-db = name #只对这个数据库进行镜像处理。 replicate-ignore-table = dbname.tablename #不对这个数据表进行镜像处理。 replicate-wild-ignore-table = dbn.tablen #不对这些数据表进行镜像处理。 replicate-ignore-db = dbname #不对这个数据库进行镜像处理。 replicate-rewrite-db = db1name &gt; db2name #把主控数据库上的db1name数据库镜像处理为从属服务器上的db2name数据库。 report-host = hostname #从属服务器的主机名; 这项信息只与SHOW SLAVE HOSTS命令有关–主控服务器可以用这条命令生成一份从属服务器的名单。 slave-compressed-protocol = 1 #主、从服务器使用压缩格式进行通信–如果它们都支持这么做的话。 slave-skip-errors = n1, n2, …或all #即使发生出错代码为n1、n2等的错误，镜像处理工作也继续进行(即不管发生什么错误，镜像处理工作也继续进行)。如果配置得当，从属服务器不应该在执行 SQL命令时发生错误(在主控服务器上执行出错的SQL命令不会被发送到从属服务器上做镜像处理); 如果不使用slave-skip-errors选项，从属服务器上的镜像工作就可能因为发生错误而中断，中断后需要有人工参与才能继续进行。 mysqld–InnoDB：基本设置、表空间文件 skip-innodb #不加载InnoDB数据表驱动程序–如果用不着InnoDB数据表，可以用这个选项节省一些内存。 innodb-file-per-table #为每一个新数据表创建一个表空间文件而不是把数据表都集中保存在中央表空间里(后者是默认设置)。该选项始见于MySQL 4.1。 innodb-open-file = n #InnoDB数据表驱动程序最多可以同时打开的文件数(默认设置是300)。如果使用了innodb-file-per-table选项并且需要同时打开很多数据表的话，这个数字很可能需要加大。 innodb_data_home_dir = p #InnoDB主目录，所有与InnoDB数据表有关的目录或文件路径都相对于这个路径。在默认的情况下，这个主目录就是MySQL的数据目录。 innodb_data_file_path = ts #用来容纳InnoDB为数据表的表空间: 可能涉及一个以上的文件; 每一个表空间文件的最大长度都必须以字节(B)、兆字节(MB)或千兆字节(GB)为单位给出; 表空间文件的名字必须以分号隔开; 最后一个表空间文件还可以带一个autoextend属性和一个最大长度(max:n)。例如，ibdata1:1G; ibdata2:1G:autoextend:max:2G的意思是: 表空间文件ibdata1的最大长度是1GB，ibdata2的最大长度也是1G，但允许它扩充到2GB。除文件名外，还可以用硬盘分区的设置名来定义表 空间，此时必须给表空间的最大初始长度值加上newraw关键字做后缀，给表空间的最大扩充长度值加上raw关键字做后缀(例如/dev/hdb1: 20Gnewraw或/dev/hdb1:20Graw); MySQL 4.0及更高版本的默认设置是ibdata1:10M:autoextend。 innodb_autoextend_increment = n #带有autoextend属性的表空间文件每次加大多少兆字节(默认设置是8MB)。这个属性不涉及具体的数据表文件，那些文件的增大速度相对是比较小的。 innodb_lock_wait_timeout = n #如果某个事务在等待n秒(s)后还没有获得所需要的资源，就使用ROLLBACK命令放弃这个事务。这项设置对于发现和处理未能被InnoDB数据表驱动 程序识别出来的死锁条件有着重要的意义。这个选项的默认设置是50s。 innodb_fast_shutdown 0/1 #是否以最快的速度关闭InnoDB，默认设置是1，意思是不把缓存在INSERT缓存区的数据写入数据表，那些数据将在MySQL服务器下次启动时再写入 (这么做没有什么风险，因为INSERT缓存区是表空间的一个组成部分，数据不会丢失)。把这个选项设置为0反面危险，因为在计算机关闭时，InnoDB 驱动程序很可能没有足够的时间完成它的数据同步工作，操作系统也许会在它完成数据同步工作之前强行结束InnoDB，而这会导致数据不完整。 mysqld程序：InnoDB–日志 innodb_log_group_home_dir = p #用来存放InnoDB日志文件的目录路径(如ib_logfile0、ib_logfile1等)。在默认的情况下，InnoDB驱动程序将使用 MySQL数据目录作为自己保存日志文件的位置。 innodb_log_files_in_group = n #使用多少个日志文件(默认设置是2)。InnoDB数据表驱动程序将以轮转方式依次填写这些文件; 当所有的日志文件都写满以后，之后的日志信息将写入第一个日志文件的最大长度(默认设置是5MB)。这个长度必须以MB(兆字节)或GB(千兆字节)为单 位进行设置。 innodb_flush_log_at_trx_commit = 0/1/2 #这个选项决定着什么时候把日志信息写入日志文件以及什么时候把这些文件物理地写(术语称为”同步”)到硬盘上。设置值0的意思是每隔一秒写一次日志并进行 同步，这可以减少硬盘写操作次数，但可能造成数据丢失; 设置值1(设置设置)的意思是在每执行完一条COMMIT命令就写一次日志并进行同步，这可以防止数据丢失，但硬盘写操作可能会很频繁; 设置值2是一般折衷的办法，即每执行完一条COMMIT命令写一次日志，每隔一秒进行一次同步。 innodb_flush_method = x #InnoDB日志文件的同步办法(仅适用于UNIX/Linux系统)。这个选项的可取值有两种: fdatasync，用fsync()函数进行同步; O_DSYNC，用O_SYNC()函数进行同步。 innodb_log_archive = 1 #启用InnoDB驱动程序的archive(档案)日志功能，把日志信息写入ib_arch_log_n文件。启用这种日志功能在InnoDB与 MySQL一起使用时没有多大意义(启用MySQL服务器的二进制日志功能就足够用了)。 mysqld程序–InnoDB：缓存区的设置和优化 innodb_log_buffer_pool_size = n #为InnoDB数据表及其索引而保留的RAM内存量(默认设置是8MB)。这个参数对速度有着相当大的影响，如果计算机上只运行有 MySQL/InnoDB数据库服务器，就应该把全部内存的80%用于这个用途。 innodb_log_buffer_size = n #事务日志文件写操作缓存区的最大长度(默认设置是1MB)。 innodb_additional_men_pool_size = n #为用于内部管理的各种数据结构分配的缓存区最大长度(默认设置是1MB)。 innodb_file_io_threads = n #I/O操作(硬盘写操作)的最大线程个数(默认设置是4)。 innodb_thread_concurrency = n #InnoDB驱动程序能够同时使用的最大线程个数(默认设置是8)。 mysqld程序：其它选项 bind-address = ipaddr #MySQL服务器的IP地址。如果MySQL服务器所在的计算机有多个IP地址，这个选项将非常重要。 default-storage-engine = type #新数据表的默认数据表类型(默认设置是MyISAM)。这项设置还可以通过–default-table-type选项来设置。 default-timezone = name #为MySQL服务器设置一个地理时区(如果它与本地计算机的地理时区不一样)。 ft_min_word_len = n #全文索引的最小单词长度工。这个选项的默认设置是4，意思是在创建全文索引时不考虑那些由3个或更少的字符构建单词。 Max-allowed-packet = n #客户与服务器之间交换的数据包的最大长度，这个数字至少应该大于客户程序将要处理的最大BLOB块的长度。这个选项的默认设置是1MB。 Sql-mode = model1, mode2, … #MySQL将运行在哪一种SQL模式下。这个选项的作用是让MySQL与其他的数据库系统保持最大程度的兼容。这个选项的可取值包括ansi、db2、 oracle、no_zero_date、pipes_as_concat。 mysql配置文件my.cnf详解2 配置MySQL服务器是一个丰富而复杂的工作。在本文中，我只能肤浅的说一下各种选项。可以使用的mysql配置文件共有５个。·/etc/my.cnf是默认的MySQL配置文件。应该对这个文件配置修改。它是为学习目的而设计的。·my-small.cnf是为了小型数据库而设计的。不应该把这个模型用于含有一些常用项目的数据库。·my-medium.cnf是为中等规模的数据库而设计的。如果你正在企业中使用RHEL,可能会比这个操作系统的最小RAM需求(256MB)明显多得多的物理内存。由此可见，如果有那么多RAM内存可以使用，自然可以在同一台机器上运行其它服务。·my-large.cnf是为专用于一个SQL数据库的计算机而设计的。由于它可以为该数据库使用多达512MB的内存，所以在这种类型的系统上将需要至少1GB的RAM,以便它能够同时处理操作系统与数据库应用程序。·my-huge.cnf是为企业中的数据库而设计的。这样的数据库要求专用服务器和1GB或1GB以上的RAM。这些选择高度依赖于内存的数量、计算机的运算速度、数据库的细节大小、访问数据库的用户数量以及在数据库中装入并访问数据的用户数量。随着数据库和用户的不断增加，数据库的性能可能会发生变化。我将逐个的说明这些配置文件。如果用户决定使用my-.cnf文件之一，将首先需要把这个文件复制到/etc/my.cnf文件上。由于这些原因，用户应该仔细观察数据库系统的性能。如果发现问题，可能需要增加更多的RAM，或者把数据库迁移到一个含有附加资源(比如多个CPU)的系统上。提示：数据库变得非常大。把一个SQL数据库目录配置在一个专用分区上可能更有道理。虽然一个不断增长的数据库可能会占满整个分区，但它至少不会吞掉RHEL运行所必需的磁盘空间。/etc/my.cnf文件默认是/etc/my.cnf文件。它包含6条命令，并且这6条命令被组织在3个配置段中。这些配置段与Samba配置文件中的配置段相似，并且含有功能组名称和相关的命令。本文将逐行的说明这个文件的默认版本。如果用户进行了任何修改，将需要确保MySQL启动脚本(即/etc/rc.d /init.d/mysqld)中的命令一致。[mysqld]在这个配置段之内，将会看到与MySQL守护进程相关的命令。datadir=/var/lib/mysqlMySQL服务器把数据库存储在由datadir变量所定义的目录中。Socket=/var/lib/mysql/mysql.sockMySQL套接字把数据库程序局部的或通过网络连接到MySQL客户。提示：MySQL被配置成使用InnoDB存储器引擎。如果用户在自己的系统上还没有一个InnoDB数据库，将需要给[mysqld]配置段添加skip-innodb语句。[mysql.server]在这个配置段之内，将会看到MySQL服务器守护进程有关的命令。这个配置段的较早期版本被命名为[mysql_server]。如果使用 MySQL4.X或MySQL4.X以上版本，将必须把这个配置段标题改成[mysql_server]。当启动MySQL服务时，它使用这个配置段中的选项。user=mysql与MySQL服务相关联的标准用户名是mysql。它应该是/etc/passwd文件的一部分；如果在这个文件中没有发现它，用户可能还没有安装Red Hat Enterprise Linux mysql-server RPM程序包。basedir=/var/lib这表示MySQL数据库的顶级目录。它充当MySQL系统上的一个根目录；这个数据库中的其它目录都是相对于这个目录。[safe_mysqld]这个配置段包含MySQL启动脚本所引用的命令。如果使用MySQL4.X或4.X以上版本，必须把这个配置段改成[mysqld_safe]。err-log=/var/log/mysqld.log这是MySQL所关联的错误被发送到的这个文件。如果使用MySQL4.X或4.X以上版本，必须使用log-error指令替换这条命令。pid-file=/var/run/mysqld/mysqld.pid最后，pid-file指令定义MySQL服务器在运作期间的进程标识符(PID)。如果MySQL服务器当前没有运行，这个文件应该不存在。提示：用户可以配置与用户特定相关的MySQL配置文件；为此，只需给指定用户主目录中的.my.cnf隐含文件添加所选的配置命令即可。my-samll-cnf在本文中，将说明my-small-cnf配置文本中的所有命令。当回顾其它MySQL样本配置文件时，将参考本文所解释的各条命令和指令的含义。先从下面这个配置段开始分析该文件中的有效命令和指令：[client]这个配置把指令传递给与MySQL服务器相关的客户。port＝3306MySQL所相关的标准TCP/IP端口是3306。如果需要修改这个端口号(可以增强安全)，必须确保用于MySQL客户与服务器的所有相应配置文件中均修改这个号。socket=/var/lib/mysql/mysql.sock正像默认的/etc/my.cnf文件中所定义的那样，这是控制MySQL客户与服务器间通信的标准套接字文件。[mysqld]当启动MySQL服务器时，它由[mysqld]配置段中所定义的命令来控制。port=3306socket=/var/lib/mysql/mysql.sock当然，与同一个MySQL数据库相关的客户与服务器需要使用相同的TCP/IP端口和套接字。skip-locking多个客户可能会访问同一个数据库，因此这防止外部客户锁定MySQL服务器。这个skip-locking命令是MySQL4.X或4.X以上版本中的skip-external-locking命令。一般来说，如果正在使用MySQL4.X或4.X上以版本，这个set-variable指令没有必要带有这个列表中的这些命令。set-variable=key_buffer=16k这个缓冲区确实很小；如果一个数据库在一个文本文件中包含不止几百行数据，它将会超载这个缓冲区的容量。这个数据库可能不会超载一个文本文件地址簿的容量。如果这不只是一个供个人使用的数据库，这个限额很快就会被达到。假使那样的话，可能需要考虑与其它配置文件之一相关的那些限额。set-variable=max_allowed_packet=1M当然，与一个数据库相关的信息会增加到超出实际数据。在默认的情况下，如果该信息在一个服务器上超过1MB以上，MySQL将会产生一条错误信息。set-variable=thread_stack=64k这条指令限定用于每个数据库线程的栈大小。默认设置足以满足大多数应用。set-variable=table_cache=4用户可以限定一个数据库中打开表的数量；越小的限额(默认值是64)适合越小规模的数据库。set-variable=sort_buffer=64k在处理一个数据库时，用户可能需要内存中附加的缓冲区空间。set-variable=net_buffer_length=2k正如net_buffer_length指令所定义的，MySQL服务器还给传入的请求保留了空间。server-id=1一般来说，如果有一个MySQL主服务器，应该把它的server-id设置成１；应该把MySQL从属服务器的server-id设置成２；[mysqldump]用户可以在不同类型的SQL数据库之间传输数据，这由[mysqldump]配置段中的命令来控制。quickquick选项支持较大数据库的转储。set-variable=max_allowed_packet=16M当然，用来传输数据库表到其它数据库的max_allowed_packet大于客户与服务器之间的简单通信所使用的信息包。[mysql]no-auto-rehash这个配置段设置启动MySQL服务的条件；在这种情况下，no-auto-rehash确保这个服务启动得比较快。[isamchk][myisamchk]像SQL这样的关系数据库用所谓的Indexed Sequential Access Method(索引顺序存取方法，简称ISAM)来处理。这两个配置段中的命令是相同的；这些命令与检查并修复数据库表的同名命令有关。set-variable=key_buffer=8Mset-variable=sort_buffer=8M在前面谈及MySQL服务器时，用户己经见过这些变量。它们在这里都比较大，以便支持数据库的较快速检查与修复。[mysqlhotcopy]interactive-timeout正如[mysqlhotcopy]配置段所指定的，在一个数据库复制操作期间，连接会挂起。在默认情况下，interactive-timeout变量把一个数据传输的最大时间量设置为28800秒(8个小时)。my-medium.cnf文件与中等数据库相关的MySQL配置文件含有和my-small-cnf配置文件中一样的有效配置段。在[mysqld]配置段中，下面这些命令支持较大规模的服务器数据库：set-variable=key_buffer=16Mset-variable=table_cache=64set-variable=sort_buffer=512Kset-variable=net_buffer_length=8Klog-bin一般来说，这个配置段中的命令支持服务器上的较大高速缓存与缓冲区长度。应该看到两条新命令。set-variable=myisam_sort_buffer_size=8Mlog-binmyisam_sort_buffer_size命令允许MySQL索引数据库，第二条命令支持二进制日志记录方法。[isamchk][myisamchk]当然，这两个配置段中的缓冲区比用于数据库传输的缓冲区大，这个文件包含下面这些命令；它们发送消息到服务器和接收来自服务器的消息。set-variable=read_buffer=2Mset-variable=write_buffer=2Mmy-large.cnf文件与较大型数据库相关的MySQL配置文件含有和my-samll-cnf配置文件中一样的有效配置段。在本文中，将比较my-large-cnf与my-medium-cnf样本文件中的各条命令。在[mysqld]配置段中，下面这些命令支持较大型的服务器数据库：set-variable=key_buffer=256Mset-variable=table_cache=256set-variable=sort_buffer=1Mset-variable=myisam_sort_buffer_size=64Mset-variable=net_buffer_length=8K这个配置段中有３条附加的命令。record_buffer命令保存对一个数据库中不同表的扫描结果。thread_cache命令对多请求有用；空闲线程被高速缓存起来，进而允许新的搜索操作采用己有的线程。只要这防止搜索操作启动新的服务器进程，这就能减轻系统上的负荷。set-variable=record_buffer=1Mset-variable=thread_cache=8set-variable=thread_concurrency=8thread_concurrency变量限定同时运行的线程数量。my-large.cnf样本文件建议用户应该把这个数量限定于本计算机上CPU数量的两倍；这个特定设置相当于４个CPU。*my-huge.cnf文件my-huge.cnf文件含有和my-large.cnf配置文件中一样的命令。当然，分配给大多数指令的值比较大并适合较大型的数据库。]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[google-cloud搭建vpn]]></title>
    <url>%2F2017%2F07%2F09%2Fgoogle-cloud%E6%90%AD%E5%BB%BAvpn%2F</url>
    <content type="text"><![CDATA[引言由于公司需要，而老板又不舍得花钱，于是使用google cloud免费vps，搭建vpn。google cloud需要翻墙访问，有gmail账户，单币种美金信用卡(好像有些双币种信用卡也可以，具体没试过)免费试用1年，赠送300$，所以申请vps时，用最低配置，每个月接近5$，300$可以支撑一年，但是流量是收费的，所以流量很大情况下，可能用不到一年。下面就是具体配置了，分两版：centos和ubuntu Google Cloud配置建立好Compute Engine后，申请一个永久静态地址，然后配置SSH登录证书等内容。详情查看Google文档如果实在不想看文档，可以看这里 主要配置是在Google的Firewall rules里，这里决定了什么包可以访问到内部的instance，其后才是instance内部的iptables的配置。 这里我们建立一条新的rule，source filter填写0.0.0.0/0，代表任何地方发出的包，除非你只想在特定IP上访问，否则就填写这个。然后在Allowed protocols and ports里添加udp:500;udp:4500;esp。 这里udp:500是IPSEC协议指定的端口，会通过这个端口来发送Control plane的包 udp:4500是当source或者destination在NAT后时转而使用的端口，另外当NAT被检测到后，Data plane的数据包也会被使用端口，这个时候ESP的数据包会被包含在UDP包中，端口也是这个 最后esp就是允许Data plane的数据包通过 另外需要勾选允许ip forwarding。 安装StrongSwan从源文件编译安装安装PAM库和SSL库，以及make和gcc1234567#ubuntuapt-get updateapt-get install libpam0g-dev libssl-dev make gcc#centosyum -y updateyum -y install pam-devel openssl-devel make gcc 下载StrongSwan的源码并编译12345678910111213141516171819202122232425#下载wget http://download.strongswan.org/strongswan.tar.gztar xzf strongswan.tar.gzcd strongswan-*#生成 Makefile为编译做准备#OpenVZ使用以下参数./configure --enable-eap-identity --enable-eap-md5 \--enable-eap-mschapv2 --enable-eap-tls --enable-eap-ttls --enable-eap-peap \--enable-eap-tnc --enable-eap-dynamic --enable-eap-radius --enable-xauth-eap \--enable-xauth-pam --enable-dhcp --enable-openssl --enable-addrblock --enable-unity \--enable-certexpire --enable-radattr --enable-tools --enable-openssl --disable-gmp --enable-kernel-libipsec#其它服务器执行./configure --prefix=/usr --sysconfdir=/etc/strongswan --enable-eap-identity \--enable-eap-md5 --enable-eap-mschapv2 --enable-eap-tls --enable-eap-ttls \-- enable-eap-peap --enable-eap-tnc --enable-eap-dynamic \--enable-eap-radius --enable-xauth-eap --enable-xauth-pam --enable-dhcp \--enable-addrblock --enable-unity --enable-certexpire --enable-radattr \--enable-openssl --disable-gmp#编译并且安装make&amp;&amp;make install#生成ipsec和strongswan命令mv /usr/sbin/&#123;ipsec,strongswan&#125; 判断VPS是Openvz还是KVM还是Xen1.通过系统上的相关目录或文件判断执行：ls /proc/ ，一般Xen的VPS，/proc目录下面会有xen的目录，openvz的会有vz目录。2.执行：free -m 看内存，openvz的没有swap，当然也有xen的没有swap，但是xen的是可以加的，openvz不行。3.执行：uname -a 有些xen的VPS里面会显示有xen。4.执行：ifconfig 查看网卡，openvz的一般都是venet0: ，xen的一般都是eth。5.通过VPS控制面板查看，像SolusVM、vePortal控制面板上都显示虚拟技术。 完成后执行ipsec version查看是否安装成功。 生成证书生成CA私钥1ipsec pki --gen --outform pem &gt; ca.pem 利用私钥签名CA证书1ipsec pki --self --in ca.pem --dn &quot;C=com, O=myvpn, CN=VPN CA&quot; --ca --outform pem &gt;ca.cert.pem 生成server端私钥1ipsec pki --gen --outform pem &gt; server.pem 用CA证书签发server端证书这里需要将下面的地址更换为google cloud中申请到的静态公网ip地址。 12345SERVER_ADDR=&quot;[REPLACE_WITH_YOUR_OWN_IP_ADDRESS]&quot;ipsec pki --pub --in server.pem | ipsec pki --issue --cacert ca.cert.pem \--cakey ca.pem --dn &quot;C=com, O=myvpn, CN=$SERVER_ADDR&quot; \--san=&quot;$SERVER_ADDR&quot; --flag serverAuth --flag ikeIntermediate \--outform pem &gt; server.cert.pem 生成client端私钥1ipsec pki --gen --outform pem &gt; client.pem 利用CA证书签发client端证书1ipsec pki --pub --in client.pem | ipsec pki --issue --cacert ca.cert.pem --cakey ca.pem --dn &quot;C=com, O=myvpn, CN=VPN Client&quot; --outform pem &gt; client.cert.pem 生成client端p12证书1openssl pkcs12 -export -inkey client.pem -in client.cert.pem -name &quot;client&quot; -certfile ca.cert.pem -caname &quot;VPN CA&quot; -out client.cert.p12 安装证书1234567891011121314# if not root probably you need to prepend sudo in front of the following commands#for ubuntu cp -r ca.cert.pem /usr/local/etc/ipsec.d/cacerts/cp -r server.cert.pem /usr/local/etc/ipsec.d/certs/cp -r server.pem /usr/local/etc/ipsec.d/private/cp -r client.cert.pem /usr/local/etc/ipsec.d/certs/cp -r client.pem /usr/local/etc/ipsec.d/private/#for centoscp -r ca.cert.pem /etc/strongswan/ipsec.d/cacerts/cp -r server.cert.pem /etc/strongswan/ipsec.d/certs/cp -r server.pem /etc/strongswan/ipsec.d/private/cp -r client.cert.pem /etc/strongswan/ipsec.d/certs/cp -r client.pem /etc/strongswan/ipsec.d/private/ 配置StrongSwan配置ipsec.confubuntu:/usr/local/etc/ipsec.confcentos:/etc/strongswan/ipsec.conf替换或新添加为如下内容(rightsourceip为申请的静态公网ip地址)：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455config setup uniqueids=neverconn iOS_cert keyexchange=ikev1 # strongswan version &gt;= 5.0.2, compatible with iOS 6.0,6.0.1 fragmentation=yes left=%defaultroute leftauth=pubkey leftsubnet=0.0.0.0/0 leftcert=server.cert.pem right=%any rightauth=pubkey rightauth2=xauth rightsourceip=10.31.2.0/24 rightcert=client.cert.pem auto=addconn android_xauth_psk keyexchange=ikev1 left=%defaultroute leftauth=psk leftsubnet=0.0.0.0/0 right=%any rightauth=psk rightauth2=xauth rightsourceip=10.31.2.0/24 auto=addconn networkmanager-strongswan keyexchange=ikev2 left=%defaultroute leftauth=pubkey leftsubnet=0.0.0.0/0 leftcert=server.cert.pem right=%any rightauth=pubkey rightsourceip=10.31.2.0/24 rightcert=client.cert.pem auto=addconn windows7 keyexchange=ikev2 ike=aes256-sha1-modp1024! rekey=no left=%defaultroute leftauth=pubkey leftsubnet=0.0.0.0/0 leftcert=server.cert.pem right=%any rightauth=eap-mschapv2 rightsourceip=10.31.2.0/24 rightsendcert=never eap_identity=%any auto=add 配置strongswan.confubuntu:/usr/local/etc/ipsec.confcentos:/etc/strongswan/ipsec.conf替换或新添加为如下内容：12345678910111213charon &#123; load_modular = yes duplicheck.enable = no compress = yes plugins &#123; include strongswan.d/charon/*.conf &#125; dns1 = 8.8.8.8 dns2 = 8.8.4.4 nbns1 = 8.8.8.8 nbns2 = 8.8.4.4 &#125; include strongswan.d/*.conf 配置ipsec.secretsubuntu:/usr/local/etc/ipsec.confcentos:/etc/strongswan/ipsec.conf替换或新添加为如下内容：1234: RSA server.pem: PSK &quot;mykey&quot;: XAUTH &quot;mykey&quot;[用户名] %any : EAP &quot;[密码]&quot; 注意将PSK、XAUTH处的”mykey”编辑为唯一且私密的字符串，并且将[用户名]改为自己想要的登录名，[密码]改为自己想要的密码（[]符号去掉），可以添加多行，得到多个用户。 配置iptables修改系统转发sysctrl.conf打开/etc/sysctl.conf，然后uncomment包含net.ipv4.ip_forward=1的这一行。 保存后，执行sysctl -p。 修改iptables将INF替换为自己的网络接口.12345678910111213INF=&quot;Your own network interface&quot;iptables -A FORWARD -m state --state RELATED,ESTABLISHED -j ACCEPTiptables -A FORWARD -s 10.31.2.0/24 -j ACCEPTiptables -A INPUT -i $INF -p esp -j ACCEPTiptables -A INPUT -i $INF -p udp --dport 500 -j ACCEPTiptables -A INPUT -i $INF -p tcp --dport 500 -j ACCEPTiptables -A INPUT -i $INF -p udp --dport 4500 -j ACCEPT# for l2tpiptables -A INPUT -i $INF -p udp --dport 1701 -j ACCEPT# for pptpiptables -A INPUT -i $INF -p tcp --dport 1723 -j ACCEPTiptables -A FORWARD -j REJECTiptables -t nat -A POSTROUTING -s 10.31.2.0/24 -o $INF -j MASQUERADE 【注意】：1.此处$INF为服务器网卡设备，对于OpenVZ主机请添venet0，其他主机添eth0，具体通过ifconfig查看使用的那个网卡2.此处ip：10.31.2.0/24仅举例，必须与上文ipsec.conf中的设置保持一致，但可是设置多对。 保存iptables且开机自动启动12345678910#for ubuntuiptables-save &gt; /etc/iptables.rulescat &gt; /etc/network/if-up.d/iptables&lt;&lt;EOF#!/bin/shiptables-restore &lt; /etc/iptables.rulesEOFchmod +x /etc/network/if-up.d/iptables#for centosservice iptables save 重启ipsec/iptables/strongswan服务123service iptables restartservice strongswan restartipsec restart 至此分讲完成。 WP8.1手机安装ca.cert.pem，进入设置VPN添加IKEv2连接，地址为证书中的地址或IP，通过用户名-密码连接。Windows连接也是一样，但注意将证书导入本地计算机而不是当前用户的“受信任的证书颁发机构”。iOS/Android/Mac OS X设备添加Cisco IPSec PSK验证方式，预共享密钥是/usr/local/etc/ipsec.secrets或者/etc/strongswan/ipsec.secrets中PSK后的字符串（不含引号），用户名密码同上，可以通过任意域名或IP连接，不需要证书. 自动化安装脚本下面附上自动化安装脚本，点我获取，如若有问题请创建issue沟通。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>vpn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[github搭建个人maven仓库]]></title>
    <url>%2F2017%2F07%2F02%2Fgithub%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BAmaven%E4%BB%93%E5%BA%93%2F</url>
    <content type="text"><![CDATA[引言三步： deploy到本地目录把本地目录提交到gtihub上配置github地址为仓库地址配置local file maven仓库 deploy到本地 maven可以通过http, ftp, ssh等deploy到远程服务器，也可以deploy到本地文件系统里。例如把项目deploy到/home/jet/workspace/gerrit/maven_xm_repo/目录下： &lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;hengyunabc-mvn-repo&lt;/id&gt; &lt;url&gt;file:/home/hengyunabc/code/maven-repo/repository/&lt;/url&gt; &lt;/repository&gt; &lt;/distributionManagement&gt; 推荐使用命令行来deploy，避免在项目里显式配置: mvn deploy -DaltDeploymentRepository=maven_xm_repo::default::file:/home/jet/workspace/gerrit/maven_xm_repo/repository/ 上面把项目deploy到本地目录/home/jet/workspace/gerrit/maven_xm_repo/repository/里，下面把这个目录提交到github上。 在Github上新建一个项目，然后把/home/jet/workspace/gerrit/maven_xm_repo/下的文件都提交到gtihub上。 cd /home/jet/workspace/gerrit/maven_xm_repo/ git init git add . git commit -m &#39;deploy xxx&#39; git remote add origin git@github.com:jethan/maven_xm_repo.git git push origin master 最终效果可以参考我的个人仓库： maven_xm_repo github maven仓库的使用 因为github使用了raw.githubusercontent.com这个域名用于raw文件下载。所以使用这个maven仓库，只要在pom.xml里增加： &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;hengyunabc-maven-repo&lt;/id&gt; &lt;url&gt;https://raw.githubusercontent.com/jethan/maven_xm_repo/master/repository&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; 目录查看和搜索 值得注意的是，github因为安全原因，把raw文件下载和原来的github域名分开了，而raw.githubusercontent.com这个域名是不支持目录浏览的。所以，想要浏览文件目录，或者搜索的话，可以直接到github域名下的仓库去查看。 比如文件fastjson-1.2.5.jar： 浏览器urlmaven仓库url maven仓库工作的机制 下面介绍一些maven仓库工作的原理。典型的一个maven依赖下会有这三个文件： maven-metadata.xml maven-metadata.xml.md5 maven-metadata.xml.sha1 maven-metadata.xml里面记录了最后deploy的版本和时间。 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;metadata modelVersion=&quot;1.1.0&quot;&gt; &lt;groupId&gt;io.github.hengyunabc&lt;/groupId&gt; &lt;artifactId&gt;mybatis-ehcache-spring&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;versioning&gt; &lt;snapshot&gt; &lt;timestamp&gt;20150804.095005&lt;/timestamp&gt; &lt;buildNumber&gt;1&lt;/buildNumber&gt; &lt;/snapshot&gt; &lt;lastUpdated&gt;20150804095005&lt;/lastUpdated&gt; &lt;/versioning&gt; &lt;/metadata&gt; 其中md5, sha1校验文件是用来保证这个meta文件的完整性。 maven在编绎项目时，会先尝试请求maven-metadata.xml，如果没有找到，则会直接尝试请求到jar文件，在下载jar文件时也会尝试下载jar的md5, sha1文件。 maven-metadata.xml文件很重要，如果没有这个文件来指明最新的jar版本，那么即使远程仓库里的jar更新了版本，本地maven编绎时用上-U参数，也不会拉取到最新的jar！ 所以并不能简单地把jar包放到github上就完事了，一定要先在本地Deploy，生成maven-metadata.xml文件，并上传到github上。 参考 maven的仓库关系 配置使用本地仓库 想要使用本地file仓库里，在项目的pom.xml里配置，如： &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;hengyunabc-maven-repo&lt;/id&gt; &lt;url&gt;file:/home/hengyunabc/code/maven-repo/repository/&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; 注意事项 maven的repository并没有优先级的配置，也不能单独为某些依赖配置repository。所以如果项目配置了多个repository，在首次编绎时，会依次尝试下载依赖。如果没有找到，尝试下一个，整个流程会很长。 所以尽量多个依赖放同一个仓库，不要每个项目都有一个自己的仓库。 参考1参考2]]></content>
      <categories>
        <category>maven</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git]]></title>
    <url>%2F2017%2F06%2F24%2Fgit%2F</url>
    <content type="text"><![CDATA[引言集中式vs分布式 Linus一直痛恨的CVS、VSS及SVN都是集中式的版本控制系统，而Git是分布式版本控制系统，集中式和分布式版本控制系统有什么区别呢？ 先说集中式版本控制系统，版本库是集中存放在中央服务器的，而干活的时候，用的都是自己的电脑，所以要先从中央服务器取得最新的版本，然后开始干活，干完活了，再把自己的活推送给中央服务器。中央服务器就好比是一个图书馆，你要改一本书，必须先从图书馆借出来，然后回到家自己改，改完了，再放回图书馆。 集中式版本控制系统最大的毛病就是必须联网才能工作，如果在局域网内还好，带宽够大，速度够快，可如果在互联网上，遇到网速慢的话，可能提交一个10M的文件就需要5分钟，这还不得把人给憋死啊。 那分布式版本控制系统与集中式版本控制系统有何不同呢？首先，分布式版本控制系统根本没有“中央服务器”，每个人的电脑上都是一个完整的版本库，这样，你工作的时候，就不需要联网了，因为版本库就在你自己的电脑上。既然每个人电脑上都有一个完整的版本库，那多个人如何协作呢？比方说你在自己电脑上改了文件A，你的同事也在他的电脑上改了文件A，这时，你们俩之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。 和集中式版本控制系统相比，分布式版本控制系统的安全性要高很多，因为每个人电脑里都有完整的版本库，某一个人的电脑坏掉了不要紧，随便从其他人那里复制一个就可以了。而集中式版本控制系统的中央服务器要是出了问题，所有人都没法干活了。在实际使用分布式版本控制系统的时候，其实很少在两人之间的电脑上推送版本库的修改，因为可能你们俩不在一个局域网内，两台电脑互相访问不了，也可能今天你的同事病了，他的电脑压根没有开机。因此，分布式版本控制系统通常也有一台充当“中央服务器”的电脑，但这个服务器的作用仅仅是用来方便“交换”大家的修改，没有它大家也一样干活，只是交换修改不方便而已。 当然，Git的优势不单是不必联网这么简单，后面我们还会看到Git极其强大的分支管理，把SVN等远远抛在了后面。 CVS作为最早的开源而且免费的集中式版本控制系统，直到现在还有不少人在用。由于CVS自身设计的问题，会造成提交文件不完整，版本库莫名其妙损坏的情况。同样是开源而且免费的SVN修正了CVS的一些稳定性问题，是目前用得最多的集中式版本库控制系统。除了免费的外，还有收费的集中式版本控制系统，比如IBM的ClearCase（以前是Rational公司的，被IBM收购了），特点是安装比Windows还大，运行比蜗牛还慢，能用ClearCase的一般是世界500强，他们有个共同的特点是财大气粗，或者人傻钱多。微软自己也有一个集中式版本控制系统叫VSS，集成在Visual Studio中。由于其反人类的设计，连微软自己都不好意思用了。 分布式版本控制系统除了Git以及促使Git诞生的BitKeeper外，还有类似Git的Mercurial和Bazaar等。这些分布式版本控制系统各有特点，但最快、最简单也最流行的依然是Git！ 很幸运的是毕业入职的第一家公司所在团队就使用git版本控制工具，intelligent idea开发工具。感谢Muhlin Chen，Ying Tan，Ken Logan，虽然你们不会看见。 在stackoverflow上又看到这样一段对于git工作模式的描述， 1A typical distributed workflow using Git is for a contributor to fork a project, build on it, publish the result to her public repository, and ask the &quot;upstream&quot; person (often the owner of the project where she forked from) to pull from her public repository. Requesting such a &quot;pull&quot; is made easy by the git request-pull command. 此时我不禁发现，对git的理解还是太浅薄。当初推荐小伙伴使用git时，我只能说出git比svn好，却不知为何更好。显然这样的表达是毫无说服力的。在网上一番搜索之后，发现一篇文章，探讨了四种常见的Git工作模式。我决定将本文翻译于此，算是对用了三年git的一个交代吧。 值得注意的是，如文章作者在一开始交代的，这四种方式只是四个典型的应用方式。我们不应该仅限于这五种方式，我们可以对这些方法进行融汇、修剪，创造出最适合自己团队的工作模式。 Git Workflows 分布式工作流由于不知道Git可能的工作模式，刚刚在工作中接触Git的人可能会感到有些困难。本文描述了最常见的几种Git工作模式，希望以此作为新人探索Git世界的一个起点。 当你在阅读本文的时候，这些工作模式只是一些指导意见，而不是不可违背的规则。我们希望通过告诉你什么是可能的，让你能够根据个人的需求混合、订制自己的工作模式。 转到一个分布式的版本控制系统看起来是一个令人畏惧的任务，但是你并不必改变现有的工作模式就可以享受Git带来的好处。你的团队可以按照与svn一样的模式进行工作。 然而，相比svn而言，在你的工作流程中使用Git会带来几个好处。第一，每个开发者都是整个项目的本地备份。这种隔离的工作环境可以使每个开发者独立的工作，他们可以提交修改到自己的本地仓库，可以忽视忘记上游的开发过程。直到合适的时候再通知上游。 第二，Git提供了健壮的分支和合并模型。与svn不同，Git的分支为集成代码和分享改动采用了一种fail-safe的机制。 工作原理就像Subversion一样，Centralized-workflow使用一个中央仓库作为代码提交的唯一入口。Svn中使用trunk，而Git中默认的开发分支叫作mster，所有的改动都会提交到这个分支。这种工作模式master以外的其他任何分支。 开发者首先clone这个中央仓库。在他们自己的本地备份中，他们修改文件、提交改动，就和在svn中一样。然而，这些提交仅仅储存在本地，它们和远程的那个中央仓库是完全隔离的。这就允许开发者可以在自己满意的一个时间点同步自己的代码到上游仓库中。 开发者通过push，将自己的master分支推送到中央仓库，来完成发布改动的过程。这和svn commit等价，除了git push会把所有本地提交里远程仓库中没有的都提交给中央仓库的master分支。 解决冲突 中央仓库代表官方工程，所以它的提交历史应该是正式且不可变的。如果一个开发者的本地提交偏离了中央仓库，Git将会拒绝push他的改动，因为这会覆盖掉官方的提交。 在开发者发布他们的修改之前，他们需要先取到中央仓库中本地没有的那些提交，将自己的改动建立在那些提交之上。这就好像是说，“我想把自己的改动添加到其他人已经做过的改动之上。”结果是一个绝对线性的提交历史，就跟传统的svn工作模式一样。 如果本地改动和上游的提交直接产生了冲突，Git将会暂停并让你手动的解决这些冲突。Git的好处之一是它使用了git status和git add同时用于生成提交和解决合并冲突。这使得新开发者更容易管理自己的合并。而且，如果他们陷入了麻烦，git就会停止合并过程，让开发者重试或者寻求帮助。 示例让我们来一步一步的看看一个典型的小团队如何在这种模式下合作。我们将会看到两个开发者，John和Mary，通过一个中央仓库，分别进行两个feature的开发并且分享他们的贡献。 Someone initializes the distributed repository 首先，有个人需要在一台服务器上创建中央仓库。如果这是一个新工程，你可以初始化一个空的仓库。否则，你需要导入一个已有的项目。 中央仓库应该是空的仓库，它不应该是一个已有的工作目录。我们可以这样创建，12ssh user@hostgit init --bare /path/to/repo.git 确保user是正确的SSH Username，host是你的服务器的域名或者IP，还有你希望存放仓库的位置。 Everybody clones the distributed repository 接下来，每个开发者创建一个整个工程的本地备份。我们可以通过命令git clone完成，1git clone ssh://user@host/path/to/repo.git 当你克隆了一个仓库，Git将会自动为你添加一个叫作origin的标签，这个标签指回到父仓库，以便你今后和其进行交互。 John works on his feature 在他的本地仓库中，John可以使用标准的Git提交流程进行开发，edit、stage、commit。如果你不熟悉工作目录，有一种方法可以让你指定提交的内容。这可以进行针对性的提交，即使你在本地进行了很多修改。 123git status # View the state of the repogit add # Stage a filegit commit # Commit a file 记住，因为这些命令只完成了本地的提交工作，John可以重复这个过程，随意进行提交，而不必担心远程的中央仓库发生了什么。这对于大feature而言非常有用，因为这些大feature往往需要打碎成更多更简单、更小的部分。 Mary works on her feature 于此同时，Mary也在她本地进行自己的feature开发，使用同样的edit、stage、commit流程。和John一样，她不必担心远程的中央仓库正在发生什么。而且也不担心John在他的本地仓库正在干什么，因为所有的本地仓库都是私有的。 John publishes his feature 一旦John完成了他的feature，他就应该把自己的本地提交发布到中央仓库，使其他团队成员可以访问。他可以通过git push来完成， 1git push origin master 记住，origin是当John clone的时候Git创建的指向中央仓库的远程连接。参数master告诉git，他希望让origin的master分支和他本地的master分支一样。因为中央仓库在John clone之后还没有被更新过，所以不会导致冲突，push将会顺利完成。 Mary tries to publish her feature 我们来看看当John成功发布之后，Mary试图发布的时候会发生什么。她可以使用完全一样的命令， 1git push origin master 但是，因为她本地的历史与中央仓库的历史发生了偏离，Git将会拒绝她的请求。 12345error: failed to push some refs to &apos;/path/to/repo.git&apos;hint: Updates were rejected because the tip of your current branch is behindhint: its remote counterpart. Merge the remote changes (e.g. &apos;git pull&apos;)hint: before pushing again.hint: See the &apos;Note about fast-forwards&apos; in &apos;git push --help&apos; for details. 这阻止了Mary覆盖官方的提交。她需要首先将John的提交拿到本地，和本地的修改进行集成，然后重试。 Mary rebases on top of John’s commits Mary可以使用git pull将上游的提交混合到本地。这个命令有点像svn update，它把上游的提交历史取到本地，并试图和本地的修改合并。 1git pull --rebase origin master 选项—rebase告诉Git在同步了中央仓库的改动之后，把Mary的改动移到master分支的顶部。如下图所示， 如果你忘了那个选项，pull仍然可以工作，但是每次有人需要同步中央仓库的时候，都会出现很多”merge commit”。对于这种工作模式而言，最好rebase，而不要生成merge commit。 Mary resolves a merge conflict Rebase把本地的提交一次一个的放到更新过的master上。这意味着merge conflict只会发生在你的一次提交之上，而不是把你的所有提交作为整体进行合并。这可以使你的提交更有针对性，并且保持一个干净的提交历史。相应的，这使得找到bug是在哪里引进的更加容易，如果必要，可以对项目以最小代价进行回滚操作。 如果Mary和John分别工作在无关的feature上，rebase的过程不大可能会发生冲突。但是如果冲突发生了，Git将会在当前提交处暂停rebase的过程，并且输入如下信息，和一些相应的提示， 1CONFLICT (content): Merge conflict in &lt;some-file&gt; Git的一个伟大之处在于，任何人都可以解决他们自己的合并冲突。在我们的例子中，Mary可以简单的执行git status看看问题发生在哪里。冲突文件将会出现在Unmerged path一节。 12345# Unmerged paths:# (use &quot;git reset HEAD &lt;some-file&gt;...&quot; to unstage)# (use &quot;git add/rm &lt;some-file&gt;...&quot; as appropriate to mark resolution)## both modified: &lt;some-file&gt; 然后，她就可以把文件修改成自己需要的样子。一旦她修改完毕，她就可以将文件置入工作区，让git rebase继续做剩下的事情， 12git add &lt;some-file&gt;git rebase --continue 这就是需要做的所有事情了。Git将会移动到下一个提交，对所有产生冲突的提交重复刚才的步骤。 如果你遇到了某种情况，而且解决不了时，不必惊慌。只需要执行下面的命令，你就可以回到执行git pull —rebase之前的状态。 1git rebase --abort Mary successfully publishes her feature 当她完成与中央仓库的同步之后。Mary就可以成功发布她的改动了。 1git push origin master Feature分支工作流 一旦你熟悉了Centralized Workflow，在你的开发过程中加入feature分支成了一种简单的促进开发者协作的方法。 Feature Branch Workflow的核心想法在于所有feature都应该在自己的分支中开发，而不是都在master分支中。这种封装使得多个开发者可以在不干扰主代码库的前提下开发自己的feature。这同时意味着master分支将永远不会包含不健全的代码，这对于不断进行的集成开发是一个非常大的好处。 这种对feature开发的封装，也使得我们可以在开发中利用pull requests，这是一种发起关于某个分支的讨论的方法。这给了其他开发者一个在代码被合并到主项目之前审查某个feature的机会。或者，当你卡在某个feature开发中时，你可以发起一个pull request向你的同事征求意见。总而言之，pull requests以一种非常简单的方式为你的团队提供了评论彼此工作的条件。 工作原理Feature Branch Workflow仍然使用中央仓库，master分支仍然代表官方工程的历史。但是，并不是直接提交到本地的master分支，开发者每次开始一个新feature时，首先需要创建一个新的分支。Feature分支应该有描述性的名称，比如animated-menu-items或者issue-#1061.这是为了给每个分支提供一个清晰、明确的目的。 Git对于master分支和feature分支没有本质上的区分，所以开发者可以edit、stage并且commit改动到feature分支，就和在Centralized Workflow中一样。 除此之外，feature分支可以被合并到中央仓库中。这就可以在不动官方代码的前提下在开发者之间共享一个feature。因为master是唯一的特殊分支，在中央仓库中储存多个feature分支并不会带来什么问题。当然，这也是一种备份本地提交的好办法。 Pull Requests 除了隔离feature的开发环境之外，分支使得我们可以通过pull requests来讨论代码改动。一旦某人完成了一个feature，他们不需要立刻合并到master中。他们会合并到feature分支，然后发起一个pull request要求合并他们的改动到master中。这给了其他开发者一个在其进入主代码库之前审查代码改动的机会。 代码审查时pull requests的一个好处，但是它却是被设计做一种讨论代码的通用方法。你可以认为pull requests是针对某个分支的讨论。这意味着也可以在开发流程中更早的阶段使用它。比如说，如果一个开发者需要帮助，他就可以发起一个pull request。相关的人会被自动通知，他们就可以看到提交下面的问题了。 一旦一个pull request被接受了，发布一个feature的过程和Centralized Workflow是一样的。首先，需要确保本地的master分支和上游的master进行了同步，然后，你将feature分支合并到master，再合并到中央仓库的master中。 一些代码管理工具可以帮助我们处理pull requests，如Bitbucker或Stash。 示例下面的例子将演示如何将pull requests作为代码审查的一种形式，但是切记它还可以用于很多其他的目的。 Mary begins a new feature 在她开始开发一个feature之前，她需要一个隔离的分支。她可以新开一个分支， 1git checkout -b marys-feature master 这检出了一个叫作marys-feature的分支，基于master。选项-b告诉Git如果这个分支不存在，就创建一个。在这个分支上，Mary edit、stage并且commit，按照通常的方式，提交多次后建立起了她的feature。 123git statusgit add &lt;some-file&gt;git commit Mary goes to lunch 在早上Mary为她的分支进行了若干次提交。在她去吃午饭之前，应该把她的feature分支上传到中央仓库。这相当于进行了备份，但是如果Mary和其他开发者进行协作，那这使得其他开发者可以访问她的提交内容了。 1git push -u origin marys-feature 这个命令将marys-feature上传到中央仓库origin，选项-u将其添加为一个远程跟踪分支。设置好这个跟踪分支后，Mary可以直接执行git push，无需任何其他参数就可以上传feature了。 Mary finishes her feature 当Mary吃完午饭回来后，她完成了她的feature。在她将其合并入master之前，她需要发起一个pull request让组内其余的人知道她完成了。但是首先，她需要确保中央仓库已经有了她最新的提交， 1git push 然后，她在她的Git GUI中发起了一个pull request，请求合并marys-feature到master，其他组员将会自动收到提醒。pull requests允许在提交的下面进行评论，所以这对于问问题、讨论来说非常简单。 Bill receives the pull request Bill收到了pull request并且查看了marys-feature。他决定在集成到官方工程之前进行一些修改，然后他和Mary前前后后通过pull request进行了一番交流。 Mary makes the changes Mary通过edit、stage、commits完成了修改，并且上传到了中央仓库。她所有的活动都在pull request中有所展现，Bill仍然可以进行评论。 如果他愿意，Bill可以拿到marys-feature，在自己的本地备份中工作。任何他的提交也会出现在pull request中。 Mary publishes her feature 一旦Bill决定要接受这个pull request了，某个人需要合并这个feature到稳定的工程中去，这个人既可以是Bill也可以使Mary。 1234git checkout mastergit pullgit pull origin marys-featuregit push 首先，不论是谁都要检出master分支，然后确保它是最新的。然后，git pull origin marys-feature将中央仓库中的marys-feature合并到本地的master。有也可以简单的使用git merge marys-feature，但是上面的命令确保你总是拿到最新的feature branch。最后，更新过的master需要上传到origin去。 一些GUI能够自动化pull request的接受过程，仅仅需要点击Accept按钮，就可以触发一系列命令完成工作。如果你的不行，它至少也可以在合并代码之后自动关闭这个pull request。 Meanwhile, John is doing the exact same thing 当Mary和Bill开发marys-feature，在Mary的pull request中讨论时，John也在做同样的事情。通过隔离feature到不同的分支，所有人都可以独立的工作，如果必要和其他开发者共享代码改动也是很轻松的事情。 Gitflow工作流 Gitflow Workflow源自Vincent Driessen在nvie的文章。 Gitflow Workflow定义了一个用于工程发布的严格的分支模型。比起Feature Branch Workflow稍微复杂一些，其为管理较大项目提供了一个可靠的框架。 这种工作模式在Feature Branch Workflow的基础上没有增加新的概念或者命令。它只是为不同的分支定义了明确的角色，并且定义它们之间何时以及如何交互。与Feature Branch Workflow相比，它为准备、维护、发布定义了自己的分支。当然，你也可以享受到所有Feature Branch Workflow拥有的好处：pull requests，隔离环境，和更加有效的协作。 工作原理Gitflow Workflow仍然使用一个中央仓库。与其他工作模式相同，开发者可以在本地工作，然后再将分支push到中央仓库中。唯一的不同在于工程的分支结构。 Historical Branches 与单一master分支不同，本工作模式使用两个分支来记录工程的历史。master分支存储官方发布的历史，develop分支用于集成feature。要为master分支的每一个提交打上一个版本号作为tag也是很方便的。 本工作模式的其余部分都在考虑让这两个分支进行交互。 Feature Branches 每一个新feature应该在自己的分支上，这个分支可以被push到中央仓库以便备份或者协作之用。但是，feature分支把develop分支作为父分支，而不是从master分支上分裂出来。当一个feature完成后，它会被合并会develop分支。Features永远都不应该直接和master交互。 注意feature分支和develop分支就是Feature Branch Workflow。但是Gitflow Workflow并不只是这样。 Release Branches 当develop收集到了足够一次发布的features时，或者一个预先约定的发布日期到达时，你就从develop分裂出一个分支。这个分支的创建就代表着一个发布周期的开始，所以这个时间点之后任何新feature都不能加进来，除了修复bug，文档生成，和其他发布相关的任务才能进入这个分支。当这个分支可以发布时，这个分支将会合并到master，并且用版本号打上一个tag。除此之外，还应该合并会develop分支，因为这个分支可能包含了在创建之初还没有的进展。 使用一个特定的分支来准备发布，就可以让一个团队继续优化当前版本，而另一个团队继续为下个版本开发新feature。它同时也创建了良好定义的开发术语，比如我们可以说，“这周我们准备4.0版的发布”，实际上我们也可以在代码仓库中看到这个结构。 Maintenance Branches Maintenance或者说hotfix分支用来对生产环境的版本进行快速修复。这是唯一可以直接从master分裂的分支。一旦修复完成，就应该马上被合并到master和develop分支中，而且master应该用更新版本号打上一个tag。 拥有一个特定的开发线路供修复bug使得你的团队可以在不干扰其他工作流程，也不用等待下个发布周期的前提下处理issue。你可以认为maintenance分支是一个直接和master分支交互的发布分支。 示例下面的例子展示了这个工作模式如何处理一个发布周期。我们假设已经创建了一个中央仓库。 Create a develop branch 第一步是在默认master分支的基础上补全一个develop分支。一个简单的方法是在本地创建一个空的develop分支，然后push到服务器上， 12git branch developgit push -u origin develop 这个分支包含了整个工程的完整历史，而master只包含了一个削减过的版本。其他开发者现在应该clone中央仓库，并且创建一个develop的跟踪分支。 12git clone ssh://user@host/path/to/repo.gitgit checkout -b develop origin/develop 现在所有人都在本地建立起了一份历史分支的备份。 Mary and John begin new features 我们的例子开始于John和Mary要开发不同的feature。他们都需要创建各自的分支。他们不应该以master作为基础，而应该以develop作为基础， 1git checkout -b some-feature develop 他们两个都通过edit、stage、commit的方法，向各自的feature分支进行提交。 123git statusgit add &lt;some-file&gt;git commit Mary finishes her feature 在提交了若干次之后，Mary认为她的feature已经完成了。如果她的团队使用pull requests，这就是一个合适的发起一个pull request请求合并她的feature到develop的时间。否则，她可以合并到本地的develop然后push到中央仓库， 12345git pull origin developgit checkout developgit merge some-featuregit pushgit branch -d some-feature 第一个命令确保本地的develop分支是最新的。注意feature始终不应该直接合并到master中。冲突的解决方法和Centralized Workflow中描述的一样。 Mary begins to prepare a release 当John仍然在开发他的feature时，Mary开始准备项目的第一个官方发行。跟feature开发一样，她使用一个新的分支来封装发行的准备工作。这一步也是创建发行版本号的时候， 1git checkout -b release-0.1 develop 这个分支用来整理、测试、更新文档，以及为下一次发行做一切准备工作。这就是像是一个为了优化发行版本的feature分支。 一旦Mary创建了这个分支，并且push到了中央仓库，这个发行就变成feature-frozen了。任何不在develop中的功能都要推迟到下个发布周期。 Mary finishes the release 当release准备好上线时，Mary将其合并回master和develop，然后删除这个发行分支。合并会develop是非常重要的，因为重要的修改可能被加入了这个发行分支，他们对于新的feature而言是有用的。如果Mary的组织强调代码审查，这也是一个理想的发起pull request的位置。 1234567git checkout mastergit merge release-0.1git pushgit checkout developgit merge release-0.1git pushgit branch -d release-0.1 release分支好像是一个feature开发版本(develop)与公开发行版本(master)之间的缓冲区。不论什么时候你合并回master，你都应该为提交打上tag， 12git tag -a 0.1 -m &quot;Initial public release&quot; mastergit push --tags Git提供了一些脚本，可以在代码仓库发生了一些特定的事件时触发。你可以配置，使得每当有master分支或者一个tag被push到中央仓库时，自动的创建一个公开发行版本。 End-user discovers a bug 在发布之后，Mary回到下个版本的feature开发中。直到一个终端用户在现有版本中发现了一个bug。为了处理这个bug，Mary从master创建了一个maintenance分支，修复bug，然后直接合并回master。 12345git checkout -b issue-#001 master# Fix the buggit checkout mastergit merge issue-#001git push 和release分支一样，maintenance分支包括了重要的修改，这些修改也应该合并到develop中。然后，就可以删掉这个分支了， 1234git checkout developgit merge issue-#001git pushgit branch -d issue-#001 Forking工作流Forking Workflow和本文中谈到的其他工作模式都不相同。它并不是只有一个单独的服务器端的仓库来扮演中央代码库，在这个模式中，每个开发者都有一个自己的服务器端的仓库。这意味着每一个贡献者都有两个Git的仓库，一个私有的本地的，一个共有的服务器端的。 Forking Workflow最大的好处在于不用所有人都push到一个中央仓库。开发者可以push自己的服务器端仓库，只有项目的维护者才能push到官方的仓库。它允许维护者维护者接受其他开发者的提交，而不给他们对官方代码库的写权限。 这就构成了一种分布式的工作模式。为大型团队安全的协作提供了一种灵活的方式。 工作原理跟其他Git工作模式一样，Forking Workflow开始于服务器端的官方公开仓库。但是当一个新开发者想要在这个项目上工作时，他并不能呢个直接clone这个官方工程。 他需要先fork这个官方工程，在服务器上创建一份自己的备份。这个新的备份就是它的个人公开仓库，其他开发者都不允许push到这个仓库，但是他们可以pull这个仓库的改动到自己的代码中。当他们创建自己服务器端的备份后，开发者执行git clone在本地建立一个备份。这就是他们私人的开发环境，就跟别的工作模式一样。 当他们想要发布本地的提交时，他们push这个提交到他们自己的公开仓库中，而不是官方的那个。然后，他们发起一个pull request，让官方工程维护者知道有一个更新等待被集成。那个pull request也成为了一个关于提交代码讨论的地方。 有O把这个feature集成到官方代码库中，维护者pull贡献者的改到到本地，检查功能是否正常，是否打破工程，然后合并到本地master，然后push到服务器的公开仓库中。现在这个feature就是这个工程的一部分了，其他开发者也应该从官方仓库pull这些改动到本地来进行同步。 The official repository 在Forking Workflow中的“官方”一词只是一种习惯。从技术角度来说，Git并不认为官方的公共仓库和其他开发者的公共仓库有什么不同。实际上，唯一使得官方仓库官方的原因在于其实工程维护者的公开仓库。 Branching in the Forking Workflow 所有这些个人的公共仓库只是一种方便共享分支给其他开发者的方式。所有人仍然应该使用分支来隔离不同的feature，就像Feature Branch Workflow和Gitflow Workflow一样。唯一的区别是这些分支如何共享。在Forking Workflow中，他们被pull到另一个开发者的本地仓库中，而Feature Branch Workflow和Gitflow Workflow则是push到官方仓库中。 示例 github gitcafe 相关资料推荐 玩游戏，学习git分支 大牛的博客，详细简单基础]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>版本控制</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux常用操作命令(一)]]></title>
    <url>%2F2017%2F06%2F19%2Flinux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[引言 ◆ 安装和登录命令：login、shutdown、halt、reboot、install、mount、umount、chsh、exit、last； ◆ 文件处理命令：file、mkdir、dd、rm、grep、find、mv、cp、ls、diff、cat、ln、tail、head、more、less、cd、管道； ◆ 系统管理相关命令：df、top、free、quota、at、lp、adduser、groupadd、kill、crontab； ◆ 网络操作命令：ifconfig、ip、ping、netstat、telnet、ftp、route、rlogin、rcp、finger、mail、nslookup； ◆ 系统安全相关命令：passwd、su、umask、chgrp、chmod、chown、chattr、sudo ps、who、which、whois； ◆ 其它命令：tar、unzip、gunzip、unarj、mtools、man、unendcode、uudecode。系统管理命令 stat ＃显示指定文件的详细信息，比ls更详细 who ＃显示在线登陆用户 whoami ＃显示当前操作用户 hostname ＃显示主机名 uname ＃显示系统信息 top ＃动态显示当前耗费资源最多进程信息 ps ＃显示瞬间进程状态 ps -aux du ＃查看目录大小 du -h /home带有单位显示目录信息 df ＃查看磁盘大小 df -h 带有单位显示磁盘信息 ifconfig ＃查看网络情况 ping ＃测试网络连通 netstat ＃显示网络状态信息 man ＃命令不会用了，找男人? 如：man ls clear ＃清屏 alias ＃对命令重命名 如：alias showmeit=”ps -aux” ，另外解除使用unaliax showmeit kill ＃杀死进程，可以先用ps 或 top命令查看进程的id，然后再用kill命令杀死进程。 常用基本指令 ls #显示文件或目录 -l #列出文件详细信息l(list) -a #列出当前目录下所有文件及目录，包括隐藏的a(all) mkdir #创建目录 -p #创建目录，若无父目录，则创建p(parent) cd #切换目录 touch #创建空文件 echo #创建带有内容的文件。 cat #查看文件内容 cp #拷贝 mv #移动或重命名 rm #删除文件 -r #递归删除，可删除子目录及文件 -f #强制删除 find #在文件系统中搜索某文件 wc #统计文本中行数、字数、字符数 grep #在文本文件中查找某个字符串 rmdir #删除空目录 tree #树形结构显示目录，需要安装tree包 pwd #显示当前目录 ln #创建链接文件 more、less #分页显示文本文件内容 head、tail #显示文件头、尾内容 ctrl+alt+F1 #命令行全屏模式 下面只介绍一些常用的基本命令 安装和登录命令shutdown/halt/reboot/exit/logout命令说明 shutdown -r #关机重启 -h #关机不重启 now #立刻关机 halt #关机 reboot #重启 exit #退出当前shell logout #退出登录shell mount/unmount命令说明 fdisk -l #查看磁盘情况 fdisk /dev/sda #为/dev/sda设备分区 m #显示所有命令 n #添加分区 p/e #主分区/逻辑分区 +50G #指定分区大小为50G p #打印分区列表 w #保存 reboot #重启 cat /etc/fstab #查看文件系统 mke2fs -t ext4 /dev/sda4 #格式化文件系统 mount /dev/sda4 /home #挂载到指定目录/home umount #取消挂载 #开机自动挂载 echo &quot;/dev/sda4 /home ext4 defaults 1 1&quot; &gt;&gt; /etc/fstab 文件处理命令awk一种编程语言，用于在linux/unix下对文本和数据进行处理 数据可以来自标准输入(stdin)、一个或多个文件，或其它命令的输出。它支持用户自定义函数和动态正则表达式等先进功能，是linux/unix下的一个强大编程工具。它在命令行中使用，但更多是作为脚本来使用。awk有很多内建的功能，比如数组、函数等，这是它和C语言的相同之处，灵活性是awk最大的优势。 awk [options] &#39;script&#39; var=value file(s) awk [options] -f scriptfile var=value file(s) -F fs fs指定输入分隔符，fs可以是字符串或正则表达式，如-F: -v var=value 赋值一个用户定义变量，将外部变量传递给awk -f scripfile 从脚本文件中读取awk命令 -m[fr] val 对val值设置内在限制，-mf选项限制分配给val的最大块数目；-mr选项限制记录的最大数目。这两个功能是Bell实验室版awk的扩展功能，在标准awk中不适用。 {} 要执行的脚本内容 eg: cat /etc/passwd |awk -F &#39;:&#39; &#39;{print $1&quot;\t&quot;$7}&#39; awk模式和操作 awk脚本是由模式和操作组成的。 模式 模式可以是以下任意一个： /正则表达式/：使用通配符的扩展集。 关系表达式：使用运算符进行操作，可以是字符串或数字的比较测试。 模式匹配表达式：用运算符~（匹配）和~!（不匹配）。 BEGIN语句块、pattern语句块、END语句块：参见awk的工作原理 操作 操作由一个或多个命令、函数、表达式组成，之间由换行符或分号隔开，并位于大括号内，主要部分是： 变量或数组赋值 输出命令 内置函数 控制流语句 awk脚本基本结构 awk &#39;BEGIN{ print &quot;start&quot; } pattern{ commands } END{ print &quot;end&quot; }&#39; file 一个awk脚本通常由：BEGIN语句块、能够使用模式匹配的通用语句块、END语句块3部分组成，这三个部分是可选的。任意一个部分都可以不出现在脚本中，脚本通常是被单引号或双引号中，例如： awk &#39;BEGIN{ i=0 } { i++ } END{ print i }&#39; filename awk &quot;BEGIN{ i=0 } { i++ } END{ print i }&quot; filename awk的工作原理 awk &#39;BEGIN{ commands } pattern{ commands } END{ commands }&#39; 第一步：执行BEGIN{ commands }语句块中的语句； 第二步：从文件或标准输入(stdin)读取一行，然后执行pattern{ commands }语句块，它逐行扫描文件，从第一行到最后一行重复这个过程，直到文件全部被读取完毕。 第三步：当读至输入流末尾时，执行END{ commands }语句块。 BEGIN语句块在awk开始从输入流中读取行之前被执行，这是一个可选的语句块，比如变量初始化、打印输出表格的表头等语句通常可以写在BEGIN语句块中。 END语句块在awk从输入流中读取完所有的行之后即被执行，比如打印所有行的分析结果这类信息汇总都是在END语句块中完成，它也是一个可选语句块。 pattern语句块中的通用命令是最重要的部分，它也是可选的。如果没有提供pattern语句块，则默认执行{ print }，即打印每一个读取到的行，awk读取的每一行都会执行该语句块。 eg： [jet@jet ~]$ echo -e &quot;A line 1\nA line 2&quot; | awk &#39;BEGIN{ print &quot;Start&quot; } { print } END{ print &quot;End&quot; }&#39; Start A line 1 A line 2 End 当使用不带参数的print时，它就打印当前行，当print的参数是以逗号进行分隔时，打印时则以空格作为定界符。在awk的print语句块中双引号是被当作拼接符使用，例如： echo | awk &#39;{ var1=&quot;v1&quot;; var2=&quot;v2&quot;; var3=&quot;v3&quot;; print var1,var2,var3; }&#39; v1 v2 v3 双引号拼接使用： echo | awk &#39;{ var1=&quot;v1&quot;; var2=&quot;v2&quot;; var3=&quot;v3&quot;; print var1&quot;=&quot;var2&quot;=&quot;var3; }&#39; v1=v2=v3 { }类似一个循环体，会对文件中的每一行进行迭代，通常变量初始化语句（如：i=0）以及打印文件头部的语句放入BEGIN语句块中，将打印的结果等语句放在END语句块中。 awk内置变量（预定义变量） 说明：[A][N][P][G]表示第一个支持变量的工具，[A]=awk、[N]=nawk、[P]=POSIXawk、[G]=gawk $n 当前记录的第n个字段，比如n为1表示第一个字段，n为2表示第二个字段。 $0 这个变量包含执行过程中当前行的文本内容。 [N] ARGC 命令行参数的数目。 [G] ARGIND 命令行中当前文件的位置（从0开始算）。 [N] ARGV 包含命令行参数的数组。 [G] CONVFMT 数字转换格式（默认值为%.6g）。 [P] ENVIRON 环境变量关联数组。 [N] ERRNO 最后一个系统错误的描述。 [G] FIELDWIDTHS 字段宽度列表（用空格键分隔）。 [A] FILENAME 当前输入文件的名。 [P] FNR 同NR，但相对于当前文件。 [A] FS 字段分隔符（默认是任何空格）。 [G] IGNORECASE 如果为真，则进行忽略大小写的匹配。 [A] NF 表示字段数，在执行过程中对应于当前的字段数。 [A] NR 表示记录数，在执行过程中对应于当前的行号。 [A] OFMT 数字的输出格式（默认值是%.6g）。 [A] OFS 输出字段分隔符（默认值是一个空格）。 [A] ORS 输出记录分隔符（默认值是一个换行符）。 [A] RS 记录分隔符（默认是一个换行符）。 [N] RSTART 由match函数所匹配的字符串的第一个位置。 [N] RLENGTH 由match函数所匹配的字符串的长度。 [N] SUBSEP 数组下标分隔符（默认值是34）。 eg: echo -e &quot;line1 f2 f3nline2 f4 f5nline3 f6 f7&quot; | awk &#39;{print &quot;Line No:&quot;NR&quot;, No of fields:&quot;NF, &quot;$0=&quot;$0, &quot;$1=&quot;$1, &quot;$2=&quot;$2, &quot;$3=&quot;$3}&#39; Line No:1, No of fields:3 $0=line1 f2 f3 $1=line1 $2=f2 $3=f3 Line No:2, No of fields:3 $0=line2 f4 f5 $1=line2 $2=f4 $3=f5 Line No:3, No of fields:3 $0=line3 f6 f7 $1=line3 $2=f6 $3=f7 使用print $NF可以打印出一行中的最后一个字段，使用$(NF-1)则是打印倒数第二个字段，其他以此类推： echo -e &quot;line1 f2 f3n line2 f4 f5&quot; | awk &#39;{print $NF}&#39; f3 f5 echo -e &quot;line1 f2 f3n line2 f4 f5&quot; | awk &#39;{print $(NF-1)}&#39; f2 f4 打印每一行的第二和第三个字段： awk &#39;{ print $2,$3 }&#39; filename 统计文件中的行数： awk &#39;END{ print NR }&#39; filename 以上命令只使用了END语句块，在读入每一行的时，awk会将NR更新为对应的行号，当到达最后一行NR的值就是最后一行的行号，所以END语句块中的NR就是文件的行数。 一个每一行中第一个字段值累加的例子： seq 5 | awk &#39;BEGIN{ sum=0; print &quot;总和：&quot; } { print $1&quot;+&quot;; sum+=$1 } END{ print &quot;等于&quot;; print sum }&#39; 总和： 1+ 2+ 3+ 4+ 5+ 等于 15 将外部变量值传递给awk 借助-v选项，可以将外部值（并非来自stdin）传递给awk： VAR=10000 echo | awk -v VARIABLE=$VAR &#39;{ print VARIABLE }&#39; 另一种传递外部变量方法： var1=”aaa”var2=”bbb”echo | awk ‘{ print v1,v2 }’ v1=$var1 v2=$var2 当输入来自于文件时使用： awk ‘{ print v1,v2 }’ v1=$var1 v2=$var2 filename 以上方法中，变量之间用空格分隔作为awk的命令行参数跟随在BEGIN、{}和END语句块之后。 awk运算与判断 作为一种程序设计语言所应具有的特点之一，awk支持多种运算，这些运算与C语言提供的基本相同。awk还提供了一系列内置的运算函数（如log、sqr、cos、sin等）和一些用于对字符串进行操作（运算）的函数（如length、substr等等）。这些函数的引用大大的提高了awk的运算功能。作为对条件转移指令的一部分，关系判断是每种程序设计语言都具备的功能，awk也不例外，awk中允许进行多种测试，作为样式匹配，还提供了模式匹配表达式~（匹配）和~!（不匹配）。作为对测试的一种扩充，awk也支持用逻辑运算符。 算术运算符 运算符 描述符 + - 加，减 * / &amp; 乘，除与求余 + - ！ 一元加 ，减和逻辑非 ^ *** 求冥 ++ — 自增,自减 作为前缀或后缀 eg： awk &#39;BEGIN{a=&quot;b&quot;;print a++,++a;}&#39; 0 2 注意：所有用作算术运算符进行操作，操作数自动转为数值，所有非数值都变为0 赋值运算符 运算符 描述符 = += -= *= /= %= ^= **= 赋值语句 eg： a+=5; 等价于：a=a+5; 逻辑运算符 运算符 描述 &#124;&#124; 逻辑或 &amp;&amp; 逻辑与 eg： awk &#39;BEGIN{a=1;b=2;print (a&gt;5 &amp;&amp; b&lt;=2),(a&gt;5 || b&lt;=2);}&#39; 0 1 正则运算符 运算符 描述 ~ ~! 匹配正则表达式和不匹配正则表达式 eg： awk &#39;BEGIN{a=&quot;100testa&quot;;if(a ~ /^100*/){print &quot;ok&quot;;}}&#39; ok 关系运算符 运算符 描述 &lt; &lt;= &gt; &gt;= != == 关系运算符 eg： awk &#39;BEGIN{a=11;if(a &gt;= 9){print &quot;ok&quot;;}}&#39; ok 注意：> < 可以作为字符串比较，也可以用作数值比较，关键看操作数如果是字符串就会转换为字符串比较。两个都为数字才转为数值比较。字符串比较：按照ASCII码顺序比较。 其它运算符 运算符 描述 $ 字段引用 空格 字符串连接符 ?: C条件表达式 in 数组中是否存在某键值 eg： awk &#39;BEGIN{a=&quot;b&quot;;print a==&quot;b&quot;?&quot;ok&quot;:&quot;err&quot;;}&#39; ok awk &#39;BEGIN{a=&quot;b&quot;;arr[0]=&quot;b&quot;;arr[1]=&quot;c&quot;;print (a in arr);}&#39; 0 awk &#39;BEGIN{a=&quot;b&quot;;arr[0]=&quot;b&quot;;arr[&quot;b&quot;]=&quot;c&quot;;print (a in arr);}&#39; 1 运算级优先级表 awk高级输入输出 读取下一条记录 awk中next语句使用：在循环逐行匹配，如果遇到next，就会跳过当前行，直接忽略下面语句。而进行下一行匹配。net语句一般用于多行合并： cat text.txt a b c d e awk &#39;NR%2==1{next}{print NR,$0;}&#39; text.txt 2 b 4 d 当记录行号除以2余1，就跳过当前行。下面的print NR,$0也不会执行。下一行开始，程序有开始判断NR%2值。这个时候记录行号是：2 ，就会执行下面语句块：&#39;print NR,$0&#39; 分析发现需要将包含有“web”行进行跳过，然后需要将内容与下面行合并为一行： [jet@jet oschina_hexo_server]$ cat test.txt web01[192.168.2.100] httpd ok tomcat ok sendmail ok web02[192.168.2.101] httpd ok postfix ok web03[192.168.2.102] mysqld ok httpd ok 0 [jet@jet oschina_hexo_server]$ awk &#39;/^web/{T=$0;next;}{print T&quot;:\t&quot;$0;}&#39; test.txt web01[192.168.2.100] : httpd ok web01[192.168.2.100] : tomcat ok web01[192.168.2.100] : sendmail ok web02[192.168.2.101] : httpd ok web02[192.168.2.101] : postfix ok web03[192.168.2.102] : mysqld ok web03[192.168.2.102] : httpd ok web03[192.168.2.102] : 0 web03[192.168.2.102] : 简单地读取一条记录 awk getline用法：输出重定向需用到getline函数。getline从标准输入、管道或者当前正在处理的文件之外的其他输入文件获得输入。它负责从输入获得下一行的内容，并给NF,NR和FNR等内建变量赋值。如果得到一条记录，getline函数返回1，如果到达文件的末尾就返回0，如果出现错误，例如打开文件失败，就返回-1。 getline语法：getline var，变量var包含了特定行的内容。 awk getline从整体上来说，用法说明： 当其左右无重定向符|或&lt;时：getline作用于当前文件，读入当前文件的第一行给其后跟的变量var或$0（无变量），应该注意到，由于awk在处理getline之前已经读入了一行，所以getline得到的返回结果是隔行的。 当其左右有重定向符|或&lt;时：getline则作用于定向输入文件，由于该文件是刚打开，并没有被awk读入一行，只是getline读入，那么getline返回的是该文件的第一行，而不是隔行。 eg： 执行linux的date命令，并通过管道输出给getline，然后再把输出赋值给自定义变量out，并打印它： awk &#39;BEGIN{ &quot;date&quot; | getline out; print out }&#39; test 执行shell的date命令，并通过管道输出给getline，然后getline从管道中读取并将输入赋值给out，split函数把变量out转化成数组mon，然后打印数组mon的第二个元素： awk &#39;BEGIN{ &quot;date&quot; | getline out; split(out,mon); print mon[2] }&#39; test 命令ls的输出传递给geline作为输入，循环使getline从ls的输出中读取一行，并把它打印到屏幕。这里没有输入文件，因为BEGIN块在打开输入文件前执行，所以可以忽略输入文件。 awk &#39;BEGIN{ while( &quot;ls&quot; | getline) print }&#39; 关闭文件 awk中允许在程序中关闭一个输入或输出文件，方法是使用awk的close语句。 close(&quot;filename&quot;) filename可以是getline打开的文件，也可以是stdin，包含文件名的变量或者getline使用的确切命令。或一个输出文件，可以是stdout，包含文件名的变量或使用管道的确切命令。 输出到一个文件 awk中允许用如下方式将结果输出到一个文件： echo | awk &#39;{printf(&quot;hello word!n&quot;) &gt; &quot;datafile&quot;}&#39; 或 echo | awk &#39;{printf(&quot;hello word!n&quot;) &gt;&gt; &quot;datafile&quot;}&#39; 设置字段定界符 默认的字段定界符是空格，可以使用-F &quot;定界符&quot;明确指定一个定界符： awk -F: &#39;{ print $NF }&#39; /etc/passwd 或 awk &#39;BEGIN{ FS=&quot;:&quot; } { print $NF }&#39; /etc/passwd 在BEGIN语句块中则可以用OFS=“定界符”设置输出字段的定界符。 流程控制语句 在linux awk的while、do-while和for语句中允许使用break,continue语句来控制流程走向，也允许使用exit这样的语句来退出。break中断当前正在执行的循环并跳到循环外执行下一条语句。if 是流程选择用法。awk中，流程控制语句，语法结构，与c语言类型。有了这些语句，其实很多shell程序都可以交给awk，而且性能是非常快的。下面是各个语句用法。 条件判断语句 if(表达式) 语句1 else 语句2 格式中语句1可以是多个语句，为了方便判断和阅读，最好将多个语句用{}括起来。awk分枝结构允许嵌套，其格式为： if(表达式) {语句1} else if(表达式) {语句2} else {语句3} eg： awk &#39;BEGIN{ test=100; if(test&amp;gt;90){ print &quot;very good&quot;; } else if(test&amp;gt;60){ print &quot;good&quot;; } else{ print &quot;no pass&quot;; } }&#39; very good 每条命令语句后面可以用;分号结尾。 循环语句 while语句 while(表达式) {语句} eg： awk &#39;BEGIN{ test=100; total=0; while(i&amp;lt;=test){ total+=i; i++; } print total; }&#39; 5050 for循环 for循环有两种格式： 格式1： for(变量 in 数组) {语句} eg： awk &#39;BEGIN{ for(k in ENVIRON){ print k&quot;=&quot;ENVIRON[k]; } }&#39; TERM=linux G_BROKEN_FILENAMES=1 SHLVL=1 pwd=/root/text ... logname=root HOME=/root SSH_CLIENT=192.168.1.21 53087 22 【注】ENVIRON是awk常量，是子典型数组。 格式2： for(变量;条件;表达式) {语句} eg： awk &#39;BEGIN{ total=0; for(i=0;i&amp;lt;=100;i++){ total+=i; } print total; }&#39; do循环 do {语句} while(条件) eg： awk &#39;BEGIN{ total=0; i=0; do {total+=i;i++;} while(i&amp;lt;=100) print total; }&#39; 5050 其他语句 break 当 break 语句用于 while 或 for 语句时，导致退出程序循环。 continue 当 continue 语句用于 while 或 for 语句时，使程序循环移动到下一个迭代。 next 能能够导致读入下一个输入行，并返回到脚本的顶部。这可以避免对当前输入行执行其他的操作过程。 exit 语句使主输入循环退出并将控制转移到END,如果END存在的话。如果没有定义END规则，或在END中应用exit语句，则终止脚本的执行。 数组应用 数组是awk的灵魂，处理文本中最不能少的就是它的数组处理。因为数组索引（下标）可以是数字和字符串在awk中数组叫做关联数组(associative arrays)。awk 中的数组不必提前声明，也不必声明大小。数组元素用0或空字符串来初始化，这根据上下文而定。 数组的定义 数字做数组索引（下标）： Array[1]=&quot;sun&quot; Array[2]=&quot;kai&quot; 字符串做数组索引（下标）： Array[&quot;first&quot;]=&quot;www&quot; Array[&quot;last&quot;]=&quot;name&quot; Array[&quot;birth&quot;]=&quot;1987&quot; 使用中print Array[1]会打印出sun；使用print Array[2]会打印出kai；使用print[&quot;birth&quot;]会得到1987。 读取数组的值 { for(item in array) {print array[item]}; } #输出的顺序是随机的 { for(i=1;i&lt;=len;i++) {print array[i]}; } #Len是数组的长度 数组相关函数 得到数组长度: awk &#39;BEGIN{info=&quot;it is a test&quot;;lens=split(info,tA,&quot; &quot;);print length(tA),lens;}&#39; 4 4 length返回字符串以及数组长度，split进行分割字符串为数组，也会返回分割得到数组长度。 awk &#39;BEGIN{info=&quot;it is a test&quot;;split(info,tA,&quot; &quot;);print asort(tA);}&#39; 4 asort对数组进行排序，返回数组长度。 输出数组内容（无序，有序输出）： awk ‘BEGIN{info=”it is a test”;split(info,tA,” “);for(k in tA){print k,tA[k];}}’4 test1 it2 is3 a for…in输出，因为数组是关联数组，默认是无序的。所以通过for…in得到是无序的数组。如果需要得到有序数组，需要通过下标获得。 awk &#39;BEGIN{info=&quot;it is a test&quot;;tlen=split(info,tA,&quot; &quot;);for(k=1;k&lt;=tlen;k++){print k,tA[k];}}&#39; 1 it 2 is 3 a 4 test 注意：数组下标是从1开始，与C数组不一样。 判断键值存在以及删除键值： #错误的判断方法： awk &#39;BEGIN{tB[&quot;a&quot;]=&quot;a1&quot;;tB[&quot;b&quot;]=&quot;b1&quot;;if(tB[&quot;c&quot;]!=&quot;1&quot;){print &quot;no found&quot;;};for(k in tB){print k,tB[k];}}&#39; no found a a1 b b1 c 以上出现奇怪问题，tB[“c”]没有定义，但是循环时候，发现已经存在该键值，它的值为空，这里需要注意，awk数组是关联数组，只要通过数组引用它的key，就会自动创建改序列。 #正确判断方法： awk &#39;BEGIN{tB[&quot;a&quot;]=&quot;a1&quot;;tB[&quot;b&quot;]=&quot;b1&quot;;if( &quot;c&quot; in tB){print &quot;ok&quot;;};for(k in tB){print k,tB[k];}}&#39; a a1 b b1 if(key in array)通过这种方法判断数组中是否包含key键值。 #删除键值： [chengmo@localhost ~]$ awk &#39;BEGIN{tB[&quot;a&quot;]=&quot;a1&quot;;tB[&quot;b&quot;]=&quot;b1&quot;;delete tB[&quot;a&quot;];for(k in tB){print k,tB[k];}}&#39; b b1 delete array[key]可以删除，对应数组key的，序列值。 二维、多维数组使用 awk的多维数组在本质上是一维数组，更确切一点，awk在存储上并不支持多维数组。awk提供了逻辑上模拟二维数组的访问方式。例如，array[2,4]=1这样的访问是允许的。awk使用一个特殊的字符串SUBSEP(�34)作为分割字段，在上面的例子中，关联数组array存储的键值实际上是2�344。 类似一维数组的成员测试，多维数组可以使用if ( (i,j) in array)这样的语法，但是下标必须放置在圆括号中。类似一维数组的循环访问，多维数组使用for ( item in array )这样的语法遍历数组。与一维数组不同的是，多维数组必须使用split()函数来访问单独的下标分量。 awk &#39;BEGIN{ for(i=1;i&amp;lt;=9;i++){ for(j=1;j&amp;lt;=9;j++){ tarr[i,j]=i*j; print i,&quot;*&quot;,j,&quot;=&quot;,tarr[i,j]; } } }&#39; 1 * 1 = 1 1 * 2 = 2 1 * 3 = 3 1 * 4 = 4 1 * 5 = 5 1 * 6 = 6 ... 9 * 6 = 54 9 * 7 = 63 9 * 8 = 72 9 * 9 = 81 可以通过array[k,k2]引用获得数组内容。 另一种方法： awk ‘BEGIN{ for(i=1;i&lt;=9;i++){ for(j=1;j&lt;=9;j++){ tarr[i,j]=ij; } } for(m in tarr){ split(m,tarr2,SUBSEP); print tarr2[1],”“,tarr2[2],”=”,tarr[m]; } }’ 内置函数 awk内置函数，主要分以下3种类似：算数函数、字符串函数、其它一般函数、时间函数 算术函数 格式 描述 atan2( y, x ) 返回 y/x 的反正切。 cos( x ) 返回 x 的余弦；x 是弧度。 sin( x ) 返回 x 的正弦；x 是弧度。 exp( x ) 返回 x 幂函数。 log( x ) 返回 x 的自然对数。 sqrt( x ) 返回 x 平方根。 int( x ) 返回 x 的截断至整数的值。 rand( ) 返回任意数字 n，其中 0 &lt;= n &lt; 1。 srand( [expr] ) 将 rand 函数的种子值设置为 Expr 参数的值，或如果省略 Expr 参数则使用某天的时间。返回先前的种子值。 举例说明： awk &#39;BEGIN{OFMT=&quot;%.3f&quot;;fs=sin(1);fe=exp(10);fl=log(10);fi=int(3.1415);print fs,fe,fl,fi;}&#39; 0.841 22026.466 2.303 3 OFMT 设置输出数据格式是保留3位小数。 获得随机数： awk &#39;BEGIN{srand();fr=int(100*rand());print fr;}&#39; 78 awk &#39;BEGIN{srand();fr=int(100*rand());print fr;}&#39; 31 awk &#39;BEGIN{srand();fr=int(100*rand());print fr;}&#39; 41 字符串函数 格式 描述 gsub( Ere, Repl, [ In ] ) 除了正则表达式所有具体值被替代这点，它和 sub 函数完全一样地执行。 sub( Ere, Repl, [ In ] ) 用 Repl 参数指定的字符串替换 In 参数指定的字符串中的由 Ere 参数指定的扩展正则表达式的第一个具体值。sub 函数返回替换的数量。出现在 Repl 参数指定的字符串中的 &amp;（和符号）由 In 参数指定的与 Ere 参数的指定的扩展正则表达式匹配的字符串替换。如果未指定 In 参数，缺省值是整个记录（$0 记录变量）。 index( String1, String2 ) 在由 String1 参数指定的字符串（其中有出现 String2 指定的参数）中，返回位置，从 1 开始编号。如果 String2 参数不在 String1 参数中出现，则返回 0（零）。 length [(String)] 返回 String 参数指定的字符串的长度（字符形式）。如果未给出 String 参数，则返回整个记录的长度（$0 记录变量）。 blength [(String)] 返回 String 参数指定的字符串的长度（以字节为单位）。如果未给出 String 参数，则返回整个记录的长度（$0 记录变量）。 substr( String, M, [ N ] ) 返回具有 N 参数指定的字符数量子串。子串从 String 参数指定的字符串取得，其字符以 M 参数指定的位置开始。M 参数指定为将 String 参数中的第一个字符作为编号 1。如果未指定 N 参数，则子串的长度将是 M 参数指定的位置到 String 参数的末尾 的长度。 match( String, Ere ) 在 String 参数指定的字符串（Ere 参数指定的扩展正则表达式出现在其中）中返回位置（字符形式），从 1 开始编号，或如果 Ere 参数不出现，则返回 0（零）。RSTART 特殊变量设置为返回值。RLENGTH 特殊变量设置为匹配的字符串的长度，或如果未找到任何匹配，则设置为 -1（负一）。 split( String, A, [Ere] ) 将 String 参数指定的参数分割为数组元素 A[1], A[2], . . ., A[n]，并返回 n 变量的值。此分隔可以通过 Ere 参数指定的扩展正则表达式进行，或用当前字段分隔符（FS 特殊变量）来进行（如果没有给出 Ere 参数）。除非上下文指明特定的元素还应具有一个数字值，否则 A 数组中的元素用字符串值来创建。 tolower( String ) 返回 String 参数指定的字符串，字符串中每个大写字符将更改为小写。大写和小写的映射由当前语言环境的 LC_CTYPE 范畴定义。 toupper( String ) 返回 String 参数指定的字符串，字符串中每个小写字符将更改为大写。大写和小写的映射由当前语言环境的 LC_CTYPE 范畴定义。 sprintf(Format, Expr, Expr, . . . ) 根据 Format 参数指定的 printf 子例程格式字符串来格式化 Expr 参数指定的表达式并返回最后生成的字符串。 注：Ere都可以是正则表达式。 gsub,sub使用 awk &#39;BEGIN{info=&quot;this is a test2010test!&quot;;gsub(/[0-9]+/,&quot;!&quot;,info);print info}&#39; this is a test!test! 在 info中查找满足正则表达式，/[0-9]+/用””替换，并且替换后的值，赋值给info 未给info值，默认是$0 查找字符串（index使用） awk &#39;BEGIN{info=&quot;this is a test2010test!&quot;;print index(info,&quot;test&quot;)?&quot;ok&quot;:&quot;no found&quot;;}&#39; ok 未找到，返回0 正则表达式匹配查找(match使用） awk &#39;BEGIN{info=&quot;this is a test2010test!&quot;;print match(info,/[0-9]+/)?&quot;ok&quot;:&quot;no found&quot;;}&#39; ok 截取字符串(substr使用） [wangsl@centos5 ~]$ awk &#39;BEGIN{info=&quot;this is a test2010test!&quot;;print substr(info,4,10);}&#39; s is a tes 从第 4个 字符开始，截取10个长度字符串 字符串分割（split使用） awk &#39;BEGIN{info=&quot;this is a test&quot;;split(info,tA,&quot; &quot;);print length(tA);for(k in tA){print k,tA[k];}}&#39; 4 4 test 1 this 2 is 3 a 分割info，动态创建数组tA，这里比较有意思，awk for …in循环，是一个无序的循环。 并不是从数组下标1…n ，因此使用时候需要注意。 格式化字符串输出（sprintf使用） 格式化字符串格式： 其中格式化字符串包括两部分内容：一部分是正常字符，这些字符将按原样输出; 另一部分是格式化规定字符，以”%”开始，后跟一个或几个规定字符,用来确定输出内容格式。 格式 描述 %d 十进制有符号整数 %u 十进制无符号整数 %f 浮点数 %s 字符串 %c 单个字符 %p 指针的值 %e 指数形式的浮点数 %x %X无符号以十六进制表示的整数 %o 无符号以八进制表示的整数 %g 自动选择合适的表示法 awk &#39;BEGIN{n1=124.113;n2=-1.224;n3=1.2345; printf(&quot;%.2f,%.2u,%.2g,%X,%on&quot;,n1,n2,n3,n1,n1);}&#39; 124.11,18446744073709551615,1.2,7C,174 一般函数 格式 描述 close( Expression ) 用同一个带字符串值的 Expression 参数来关闭由 print 或 printf 语句打开的或调用 getline 函数打开的文件或管道。如果文件或管道成功关闭，则返回 0；其它情况下返回非零值。如果打算写一个文件，并稍后在同一个程序中读取文件，则 close 语句是必需的。 system(command ) 执行 Command 参数指定的命令，并返回退出状态。等同于 system 子例程。 Expression&#124;getline [ Variable ] 从来自 Expression 参数指定的命令的输出中通过管道传送的流中读取一个输入记录，并将该记录的值指定给 Variable 参数指定的变量。如果当前未打开将 Expression 参数的值作为其命令名称的流，则创建流。创建的流等同于调用 popen 子例程，此时 Command 参数取 Expression 参数的值且 Mode 参数设置为一个是 r 的值。只要流保留打开且 Expression 参数求得同一个字符串，则对 getline 函数的每次后续调用读取另一个记录。如果未指定 Variable 参数，则 $0 记录变量和 NF 特殊变量设置为从流读取的记录。 getline [ Variable ] &lt; Expression 从 Expression 参数指定的文件读取输入的下一个记录，并将 Variable 参数指定的变量设置为该记录的值。只要流保留打开且 Expression 参数对同一个字符串求值，则对 getline 函数的每次后续调用读取另一个记录。如果未指定 Variable 参数，则 $0 记录变量和 NF 特殊变量设置为从流读取的记录。 getline [ Variable ] 将 Variable 参数指定的变量设置为从当前输入文件读取的下一个输入记录。如果未指定 Variable 参数，则 $0 记录变量设置为该记录的值，还将设置 NF、NR 和 FNR 特殊变量。 打开外部文件（close用法） awk &#39;BEGIN{while(&quot;cat /etc/passwd&quot;|getline){print $0;};close(&quot;/etc/passwd&quot;);}&#39; root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin 逐行读取外部文件(getline使用方法） awk &#39;BEGIN{while(getline &lt; &quot;/etc/passwd&quot;){print $0;};close(&quot;/etc/passwd&quot;);}&#39; root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin awk &#39;BEGIN{print &quot;Enter your name:&quot;;getline name;print name;}&#39; Enter your name: chengmo chengmo 调用外部应用程序(system使用方法） awk &#39;BEGIN{b=system(&quot;ls -al&quot;);print b;}&#39; total 42092 drwxr-xr-x 14 chengmo chengmo 4096 09-30 17:47 . drwxr-xr-x 95 root root 4096 10-08 14:01 .. b返回值，是执行结果。 时间函数 格式 描述 函数名 说明 mktime( YYYY MM dd HH MM ss[ DST]) 生成时间格式 strftime([format [, timestamp]]) 格式化时间输出，将时间戳转为时间字符串 具体格式，见下表. systime() 得到时间戳,返回从1970年1月1日开始到当前时间(不计闰年)的整秒数 建指定时间(mktime使用） awk &#39;BEGIN{tstamp=mktime(&quot;2001 01 01 12 12 12&quot;);print strftime(&quot;%c&quot;,tstamp);}&#39; 2001年01月01日 星期一 12时12分12秒 awk &#39;BEGIN{tstamp1=mktime(&quot;2001 01 01 12 12 12&quot;);tstamp2=mktime(&quot;2001 02 01 0 0 0&quot;);print tstamp2-tstamp1;}&#39; 2634468 求2个时间段中间时间差，介绍了strftime使用方法 awk &#39;BEGIN{tstamp1=mktime(&quot;2001 01 01 12 12 12&quot;);tstamp2=systime();print tstamp2-tstamp1;}&#39; 308201392 strftime日期和时间格式说明符 格式 描述 %a 星期几的缩写(Sun) %A 星期几的完整写法(Sunday) %b 月名的缩写(Oct) %B 月名的完整写法(October) %c 本地日期和时间 %d 十进制日期 %D 日期 08/20/99 %e 日期，如果只有一位会补上一个空格 %H 用十进制表示24小时格式的小时 %I 用十进制表示12小时格式的小时 %j 从1月1日起一年中的第几天 %m 十进制表示的月份 %M 十进制表示的分钟 %p 12小时表示法(AM/PM) %S 十进制表示的秒 %U 十进制表示的一年中的第几个星期(星期天作为一个星期的开始) %w 十进制表示的星期几(星期天是0) %W 十进制表示的一年中的第几个星期(星期一作为一个星期的开始) %x 重新设置本地日期(08/20/99) %X 重新设置本地时间(12：00：00) %y 两位数字表示的年(99) %Y 当前月份 %Z 时区(PDT) %% 百分号(%) sed 对数据行进行替换、删除、新增、选取等操作 a 新增，在新的下一行出现 c 取代，取代 n1,n2 之间的行 eg: sed &#39;1,2c Hi&#39; ab d 删除 i 插入，在新的上一行出现 eg: #指定时间段查看日志 sed -n &#39;/2016-10-21 14:18:29/,/2016-10-21 18:18:29/p&#39; catalina.out #替换当前目录下所有文件中的 /usr/local为/data/dshp sed -i &quot;s/\/usr\/local/\/data\/dshp/g&quot; . paste 合并文件，需确保合并的两文件行数相同 -d 指定不同于空格或tab键的域分隔符 -s 按行合并，单独一个文件为一行 rename 重命名文件 #批量重命名相同前缀的文件 #将当前目录下所有以central开头的文件中的central替换为distributed rename central distributed central* wc wc 计算数字 利用wc指令我们可以计算文件的Byte数、字数或是列数，若不指定文件名称，或是所给予的文件名为“-”，则wc指令会从标准输入设备读取数据 wc(选项)(参数) #(选项) -c或--bytes或——chars：只显示Bytes数； -l或——lines：只显示列数； -w或——words：只显示字数。 #(参数) 文件：需要统计的文件列表。 统计当前文件夹下文件的个数 ls -l |grep &quot;^-&quot;|wc -l 统计当前文件夹下目录的个数 ls -l |grep &quot;^d&quot;|wc -l 统计当前文件夹下文件的个数，包括子文件夹里的 ls -lR|grep &quot;^-&quot;|wc -l 统计文件夹下目录的个数，包括子文件夹里的 ls -lR|grep &quot;^d&quot;|wc -l ls -l #长列表输出当前文件夹下文件信息(注意这里的文件，不同于一般的文件，可能是目录、链接、设备文件等) grep &quot;^-&quot; #这里将长列表输出信息过滤一部分，只保留一般文件，如果只保留目录就是 ^d wc -l #统计当前目录下指定文件后缀的行数，既可以统计项目的代码量 find . -name &quot;*.java&quot; -or -name &quot;*.jsp&quot; -or -name &quot;*.xml&quot; -or -name &quot;*.c&quot; |xargs grep -v &quot;^$&quot;|wc -l #统计输出信息的行数，因为已经过滤得只剩一般文件了，所以统计结果就是一般文件信息的行数，又由于一行信息对应一个文件，所以也就是文件的个数 uniq uniq 去除文件中相邻的重复行 清空/新建文件，将内容重定向输入进去 &amp;&gt; 正确、错误都重定向过去 后面追加 file 该命令用于判断接在file命令后的文件的基本数据，因为在Linux下文件的类型并不是以后缀为分的，所以这个命令对我们来说就很有用了，它的用法非常简单，基本语法如下： [plain] view plain copy print? file filename #例如： file ./test mkdir 创建新目录 mkdir [选项] 目录… -p #递归创建目录，若父目录不存在则依次创建 eg: mkdir -p ~/temp/test -m #自定义创建目录的权限 eg:mkdir -m 777 temp -v #显示创建目录的详细信息 eg:mkdir -m 662 -pv ~/temp/test grep 用正则表达式搜索文本，并把匹配的行打印出来 grep ‘正则表达式’ 文件名 | -c 只输出匹配行的计数。 -I 不区分大小写(只适用于单字符)。 -l 只显示文件名 -v 显示不包含匹配文本的所有行。 -n 显示匹配行数据及其行号 eg: # 取出文件urls.txt中包含mysql的行，并把找到的关键字加上颜色 grep --color=auto &#39;mysql&#39; urls.txt # 把ls -l的输出中包含字母file（不区分大小写）的内容输出 ls -l | grep -i file # 查找当前目录下所有包含mysql的文件并逐行显示,文件路径+行号+匹配内容 grep -rn &quot;mysql&quot; ./* find 在文件树种查找文件，并作出相应的处理 find [PATH] [option] [action] 选项与参数： 与时间有关的选项：共有 -atime, -ctime 与 -mtime 和-amin,-cmin与-mmin，以 -mtime 说明 -mtime n ：n 为数字，意义为在 n 天之前的『一天之内』被更动过内容的档案； -mtime +n ：列出在 n 天之前(不含 n 天本身)被更动过内容的档案档名； -mtime -n ：列出在 n 天之内(含 n 天本身)被更动过内容的档案档名。 -newer file ：file 为一个存在的档案，列出比 file 还要新的档案档名 eg： find ./ -mtime 0 # 在当前目录下查找今天之内有改动的文件 与使用者或组名有关的参数： -uid n ：n 为数字，这个数字是用户的账号 ID，亦即 UID -gid n ：n 为数字，这个数字是组名的 ID，亦即 GID -user name ：name 为使用者账号名称！例如 dmtsai -group name：name 为组名，例如 users ； -nouser ：寻找档案的拥有者不存在 /etc/passwd 的人！ -nogroup ：寻找档案的拥有群组不存在于 /etc/group 的档案！ eg： find /home/jet -user jet # 在目录/home/jet中找出所有者为jet的文件 与档案权限及名称有关的参数： -name filename #搜寻文件名为 filename 的档案（可使用通配符） -size [+-]SIZE #搜寻比 SIZE 还要大(+)或小(-)的档案。这个 SIZE 的规格有： c: 代表 byte k: 代表 1024bytes。所以，要找比 50KB还要大的档案，就是『 -size +50k 』 -type TYPE #搜寻档案的类型为 TYPE 的，类型主要有： 一般正规档案 (f) 装置档案 (b, c) 目录 (d) 连结档 (l) socket (s) FIFO (p) -perm mode #搜寻档案权限『刚好等于』 mode的档案，这个mode为类似chmod的属性值 举例来说，-rwsr-xr-x 的属性为4755！ -perm -mode #搜寻档案权限『必须要全部囊括 mode 的权限』的档案 举例来说，我们要搜寻-rwxr--r-- 亦即 0744 的档案，使用-perm -0744，当一个档案的权限为 -rwsr-xr-x ，亦即 4755 时，也会被列出来，因为 -rwsr-xr-x 的属性已经囊括了 -rwxr--r-- 的属性了。 -perm +mode #搜寻档案权限『包含任一 mode 的权限』的档案 举例来说，我们搜寻-rwxr-xr-x ，亦即 -perm +755 时，但一个文件属性为 -rw-------也会被列出来，因为他有 -rw.... 的属性存在！ eg： find / -name passwd # 查找文件名为passwd的文件 find . -perm 0755 # 查找当前目录中文件权限的0755的文件 find . -size +12k # 查找当前目录中大于12KB的文件，注意c表示byte 额外可进行的动作： -exec command #command 为其他指令，-exec 后面可再接额外的指令来处理搜寻到的结果。 -print ：将结果打印到屏幕上，这个动作是预设动作！ eg: find / -perm +7000 -exec ls -l {} \; #额外指令以-exec开头，以\;结尾{}代替前面找到的内容 | xargs -i 默认的前面输出用{}代替 eg: # 将当前目录下所有以.log结尾的文件移动到文件夹logs中，logs文件夹需要先建立好，不然会生成一个logs空文件 find . -name &quot;*.log&quot; | xargs -i mv {} logs # 查找当前目录下所有log结尾的文件并删除 find . -name *.log | xargs rm dd 用指定大小的块拷贝一个文件，并在拷贝的同时进行指定的转换(convert and copy a file ) 语法：dd [选项] if =输入文件（或设备名称）。 of =输出文件（或设备名称）。 ibs = bytes 一次读取bytes字节，即读入缓冲区的字节数。 skip = blocks 跳过读入缓冲区开头的ibs*blocks块。 obs = bytes 一次写入bytes字节，即写入缓冲区的字节数。 bs = bytes 同时设置读/写缓冲区的字节数（等于设置ibs和obs）。 cbs = byte 一次转换bytes字节。 count=blocks 只拷贝输入的blocks块。 conv = ASCII 把EBCDIC码转换为ASCIl码。 conv = ebcdic 把ASCIl码转换为EBCDIC码。 conv = ibm 把ASCIl码转换为alternate EBCDIC码。 conv = block 把变动位转换成固定字符。 conv = ublock 把固定位转换成变动位。 conv = ucase 把字母由小写转换为大写。 conv = lcase 把字母由大写转换为小写。 conv = notrunc 不截短输出文件。 conv = swab 交换每一对输入字节。 conv = noerror 出错时不停止处理。 conv = sync 把每个输入记录的大小都调到ibs的大小（用NUL填充）。 例1：要把一张软盘的内容拷贝到另一张软盘上，利用/tmp作为临时存储区。把源盘插入驱动器中，输入下述命令： $ dd if =/dev/fd0 of = /tmp/tmpfile 拷贝完成后，将源盘从驱动器中取出，把目标盘插入，输入命令： $ dd if = /tmp/tmpfile of =/dev/fd0 软盘拷贝完成后，应该将临时文件删除： $ rm /tmp/tmpfile 例2：把net.i这个文件写入软盘中，并设定读/写缓冲区的数目。 （注意：软盘中的内容会被完全覆盖掉） $ dd if = net.i of = /dev/fd0 bs = 16384 例3：将文件sfile拷贝到文件 dfile中。 $ dd if=sfile of=dfile 例4：创建一个100M的空文件 $ dd if=/dev/zero of=hello.txt bs=100M count=1 # 创建一个大小为1k的空文件 $ dd if=/dev/zero of=./test.txt bs=1k count=1 $ ls -l total 4 -rw-rw-r--. 1 jet jet 1024 Jun 20 16:36 test.txt # 将access_log中错误信息丢弃 $ find / -name access_log 2&gt;/dev/null &gt;-&gt;&gt;-/dev/null-/dev/zero /dev/null: 它是空设备，也称为位桶（bit bucket），外号叫无底洞，任何写入它的输出都会被抛弃。如果不想让消息以标准输出显示或写入文件，那么可以将消息重定向到位桶。 /dev/zero: 是一个输入设备，该设备无穷尽地提供0，可以使用任何你需要的数目，用于向设备或文件写入字符串0，你可你用它来初始化文件。 &lt; ：由 &lt; 的右边读入参数档案； &gt; ：将原本由屏幕输出的正确数据输出到 &gt; 右边的 file ( 文件名称 ) 或 device ( 装置，如 printer )去； &gt;&gt; ：将原本由屏幕输出的正确数据输出到 &gt;&gt; 右边，与 &gt; 不同的是，该档案将不会被覆盖，而新的数据将以『增加的方式』增加到该档案的最后面； 2&gt; ：将原本应该由屏幕输出的错误数据输出到 2&gt; 的右边去。 说明 [jet @jet oschina_hexo_server]# ls -al &gt; test.txt # 将显示的结果输出到 test.txt 档案中，若该档案以存在则覆盖！ [jet @jet oschina_hexo_server]# ls -al &gt;&gt; test.txt # 将显示的结果追加到 test.txt 档案中，该档案为累加的，旧数据保留！ [jet @jet oschina_hexo_server]# ls -al 1&gt; test.txt 2&gt; test.err # 将显示的数据，正确的输出到 test.txt 错误的数据输出到 test.err [jet @jet oschina_hexo_server]# ls -al 1&gt; test.txt 2&gt;&amp;1 # 将显示的数据，不论正确或错误均输出到 test.txt 当中！ [jet @jet oschina_hexo_server]# ls -al 1&gt; test.txt 2&gt; /dev/null # 将显示的数据，正确的输出到 test.txt 错误的数据则予以丢弃！ 【注意】错误与正确档案输出到同一个档案中，则必须以上面的方法来写！ 不能写成其它格式！这个观念相当的重要，尤其是在 /etc/crontab 当中执行的时候，如果我们已经知道错误的讯息为何，又不想要让错误的讯息一直填满 root 的信箱，就必须以 2&gt; 搭配 /dev/null 这个垃圾桶黑洞装置，来将数据丢弃！这个相当的重要！ rm 删除文件 rm [选项] 文件 -r 【--recursive】删除文件夹即递归的删除目录下面文件以及子目录下文件。 -f 【--force】强制删除不提示，忽略不存在的文件。 -i 【--interactive】交互模式删除文件，删除文件前给出提示 -v 【-verbose】详细显示进行步骤 cd 切换工作目录 cd . #返回上层目录 cd .. #返回上层目录 cd 回车 #返回主目录同cd ~ cd / #根目录 cd ~/git/ #主目录下的git目录 cd - #回到之前的目录 ls 列出相关目录下的所有目录和文件 ls [选项] [目录名] -a 列出包括.a开头的隐藏文件的所有文件 -A 通-a，但不列出&quot;.&quot;和&quot;..&quot; -l 列出文件的详细信息 -c 根据ctime排序显示 -t 根据文件修改时间排序 ---color[=WHEN] 用色彩辨别文件类型 WHEN 可以是’never’、’always’或’auto’其中之一 白色：表示普通文件 蓝色：表示目录 绿色：表示可执行文件 红色：表示压缩文件 浅蓝色：链接文件 红色闪烁：表示链接的文件有问题 黄色：表示设备文件 灰色：表示其它文件 mv 移动或重命名文件 mv [选项] 源文件或目录 目录或多个源文件 -b 覆盖前做备份 -f 如存在不询问而强制覆盖 -i 如存在则询问是否覆盖 -u 较新才覆盖 -t 将多个源文件移动到统一目录下，目录参数在前，文件参数在后 eg: mv a /tmp/ 将文件a移动到 /tmp目录下 mv a b 将a命名为b mv /home/zenghao test1.txt test2.txt test3.txt cp 将源文件复制至目标文件，或将多个源文件复制至目标目录。 cp [选项] 源文件或目录 目录或多个源文件 -r -R #递归复制该目录及其子目录内容 -p #连同档案属性一起复制过去 -f #不询问而强制复制 -s #生成快捷方式 -a #将档案的所有特性都一起复制 eg: cp -a file1 file2 #连同文件的所有特性把文件file1复制成文件file2 cp file1 file2 file3 dir #把文件file1、file2、file3复制到目录dir中 touch 创建空文件或更新文件时间 touch [选项] 文件 -a #只修改存取时间 -m #值修改变动时间 -r #eg:touch -r a b ,使b的时间和a相同 -t #指定特定的时间 eg:touch -t 201211142234.50 log.log #-t time [[CC]YY]MMDDhhmm[.SS],C:年前两位 pwd 查看当前所在路径 rmdir 删除空目录 -v 显示执行过程 -p 若自父母删除后父目录为空则一并删除 rm 删除一个或多个文件或目录 rm [选项].. 文件 -f 忽略不存在的文件，不给出提示 -i 交互式删除 -r 将列出的目录及其子目录递归删除 -v 列出详细信息 echo 显示内容到屏幕 -n 输出后不换行 -e 遇到转义字符特殊处理 eg: echo &quot;hello\nworld&quot; 显示hello\nworld ehco -e &quot;hello\nworld&quot; 显示hello(换行了)world cat 一次显示整个文件或从键盘创建一个文件或将几个文件合并成一个文件 cat [选项] [文件].. -n 编号文件内容再输出 -E 在结束行提示$ tac cat的反向显示 more 按页查看文章内容，从前向后读取文件，因此在启动时就加载整个文件 +n 从第n行开始显示 -n 每次查看n行数据 +/String 搜寻String字符串位置，从其前两行开始查看 -c 清屏再显示 -p 换页时清屏 less 可前后移动地逐屏查看文章内容，在查看前不会加载整个文件 -m 显示类似于more命令的百分比 -N 显示行号 / 字符串：向下搜索“字符串”的功能 ? 字符串：向上搜索“字符串”的功能 n 重复前一个搜索（与 / 或 ? 有关） N 反向重复前一个搜索（与 / 或 ? 有关） b 向后翻一页 d 向后翻半页 nl 将输出内容自动加上行号 nl [选项]… [文件]… -b -b a 不论是否有空行，都列出行号（类似 cat -n) -b t 空行则不列行号（默认） -n 有ln rn rz三个参数，分别为再最左方显示，最右方显示不加0，最右方显示加0 head 显示档案开头，默认开头10行 head [参数]… [文件]… -v 显示文件名 -c number 显示前number个字符,若number为负数,则显示除最后number个字符的所有内容 -number/n (+)number 显示前number行内容， -n number 若number为负数，则显示除最后number行数据的所有内容 tail 显示文件结尾内容 tail [必要参数] [选择参数] [文件] -v #显示详细的处理信息 -q #不显示处理信息 -num/-n (-)num #显示最后num行内容 -n +num #从第num行开始显示后面的数据 -c #显示最后c个字符 -f #循环读取 # 实时查看日志，从文件最后50行开始 tail -fn 50 ExecuteConfig.log vi 编辑文件 :w filename #将文章以指定的文件名保存起来 :q #退出 :q! #强制退出 :wq #保存并退出 :set nu #显示行号 :set nonu #隐藏行号 /git #在文档中查找git 按n跳到下一个，shift+n上一个 yyp #复制光标所在行，并粘贴 h(左移一个字符←)、j(下一行↓)、k(上一行↑)、l(右移一个字符→) 命令行模式功能键 1. 插入模式 按「i」切换进入插入模式「insert mode」，按&quot;i&quot;进入插入模式后是从光标当前位置开始输入文件； 按「a」进入插入模式后，是从目前光标所在位置的下一个位置开始输入文字； 按「o」进入插入模式后，是插入新的一行，从行首开始输入文字。 2. 从插入模式切换为命令行模式 按「ESC」键。 3. 移动光标 vi可以直接用键盘上的光标来上下左右移动，但正规的vi是用小写英文字母「h」、「j」、「k」、「l」，分别控制光标左、下、上、右移一格。 按「ctrl」+「b」#屏幕往&quot;后&quot;移动一页。 按「ctrl」+「f」#屏幕往&quot;前&quot;移动一页。 按「ctrl」+「u」#屏幕往&quot;后&quot;移动半页。 按「ctrl」+「d」#屏幕往&quot;前&quot;移动半页。 按数字「0」#移到文章的开头。 按「G」#移动到文章的最后。 按「$」#移动到光标所在行的&quot;行尾&quot;。 按「^」#移动到光标所在行的&quot;行首&quot; 按「w」#光标跳到下个字的开头 按「e」#光标跳到下个字的字尾 按「b」#光标回到上个字的开头 按「#l」#光标移到该行的第#个位置，如：5l,56l。 4. 删除文字 「x」#每按一次，删除光标所在位置的&quot;后面&quot;一个字符。 「#x」#例如，「6x」表示删除光标所在位置的&quot;后面&quot;6个字符。 「X」#大写的X，每按一次，删除光标所在位置的&quot;前面&quot;一个字符。 「#X」#例如，「20X」表示删除光标所在位置的&quot;前面&quot;20个字符。 「dd」#删除光标所在行。 「#dd」#从光标所在行开始删除#行 5. 复制 「yw」#将光标所在之处到字尾的字符复制到缓冲区中。 「#yw」#复制#个字到缓冲区 「yy」#复制光标所在行到缓冲区。 「#yy」#例如，「6yy」表示拷贝从光标所在的该行&quot;往下数&quot;6行文字。 「p」#将缓冲区内的字符贴到光标所在位置。注意：所有与&quot;y&quot;有关的复制命令都必须与&quot;p&quot;配合才能完成复制与粘贴功能。 6. 替换 「r」#替换光标所在处的字符。 「R」#替换光标所到之处的字符，直到按下「ESC」键为止。 7. 恢复上一次操作 「u」#如果您误执行一个命令，可以马上按下「u」，回到上一个操作。按多次&quot;u&quot;可以执行多次回复。 8. 更改 「cw」#更改光标所在处的字到字尾处 「c#w」#例如，「c3w」表示更改3个字 9. 跳至指定的行 「ctrl」+「g」 #列出光标所在行的行号。 「#G」：例如，「15G」，表示移动光标至文章的第15行行首。 10.视图模式 「ctrl」+「v」#进入视图模式，可以移动方向键选中多行，按d键可以删除 11.清空文件 :.,$d 回车 #命令模式输入 .,$d 后回车 12.替换文本内容 #可以替换当前行的所有/usr/local为/data/dshp，命令模式输入s/old\new/g :s/\/usr\/local/\/data\/dshp/g 管道 将一个命令的标准输出作为另一个命令的标准输入。也就是把几个命令组合起来使用，后一个命令除以前一个命令的结果。 grep -r “close” /home/* | more 在home目录下所有文件中查找，包括close的文件，并分页输出。 xargs 管道实现的是将前面的stdout作为后面的stdin，但是有些命令不接受管道的传递方式，最常见的就是ls命令。有些时候命令希望管道传递的是参数，但是直接用管道有时无法传递到命令的参数位，这时候需要xargs，xargs实现的是将管道传输过来的stdin进行处理然后传递到命令的参数位上。也就是说xargs完成了两个行为：处理管道传输过来的stdin；将处理后的传递到正确的位置上。 -0 当sdtin含有特殊字元时候，将其当成一般字符，如/、空格等 例如：root@localhost:~/test#echo &quot;//&quot;|xargs echo root@localhost:~/test#echo &quot;//&quot;|xargs -0 echo / -a file 从文件中读入作为sdtin，（看例一） -e flag ，注意有的时候可能会是-E，flag必须是一个以空格分隔的标志，当xargs分析到含有flag这个标志的时候就停止。（例二） -p 当每次执行一个argument的时候询问一次用户。（例三） -n num 后面加次数，表示命令在执行的时候一次用的argument的个数，默认是用所有的。（例四） -t 表示先打印命令，然后再执行。（例五） -i 或者是-I，这得看Linux支持了，将xargs的每项名称，一般是一行一行赋值给{}，可以用{}代替。（例六） -r no-run-if-empty 当xargs的输入为空的时候则停止xargs，不用再去执行了。（例七） -s num 命令行的最好字符数，指的是xargs后面那个命令的最大命令行字符数。（例八） -L num Use at most max-lines nonblank input lines per command line.-s是含有空格的。 -l 同-L -d delim 分隔符，默认的xargs分隔符是回车，argument的分隔符是空格，这里修改的是xargs的分隔符（例九） -x exit的意思，主要是配合-s使用。 -P 修改最大的进程数，默认是1，为0时候为as many as it can ，这个例子我没有想到，应该平时都用不到的吧。 示例例一： root@localhost:~/test#cat test #!/bin/sh echo &quot;hello world/n&quot; root@localhost:~/test#xargs -a test echo #!/bin/sh echo hello world/n 例二： root@localhost:~/test#cat txt /bin tao shou kun root@localhost:~/test#cat txt|xargs -E &#39;shou&#39; echo /bin tao 例三： root@localhost:~/test#cat txt|xargs -p echo echo /bin tao shou kun ff ?...y /bin tao shou kun ff 例四： root@localhost:~/test#cat txt|xargs -n1 echo /bin tao shou kun root@localhost:~/test3#cat txt|xargs echo /bin tao shou kun 例五： root@localhost:~/test#cat txt|xargs -t echo echo /bin tao shou kun /bin tao shou kun 例六： $ ls | xargs -t -i mv {} {}.bak 例七： root@localhost:~/test#echo &quot;&quot;|xargs -t mv mv mv: missing file operand Try `mv --help&#39; for more information. root@localhost:~/test#echo &quot;&quot;|xargs -t -r mv root@localhost:~/test# （直接退出） 例八： root@localhost:~/test#cat test |xargs -i -x -s 14 echo &quot;{}&quot; exp1 exp5 file xargs: argument line too long linux-2 例九： root@localhost:~/test#cat txt |xargs -i -p echo {} echo /bin tao shou kun ?...y root@localhost:~/test#cat txt |xargs -i -p -d &quot; &quot; echo {} echo /bin ?...y echo tao ?.../bin y echo shou ?...tao 再如： root@localhost:~/test#cat test |xargs -i -p -d &quot; &quot; echo {} echo exp1 exp5 file linux-2 ngis_post tao test txt xen-3 ?...y root@localhost:~/test#cat test |xargs -i -p echo {} echo exp1 ?...y echo exp5 ?...exp1 y echo file ?...exp5 y diff 以逐行的方式，比较文本文件的异同处。指定要比较目录，则diff会比较目录中相同文件名的文件，但不会比较其中子目录。 diff [参数] [文件1或目录1] [文件2或目录2] -&lt;行数&gt; 指定要显示多少行的文本。此参数必须与-c或-u参数一并使用。 -a或--text diff预设只会逐行比较文本文件。 -b或--ignore-space-change 不检查空格字符的不同。 -B或--ignore-blank-lines 不检查空白行。 -c 显示全部内文，并标出不同之处。 -C&lt;行数&gt;或--context&lt;行数&gt; 与执行&quot;-c-&lt;行数&gt;&quot;指令相同。 -d或--minimal 使用不同的演算法，以较小的单位来做比较。 -D&lt;巨集名称&gt;或ifdef&lt;巨集名称&gt; 此参数的输出格式可用于前置处理器巨集。 -e或--ed 此参数的输出格式可用于ed的script文件。 -f或-forward-ed 输出的格式类似ed的script文件，但按照原来文件的顺序来显示不同处。 -H或--speed-large-files 比较大文件时，可加快速度。 -l&lt;字符或字符串&gt;或--ignore-matching-lines&lt;字符或字符串&gt; 若两个文件在某几行有所不同，而这几行同时都包含了选项中指定的字符或字符串，则不显示这两个文件的差异。 -i或--ignore-case 不检查大小写的不同。 -l或--paginate 将结果交由pr程序来分页。 -n或--rcs 将比较结果以RCS的格式来显示。 -N或--new-file 在比较目录时，若文件A仅出现在某个目录中，预设会显示： Only in目录：文件A若使用-N参数，则diff会将文件A与一个空白的文件比较。 -p 若比较的文件为C语言的程序码文件时，显示差异所在的函数名称。 -P或--unidirectional-new-file 与-N类似，但只有当第二个目录包含了一个第一个目录所没有的文件时，才会将这个文件与空白的文件做比较。 -q或--brief 仅显示有无差异，不显示详细的信息。 -r或--recursive 比较子目录中的文件。 -s或--report-identical-files 若没有发现任何差异，仍然显示信息。 -S&lt;文件&gt;或--starting-file&lt;文件&gt; 在比较目录时，从指定的文件开始比较。 -t或--expand-tabs 在输出时，将tab字符展开。 -T或--initial-tab 在每行前面加上tab字符以便对齐。 -u,-U&lt;列数&gt;或--unified=&lt;列数&gt; 以合并的方式来显示文件内容的不同。 -v或--version 显示版本信息。 -w或--ignore-all-space 忽略全部的空格字符。 -W&lt;宽度&gt;或--width&lt;宽度&gt; 在使用-y参数时，指定栏宽。 -x&lt;文件名或目录&gt;或--exclude&lt;文件名或目录&gt; 不比较选项中所指定的文件或目录。 -X&lt;文件&gt;或--exclude-from&lt;文件&gt; 您可以将文件或目录类型存成文本文件，然后在=&lt;文件&gt;中指定此文本文件。 -y或--side-by-side 以并列的方式显示文件的异同之处。 --help 显示帮助。 --left-column 在使用-y参数时，若两个文件某一行内容相同，则仅在左侧的栏位显示该行内容。 --suppress-common-lines 在使用-y参数时，仅显示不同之处 示例： 比较两个文件 [root@localhost test3]# diff log2014.log log2013.log 3c3 &lt; 2014-03 --- &gt; 2013-03 8c8 &lt; 2013-07 --- &gt; 2013-08 11,12d10 &lt; 2013-11 &lt; 2013-12 【注】 上面的”3c3”和”8c8”表示log2014.log和log20143log文件在3行和第8行内容有所不同；”11,12d10”表示第一个文件比第二个文件多了第11和12行。 并排格式输出 [root@localhost test3]# diff log2014.log log2013.log -y -W 50 2013-01 2013-01 2013-02 2013-02 2014-03 | 2013-03 2013-04 2013-04 2013-05 2013-05 2013-06 2013-06 2013-07 2013-07 2013-07 | 2013-08 2013-09 2013-09 2013-10 2013-10 2013-11 &lt; 2013-12 &lt; [root@localhost test3]# diff log2013.log log2014.log -y -W 50 2013-01 2013-01 2013-02 2013-02 2013-03 | 2014-03 2013-04 2013-04 2013-05 2013-05 2013-06 2013-06 2013-07 2013-07 2013-08 | 2013-07 2013-09 2013-09 2013-10 2013-10 &gt; 2013-11 &gt; 2013-12 【注】 “|”表示前后2个文件内容有不同 “&lt;”表示后面文件比前面文件少了1行内容 “&gt;”表示后面文件比前面文件多了1行内容 ln 某一个文件在另外一个位置建立一个同步的链接，通常给/usr/bin/下建立软连接，相当于给某个应用程序配置环境变量一样，可以不带路径直接运行命令 ln [参数] [源文件或目录] [目标文件或目录] -s 建立软连接 -v 显示详细的处理过程 which 查看可执行文件的位置，在PATH变量指定的路径中查看系统命令是否存在及其位置 which 可执行文件名称 whereis 定位可执行文件、源代码文件、帮助文件在文件系统中的位置 whereis [-bmsu] [BMS 目录名 -f ] 文件名 -b 定位可执行文件。 -m 定位帮助文件。 -s 定位源代码文件。 -u 搜索默认路径下除可执行文件、源代码文件、帮助文件以外的其它文件。 -B 指定搜索可执行文件的路径。 -M 指定搜索帮助文件的路径。 -S 指定搜索源代码文件的路径。 locate 通过搜寻数据库快速搜寻档案 -r 使用正规运算式做寻找的条件 系统管理相关命令ps 列出当前进程的快照 a 显示所有的进程 -a 显示同一终端下的所有程序 e 显示环境变量 f 显示进程间的关系 -H 显示树状结构 r 显示当前终端的程序 T 显示当前终端的所有程序 -au 显示更详细的信息 -aux 显示所有包含其他使用者的行程 -u 指定用户的所有进程 eg: ps aux # 查看系统所有的进程数据 ps ax # 查看不与terminal有关的所有进程 ps -lA # 查看系统所有的进程数据 ps axjf # 查看连同一部分进程树状态 ps aux | grep tomcat ps -ef | grep tomcat df 显示指定磁盘文件的可用空间,如果没有文件名被指定，则所有当前被挂载的文件系统的可用空间将被显示 df [选项] [文件] -a 显示全部文件系统 -h 文件大小友好显示，即会显示单位 -l 只显示本地文件系统 -i 显示inode信息 -T 显示文件系统类型 du 显示每个文件和目录的磁盘使用空间 du [选项] [文件] -h 方便阅读的方式，会带单位 -s 只显示总和的大小 eg: #按照文件/文件夹从大到小降序排列，方便查找大文件 du -sh * | sort -nr | head top 显示当前系统正在执行的进程的相关信息，包括进程ID、内存占用率、CPU占用率等 top [参数] free 显示Linux系统中空闲的、已用的物理内存及swap内存,及被内核使用的buffer free [参数] quota 显示用户或者工作组的磁盘配额信息。输出信息包括磁盘使用和配额限制 quota(选项)(参数) -g：列出群组的磁盘空间限制； -q：简明列表，只列出超过限制的部分； -u：列出用户的磁盘空间限制； -v：显示该用户或群组，在所有挂入系统的存储设备的空间限制； -V：显示版本信息。 我们可以限制某一群组所能使用的最大磁盘配额，而且可以再限制某一使用者的最大磁盘配额 ，好比做一个收费的应用，vip可以得到空间更大一些。另外，以 Link 的方式，来使邮件可以作为限制的配额（更改/var/spool/mail 这个路径），不2，需要重新再规划一个硬盘！直接使用 Link 的方式指向 /home （或者其它已经做好的 quota 磁盘）就可以！这通常是用在原本规划不好，但是却又不想要更动原有主机架构的情况中！ 要求：Linux 主机里面主要针对 quser1 及 quser2 两个使用者来进行磁盘配额， 且这两个使用者都是挂在 qgroup 组里面的。每个使用者总共有 50MB 的磁盘空间 (不考虑 inode) 限制！并且 soft limit 为 45 MB；而宽限时间设定为 1 天， 但是在一天之内必须要将多余的文件删除掉，否则将无法使用剩下的空间 ；gquota 这个组考虑最大限额，所以设定为 90 MB！（注意，这样设置的好处是富有弹性，好比现在的邮件服务，那么多用户，承诺给用户每人最大空间为数GB，然而人们不可能每人都会使用那么大的空间，所以邮件服务的总空间，实际上肯定不是注册客户数乘以数GB，否则这样得多大啊。） [root@jet ~]# groupadd qgroup [root@jet ~]# useradd -m -g qgroup quser1 [root@jet ~]# useradd -m -g qgroup quser2 [root@jet ~]# passwd quser1 [root@jet ~]# passwd quser2 [root@jet ~]# df #用/disk2测试 Filesystem 1K-blocks Used Available Use% Mounted on /dev/hda1 5952252 3193292 2451720 57% / /dev/hdb1 28267608 77904 26730604 1% /disk2 /dev/hda5 9492644 227252 8775412 3% /disk1 [root@jet ~]# vi /etc/fstab LABEL=/ / ext3 defaults 1 1 LABEL=/disk1 /disk1 ext3 defaults 1 2 LABEL=/disk2 /disk2 ext3 defaults,usrquota,grpquota 1 2 /dev/hda3 swap swap defaults 0 0 注意多了usrquota,grpquota，在defaults,usrquota,grpquota之间都没有空格，务必正确书写。这样就算加入了 quota 的磁盘格式了！不过，由于真正的 quota 在读取的时候是读取/etc/mtab这个文件的，而该文件需要重新开机之后才能够以/etc/fstab 的新数据进行改写！所以这个时候可以选择：重新开机 (reboot)。 重新remount filesystem来驱动设定值。 [root@jet ~]# umount /dev/hdb1 [root@jet ~]# mount -a [root@jet ~]# grep &#39;/disk2&#39; /etc/mtab /dev/hdb1 /disk2 ext3 rw,usrquota,grpquota 0 0 事实上，也可以利用 mount 的 remount 功能。 [root@jet ~]# mount -o remount /disk2 这样就已经成功的将 filesystem 的 quota 功能加入。 扫瞄磁盘的使用者使用状况，并产生重要的 aquota.group 与 aquota.user： [root@jet ~]# quotacheck -avug quotacheck: Scanning /dev/hdb1 [/disk2] done quotacheck: Checked 3 directories and 4 files [root@localhost ~]# ll /disk2 -rw------- 1 root root 6144 Sep 6 11:44 aquota.group -rw------- 1 root root 6144 Sep 6 11:44 aquota.user 使用 quotacheck 就可以轻易的将所需要的数据给他输出了！但奇怪的是，在某些 Linux 版本中，不能够以 aquota.user(group) 来启动quota ，可能是因为旧版 quota 的关系， 所以就另外做了一个 link 文件按来欺骗 quota，这个动作非必要。（主要是学习这个思维很重要） [root@localhost ~]# cd /disk2 [root@localhost ~]# ln -s aquota.user quota.user [root@localhost ~]# ln -s aquota.group quota.group 启动 quota 的限额： [root@localhost ~]# quotaon -avug /dev/hdb1 [/disk2]: group quotas turned on /dev/hdb1 [/disk2]: user quotas turned on ===&gt; 看到turned on，才是真的成功！ 编辑使用者的可使用空间： [root@localhost ~]# edquota -u quser1 Disk quotas for user quser1 (uid 502): Filesystem blocks soft hard inodes soft hard /dev/hdb1 0 45000 50000 0 0 0 [root@localhost ~]# edquota -p quser1 quser2 ===&gt; 直接复制给quser2 接下来要来设定宽限时间，还是使用 edquota [root@localhost ~]# edquota -t Grace period before enforcing soft limits for users: time units may be: days, hours, minutes, or seconds Filesystem Block grace period Inode grace period /dev/hdb1 1days 7days 使用quota -v来查询： [root@localhost ~]# quota -vu quser1 quser2 Disk quotas for user quser1 (uid 502): Filesystem blocks quota limit grace files quota limit grace /dev/hdb1 0 45000 50000 0 0 0 Disk quotas for user quser2 (uid 503): Filesystem blocks quota limit grace files quota limit grace /dev/hdb1 0 45000 50000 0 0 0 注意，由于使用者尚未超过45 MB，所以 grace ( 宽限时间 ) 就不会出现。 编辑群组可使用的空间： [root@localhost ~]# edquota -g qgroup Disk quotas for group qgroup (gid 502): Filesystem blocks soft hard inodes soft hard /dev/hdb1 0 80000 90000 0 0 0 [root@localhost ~]# quota -vg qgroup Disk quotas for group qgroup (gid 502): Filesystem blocks quota limit grace files quota limit grace /dev/hdb1 0 80000 90000 0 0 0 kill 用于向某个工作（%jobnumber）或者是某个PID（数字）传送一个信号，它通常与ps和jobs命令一起使用 kill [参数] [进程号] 1：SIGHUP，启动被终止的进程 2：SIGINT，相当于输入ctrl+c，中断一个程序的进行 9：SIGKILL，强制中断一个进程的进行 15：SIGTERM，以正常的结束进程方式来终止进程 17：SIGSTOP，相当于输入ctrl+z，暂停一个进程的进行 eg: kill -9 19785 killall 杀死同一进程组内的所有进程。其允许指定要终止的进程的名称，而非PID -i ：交互式的意思，若需要删除时，会询问用户 -e ：表示后面接的command name要一致，但command name不能超过15个字符 -I ：命令名称忽略大小写 eg: killall -SIGHUP syslogd # 重新启动syslogd useradd 创建的新的系统用户 帐号建好之后，再用passwd设定帐号的密码．而可用userdel删除帐号。使用useradd指令所建立的帐号，实际上是保存在/etc/passwd文本文件中。 在Slackware中，adduser指令是个script程序，利用交谈的方式取得输入的用户帐号资料，然后再交由真正建立帐号的useradd命令建立新用户，如此可方便管理员建立用户帐号。在Red Hat Linux中，adduser命令则是useradd命令的符号连接，两者实际上是同一个指令 useradd(选项)(参数) -c&lt;备注&gt;：加上备注文字。备注文字会保存在passwd的备注栏位中； -d&lt;登入目录&gt;：指定用户登入时的启始目录； -D：变更预设值； -e&lt;有效期限&gt;：指定帐号的有效期限； -f&lt;缓冲天数&gt;：指定在密码过期后多少天即关闭该帐号； -g&lt;群组&gt;：指定用户所属的群组； -G&lt;群组&gt;：指定用户所属的附加群组； -m：自动建立用户的登入目录； -M：不要自动建立用户的登入目录； -n：取消建立以用户名称为名的群组； -r：建立系统帐号； -s：指定用户登入后所使用的shell； -u：指定用户id。 新建用户加入组： useradd –g sales jack –G company,employees //-g：加入主要组、-G：加入次要组 建立一个新用户账户，并设置ID： useradd caojh -u 544 需要说明的是，设定ID值时尽量要大于500，以免冲突。因为Linux安装后会建立一些特殊用户，一般0到499之间的值留给bin、mail这样的系统账号 groupadd 创建一个新的工作组，新工作组的信息将被添加到系统文件中 groupadd(选项)(参数) -g：指定新建工作组的id； -r：创建系统工作组，系统工作组的组ID小于500； -K：覆盖配置文件“/ect/login.defs”； -o：允许添加组ID号不唯一的工作组。 实例 建立一个新组，并设置组ID加入系统： groupadd -g 344 linuxde 此时在/etc/passwd文件中产生一个组ID（GID）是344的项目 groupdel 删除指定的工作组 要修改的系统文件包括/ect/group和/ect/gshadow。若该群组中仍包括某些用户，则必须先删除这些用户后，方能删除群组 groupdel(参数) eg: groupadd damon //创建damon工作组 groupdel damon //删除这个工作组 crontab 提交和管理用户的需要周期性执行的任务 与windows下的计划任务类似，当安装完成操作系统后，默认会安装此服务工具，并且会自动启动crond进程，crond进程每分钟会定期检查是否有要执行的任务，如果有要执行的任务，则自动执行该任务。 crontab(选项)(参数) -e：编辑该用户的计时器设置； -l：列出该用户的计时器设置； -r：删除该用户的计时器设置； -u&lt;用户名称&gt;：指定要设定计时器的用户名称。 Linux下的任务调度分为两类：系统任务调度和用户任务调度。 系统任务调度：系统周期性所要执行的工作，比如写缓存数据到硬盘、日志清理等。在/etc目录下有一个crontab文件，这个就是系统任务调度的配置文件。 /etc/crontab文件包括下面几行： SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=&quot;&quot;HOME=/ # run-parts 51 * * * * root run-parts /etc/cron.hourly 24 7 * * * root run-parts /etc/cron.daily 22 4 * * 0 root run-parts /etc/cron.weekly 42 4 1 * * root run-parts /etc/cron.monthly 【注】 前四行是用来配置crond任务运行的环境变量，第一行SHELL变量指定了系统要使用哪个shell，这里是bash，第二行PATH变量指定了系统执行命令的路径，第三行MAILTO变量指定了crond的任务执行信息将通过电子邮件发送给root用户，如果MAILTO变量的值为空，则表示不发送任务执行信息给用户，第四行的HOME变量指定了在执行命令或者脚本时使用的主目录。 用户任务调度：用户定期要执行的工作，比如用户数据备份、定时邮件提醒等。用户可以使用 crontab 工具来定制自己的计划任务。所有用户定义的crontab文件都被保存在/var/spool/cron目录中。其文件名与用户名一致，使用者权限文件如下： /etc/cron.deny 该文件中所列用户不允许使用crontab命令 /etc/cron.allow 该文件中所列用户允许使用crontab命令 /var/spool/cron/ 所有用户crontab文件存放的目录,以用户名命名 crontab文件的含义：用户所建立的crontab文件中，每一行都代表一项任务，每行的每个字段代表一项设置，它的格式共分为六个字段，前五段是时间设定段，第六段是要执行的命令段，格式如下： minute hour day month week command 顺序：分 时 日 月 周 minute： 表示分钟，可以是从0到59之间的任何整数。 hour：表示小时，可以是从0到23之间的任何整数。 day：表示日期，可以是从1到31之间的任何整数。 month：表示月份，可以是从1到12之间的任何整数。 week：表示星期几，可以是从0到7之间的任何整数，这里的0或7代表星期日。 command：要执行的命令，可以是系统命令，也可以是自己编写的脚本文件。 在以上各个字段中，还可以使用以下特殊字符： 星号（*）：代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。 逗号（,）：可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9” 中杠（-）：可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6” 正 斜线（/）：可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如*/10，如果用在minute字段，表示每十分钟执行一次。 service crond start #启动服务 service crond stop #关闭服务 service crond restart #重启服务 service crond reload #重新载入配置 service crond status #查看crontab服务状态 ntsysv #查看crontab服务是否已设置为开机启动 chkconfig –level 35 crond on #开机启动 eg: * * * * * command #每1分钟执行一次command 3,15 * * * * command #每小时的第3和第15分钟执行 3,15 8-11 * * * command #在上午8点到11点的第3和第15分钟执行 3,15 8-11 */2 * * command #每隔两天的上午8点到11点的第3和第15分钟执行 3,15 8-11 * * 1 command #每个星期一的上午8点到11点的第3和第15分钟执行 30 21 * * * /etc/init.d/smb restart #每晚的21:30重启smb 45 4 1,10,22 * * /etc/init.d/smb restart #每月1、10、22日的4 : 45重启smb 10 1 * * 6,0 /etc/init.d/smb restart #每周六、周日的1:10重启smb 0,30 18-23 * * * /etc/init.d/smb restart #每天18 : 00至23 : 00之间每隔30分钟重启smb 0 23 * * 6 /etc/init.d/smb restart #每星期六的晚上11:00 pm重启smb * */1 * * * /etc/init.d/smb restart #每一小时重启smb * 23-7/1 * * * /etc/init.d/smb restart #晚上11点到早上7点之间，每隔一小时重启smb 0 11 4 * mon-wed /etc/init.d/smb restart #每月的4号与每周一到周三的11点重启smb 0 4 1 jan * /etc/init.d/smb restart #一月一号的4点重启smb 01 * * * * root run-parts /etc/cron.hourly #每小时执行/etc/cron.hourly目录内的脚本 网络操作命令ifconfig 配置和显示Linux内核中网络接口的网络参数 用ifconfig命令配置的网卡信息，在网卡重启后机器重启后，配置就不存在。要想将上述的配置信息永远的存的电脑里，那就要修改网卡的配置文件了。 ifconfig(参数) add&lt;地址&gt;：设置网络设备IPv6的ip地址； del&amp;lt;地址&amp;gt;：删除网络设备IPv6的IP地址； down：关闭指定的网络设备； &amp;lt;hw&amp;lt;网络设备类型&amp;gt;&amp;lt;硬件地址&amp;gt;：设置网络设备的类型与硬件地址； io_addr&amp;lt;I/O地址&amp;gt;：设置网络设备的I/O地址； irq&amp;lt;IRQ地址&amp;gt;：设置网络设备的IRQ； media&amp;lt;网络媒介类型&amp;gt;：设置网络设备的媒介类型； mem_start&amp;lt;内存地址&amp;gt;：设置网络设备在主内存所占用的起始地址； metric&amp;lt;数目&amp;gt;：指定在计算数据包的转送次数时，所要加上的数目； mtu&amp;lt;字节&amp;gt;：设置网络设备的MTU； netmask&amp;lt;子网掩码&amp;gt;：设置网络设备的子网掩码； tunnel&amp;lt;地址&amp;gt;：建立IPv4与IPv6之间的隧道通信地址； up：启动指定的网络设备； -broadcast&amp;lt;地址&amp;gt;：将要送往指定地址的数据包当成广播数据包来处理； -pointopoint&amp;lt;地址&amp;gt;：与指定地址的网络设备建立直接连线，此模式具有保密功能； -promisc：关闭或启动指定网络设备的promiscuous模式； IP地址：指定网络设备的IP地址； 网络设备：指定网络设备的名称。 显示网络设备信息（激活状态的）： [root@jet ~]# ifconfig eth0 Link encap:Ethernet HWaddr 00:16:3E:00:1E:51 inet addr:10.160.7.81 Bcast:10.160.15.255 Mask:255.255.240.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:61430830 errors:0 dropped:0 overruns:0 frame:0 TX packets:88534 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:3607197869 (3.3 GiB) TX bytes:6115042 (5.8 MiB) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:56103 errors:0 dropped:0 overruns:0 frame:0 TX packets:56103 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:5079451 (4.8 MiB) TX bytes:5079451 (4.8 MiB) 【注】eth0表示第一块网卡，其中HWaddr表示网卡的物理地址，可以看到目前这个网卡的物理地址(MAC地址）是00:16:3E:00:1E:51。 inet addr**用来表示网卡的IP地址，此网卡的IP地址是10.160.7.81，广播地址Bcast:10.160.15.255，掩码地址Mask:255.255.240.0。 lo是表示主机的回坏地址，这个一般是用来测试一个网络程序，但又不想让局域网或外网的用户能够查看，只能在此台主机上运行和查看所用的网络接口。比如把 httpd服务器的指定到回坏地址，在浏览器输入127.0.0.1就能看到你所架WEB网站了。但只是您能看得到，局域网的其它主机或用户无从知道。 第一行：连接类型：Ethernet（以太网）HWaddr（硬件mac地址）。第二行：网卡的IP地址、子网、掩码。第三行：UP（代表网卡开启状态）RUNNING（代表网卡的网线被接上）MULTICAST（支持组播）MTU:1500（最大传输单元）：1500字节。第四、五行：接收、发送数据包情况统计。第七行：接收、发送数据字节数统计信息。 启动关闭指定网卡： ifconfig eth0 up ifconfig eth0 down ifconfig eth0 up为启动网卡eth0，ifconfig eth0 down为关闭网卡eth0。ssh登陆linux服务器操作要小心，关闭了就不能开启了，除非你有多网卡。 为网卡配置和删除IPv6地址： ifconfig eth0 add 33ffe:3240:800:1005::2/64 #为网卡eth0配置IPv6地址 ifconfig eth0 del 33ffe:3240:800:1005::2/64 #为网卡eth0删除IPv6地址 用ifconfig修改MAC地址： ifconfig eth0 hw ether 00:AA:BB:CC:dd:EE 配置IP地址： [root@localhost ~]# ifconfig eth0 192.168.2.10 [root@localhost ~]# ifconfig eth0 192.168.2.10 netmask 255.255.255.0 [root@localhost ~]# ifconfig eth0 192.168.2.10 netmask 255.255.255.0 broadcast 192.168.2.255 启用和关闭arp协议： ifconfig eth0 arp #开启网卡eth0 的arp协议 ifconfig eth0 -arp #关闭网卡eth0 的arp协议 设置最大传输单元： ifconfig eth0 mtu 1500 #设置能通过的最大数据包大小为 1500 bytes netstat 打印Linux中网络系统的状态信息，可让你得知整个Linux系统的网络情况 netstat(选项) -a或--all：显示所有连线中的Socket； -A&amp;lt;网络类型&amp;gt;或--&amp;lt;网络类型&amp;gt;：列出该网络类型连线中的相关地址； -c或--continuous：持续列出网络状态； -C或--cache：显示路由器配置的快取信息； -e或--extend：显示网络其他相关信息； -F或--fib：显示FIB； -g或--groups：显示多重广播功能群组组员名单； -h或--help：在线帮助； -i或--interfaces：显示网络界面信息表单； -l或--listening：显示监控中的服务器的Socket； -M或--masquerade：显示伪装的网络连线； -n或--numeric：直接使用ip地址，而不通过域名服务器； -N或--netlink或--symbolic：显示网络硬件外围设备的符号连接名称； -o或--timers：显示计时器； -p或--programs：显示正在使用Socket的程序识别码和程序名称； -r或--route：显示Routing Table； -s或--statistice：显示网络工作信息统计表； -t或--tcp：显示TCP传输协议的连线状况； -u或--udp：显示UDP传输协议的连线状况； -v或--verbose：显示指令执行过程； -V或--version：显示版本信息； -w或--raw：显示RAW传输协议的连线状况； -x或--unix：此参数的效果和指定&quot;-A unix&quot;参数相同； --ip或--inet：此参数的效果和指定&quot;-A inet&quot;参数相同。 eg: netstat -a #列出所有端口 netstat -at #列出所有tcp端口 netstat -au #列出所有udp端口 netstat -l #只显示监听端口 netstat -lt #只列出所有监听 tcp 端口 netstat -lu #只列出所有监听 udp 端口 netstat -lx #只列出所有监听 UNIX 端口 netstat -s #显示所有端口的统计信息 netstat -st #显示TCP端口的统计信息 netstat -su #显示UDP端口的统计信息 netstat -pt #在netstat输出中显示 PID 和进程名称 netstat -p可以与其它开关一起使用，就可以添加“PID/进程名称”到netstat输出中，这样debugging的时候可以很方便的发现特定端口运行的程序。 在netstat输出中不显示主机，端口和用户名(host, port or user) 当你不想让主机，端口和用户名显示，使用netstat -n。将会使用数字代替那些名称。同样可以加速输出，因为不用进行比对查询。 netstat -an 如果只是不想让这三个名称中的一个被显示，使用以下命令: netsat -a --numeric-ports netsat -a --numeric-hosts netsat -a --numeric-users 持续输出netstat信息 netstat -c #每隔一秒输出网络信息 显示系统不支持的地址族(Address Families) netstat --verbose 在输出的末尾，会有如下的信息： netstat: no support for `AF IPX&#39; on this system. netstat: no support for `AF AX25&#39; on this system. netstat: no support for `AF X25&#39; on this system. netstat: no support for `AF NETROM&#39; on this system. 显示核心路由信息 netstat -r 使用netstat -rn显示数字格式，不查询主机名称。 找出程序运行的端口 并不是所有的进程都能找到，没有权限的会不显示，使用 root 权限查看所有的信息。 netstat -ap | grep ssh 找出运行在指定端口的进程： netstat -an | grep &#39;:80&#39; 显示网络接口列表 netstat -i 显示详细信息，像是ifconfig使用 netstat -ie。 IP和TCP分析 查看连接某服务端口最多的的IP地址： netstat -ntu | grep :80 | awk &#39;{print $5}&#39; | cut -d: -f1 | awk &#39;{++ip[$1]} END {for(i in ip) print ip[i],&quot;\t&quot;,i}&#39; | sort -nr TCP各种状态列表： netstat -nt | grep -e 127.0.0.1 -e 0.0.0.0 -e ::: -v | awk &#39;/^tcp/ {++state[$NF]} END {for(i in state) print i,&quot;\t&quot;,state[i]}&#39; 查看phpcgi进程数，如果接近预设值，说明不够用，需要增加： netstat -anpo | grep &quot;php-cgi&quot; | wc -l telnet 登录远程主机，对远程主机进行管理 telnet因为采用明文传送报文，安全性不好，很多Linux服务器都不开放telnet服务，而改用更安全的ssh方式了。但仍然有很多别的系统可能采用了telnet方式来提供远程登录，因此弄清楚telnet客户端的使用方式仍是很有必要的。 telnet(选项)(参数) -8：允许使用8位字符资料，包括输入与输出； -a：尝试自动登入远端系统； -b&lt;主机别名&gt;：使用别名指定远端主机名称； -c：不读取用户专属目录里的.telnetrc文件； -d：启动排错模式； -e&lt;脱离字符&gt;：设置脱离字符； -E：滤除脱离字符； -f：此参数的效果和指定&quot;-F&quot;参数相同； -F：使用Kerberos V5认证时，加上此参数可把本地主机的认证数据上传到远端主机； -k&lt;域名&gt;：使用Kerberos认证时，加上此参数让远端主机采用指定的领域名，而非该主机的域名； -K：不自动登入远端主机； -l&lt;用户名称&gt;：指定要登入远端主机的用户名称； -L：允许输出8位字符资料； -n&lt;记录文件&gt;：指定文件记录相关信息； -r：使用类似rlogin指令的用户界面； -S&lt;服务类型&gt;：设置telnet连线所需的ip TOS信息； -x：假设主机有支持数据加密的功能，就使用它； -X&lt;认证形态&gt;：关闭指定的认证形态。 eg: [root@jet oschina_hexo_server]# telnet 124.251.54.61 5001 Trying 124.251.54.61... Connected to 124.251.54.61. Escape character is &#39;^]&#39;. SSH-2.0-OpenSSH_6.7 ping 测试主机之间网络的连通性 执行ping指令会使用ICMP传输协议，发出要求回应的信息，若远端主机的网络功能没有问题，就会回应该信息，因而得知该主机运作正常。 ping(选项)(参数) -d：使用Socket的SO_DEBUG功能； -c&lt;完成次数&gt;：设置完成要求回应的次数； -f：极限检测； -i&lt;间隔秒数&gt;：指定收发信息的间隔时间； -I&lt;网络界面&gt;：使用指定的网络界面送出数据包； -l&lt;前置载入&gt;：设置在送出要求信息之前，先行发出的数据包； -n：只输出数值； -p&lt;范本样式&gt;：设置填满数据包的范本样式； -q：不显示指令执行过程，开头和结尾的相关信息除外； -r：忽略普通的Routing Table，直接将数据包送到远端主机上； -R：记录路由过程； -s&lt;数据包大小&gt;：设置数据包的大小； -t&lt;存活数值&gt;：设置存活数值TTL的大小； -v：详细显示指令的执行过程。 eg: [root@jet oschina_hexo_server]# ping www.baidu.com PING www.a.shifen.com (220.181.112.244) 56(84) bytes of data. 64 bytes from 220.181.112.244: icmp_seq=1 ttl=45 time=13.9 ms 64 bytes from 220.181.112.244: icmp_seq=2 ttl=45 time=3.27 ms 64 bytes from 220.181.112.244: icmp_seq=3 ttl=45 time=2.46 ms 64 bytes from 220.181.112.244: icmp_seq=4 ttl=45 time=3.39 ms 64 bytes from 220.181.112.244: icmp_seq=5 ttl=45 time=2.42 ms 64 bytes from 220.181.112.244: icmp_seq=6 ttl=45 time=2.70 ms 64 bytes from 220.181.112.244: icmp_seq=7 ttl=45 time=2.54 ms 64 bytes from 220.181.112.244: icmp_seq=8 ttl=45 time=3.78 ms 64 bytes from 220.181.112.244: icmp_seq=9 ttl=45 time=3.20 ms 64 bytes from 220.181.112.244: icmp_seq=10 ttl=45 time=2.46 ms 64 bytes from 220.181.112.244: icmp_seq=11 ttl=45 time=2.56 ms 64 bytes from 220.181.112.244: icmp_seq=12 ttl=45 time=2.74 ms 64 bytes from 220.181.112.244: icmp_seq=13 ttl=45 time=2.42 ms 64 bytes from 220.181.112.244: icmp_seq=14 ttl=45 time=2.46 ms #ctrl + c 结束 --- www.a.shifen.com ping statistics --- 14 packets transmitted, 14 received, 0% packet loss, time 13555ms rtt min/avg/max/mdev = 2.420/3.596/13.902/2.889 ms ftp 用来设置文件系统相关功能 ftp服务器在网上较为常见，Linux ftp命令的功能是用命令的方式来控制在本地机和远程机之间传送文件，这里详细介绍Linux ftp命令的一些经常使用的命令，相信掌握了这些使用Linux进行ftp操作将会非常容易。 ftp(选项)(参数) -d：详细显示指令执行过程，便于排错或分析程序执行的情况； -i：关闭互动模式，不询问任何问题； -g：关闭本地主机文件名称支持特殊字符的扩充特性； -n：不使用自动登录； -v：显示指令执行过程。 FTP&gt;ascii: 设定以ASCII方式传送文件(缺省值) FTP&gt;bell: 每完成一次文件传送,报警提示. FTP&gt;binary: 设定以二进制方式传送文件. FTP&gt;bye: 终止主机FTP进程,并退出FTP管理方式. FTP&gt;case: 当为ON时,用MGET命令拷贝的文件名到本地机器中,全部转换为小写字母. FTP&gt;cd: 同UNIX的CD命令. FTP&gt;cdup: 返回上一级目录. FTP&gt;chmod: 改变远端主机的文件权限. FTP&gt;close: 终止远端的FTP进程,返回到FTP命令状态, 所有的宏定义都被删除. FTP&gt;delete: 删除远端主机中的文件. FTP&gt;dir [remote-directory] [local-file] 列出当前远端主机目录中的文件.如果有本地文件,就将结果写至本地文件. FTP&gt;get [remote-file] [local-file] 从远端主机中传送至本地主机中. FTP&gt;help [command] 输出命令的解释. FTP&gt;lcd: 改变当前本地主机的工作目录,如果缺省,就转到当前用户的HOME目录. FTP&gt;ls [remote-directory] [local-file] 同DIR. FTP&gt;macdef: 定义宏命令. FTP&gt;mdelete [remote-files] 删除一批文件. FTP&gt;mget [remote-files] 从远端主机接收一批文件至本地主机. FTP&gt;mkdir directory-name 在远端主机中建立目录. FTP&gt;mput local-files 将本地主机中一批文件传送至远端主机. FTP&gt;open host [port] 重新建立一个新的连接. FTP&gt;prompt: 交互提示模式. FTP&gt;put local-file [remote-file] 将本地一个文件传送至远端主机中. FTP&gt;pwd: 列出当前远端主机目录. FTP&gt;quit: 同BYE. FTP&gt;recv remote-file [local-file] 同GET. FTP&gt;rename [from] [to] 改变远端主机中的文件名. FTP&gt;rmdir directory-name 删除远端主机中的目录. FTP&gt;send local-file [remote-file] 同PUT. FTP&gt;status: 显示当前FTP的状态. FTP&gt;system: 显示远端主机系统类型. FTP&gt;user user-name [password] [account] 重新以别的用户名登录远端主机. FTP&gt;? [command]: 同HELP. [command]指定需要帮助的命令名称。如果没有指定 command，ftp 将显示全部命令的列表。 FTP&gt;! 从 ftp 子系统退出到外壳。 sftp 交互式的文件传输程序 命令的运行和使用方式与ftp命令相似，但是，sftp命令对传输的所有信息使用ssh加密，它还支持公钥认证和压缩等功能 -B：指定传输文件时缓冲区的大小； -l：使用ssh协议版本1； -b：指定批处理文件； -C：使用压缩； -o：指定ssh选项； -F：指定ssh配置文件； -R：指定一次可以容忍多少请求数； -v：升高日志等级。 推荐一款sftp连接工具 FlashFXP iptables Linux上常用的防火墙软件 是netfilter项目的一部分。可以直接配置，也可以通过许多前端和图形界面配置。 iptables(选项)(参数) -t&lt;表&gt;：指定要操纵的表； -A：向规则链中添加条目； -D：从规则链中删除条目； -i：向规则链中插入条目； -R：替换规则链中的条目； -L：显示规则链中已有的条目； -F：清楚规则链中已有的条目； -Z：清空规则链中的数据包计算器和字节计数器； -N：创建新的用户自定义规则链； -P：定义规则链中的默认目标； -h：显示帮助信息； -p：指定要匹配的数据包协议类型； -s：指定要匹配的数据包源ip地址； -j&lt;目标&gt;：指定要跳转的目标； -i&lt;网络接口&gt;：指定数据包进入本机的网络接口； -o&lt;网络接口&gt;：指定数据包要离开本机所使用的网络接口。 iptables命令选项输入顺序： iptables -t 表名 &lt;-A/I/D/R&gt; 规则链名 [规则号] &lt;-i/o 网卡名&gt; -p 协议名 &lt;-s 源IP/源子网&gt; --sport 源端口 &lt;-d 目标IP/目标子网&gt; --dport 目标端口 -j 动作 表名包括： raw：高级功能，如：网址过滤。 mangle：数据包修改（QOS），用于实现服务质量。 net：地址转换，用于网关路由器。 filter：包过滤，用于防火墙规则。 规则链名包括： I NPUT链：处理输入数据包。 OUTPUT链：处理输出数据包。 PORWARD链：处理转发数据包。 PREROUTING链：用于目标地址转换（DNAT）。 POSTOUTING链：用于源地址转换（SNAT）。 动作包括： accept：接收数据包。 DROP：丢弃数据包。 REDIRECT：重定向、映射、透明代理。 SNAT：源地址转换。 DNAT：目标地址转换。 MASQUERADE：IP伪装（NAT），用于ADSL。 LOG：日志记录。 清除已有iptables规则 iptables -F iptables -X iptables -Z 开放指定的端口 iptables -A INPUT -s 127.0.0.1 -d 127.0.0.1 -j ACCEPT #允许本地回环接口(即运行本机访问本机) iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT #允许已建立的或相关连的通行 iptables -A OUTPUT -j ACCEPT #允许所有本机向外的访问 iptables -A INPUT -p tcp --dport 22 -j ACCEPT #允许访问22端口 iptables -A INPUT -p tcp --dport 80 -j ACCEPT #允许访问80端口 iptables -A INPUT -p tcp --dport 21 -j ACCEPT #允许ftp服务的21端口 iptables -A INPUT -p tcp --dport 20 -j ACCEPT #允许FTP服务的20端口 iptables -A INPUT -j reject #禁止其他未允许的规则访问 iptables -A FORWARD -j REJECT #禁止其他未允许的规则访问 屏蔽IP iptables -I INPUT -s 123.45.6.7 -j DROP #屏蔽单个IP的命令 iptables -I INPUT -s 123.0.0.0/8 -j DROP #封整个段即从123.0.0.1到123.255.255.254的命令 iptables -I INPUT -s 124.45.0.0/16 -j DROP #封IP段即从123.45.0.1到123.45.255.254的命令 iptables -I INPUT -s 123.45.6.0/24 -j DROP #封IP段即从123.45.6.1到123.45.6.254的命令是 查看已添加的 iptables规则 iptables -L -n -v Chain INPUT (policy DROP 48106 packets, 2690K bytes) pkts bytes target prot opt in out source destination 5075 589K ACCEPT all -- lo * 0.0.0.0/0 0.0.0.0/0 191K 90M ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:22 1499K 133M ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:80 4364K 6351M ACCEPT all -- * * 0.0.0.0/0 0.0.0.0/0 state RELATED,ESTABLISHED 6256 327K ACCEPT icmp -- * * 0.0.0.0/0 0.0.0.0/0 Chain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 3382K packets, 1819M bytes) pkts bytes target prot opt in out source destination 5075 589K ACCEPT all -- * lo 0.0.0.0/0 0.0.0.0/0 删除已添加的iptables规则 将所有iptables以序号标记显示，执行： iptables -L -n --line-numbers 比如要删除INPUT里序号为8的规则，执行： iptables -D INPUT 8 mail 命令行的电子邮件发送和接收工具 操作的界面不像elm或pine那么容易使用，但功能非常完整。 mail(选项)(参数) -b&lt;地址&gt;：指定密件副本的收信人地址； -c&lt;地址&gt;：指定副本的收信人地址； -f&lt;邮件文件&gt;：读取指定邮件文件中的邮件； -i：不显示终端发出的信息； -I：使用互动模式； -n：程序使用时，不使用mail.rc文件中的设置； -N：阅读邮件时，不显示邮件的标题； -s&lt;邮件主题&gt;：指定邮件的主题； -u&lt;用户帐号&gt;：读取指定用户的邮件； -v：执行时，显示详细的信息。 mail -s &quot;Hello from jet-han.oschina.io by shell&quot; admin@oschina.io hello,this is the content of mail. welcome to jet-han.oschina.io 【注】 第一行是输入的命令，-s表示邮件的主题，后面的admin@oschina.io则是邮件的接收人，输入完这行命令后回车，会进入邮件正文的编写，我们可以输入任何文字，比如上面的两行。当邮件正文输入完成后，需要按CTRL+D结束输入，此时会提示你输入Cc地址，即邮件抄送地址，没有直接回车就完成了邮件的发送 使用管道进行邮件发送 echo &quot;hello,this is the content of mail.welcome to jet-han.oschina.io&quot; | mail -s &quot;Hello from jet-han.oschina.io by pipe&quot; admin@oschina.io 【注】 使用管道直接敲入这行命令即可完成邮件的发送，其中echo后的是邮件正文。 使用文件进行邮件发送 mail -s &quot;Hello from jet-han.oschina.io by file&quot; admin@oschina.io &lt; mail.txt 使用上面的命令后，我们就可以把mail.txt文件的内容作为邮件的内容发送给admin@oschina.io了。 使用上述三种方式都可以给外部邮箱进行邮件发送，但因为前面2种都是直接在shell中敲入邮件内容，因此无法输入中文，即使我们使用粘贴的方式输入了中文，那么收到的邮件也是乱码的。但第3种方式，我们可以在window下编辑好邮件内容后，放到linux下，再进行发送，这样就可以正常发送中文了。不过目前邮件的中文标题暂时没有找到解决办法。 因为mail程序本身就是调用sendmail来进行邮件发送的，因此我们可以在mail命令中使用sendmail的参数进行配置，比如我想使用特定的发件人发送邮件，可以使用如下命令： mail -s &quot;Hello from linuxde.net with sender&quot; admin@oschina.io -- -f jet@oschina.io&lt; mail.txt 【注】 上面的命令中，我们使用了– -f jet@oschina.io这样的参数，这是sendmail的选项，其中-f表示邮件的发送人邮件地址 很多情况下，我们也需要使用邮件来发送附件，在linux下使用mail命令发送附件也很简单，不过首先需要安装uuencode软件包，这个程序是对二进制文件进行编码使其适合通过邮件进行发送，在CentOS上安装该软件包如下： yum install sharutils 安装完成后我们就可以来进行附件的发送了，使用如下命令： uuencode test.txt test | mail -s &quot;hello,see the attachement&quot; admin@oschina.io 完成后就可以把text.txt文件作为邮件的附件发送出去了。uuencode有两个参数，第一个是要发送的文件，第二个是显示的文件名称。 这里我主要介绍的是在CentOS下使用mail发送电子邮件的一些使用方法，需要的要求是你的linux必须安装了sendmail并开启了，同时保证可以连接外网。另外，文章中提到的命令本人都经过亲自测试，保证完全可用，不过你需要将命令中的电子邮件地址换成自己的电子邮件地址 如果出现错误[Postfix] – warning: mail_queue_enter: create file maildrop Permission denied [jet@jet oschina_hexo_server]$ lpostdrop: warning: mail_queue_enter: create file maildrop/820792.3848: Permission denied postdrop: warning: mail_queue_enter: create file maildrop/821453.3848: Permission denied postdrop: warning: mail_queue_enter: create file maildrop/821762.3848: Permission denied postdrop: warning: mail_queue_enter: create file maildrop/822488.3848: Permission denied postdrop: warning: mail_queue_enter: create file maildrop/822928.3848: Permission denied postdrop: warning: mail_queue_enter: create file maildrop/823425.3848: Permission denied postdrop: warning: mail_queue_enter: create file maildrop/823907.3848: Permission denied postdrop: warning: mail_queue_enter: create file maildrop/824427.3848: Permission denied postdrop: warning: mail_queue_enter: create file maildrop/824928.3848: Permission denied postdrop: warning: mail_queue_enter: create file maildrop/825368.3848: Permission denied postdrop: warning: mail_queue_enter: create file maildrop/825899.3848: Permission denied postdrop: warning: mail_queue_enter: create file maildrop/826355.3848: Permission denied root@jet:/var/spool/postfix# postfix check postfix/postfix-script: warning: not owned by group postdrop: /var/spool/postfix/public postfix/postfix-script: warning: not owned by group postdrop: /var/spool/postfix/maildrop root@jet:/var/spool/postfix# /etc/init.d/postfix stop root@jet:/var/spool/postfix# killall -9 postdrop root@jet:/var/spool/postfix# chgrp -R postdrop /var/spool/postfix/public root@jet:/var/spool/postfix# chgrp -R postdrop /var/spool/postfix/maildrop/ root@jet:/var/spool/postfix# postfix check root@jet:/var/spool/postfix# postfix start root@jet:/var/spool/postfix# postfix reload chmod g+s /usr/sbin/postqueue chmod g+s /usr/sbin/postdrop root@gandalf:/var/spool/postfix# postfix check #此时没有警告了 nslookup 命令是常用域名查询工具，就是查DNS信息用的命令 nslookup4有两种工作模式，即“交互模式”和“非交互模式”。在“交互模式”下，用户可以向域名服务器查询各类主机、域名的信息，或者输出域名中的主机列表。而在“非交互模式”下，用户可以针对一个主机或域名仅仅获取特定的名称或所需信息。 进入交互模式，直接输入nslookup命令，不加任何参数，则直接进入交互模式，此时nslookup会连接到默认的域名服务器（即/etc/resolv.conf 的第一个dns地址）。或者输入nslookup -nameserver/ip。进入非交互模式，就直接输入nslookup 域名就可以了。 nslookup(选项)(参数) -sil：不显示任何警告信息。 eg: [jet@jet oschina_hexo_server]$ nslookup jet-han.oschina.io Server: 114.114.114.114 Address: 114.114.114.114#53 Non-authoritative answer: Name: jet-han.oschina.io Address: 103.21.119.115 ip 显示或操纵Linux主机的路由、网络设备、策略路由和隧道，是Linux下较新的功能强大的网络配置工具 ip(选项)(参数) #(参数) 网络对象：指定要管理的网络对象； 具体操作：对指定的网络对象完成具体操作； help：显示网络对象支持的操作命令的帮助信息。 #(选项) -V：显示指令版本信息； -s：输出更详细的信息； -f：强制使用指定的协议族； -4：指定使用的网络层协议是IPv4协议； -6：指定使用的网络层协议是IPv6协议； -0：输出信息每条记录输出一行，即使内容较多也不换行显示； -r：显示主机时，不使用IP地址，而使用主机的域名。 用ip命令显示网络设备的运行状态 [jet@jet oschina_hexo_server]$ ip -s link list 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 RX: bytes packets errors dropped overrun mcast 830 14 0 0 0 0 TX: bytes packets errors dropped carrier collsns 830 14 0 0 0 0 2: eth3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:8b:22:5e brd ff:ff:ff:ff:ff:ff RX: bytes packets errors dropped overrun mcast 121209665 198774 0 0 0 0 TX: bytes packets errors dropped carrier collsns 227857521 157867 0 0 0 0 显示核心路由表 [jet@jet oschina_hexo_server]$ ip route list 10.111.24.0/24 dev eth3 proto kernel scope link src 10.111.24.222 metric 1 default via 10.111.24.1 dev eth3 proto static 显示邻居表 [jet@jet oschina_hexo_server]$ ip neigh list fe80::ac9e:6493:cb07:4add dev eth3 lladdr 54:ee:75:03:60:e7 STALE fe80::1870:3ef3:ba4f:e55b dev eth3 lladdr bc:9f:ef:8e:d3:13 STALE fe80::a28d:16ff:fe84:ac43 dev eth3 lladdr a0:8d:16:84:ac:43 STALE fe80::ca6:b92b:4736:a95a dev eth3 lladdr 24:a2:e1:39:ba:21 STALE fe80::83c:b2a6:cc95:fae7 dev eth3 lladdr 54:4e:90:7a:6b:e3 STALE fe80::8486:b8c:5150:15c1 dev eth3 lladdr 28:d2:44:74:a0:d4 STALE fe80::1c2f:e7e6:82ee:17f0 dev eth3 lladdr 20:3c:ae:b0:87:88 STALE fe80::78d2:a70e:cba3:5373 dev eth3 lladdr 28:d2:44:68:36:3c STALE fe80::9c19:a5e5:918b:b069 dev eth3 lladdr 50:7b:9d:e6:7c:ac STALE fe80::1c12:cb63:3897:fcb0 dev eth3 lladdr fc:d8:48:92:44:c9 STALE fe80::184c:1bc1:a201:2fa7 dev eth3 lladdr 90:b0:ed:77:94:4a STALE fe80::792a:9e54:8679:cb84 dev eth3 lladdr b8:ee:65:04:81:89 STALE fe80::1098:1ed2:b23a:4ef dev eth3 lladdr 5c:ad:cf:6e:11:6a STALE fe80::28bc:6b21:4fce:f51a dev eth3 lladdr 28:d2:44:c9:c0:ed STALE fe80::1895:8cec:208d:5eec dev eth3 lladdr f4:5c:89:8e:ad:a5 STALE fe80::1c44:bede:96a5:499a dev eth3 lladdr 20:ab:37:93:1f:43 STALE fe80::5a:d7d:e3f6:6f9f dev eth3 lladdr 14:2d:27:f8:4b:79 STALE fe80::61e9:b002:68c1:7ba dev eth3 lladdr 28:d2:44:6e:11:d7 STALE fe80::1cbe:22d4:b466:d564 dev eth3 lladdr 40:33:1a:ad:1b:8c STALE fe80::1863:6370:356f:c6ec dev eth3 lladdr 24:24:0e:de:6c:86 STALE fe80::426c:8fff:fe3f:304e dev eth3 lladdr 40:6c:8f:3f:30:4e STALE fe80::1824:b631:d44a:5bf3 dev eth3 lladdr 9c:fc:01:e7:c8:21 STALE fe80::1038:72ee:9f9e:51ea dev eth3 lladdr 70:48:0f:60:e7:0d STALE fe80::a069:d8a9:5fc0:219d dev eth3 lladdr ac:22:0b:c9:bb:6c STALE fe80::8e4:27f0:1ac7:97cc dev eth3 lladdr 28:d2:44:6d:fb:6f STALE fe80::59a0:8d02:8cb7:430c dev eth3 lladdr 28:d2:44:68:74:80 STALE fe80::3884:7711:39ce:2b96 dev eth3 lladdr 48:5a:b6:df:8f:8d STALE fe80::f8c1:52f5:5286:9bae dev eth3 lladdr 28:d2:44:75:5d:ec STALE fe80::c9c:69:70b5:2796 dev eth3 lladdr 2c:20:0b:bf:2d:16 STALE fe80::ee01:eeff:fe0a:fe55 dev eth3 lladdr ec:01:ee:0a:fe:55 STALE fe80::3ea3:48ff:fe99:5bf6 dev eth3 lladdr 3c:a3:48:99:5b:f6 STALE fe80::1092:6d00:3bfa:ad5f dev eth3 lladdr 7c:04:d0:32:44:24 STALE fe80::c3e:8ab7:92f8:d0f6 dev eth3 lladdr 64:b0:a6:26:a5:f0 STALE fe80::ca6:3dd9:1fe:f6a0 dev eth3 lladdr 24:24:0e:be:1a:57 STALE fe80::d265:caff:fece:62c9 dev eth3 lladdr d0:65:ca:ce:62:c9 STALE fe80::163e:bfff:fefc:ac78 dev eth3 lladdr 14:3e:bf:fc:ac:78 STALE fe80::9ef3:87ff:fec0:c6fa dev eth3 lladdr 9c:f3:87:c0:c6:fa STALE fe80::1415:65e3:71b0:4c9e dev eth3 lladdr d8:1d:72:52:6f:84 STALE 10.111.24.248 dev eth3 lladdr bc:75:74:5e:fb:2e STALE 10.111.24.220 dev eth3 lladdr 14:3e:bf:fc:ac:78 STALE 10.111.24.1 dev eth3 lladdr 10:47:80:28:02:e0 STALE 10.111.24.227 dev eth3 lladdr f4:8e:38:ba:47:3f REACHABLE scp 远程拷贝文件的命令 和它类似的命令有cp，不过cp只是在本机进行拷贝不能跨服务器，而且scp传输是加密的。可能会稍微影响一下速度。当你服务器硬盘变为只读read only system时，用scp可以帮你把文件移出来。另外，scp还非常不占资源，不会提高多少系统负荷，在这一点上，rsync就远远不及它了。虽然 rsync比scp会快一点，但当小文件众多的情况下，rsync会导致硬盘I/O非常高，而scp基本不影响系统正常使用。 scp(选项)(参数) #(选项) -1：使用ssh协议版本1； -2：使用ssh协议版本2； -4：使用ipv4； -6：使用ipv6； -B：以批处理模式运行； -C：使用压缩； -F：指定ssh配置文件； -l：指定宽带限制； -o：指定使用的ssh选项； -P：指定远程主机的端口号； -p：保留文件的最后修改时间，最后访问时间和权限模式； -q：不显示复制进度； -r：以递归方式复制； -v 详细显示输出的具体情况。 #(参数) 源文件：指定要复制的源文件。 目标文件：目标文件。格式为user@host：filename（文件名为目标文件的名称）。 (1) 复制文件： 命令格式： scp local_file remote_username@remote_ip:remote_folder 或者 scp local_file remote_username@remote_ip:remote_file 或者 scp local_file remote_ip:remote_folder 或者 scp local_file remote_ip:remote_file 第1,2个指定了用户名，命令执行后需要输入用户密码，第1个仅指定了远程的目录，文件名字不变，第2个指定了文件名 第3,4个没有指定用户名，命令执行后需要输入用户名和密码，第3个仅指定了远程的目录，文件名字不变，第4个指定了文件名 (2) 复制目录： 命令格式： scp -r local_folder remote_username@remote_ip:remote_folder 或者 scp -r local_folder remote_ip:remote_folder 第1个指定了用户名，命令执行后需要输入用户密码； 第2个没有指定用户名，命令执行后需要输入用户名和密码； eg: #从 本地 上传到 远程 scp /home/daisy/full.tar.gz root@172.19.2.75:/home/root #从 远程 下载到 本地 scp root@172.19.2.75:/home/root/full.tar.gz /home/daisy/ wget 直接从网络上下载文件 wget [参数] [URL地址] -o FILE 把记录写到FILE文件中 eg : wget -O a.txt URL wget --limit-rate=300k URL 限速下载 系统安全相关命令vmstat 对操作系统的虚拟内存、进程、CPU活动进行监控 iostat 对系统的磁盘操作活动进行监视,汇报磁盘活动统计情况，同时也会汇报出CPU使用情况 -p[磁盘] 显示磁盘和分区的情况 watch 重复执行某一命令以观察变化 watch [参数] [命令] -n 时隔多少秒刷新 -d 高亮显示动态变化 at 在一个指定的时间执行一个指定任务，只能执行一次 at [参数] [时间] HH:MM[am|pm] + number [minutes|hours|days|weeks] 强制在某年某月某日的某时刻进行该项任务 atq 查看系统未执行的任务 atrm n 删除编号为n的任务 at -c n 显示编号为n的任务的内容 passwd 用于设置用户的认证信息，包括用户密码、密码过期时间等 系统管理者则能用它管理系统用户的密码。只有管理者可以指定用户名称，一般用户只能变更自己的密码。 passwd(选项)(参数) #(选项) -l 使密码失效 -u 与-l相对，用户解锁 -S 列出登陆用户passwd文件内的相关参数 -n 后面接天数，shadow 的第 4 字段，多久不可修改密码天数 -x 后面接天数，shadow 的第 5 字段，多久内必须要更动密码 -w 后面接天数，shadow 的第 6 字段，密码过期前的警告天数 -i 后面接『日期』，shadow 的第 7 字段，密码失效日期 使用管道刘设置密码：echo &quot;zeng&quot; | passwd --stdin zenghao #(参数) 用户名：需要设置密码的用户名。 与用户、组账户信息相关的文件 存放用户信息： /etc/passwd /etc/shadow 存放组信息： /etc/group /etc/gshadow 用户信息文件分析（每项用:隔开） 例如：jack:X:503:504:::/home/jack/:/bin/bash jack //用户名 X //口令、密码 503 //用户 （0代表root、普通新建用户从500开始） 504 //所在组 : //描述 /home/jack/ //用户主目录 /bin/bash //用户缺省Shell 组信息文件分析 例如：jack:$!$:???:13801:0:99999:7:*:*: jack //组名 $!$ //被加密的口令 13801 //创建日期与今天相隔的天数 0 //口令最短位数 99999 //用户口令 7 //到7天时提醒 * //禁用天数 * //过期天数 如果是普通用户执行passwd只能修改自己的密码。如果新建用户后，要为新用户创建密码，则用passwd用户名，注意要以root用户的权限来创建 [root@jet ~]# passwd linuxde //更改或创建linuxde用户的密码； Changing password for user linuxde. New UNIX password: //请输入新密码； Retype new UNIX password: //再输入一次； passwd: all authentication tokens updated successfully. //成功； 普通用户如果想更改自己的密码，直接运行passwd即可，比如当前操作的用户是jet [jet@jet ~]$ passwd Changing password for user linuxde. //更改jet用户的密码； (current) UNIX password: //请输入当前密码； New UNIX password: //请输入新密码； Retype new UNIX password: //确认新密码； passwd: all authentication tokens updated successfully. //更改成功； 比如我们让某个用户不能修改密码，可以用-l选项来锁定： [root@localhost ~]# passwd -l linuxde //锁定用户jet不能更改密码； Locking password for user linuxde. passwd: Success //锁定成功； [jet@jet ~]# su linuxde //通过su切换到jet用户； [jet@jet ~]$ passwd //jet来更改密码； Changing password for user jet. Changing password for linuxde (current) UNIX password: //输入jet的当前密码； passwd: Authentication token manipulation error //失败，不能更改密码； 清除密码 [root@jet ~]# passwd -d jet //清除jet用户密码； Removing password for user jet. passwd: Success //清除成功； [root@jet ~]# passwd -S jet //查询jet用户密码状态； Empty password. //空密码，也就是没有密码； 【注】 当我们清除一个用户的密码时，登录时就无需密码，这一点要加以注意。 su 切换当前用户身份到其他用户身份，变更时须输入所要变更的用户帐号与密码 su [参数] user -c&lt;指令&gt;或--command=&lt;指令&gt;：执行完指定的指令后，即恢复原来的身份； -f或——fast：适用于csh与tsch，使shell不用去读取启动文件； -l或——login：改变身份时，也同时变更工作目录，以及HOME,SHELL,USER,logname。此外，也会变更PATH变量； -m,-p或--preserve-environment：变更身份时，不要变更环境变量； -s或--shell=：指定要执行的shell； --help：显示帮助； --version；显示版本信息。 eg: #变更帐号为root并在执行ls指令后退出变回原使用者： su -c ls root #变更帐号为root并传入-f选项给新执行的shell： su root -f #变更帐号为test并改变工作目录至test的家目录： su -test sudo 以其他身份来执行命令，预设的身份为root 在/etc/sudoers中设置了可执行sudo指令的用户。若其未经授权的用户企图使用sudo，则会发出警告的邮件给管理员。用户使用sudo时，必须先输入密码，之后有5分钟的有效期限，超过期限则必须重新输入密码。 sudo(选项)(参数) -b：在后台执行指令； -h：显示帮助； -H：将HOME环境变量设为新身份的HOME环境变量； -k：结束密码的有效期限，也就是下次再执行sudo时便需要输入密码；。 -l：列出目前用户可执行与无法执行的指令； -p：改变询问密码的提示符号； -s：执行指定的shell； -u&lt;用户&gt;：以指定的用户作为新的身份。若不加上此参数，则预设以root作为新的身份； -v：延长密码有效期限5分钟； -V ：显示版本信息。 配置sudo必须通过编辑/etc/sudoers文件，而且只有超级用户才可以修改它，还必须使用visudo编辑。之所以使用visudo有两个原因，一是它能够防止两个用户同时修改它；二是它也能进行有限的语法检查。所以，即使只有你一个超级用户，你也最好用visudo来检查一下语法。 visudo默认的是在vi里打开配置文件，用vi来修改文件。我们可以在编译时修改这个默认项。visudo不会擅自保存带有语法错误的配置文件，它会提示你出现的问题，并询问该如何处理，就像： &gt;&gt;&gt; sudoers file: syntax error, line 22 &lt;&lt; 此时我们有三种选择：键入“e”是重新编辑，键入“x”是不保存退出，键入“Q”是退出并保存。如果真选择Q，那么sudo将不会再运行，直到错误被纠正。 现在，我们一起来看一下神秘的配置文件，学一下如何编写它。让我们从一个简单的例子开始：让用户Foobar可以通过sudo执行所有root可执行的命令。以root身份用visudo打开配置文件，可以看到类似下面几行： # Runas alias specification # User privilege specificationroot ALL=(ALL)ALL 我们一看就明白个差不多了，root有所有权限，只要仿照现有root的例子就行，我们在下面加一行（最好用tab作为空白）： foobar ALL=(ALL) ALL 保存退出后，切换到foobar用户，我们用它的身份执行命令： [foobar@localhost ~]$ ls /root ls: /root: 权限不够 [foobar@localhost ~]$ sudo ls /root PassWord: anaconda-ks.cfg Desktop install.log install.log.syslog 好了，我们限制一下foobar的权利，不让他为所欲为。比如我们只想让他像root那样使用ls和ifconfig，把那一行改为： foobar localhost= /sbin/ifconfig, /bin/ls 再来执行命令： [foobar@localhost ~]$ sudo head -5 /etc/shadow Password: Sorry, user foobar is not allowed to execute &#39;/usr/bin/head -5 /etc/shadow&#39; as root on localhost.localdomain. [foobar@localhost ~]$ sudo /sbin/ifconfigeth0 Linkencap:Ethernet HWaddr 00:14:85:EC:E9:9B... 现在让我们来看一下那三个ALL到底是什么意思。第一个ALL是指网络中的主机，我们后面把它改成了主机名，它指明foobar可以在此主机上执行后面的命令。第二个括号里的ALL是指目标用户，也就是以谁的身份去执行命令。最后一个ALL当然就是指命令名了。例如，我们想让foobar用户在linux主机上以jimmy或rene的身份执行kill命令，这样编写配置文件： foobar linux=(jimmy,rene) /bin/kill 但这还有个问题，foobar到底以jimmy还是rene的身份执行？这时我们应该想到了sudo -u了，它正是用在这种时候。 foobar可以使用sudo -u jimmy kill PID或者sudo -u rene kill PID，但这样挺麻烦，其实我们可以不必每次加-u，把rene或jimmy设为默认的目标用户即可。再在上面加一行： Defaults:foobar runas_default=rene Defaults后面如果有冒号，是对后面用户的默认，如果没有，则是对所有用户的默认。就像配置文件中自带的一行： Defaults env_reset 另一个问题是，很多时候，我们本来就登录了，每次使用sudo还要输入密码就显得烦琐了。我们可不可以不再输入密码呢？当然可以，我们这样修改配置文件： foobar localhost=NOPASSWD: /bin/cat, /bin/ls 再来sudo一下： [foobar@localhost ~]$ sudo ls /rootanaconda-ks.cfg Desktop install.log install.log.syslog 当然，你也可以说“某些命令用户foobar不可以运行”，通过使用!操作符，但这不是一个好主意。因为，用!操作符来从ALL中“剔出”一些命令一般是没什么效果的，一个用户完全可以把那个命令拷贝到别的地方，换一个名字后再来运行。 日志与安全 sudo为安全考虑得很周到，不仅可以记录日志，还能在有必要时向系统管理员报告。但是，sudo的日志功能不是自动的，必须由管理员开启。这样来做： touch /var/log/sudo vi /etc/syslog.conf 在syslog.conf最后面加一行（必须用tab分割开）并保存： local2.debug /var/log/sudo 重启日志守候进程， ps aux grep syslogd 把得到的syslogd进程的PID（输出的第二列是PID）填入下面： kill –HUP PID 这样，sudo就可以写日志了： [foobar@localhost ~]$ sudo ls /rootanaconda-ks.cfg Desktop install.log install.log.syslog $cat /var/log/sudoJul 28 22:52:54 localhost sudo: foobar : TTY=pts/1 ; pwd=/home/foobar ; USER=root ; command=/bin/ls /root 不过，有一个小小的“缺陷”，sudo记录日志并不是很忠实： [foobar@localhost ~]$ sudo cat /etc/shadow &gt; /dev/null cat /var/log/sudo...Jul 28 23:10:24 localhost sudo: foobar : TTY=pts/1 ; PWD=/home/foobar ; USER=root ; COMMAND=/bin/cat /etc/shadow 重定向没有被记录在案！为什么？因为在命令运行之前，shell把重定向的工作做完了，sudo根本就没看到重定向。这也有个好处，下面的手段不会得逞： [foobar@localhost ~]$ sudo ls /root &gt; /etc/shadowbash: /etc/shadow: 权限不够 sudo 有自己的方式来保护安全。以root的身份执行sudo-V，查看一下sudo的设置。因为考虑到安全问题，一部分环境变量并没有传递给sudo后面的命令，或者被检查后再传递的，比如：PATH，HOME，SHELL等。当然，你也可以通过sudoers来配置这些环境变量。 chgrp 改变文件或目录所属的用户组 该命令用来改变指定文件所属的用户组。其中，组名可以是用户组的id，也可以是用户组的组名。文件名可以 是由空格分开的要改变属组的文件列表，也可以是由通配符描述的文件集合。如果用户不是该文件的文件主或超级用户(root)，则不能改变该文件的组 chgrp(选项)(参数) #(选项) -c或——changes：效果类似“-v”参数，但仅回报更改的部分； -f或--quiet或——silent：不显示错误信息； -h或--no-dereference：只对符号连接的文件作修改，而不是该其他任何相关文件； -R或——recursive：递归处理，将指令目录下的所有文件及子目录一并处理； -v或——verbose：显示指令执行过程； --reference=&lt;参考文件或目录&gt;：把指定文件或目录的所属群组全部设成和参考文件或目录的所属群组相同； #(参数) 组：指定新工作名称； 文件：指定要改变所属组的文件列表。多个文件或者目录之间使用空格隔开。 eg： chgrp users -R ./dir #递归地把dir目录下中的所有文件和子目录下所有文件的用户组修改为users chown 改变某个文件或目录的所有者和所属的组 该命令可以向某个用户授权，使该用户变成指定文件的所有者或者改变文件所属的组。用户可以是用户或者是用户D，用户组可以是组名或组id。文件名可以使由空格分开的文件列表，在文件名中可以包含通配符。 chown(选项)(参数) #(选项) -c或——changes：效果类似“-v”参数，但仅回报更改的部分； -f或--quite或——silent：不显示错误信息； -h或--no-dereference：只对符号连接的文件作修改，而不更改其他任何相关文件； -R或——recursive：递归处理，将指定目录下的所有文件及子目录一并处理； -v或——version：显示指令执行过程； --dereference：效果和“-h”参数相同； --help：在线帮助； --reference=&lt;参考文件或目录&gt;：把指定文件或目录的拥有者与所属群组全部设成和参考文件或目录的拥有者与所属群组相同； --version：显示版本信息。 #(参数) 用户：组：指定所有者和所属工作组。当省略“：组”，仅改变文件所有者； 文件：指定要改变所有者和工作组的文件列表。支持多个文件和目标，支持shell通配符。 #将目录/usr/meng及其下面的所有文件、子目录的文件主改成 liu： chown -R liu /usr/meng #文件的属主和属组属性设置 chown user:market f01 //把文件f01给uesr，添加到market组 ll -d f1 查看目录f1的属性 chmod 变更文件或目录的权限 在UNIX系统家族里，文件或目录权限的控制分别以读取、写入、执行3种一般权限来区分，另有3种特殊权限可供运用。用户可以使用chmod指令去变更文件与目录的权限，设置方式采用文字或数字代号皆可。符号连接的权限无法变更，如果用户对符号连接修改权限，其改变会作用在被连接的原始文件。 权限范围的表示法如下：u User，即文件或目录的拥有者；g Group，即文件或目录的所属群组；o Other，除了文件或目录拥有者或所属群组之外，其他用户皆属于这个范围；a All，即全部的用户，包含拥有者，所属群组以及其他用户 ；r 读取权限，数字代号为“4”;w 写入权限，数字代号为“2”；x 执行或切换权限，数字代号为“1”； - 不具任何权限，数字代号为“0”；s 特殊功能说明：变更文件或目录的权限。 chmod(选项)(参数) #(选项) -c或——changes：效果类似“-v”参数，但仅回报更改的部分； -f或--quiet或——silent：不显示错误信息； -R或——recursive：递归处理，将指令目录下的所有文件及子目录一并处理； -v或——verbose：显示指令执行过程； --reference=&lt;参考文件或目录&gt;：把指定文件或目录的所属群组全部设成和参考文件或目录的所属群组相同； &lt;权限范围&gt;+&lt;权限设置&gt;：开启权限范围的文件或目录的该选项权限设置； &lt;权限范围&gt;-&lt;权限设置&gt;：关闭权限范围的文件或目录的该选项权限设置； &lt;权限范围&gt;=&lt;权限设置&gt;：指定权限范围的文件或目录的该选项权限设置； #(参数) 权限模式：指定文件的权限模式； 文件：要改变权限的文件。 eg： chmod 0755 file # 把file的文件权限改变为-rxwr-xr-x chmod g+w file # 向file的文件权限中加入用户组可写权限 Linux用 户分为：拥有者、组群(Group)、其他（other），Linux系统中，预设的情況下，系统中所有的帐号与一般身份使用者，以及root的相关信 息， 都是记录在/etc/passwd文件中。每个人的密码则是记录在/etc/shadow文件下。 此外，所有的组群名称记录在/etc/group內！ linux文件的用户权限的分析图 文件权限管理 三种基本权限 R 读 数值表示为4 W 写 数值表示为2 X 可执行 数值表示为1 如图所示，copyright.html文件的权限为-rw-rw-r— -rw-rw-r-- 一共十个字符，分成四段。 第一个字符“-”表示普通文件；这个位置还可能会出现“l”链接；“d”表示目录 第二三四个字符“rw-”表示当前所属用户的权限。 所以用数值表示为4+2=6 第五六七个字符“rw-”表示当前所属组的权限。 所以用数值表示为4+2=6 第八九十个字符“r-–”表示其他用户权限。 所以用数值表示为4 所以操作此文件的权限用数值表示为664 用户及用户组管理 /etc/passwd 存储用户账号 /etc/group 存储组账号 /etc/shadow 存储用户账号的密码 /etc/gshadow 存储用户组账号的密码 useradd 添加用户名 userdel 删除用户名 adduser 添加用户名 groupadd 添加组名 groupdel 删除组名 passwd root 给root设置密码 su root su – root /etc/profile 系统环境变量 bash_profile 用户环境变量 .bashrc 用户环境变量 su user 切换用户，加载配置文件.bashrc su – user 切换用户，加载配置文件/etc/profile ，加载bash_profile who 显示目前登录系统的用户信息 执行who命令可得知目前有那些用户登入系统，单独执行who命令会列出登入帐号，使用的终端机，登入时间以及从何处登入或正在使用哪个X显示器。 who(选项)(参数) #(选项) -H或--heading：显示各栏位的标题信息列； -i或-u或--idle：显示闲置时间，若该用户在前一分钟之内有进行任何动作，将标示成&quot;.&quot;号，如果该用户已超过24小时没有任何动作，则标示出&quot;old&quot;字符串； -m：此参数的效果和指定&quot;am i&quot;字符串相同； -q或--count：只显示登入系统的帐号名称和总人数； -s：此参数将忽略不予处理，仅负责解决who指令其他版本的兼容性问题； -w或-T或--mesg或--message或--writable：显示用户的信息状态栏； --help：在线帮助； --version：显示版本信息。 #(参数) 文件：指定查询文件。 whoami 打印当前有效的用户名称，相当于执行id -un命令 whoami(选项) (选项) --help：在线帮助； --version：显示版本信息。 which 查找并显示给定命令的绝对路径 环境变量PATH中保存了查找命令时需要遍历的目录。which指令会在环境变量$PATH设置的目录里查找符合条件的文件。也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。 which(选项)(参数) #(选项) -n&lt;文件名长度&gt;：制定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名； -p&lt;文件名长度&gt;：与-n参数相同，但此处的&lt;文件名长度&gt;包含了文件的路径； -w：指定输出时栏位的宽度； -V：显示版本信息。 #(参数) 指令名：指令名列表。 查找文件、显示命令路径： [root@jet ~]# which pwd /bin/pwd [root@jet ~]# which adduser /usr/sbin/adduser 【注】 which是根据使用者所配置的 PATH 变量内的目录去搜寻可运行档的！所以，不同的 PATH 配置内容所找到的命令当然不一样的！ ntpdate设置本地日期和时间 服务器的时间不对的时候，可以使用ntpdate工具来校正时间。 ntpdate ip/site eg: /usr/sbin/ntpdate time.windows.com 以下是一些可用的NTP服务器地址： Name IP Location 210.72.145.44 210.72.145.44 中国（国家授时中心） 133.100.11.8 133.100.11.8 日本（福冈大学） time-a.nist.gov 129.6.15.28 NIST,Gaithersburg,Maryland time-b.nist.gov 129.6.15.29 NIST,Gaithersburg,Maryland time-a.timefreq.bldrdoc.gov 132.163.4.101 NIST,Boulder,Colorado time-b.timefreq.bldrdoc.gov 132.163.4.102 NIST,Boulder,Colorado time-c.timefreq.bldrdoc.gov 132.163.4.103 NIST,Boulder,Colorado utcnist.colorado.edu 128.138.140.44 UniversityofColorado,Boulder time.nist.gov 192.43.244.18 NCAR,Boulder,Colorado time-nw.nist.gov 131.107.1.10 Microsoft,Redmond,Washington nist1.symmetricom.com 69.25.96.13 Symmetricom,SanJose,California nist1-dc.glassey.com 216.200.93.8 Abovenet,Virginia nist1-ny.glassey.com 208.184.49.9 Abovenet,NewYorkCity nist1-sj.glassey.com 207.126.98.204 Abovenet,SanJose,California nist1.aol-ca.truetime.com 207.200.81.113 TrueTime,AOLfacility,Sunnyvale,California nist1.aol-va.truetime.com 64.236.96.53 TrueTime,AOLfacility,Virginia 其它命令gzip 压缩文件 gzip是在Linux系统中经常使用的一个对文件进行压缩和解压缩的命令，文件经它压缩过后，其名称后面会多处“.gz”扩展名，既方便又好用。gzip不仅可以用来压缩大的、较少使用的文件以节省磁盘空间，还可以和tar命令一起构成Linux操作系统中比较流行的压缩文件格式。据统计，gzip命令对文本文件有60%～70%的压缩率。减少文件大小有两个明显的好处，一是可以减少存储空间，二是通过网络传输文件时，可以减少传输的时间。 gzip(选项)(参数) #(选项) -a或——ascii：使用ASCII文字模式； -d或--decompress或----uncompress：解开压缩文件； -f或——force：强行压缩文件。不理会文件名称或硬连接是否存在以及该文件是否为符号连接； -h或——help：在线帮助； -l或——list：列出压缩文件的相关信息； -L或——license：显示版本与版权信息； -n或--no-name：压缩文件时，不保存原来的文件名称及时间戳记； -N或——name：压缩文件时，保存原来的文件名称及时间戳记； -q或——quiet：不显示警告信息； -r或——recursive：递归处理，将指定目录下的所有文件及子目录一并处理； -S或&lt;压缩字尾字符串&gt;或----suffix&lt;压缩字尾字符串&gt;：更改压缩字尾字符串； -t或——test：测试压缩文件是否正确无误； -v或——verbose：显示指令执行过程； -V或——version：显示版本信息； -&lt;压缩效率&gt;：压缩效率是一个介于1~9的数值，预设值为“6”，指定愈大的数值，压缩效率就会愈高； --best：此参数的效果和指定“-9”参数相同； --fast：此参数的效果和指定“-1”参数相同。 #(参数) 文件列表：指定要压缩的文件列表。 把test6目录下的每个文件压缩成.gz文件 gzip * 把上例中每个压缩的文件解压，并列出详细的信息 gzip -dv * 详细显示例1中每个压缩的文件的信息，并不解压 gzip -l * 压缩一个tar备份文件，此时压缩文件的扩展名为.tar.gz gzip -r log.tar 递归的压缩目录 gzip -rv test6 这样，所有test下面的文件都变成了.gz，目录依然存在只是目录里面的文件相应变成了.gz.这就是压缩，和打包不同。因为是对目录操作，所以需要加上-r选项，这样也可以对子目录进行递归了。 递归地解压目录 gzip -dr test6 gunzip 解压缩文件 gunzip是个使用广泛的解压缩程序，它用于解开被gzip压缩过的文件，这些压缩文件预设最后的扩展名为.gz。事实上gunzip就是gzip的硬连接，因此不论是压缩或解压缩，都可通过gzip指令单独完成。 gunzip(选项)(参数) #(选项) -a或——ascii：使用ASCII文字模式； -c或--stdout或--to-stdout：把解压后的文件输出到标准输出设备； -f或-force：强行解开压缩文件，不理会文件名称或硬连接是否存在以及该文件是否为符号连接； -h或——help：在线帮助； -l或——list：列出压缩文件的相关信息； -L或——license：显示版本与版权信息； -n或--no-name：解压缩时，若压缩文件内含有原来的文件名称及时间戳记，则将其忽略不予处理； -N或——name：解压缩时，若压缩文件内含有原来的文件名称及时间戳记，则将其回存到解开的文件上； -q或——quiet：不显示警告信息； -r或——recursive：递归处理，将指定目录下的所有文件及子目录一并处理； -S或&lt;压缩字尾字符串&gt;或----suffix&lt;压缩字尾字符串&gt;：更改压缩字尾字符串； -t或——test：测试压缩文件是否正确无误； -v或——verbose：显示指令执行过程； -V或——version：显示版本信息； #(参数) 文件列表：指定要解压缩的压缩包。 首先将/etc目录下的所有文件以及子目录进行压缩，备份压缩包etc.zip到/opt目录，然后对etc.zip文件进行gzip压缩，设置gzip的压缩级别为9。 zip –r /opt/etc.zip /etc gzip -9v /opt/etc.zip 查看上述etc.zip.gz文件的压缩信息。 gzip -l /opt/etc.zip.gz compressed uncompressed ratio uncompressed_name 11938745 12767265 6.5% /opt/etc.zip 解压上述etc.zip.gz文件到当前目录。 [root@mylinux ~]#gzip –d /opt/etc.zip.gz 或者执行 [root@mylinux ~]#gunzip /opt/etc.zip.gz 通过上面的示例可以知道gzip –d等价于gunzip命令。 bzip2 创建和管理（包括解压缩）“.bz2”格式的压缩包 我们遇见Linux压缩打包方法有很多种，以下讲解了Linux压缩打包方法中的Linux bzip2命令的多种范例供大家查看，相信大家看完后会有很多收获。 bzip2(选项)(参数) #(选项) -c或——stdout：将压缩与解压缩的结果送到标准输出； -d或——decompress：执行解压缩； -f或-force：bzip2在压缩或解压缩时，若输出文件与现有文件同名，预设不会覆盖现有文件。若要覆盖。请使用此参数； -h或——help：在线帮助； -k或——keep：bzip2在压缩或解压缩后，会删除原始文件。若要保留原始文件，请使用此参数； -s或——small：降低程序执行时内存的使用量； -t或——test：测试.bz2压缩文件的完整性； -v或——verbose：压缩或解压缩文件时，显示详细的信息； -z或——compress：强制执行压缩； -V或——version：显示版本信息； --repetitive-best：若文件中有重复出现的资料时，可利用此参数提高压缩效果； --repetitive-fast：若文件中有重复出现的资料时，可利用此参数加快执行效果。 #(参数) 文件：指定要压缩的文件。 压缩指定文件filename: bzip2 filename 或 bzip2 -z filename 这里，压缩的时候不会输出，会将原来的文件filename给删除，替换成filename.bz2.如果以前有filename.bz2则不会替换并提示错误（如果想要替换则指定-f选项，例如bzip2 -f filename；如果filename是目录则也提醒错误不做任何操作；如果filename已经是压过的了有bz2后缀就提醒一下，不再压缩，没有bz2后缀会再次压缩。 解压指定的文件filename.bz2: bzip2 -d filename.bz2 或 bunzip2 filename.bz2 这里，解压的时候没标准输出，会将原来的文件filename.bz2给替换成filename。如果以前有filename则不会替换并提示错误（如果想要替换则指定-f选项，例如bzip2 -df filename.bz2。 压缩解压的时候将结果也输出： $bzip2 -v filename 输入之后，输出如下： filename: 0.119:1, 67.200 bits/byte, -740.00% saved, 5 in, 42 out. 这里，加上-v选项就会输出了,只用压缩举例了，解压的时候同理bzip2 -dv filename.bz2不再举例了。 模拟解压实际并不解压： bzip2 -tv filename.bz2 输入之后，输出如下： filename.bz2: ok 这里，-t指定要进行模拟解压，不实际生成结果，也就是说类似检查文件,当然就算目录下面有filename也不会有什么错误输出了，因为它根本不会真的解压文件。为了在屏幕上输出，这里加上-v选项了,如果是真的解压bzip2 -dv filename.bz2则输出的是把”ok”替换成了”done”。 压缩解压的时候，除了生成结果文件，将原来的文件也保存: bzip2 -k filename 这里，加上-k就保存原始的文件了，否则原始文件会被结果文件替代。只用压缩举例了，解压的时候同理$bzip2 -dk filename.bz2不再举例了。 解压到标准输出： bzip2 -dc filename.bz2 输入之后，输出如下： hahahhaahahha 这里，使用-c指定到标准输出，输出的是文件filename的内容，不会将filename.bz2删除。 压缩到标准输出： bzip2 -c filename bzip2: I won&#39;t write compressed data to a terminal. bzip2: For help, type: `bzip2 --help&#39;. 这里，使用-c指定压缩到标准输出不删除原有文件，不同的是，压缩后的文件无法输出到标准输出。 使用bzip2的时候将所有后面的看作文件(即使文件名以’-‘开头)： bzip2 -- -myfilename 这里主要是为了防止文件名中-产生以为是选项的歧义。 bzcat 读取数据而无需解压 解压缩指定的.bz2文件，并显示解压缩后的文件内容。保留原压缩文件，并且不生成解压缩后的文件 bzcat(参数) #(参数) .bz2压缩文件：指定要显示内容的.bz2压缩文件。 将/tmp/man.config以bzip2格式压缩： bzip2 -z man.config 此时man.config会变成man.config.bz2 将上面的压缩文件内容读出来： bzcat man.config.bz2 此时屏幕上会显示 man.config.bz2 解压缩之后的文件内容。 tar 为linux的文件和目录创建档案 利用tar，可以为某一特定文件创建档案（备份文件），也可以在档案中改变文件，或者向档案中加入新的文件。tar最初被用来在磁带上创建档案，现在，用户可以在任何设备上创建档案。利用tar命令，可以把一大堆的文件和目录全部打包成一个文件，这对于备份文件或将几个文件组合成为一个文件以便于网络传输是非常有用的。 首先要弄清两个概念：打包和压缩。打包是指将一大堆文件或目录变成一个总的文件；压缩则是将一个大的文件通过一些压缩算法变成一个小文件。 为什么要区分这两个概念呢？这源于Linux中很多压缩程序只能针对一个文件进行压缩，这样当你想要压缩一大堆文件时，你得先将这一大堆文件先打成一个包（tar命令），然后再用压缩程序进行压缩（gzip bzip2命令）。 tar(选项)(参数) #(选项) -A或--catenate：新增文件到以存在的备份文件； -B：设置区块大小； -c或--create：建立新的备份文件； -C &lt;目录&gt;：这个选项用在解压缩，若要在特定目录解压缩，可以使用这个选项。 -d：记录文件的差别； -x或--extract或--get：从备份文件中还原文件； -t或--list：列出备份文件的内容； -z或--gzip或--ungzip：通过gzip指令处理备份文件； -Z或--compress或--uncompress：通过compress指令处理备份文件； -f&lt;备份文件&gt;或--file=&lt;备份文件&gt;：指定备份文件； -v或--verbose：显示指令执行过程； -r：添加文件到已经压缩的文件； -u：添加改变了和现有的文件到已经存在的压缩文件； -j：支持bzip2解压文件； -v：显示操作过程； -l：文件系统边界设置； -k：保留原有文件不覆盖； -m：保留文件不被覆盖； -w：确认压缩文件的正确性； -p或--same-permissions：用原来的文件权限还原文件； -P或--absolute-names：文件名使用绝对名称，不移除文件名称前的“/”号； -N &lt;日期格式&gt; 或 --newer=&lt;日期时间&gt;：只将较指定日期更新的文件保存到备份文件里； --exclude=&lt;范本样式&gt;：排除符合范本样式的文件。 #(参数) 文件或目录：指定要打包的文件或目录列表。 将文件全部打包成tar包： tar -jcvf filename.tar.bz2 要被压缩的档案或目录名称 #压 缩 tar -jtvf filename.tar.bz2 #查 询 tar -jxvf filename.tar.bz2 -C 欲解压缩的目录 #解压缩 tar -cvf log.tar log2012.log #仅打包，不压缩！ tar -zcvf log.tar.gz log2012.log #打包后，以 gzip 压缩 tar -jcvf log.tar.bz2 log2012.log #打包后，以 bzip2 压缩 在选项f之后的文件档名是自己取的，我们习惯上都用 .tar 来作为辨识。 如果加z选项，则以.tar.gz或.tgz来代表gzip压缩过的tar包；如果加j选项，则以.tar.bz2来作为tar包名。 查阅上述tar包内有哪些文件： tar -ztvf log.tar.gz 由于我们使用 gzip 压缩的log.tar.gz，所以要查阅log.tar.gz包内的文件时，就得要加上z这个选项了。 将tar包解压缩： tar -zxvf /opt/soft/test/log.tar.gz 在预设的情况下，我们可以将压缩档在任何地方解开的 只将tar内的部分文件解压出来： tar -zxvf /opt/soft/test/log30.tar.gz log2013.log 我可以透过tar -ztvf来查阅 tar 包内的文件名称，如果单只要一个文件，就可以透过这个方式来解压部分文件！ 文件备份下来，并且保存其权限： tar -zcvpf log31.tar.gz log2014.log log2015.log log2016.log 这个-p的属性是很重要的，尤其是当您要保留原本文件的属性时。 在文件夹当中，比某个日期新的文件才备份： tar -N “2012/11/13” -zcvf log17.tar.gz test 备份文件夹内容是排除部分文件： tar —exclude scf/service -zcvf scf.tar.gz scf/* 其实最简单的使用 tar 就只要记忆底下的方式即可： 压 缩：tar -jcv -f filename.tar.bz2 要被压缩的文件或目录名称 查 询：tar -jtv -f filename.tar.bz2 解压缩：tar -jxv -f filename.tar.bz2 -C 欲解压缩的目录 users 显示当前登录系统地用户 who 登录在本机的用户与来源 -H或--heading 显示各栏位的标题信息列。 w 登录在本机的用户及其运行的程序 -s 使用简洁格式列表，不显示用户登入时间，终端机阶段作业和程序所耗费的CPU时间。 -h 不显示各栏位的标题信息列。 write 给当前联机的用户发消息 wall 给所有登录再本机的用户发消息 last 查看用户的登陆日志 lastlog 查看每个用户最后的登陆时间 finger 查看用户信息 -s 显示用户的注册名、实际姓名、终端名称、写状态、停滞时间、登录时间等信息 -l 除了用-s选项显示的信息外，还显示用户主目录、登录shell、邮件状态等信息，以及用户主目录下的.plan、.project和.forward文件的内容。 -p 除了不显示.plan文件和.project文件以外，与-l选项相同 hostname 查看主机名 alias 添加别名 unalias 清除别名 chage **修改用户密码的相关属性 -l 列出该账号的详细密码参数； -d 后面接日期，修改 shadow 第三字段(最近一次更改密码的日期)，格式YYYY-MM-DD -E 后面接日期，修改 shadow 第八字段(账号失效日)，格式 YYYY-MM-DD -I 后面接天数，修改 shadow 第七字段(密码失效日期) -m 后面接天数，修改 shadow 第四字段(密码最短保留天数) -M 后面接天数，修改 shadow 第五字段(密码多久需要进行变更) -W 后面接天数，修改 shadow 第六字段(密码过期前警告日期) usermod 修改用户的相关属性 -c 后面接账号的说明，即 /etc/passwd 第五栏的说明栏，可以加入一些账号的说明。 -d 后面接账号的家目录，即修改 /etc/passwd 的第六栏； -e 后面接日期，格式是 YYYY-MM-DD 也就是在 /etc/shadow 内的第八个字段数据啦！ -f 后面接天数为 shadow 的第七字段。 -g 后面接初始群组，修改 /etc/passwd 的第四个字段，亦即是GID的字段！ -G 后面接次要群组，修改这个使用者能够支持的群组 -l 后面接账号名称。亦即是修改账号名称， /etc/passwd 的第一栏！ -s 后面接 Shell 的实际档案，例如 /bin/bash 或 /bin/csh 等等。 -u 后面接 UID 数字啦！即 /etc/passwd 第三栏的资料； -L 冻结密码 -U 解冻密码 id 查看用户相关的id信息，还可以用来判断用户是否存在 groups 查看登陆用户支持的群组， 第一个输出的群组为有效群组 newgrp 切换有效群组 groupmod 修改组信息 -g 修改既有的 GID 数字 -n 修改既有的组名 groupdel 删除群组 gpasswd 群组管理员功能 root管理员动作： -gpasswd groupname 设定密码 -gpasswd [-A user1,...] [-M user3,...] groupname -A 将 groupname 的主控权交由后面的使用者管理(该群组的管理员) -M 将某些账号加入这个群组当中 -gpasswd [-r] groupname -r 将 groupname 的密码移除 群组管理员动作： - gpasswd [-ad] user groupname -a 将某位使用者加入到 groupname 这个群组当中 -d 将某位使用者移除出 groupname 这个群组当中 chfn 修改个人信息 cut Print selected parts of lines from each FILE to standard output -b ：以字节为单位进行分割。这些字节位置将忽略多字节字符边界，除非也指定了 -n 标志。 -c ：以字符为单位进行分割。 -d ：自定义分隔符，默认为制表符。 -f ：与-d一起使用，指定显示哪个区域。 sort sort -n 依照数值的大小排序。 -o&lt;输出文件&gt; 将排序后的结果存入指定的文件。 -r 以相反的顺序来排序。 -t&lt;分隔字符&gt; 指定排序时所用的栏位分隔字符。 -k 选择以哪个区间进行排序。 set 显示环境变量和普通变量 env 显示环境变量 export 把普通变量变成环境变量 unset 删除一个环境变量 aaa(){} 定义函数 read read -p 接提示字符 -t 接等待的秒数 declare/typeset declare、typeset -i 声明为整数 -a 声明为数组 -f 声明为函数 -r 声明为只读 ulimit 限制使用者的某些系统资源 -f 此 shell 可以建立的最大档案容量 (一般可能设定为 2GB)单位为 Kbytes eg: ulimit -f 1024 限制使用者仅能建立 1MBytes 以下的容量的档案 date 显示或设定系统的日期与时间 date [参数]… [+格式] %H 小时(以00-23来表示)。 %M 分钟(以00-59来表示)。 %P AM或PM。 %D 日期(含年月日) %U 该年中的周数。 date -s “2015-10-17 01:01:01″ //时间设定 date +%Y%m%d //显示前天年月日 date +%Y%m%d --date=&quot;+1 day/month/year&quot; //显示前一天/月/年的日期 date +%Y%m%d --date=&quot;-1 day/month/year&quot; //显示后一天/月/年的日期 date -d &#39;2 weeks&#39; 2周后的日期 cal 查看日历 -1 显示当月的月历 -3 显示前、当、后一个月的日历 -m 显示星期一为一个星期的第一天 -s （默认）星期天为第一天 -j 显示当月是一年中的第几天的日历 -y 显示当前年份的日历 gcc 命令 对于一个用Linux开发C程序的人来说，这个命令就非常重要了，它用于把C语言的源程序文件，编译成可执行程序，由于g++的很多参数跟它非常相似，所以这里只介绍gcc的参数，它的常用参数如下： [plain] view plain copy print? -o ：output之意，用于指定生成一个可执行文件的文件名 -c ：用于把源文件生成目标文件（.o)，并阻止编译器创建一个完整的程序 -I ：增加编译时搜索头文件的路径 -L ：增加编译时搜索静态连接库的路径 -S ：把源文件生成汇编代码文件 -lm：表示标准库的目录中名为libm.a的函数库 -lpthread ：连接NPTL实现的线程库 -std= ：用于指定把使用的C语言的版本 # 例如： # 把源文件test.c按照c99标准编译成可执行程序test gcc -o test test.c -lm -std=c99 #把源文件test.c转换为相应的汇编程序源文件test.s gcc -S test.c time 测算一个命令（即程序）的执行时间 它的使用非常简单，就像平时输入命令一样，不过在命令的前面加入一个time即可，例如： [plain] view plain copy print? time ./process time ps aux 在程序或命令运行结束后，在最后输出了三个时间，它们分别是：user：用户CPU时间，命令执行完成花费的用户CPU时间，即命令在用户态中执行时间总和；system：系统CPU时间，命令执行完成花费的系统CPU时间，即命令在核心态中执行时间总和；real：实际时间，从command命令行开始执行到运行终止的消逝时间； 注：用户CPU时间和系统CPU时间之和为CPU时间，即命令占用CPU执行的时间总和。实际时间要大于CPU时间，因为Linux是多任务操作系统，往往在执行一条命令时，系统还要处理其它任务。另一个需要注意的问题是即使每次执行相同命令，但所花费的时间也是不一样，其花费时间是与系统运行相关的。 查看内存溢出 查看内存溢出 jmap -heap pid #打印heap的概要信息 jmap -histo pid #打印每个class的实例数目，内存占用，类全名信息 jmap -dump:format=b,file=heap.bin pid #输出heap信息到heap.bin文件 jhat -J-mx768m heap.bin #分析heap.bin文件 jstack -l pid &gt; deadlock.jstack #输出stack信息到deadlock.jstack vi deadlock.jstack #使用vi查看]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库之mysql（一）]]></title>
    <url>%2F2017%2F06%2F15%2Fcentos%E5%9C%A8%E7%BA%BF%E6%BA%90yum%E5%AE%89%E8%A3%85mysql%2F</url>
    <content type="text"><![CDATA[yum配置MySQL源并安装MySQL年前公司机房迁移，自然需要迁移数据库，定在凌晨4点左右停止服务拷贝数据，这之前需要搭好所有环境，数据拷贝到新机房服务器就启动所有生产服务，服务器版本时centos6.4 运维做的事全都落在了我的身上，在网上查了很多资料对比实践，最终考虑了两种方案，直接将数据通过mysqldump导出打包，由于数据量庞大，不锁表导出数个小时都没完事，而且锁表导出生产没法正常写，所以不停服务直接迁移思路放弃了。改用第二种直接迁移数据库文件目录，本地测试也行得通，但是遇到有数据库版本不一致遇到很多异常，所以最后保持与原生产服务器数据库版本一致迁移。 这段时间突然好些服务器磁盘出现问题，包括一台从库，害怕生产主库服务器挂掉，所以决定多做几台从库备份，以及生产环境应用程序环境备份。问题来了，从库已经挂掉了，当时没有停止主从同步，拷贝出来的数据库有问题，不能用，那么只能建空库，再执行同步，但是生产数据不能停止写，所以不能锁表进行同步。最后决定用当天的全量备份导入以后再进行同步，这样会丢失一部分数据，总体来说数据相差不会太大。 CentOS7默认数据库是mariadb,配置等用着不习惯,因此决定改成mysql,但是CentOS7的yum源中默认好像是没有mysql的。为了解决这个问题，我们要先下载mysql的repo源。 1.由于CentOS 的yum源中没有mysql，需要到mysql的官网下载yum repo配置文件 1wget http://dev.mysql.com/get/mysql57-community-release-el7-9.noarch.rpm 2.安装yum repo文件 1rpm -ivh mysql57-community-release-el7-9.noarch.rpm 执行完成后会在/etc/yum.repos.d/目录下生成两个repo文件mysql-community.repo mysql-community-source.repo 3.然后更新yum缓存 12yum clean all yum makecache 4.安装mysql 确认mysql是否已安装： 12yum list installed mysql* rpm -qa | grep mysql* 查看是否有安装包： 1yum list mysql* 安装客户端和服务器端 1yum install mysql-community-client.x86_64 mysql-community-common.x86_64 mysql-community-devel.x86_64 mysql-community-libs.x86_64 mysql-community-server.x86_64 或者 1rpm install mysql-server 指定版本安装(迁移mysql数据库时，为了避免不必要的错误，最好mysql版本一致，所以可以指定生产版本安装) 1yum install mysql-community-server-5.6.23-2.el6.x86_64 如果签名报错则到mysql官网下载校验文件将key复制进mysql签名文件及目录/etc/pki/rpm-gpg/RPM-GPG-KEY-mysql 或者修改/etc/yum.repos.d/mysql-community.repo文件 1修改gpgcheck=0即可跳过检查 5.启动mysql 1service mysqld start 6.查看初始密码（忘记修改root密码） 1grep &apos;temporary password&apos; /var/log/mysqld.log 得到如下内容： 12016-10-28T10:36:32.369073Z 1 [Note] A temporary password is generated for root@localhost: 5Oazqgpiat!p 如果没有找到，可以自行修改root密码 123456service mysqld stop #停止mysql服务，注意权限mysqld_safe --skip-grant-tables&amp; #也可以在配置文件中添加--skip-grant-tablesmysql -u root mysql #这里就不用指定-p了，直接登录use mysql #选择使用mysql数据库UPDATE user SET Password = PASSWORD(&apos;new password&apos;) WHERE user = &apos;root&apos;; #修改密码FLUSH PRIVILEGES; #刷新，生效 7.使用初始密码登录 1mysql -u root -p //回车，然后输入上一步查到的初始密码 8.更改初始密码 1ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;MyNewPass4!&apos;; 现在的mysql对密码强度要求较高，需要包含大小写字母、数字和特殊字符至此，mysql-server安装完成 9.允许远程访问设置 开放防火墙的端口号mysql增加权限：mysql库中的user表新增一条记录host为“%”，user为“root”。 12345use mysql;UPDATE user SET `Host` = &apos;%&apos; WHERE `User` = &apos;root&apos; LIMIT 1;# %表示允许所有的ip访问# 远程连接赋予权限grant all PRIVILEGES on *.* to &apos;root&apos;@&apos;%&apos; identified by &apos;password&apos; WITH GRANT OPTION; 创建用户，并赋予相应数据库的操作权限 1234CREATE USER &apos;ebook&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;ebook123&apos;;CREATE USER &apos;ebook&apos;@&apos;%&apos; IDENTIFIED BY &apos;ebook123&apos;;GRANT ALL ON ebook.* TO &apos;ebook&apos;@&apos;%&apos;;FLUSH PRIVILEGES; 查看数据库端口 1show global variables like &apos;port&apos;; 读写分离，主从配置主库IP：192.168.1.10 从库IP：192.168.1.11 1、主库配置编辑my.cnf： 12345678910111213141516171819log_bin = mysql-bin//开启二进制日志server-id = 10 //服务器id必须唯一，这里以ip最后一位表示log-bin-index=mysql-bin.indexsync_binlog=1binlog_format=mixedbinlog-do-db = testdb //需要进行同步数据库binlog-ignore-db = mysql //不需要同步的数据库，也可以不设置binlog-ignore-db = performance_schema //不需要同步的数据库，也可以不设置binlog-ignore-db = information_schema //不需要同步的数据库，也可以不设置binlog_checksum=NONE 2、创建同步账号 12mysql&gt; grant replication slave on *.* to slave@192.168.1.11 identified by &apos;123456&apos;# slave/123456为从库的用户名/密码,可以读写操作testdb库的 3、主库状态 1234567mysql&gt; flush privileges;mysql&gt; show master status;+------------------+----------+--------------+------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |+------------------+----------+--------------+------------------+| mysql-bin.000008 | 337 |testdb | mysql,performance_schema,information_schema |+------------------+----------+--------------+------------------+ 记录下二进制日志文件名(File)和位置(Position)对应的值 4、从库配置文件配置 1234567891011121314#[必须]启用二进制日志log-bin=mysql-bin#[必须]服务器唯一ID，默认是1，一般取IP最后一段server-id=11relay-log-index = slave-relay-bin.indexrelay-log = slave-relay-binsync_master_info = 1sync_relay_log = 1sync_relay_log_info = 1 5、配置连接主库 12mysql&gt; stop slave;mysql&gt; change master to master_host=&apos;192.168.1.10&apos;,master_user=&apos;slave&apos;,master_password=&apos;123456&apos;, master_log_file=&apos;mysql-bin.000008&apos;,master_log_pos=337; 6、开始同步 12mysql&gt; start slave;mysql&gt; show slave status\G; 7、正常状态 12Slave_IO_Running: YesSlave_SQL_Running: Yes 8、解决主从不同步 先上Master库： 123456789mysql&gt; show processlist; //查看下进程是否Sleep太多。发现很正常。mysql&gt; show master status; //也正常。+-------------------+----------+--------------+-------------------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |+-------------------+----------+--------------+-------------------------------+| mysqld-bin.000001 | 3260 |testdb | mysql,performance_schema,information_schema |+-------------------+----------+--------------+-------------------------------+1 row in set (0.00 sec) 再到Slave上查看 12345mysql&gt; show slave status\GSlave_IO_Running: YesSlave_SQL_Running: No 可见是Slave不同步 下面介绍两种解决方法： 方法一：忽略错误后，继续同步 该方法适用于主从库数据相差不大，或者要求数据可以不完全统一的情况，数据要求不严格的情况 解决： 1234567891011121314stop slave;#表示跳过一步错误，后面的数字可变set global sql_slave_skip_counter =1;start slave;#之后再查看：mysql&gt; show slave status\G Slave_IO_Running: YesSlave_SQL_Running: Yes ok，现在主从同步状态正常 方式二：重新做主从，完全同步 该方法适用于主从库数据相差较大，或者要求数据完全统一的情况 解决步骤如下： 1.先进入主库，进行锁表，防止数据写入 使用命令： 1mysql&gt; flush tables with read lock; 注意：该处是锁定为只读状态，语句不区分大小写 2.进行数据备份 把数据备份到mysql.bak.sql文件 1[root@server01 mysql]#mysqldump -uroot -p -hlocalhost &gt; mysql.bak.sql 这里注意一点：数据库备份一定要定期进行，确保数据万无一失 3.查看master 状态 1234567mysql&gt; show master status;+-------------------+----------+--------------+-------------------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |+-------------------+----------+--------------+-------------------------------+| mysqld-bin.000001 | 3260 |testdb | mysql,performance_schema,information_schema |+-------------------+----------+--------------+-------------------------------+1 row in set (0.00 sec) 4.把mysql备份文件传到从库机器，进行数据恢复 使用scp命令 1[root@server01 mysql]# scp mysql.bak.sql root@192.168.128.11:/tmp/ 5.停止从库的状态 1mysql&gt; stop slave; 6.然后到从库执行mysql命令，导入数据备份 10.创建数据库 123456789# localhost本地ipmysql&gt; create user &apos;slave&apos;@&apos;localhost&apos; identified by &apos;123456&apos;;# %代表外网任意ipmysql&gt; create user &apos;slave&apos;@&apos;%&apos; identified by &apos;123456&apos;;mysql&gt; grant all privileges on `testdb`.* to &apos;slave&apos;@&apos;%&apos; identified by &apos;123456&apos;;mysql&gt; flush privileges;mysql&gt; create database testdb DEFAULT CHARSET utf8 COLLATE utf8_general_ci;mysql&gt; use testdb;mysql&gt; source /tmp/mysql.bak.sql 7.设置从库同步，注意该处的同步点，就是主库show master status信息里的| File| Position两项 1change master to master_host = &apos;192.168.128.10&apos;, master_user = &apos;slave&apos;, master_port=3306, master_password=&apos;123456&apos;, master_log_file = &apos;mysqld-bin.000001&apos;, master_log_pos=3260; 8.重新开启从同步 1mysql&gt; start slave; 9.查看同步状态 12345mysql&gt; show slave status\G;Slave_IO_Running: YesSlave_SQL_Running: Yes 主从复制跳过错误mysql主从复制，经常会遇到错误而导致slave端复制中断，这个时候一般就需要人工干预，跳过错误才能继续跳过错误有两种方式： 1.跳过指定数量的事务： 123mysql&gt;slave stop;mysql&gt;SET GLOBAL SQL_SLAVE_SKIP_COUNTER = 1 #跳过一个事务mysql&gt;slave start 2.修改mysql的配置文件，通过slave_skip_errors参数来跳所有错误或指定类型的错误 1234vi /etc/my.cnf[mysqld]#slave-skip-errors=1062,1053,1146 #跳过指定error no类型的错误#slave-skip-errors=all #跳过所有错误 修改datadir位置，启动失败Mysql修改datadir导致无法启动问题解决方法,本文原因是SELINUX导致,用关闭SELINUX的方法解决 停止mysqld然后修改/etc/my.cnf datadir的位置，启动mysqld提示FAILED，查看日志 12345678120609 11:31:31 mysqld_safe mysqld from pid file /var/run/mysqld/mysqld.pid ended120609 11:35:12 mysqld_safe Starting mysqld daemon with databases from /data/mysql120609 11:35:13 [Warning] Can&apos;t create test file /data/mysql/data.lower-test120609 11:35:13 [Warning] Can&apos;t create test file /data/mysql/data.lower-test/usr/sbin/mysqld: Can&apos;t change dir to &apos;/data/mysql&apos; (Errcode: 13)120609 11:35:13 [ERROR] Aborting120609 11:35:13 [Note] /usr/libexec/mysqld: Shutdown complete120609 11:35:13 mysqld_safe mysqld from pid file /var/run/mysqld/mysqld.pid ended 新的datadir路径确实没问题，而且目录和目录下所有文件都是777权限，上层目录也有rx权限，只不过datadir和下属文件owner都是root,年前迁移也是这样的，不影响。后来查到资料说是selinux问题，设置为permissive模式之后正常启动mysqld。 1234567[root@data selinux]# getenforceEnforcing[root@data selinux]# setenforce 0[root@data selinux]# getenforcePermissivesetenforce 1 设置SELinux 成为enforcing模式setenforce 0 设置SELinux 成为permissive模式 或者彻底关闭，vi /etc/selinux/config 修改 SELINUX=disabled 12345678910# This file controls the state of SELinux on the system.# SELINUX= can take one of these three values:# enforcing - SELinux security policy is enforced.# permissive - SELinux prints warnings instead of enforcing.# disabled - No SELinux policy is loaded.SELINUX=disabled# SELINUXTYPE= can take one of these two values:# targeted - Targeted processes are protected,# mls - Multi Level Security protection.SELINUXTYPE=targeted 定期删除二进制文件对MySQL数据库的所有更新(增加、删除、修改)会被保存到MySQL的二进制日志文件里。有了这个二进制文件的话，我们可以对数据库进行回滚处理和复旧等处理。 一般就保留一份二进制文件即可，即保留主库的，从库不需要开启二进制文件，其作用如下： 1.数据恢复 如果你的数据库出问题了，而你之前有过备份，那么可以看日志文件，找出是哪个命令导致你的数据库出问题了，想办法挽回损失。 2.主从服务器之间同步数据 主服务器上所有的操作都在记录日志中，从服务器可以根据该日志来进行，以确保两个同步。 A：在每个从属服务器上，使用SHOW SLAVE STATUS来检查它正在读取哪个日志。B：使用SHOW MASTER LOGS获得主服务器上的一系列日志。C：在所有的从属服务器中判定最早的日志，这个是目标日志，如果所有的从属服务器是最新的，就是清单上的最后一个日志。D：清理所有的日志，但是不包括目标日志，因为从服务器还要跟它同步。 开启二进制日志 编辑文件： 1vi /etc/my.cnf 添加以下代码： 12log-bin=mysql-binbinlog_format=mixed 清理日志方法为： 手动清理，操作需谨慎有的时候不想让mysql服务停止，那我们可以用下面的方法来删除binary文件。我们可以看到产生了二进制文件 12345678910111213141516171819mysql&gt; show binary logs;+------------------+------------+| Log_name | File_size |+------------------+------------+| mysql-bin.000001 | 15056 | | mysql-bin.000002 | 628368 | | mysql-bin.000003 | 377 | | mysql-bin.000004 | 141 | | mysql-bin.000005 | 1073742287 | | mysql-bin.000006 | 1073742035 | | mysql-bin.000007 | 823654620 | | mysql-bin.000008 | 2265 | | mysql-bin.000009 | 628368 | | mysql-bin.000010 | 117 | | mysql-bin.000011 | 4525 | | mysql-bin.000012 | 117 | | mysql-bin.000013 | 3147 | | mysql-bin.000014 | 85468109 | +------------------+------------+ 二进制文件一般用来做replication同步，当查看slave上同步正确，或者是同步已经完成了，这时如果硬盘空间又不是很大的话，那我们可以手动去清理这些binary文件。 1mysql&gt; purge binary logs to &apos;mysql-bin.000013&apos;; 就是删除二进制文件到mysql-bin.000013，最后一个mysql-bin.000014 保留着。 重启mysql服务器 1service mysql restart 定期自动清理二进制文件的容量是非常庞大的，所以要配置日志滚动。 expire_logs_days 在MySQL数据库的my.cnf文件里添加expire_logs_days，7是保存二进制日志文件的天数。 修改my.cnf文件以后别忘了重启MySQL。 1/etc/my.cnf 添加一下代码 12345[mysqld]...expire_logs_days = 7 修改my.cnf的配置以后，不想重启数据库的可以使用SET GLOBAL命令。 1234567891011mysql&gt; SET GLOBAL expire_logs_days = 7;Query OK, 0 rows affected (0.00 sec)mysql&gt; SHOW GLOBAL VARIABLES like &apos;expire_logs_days&apos;;+------------------+-------+| Variable_name | Value |+------------------+-------+| expire_logs_days | 7 |+------------------+-------+1 row in set (0.00 sec) 全量备份和恢复 mysqldump默认是锁表进行备份的 注意，如果你运行mysqldump没有—quick或—opt选项，mysqldump将在导出结果前装载整个结果集到内存中，如果你正在导出一个大的数据库，这将可能是一个问题。 锁表进行备份时可能会影响业务操作，根据自身情况选择即可 打包成gz到当前目录 1mysqldump -h 192.168.167.55 -utest1 -ptest2 --opt --compress --single-transaction test3 | gzip &gt; test3.sql.gz 恢复备份数据库 12gunzip test3.sql.gz #解压mysql&gt;source test3.sql #恢复 直接备份并恢复到本地数据库 1mysqldump -h 192.168.167.55 -utest1 -ptest2 --opt --compress --skip-lock-tables | mysql -h localhost -uroot -proot database 解释： 192.168.167.55 远程服务器名称 test1 远程数据库登录名 test2 远程数据库登录密码 test3 远程数据库名（即：复制的源） localhost 本地数据库名称（一般情况下都是这个） root 本地数据库登录名（一般情况下都是这个） root 本地数据库登录密码（一般情况下都是这个） database 本地（即：复制的目标数据库） sql解释： mysqldump 是mysql的一个专门用于拷贝操作的命令 —single-transaction 不锁表进行备份 —opt 操作的意思 —compress 压缩要传输的数据 —skip-lock 忽略锁住的表（加上这句能防止当表有外键时的报错） -tables 某数据库所有表 -h 服务器名称 -u 用户名（后面无空格，直接加用户名） -p 密码（后面无空格，直接加密码） 注意： -u、-p的后面没有空格，直接加用户名和密码！！！ 如何将一个mysql数据库中的一个表导入到另一个mysql数据库中 db1为原数据库，db2为要导出到的数据库，fromtable 是要导出的表名 1.方法一： 登录导出到的数据库，执行 create table fromtable select * from db1.fromtable; 跨服务器 2.方法二： mysqldump -h 192.168.135.12 -u root -p db1 fromtable &gt;&gt; ~/fromtable.sql; 输入秘密，root为用户名 登录db2 执行 source ~/fromtable.sql; 3.方法三： 登录db1 执行 select * from fromtable into outfile “~/fromtable .txt”; 导出纯数据格式 登录db2 执行 load data infile ~/fromtable .txt into table fromtable; 需要先建一张和原表结构一样的空表。]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Generics]]></title>
    <url>%2F2017%2F06%2F12%2FJava%20Generics%2F</url>
    <content type="text"><![CDATA[今天看了下Java的官方教程中关于泛型的部分。泛型引起我的注意是因为微博上一篇比较List&lt;?&gt;和List&lt;Object&gt;的文章。最近看Lucene的代码，其中Util部分大量的使用了泛型，今天刚好浮生修得一日闲便全面的学习一下Java的泛型。其中很多内容都与直觉相符，所以我觉得不值得通篇翻译，这里仅就我觉得有趣也反直觉的地方做一个总结。 The Java™ Tutorials Lesson: Generics 命名规则C++和Java中都学习过泛型，可是从来觉得写T就跟写for循环中的i一样，也就是约定俗成，谁知这里还是有一些规则的。 E - Element (used extensively by the Java Collections Framework) K - Key N - Number T - Type V - Value S, U, V etc. - 2nd, 3rd, 4th types The Diamond在Java 7及以后的版本中，当调用泛型类的构造函数时，可以省去类型参数，只使用一组空的尖括号，只要在编译期类型可以被编译器确定或者推导出来。这对尖括号，就叫作diamond。比如我们可以像如下这样声明一个链表： 1List&lt;String&gt; list = new ArrayList&lt;&gt;(); diamond在英文中可以指扑克牌中的方片，两个尖括号放在一起&lt;&gt;，的确像一个方片。 Multiple BoundsList&lt;? extends A&gt; 和 List&lt;? super A&gt;代表类型为A的子类和A的父类的链表类型。这里的语法称为upper bound和lower bound。这些都是非常基础的知识了。但是类型参数可以有多个bounds，这样的写法并不常见。如: 1&lt;T extends A &amp; B &amp; C&gt; 需要注意的是，如果A、B、C中有一个为类，其余为接口的话，类必须写到第一个的位置，否则会在编译时报错。 Unbounded Wildcardunbounded wildcard在两种情形下很有用： 当你在写一个只需要类Object提供的功能就能够完成的方法时 当使用的泛型类中的方法并不依赖于泛型参数时。比如List.clear或List.size。实际上，我们经常使用Class&lt;?&gt;，因为Class&lt;T&gt;中的大部分方法都和T无关。 考虑下面的方法： 12345public static void printList(List&lt;Object&gt; list) &#123; for (Object elem : list) System.out.println(elem + &quot; &quot;); System.out.println();&#125; printList的目的是打印任意类型的列表，但是上面的函数却做不到。它只能打印Object的List，无法打印List&lt;Integer&gt;，List&lt;String&gt;或List&lt;Double&gt;，因为它们都不是List&lt;Object&gt;的子类。为了写一个泛型的printList，需要使用List&lt;?&gt;： 12345public static void printList(List&lt;?&gt; list) &#123; for (Object elem: list) System.out.print(elem + &quot; &quot;); System.out.println();&#125; 因为对任何具体类型A，List&lt;A&gt;是List&lt;?&gt;的子类。 需要特别注意的是，List&lt;Object&gt;和List&lt;?&gt;是不一样的。你可以往List&lt;Object&gt;插入Object和其他Object的子类。但是你只能往List&lt;?&gt;中插入null。 Lower Bounded Wildcard你可以为一个Wildcard指定Upper Bound或者Lower Bound，但是不能同时指定。 Wildcards and Subtyping The common parent is List&lt;?&gt; A hierarchy of several generic List class declarations. Guidelines for Wildcard Use为了讨论的方便，我们假设一个变量提供下面的两种功能： “In”变量，为函数提供输入数据 “Out”变量，为函数提供输出 Wildcard Guidelines： “In”变量用Upper Bounded Wildcard定义，使用extends关键字 “Out”变量用Lower Bounded Wildcard定义，使用super关键字 当”In”变量可以用Object中定义的方法访问时，使用Unbounded Wildcard 当变量同时作为”In”和”Out”时，不要使用Wildcard 这份Guideline并不适用于函数的返回值类型，应该避免使用wildcard作为函数的返回值类型。 泛型的限制 不能用基本类型实例化泛型 不能创建类型参数的实例 你不能创建类型参数的实例，但是可以使用反射创建。 不能创建包含类型参数的static成员 因为所有类的实例都共同拥有static成员，但是可以创建和类的类型参数不同的泛型static函数 不能创建参数类型的数组 1234Object[] stringLists = new List&lt;String&gt;[]; // compiler error, but pretend it&apos;s allowedstringLists[0] = new ArrayList&lt;String&gt;(); // OKstringLists[1] = new ArrayList&lt;Integer&gt;(); // An ArrayStoreException should be thrown, // but the runtime can&apos;t detect it. 如果允许创建类型参数的数组，上面的代码将会抛出ArrayStoreException 不能创建，catch或throw参数类型的对象 泛型类不能直接或间接继承Throwable。 12345// Extends Throwable indirectlyclass MathException&lt;T&gt; extends Exception &#123; /** ... **/ &#125; // compile-time error// Extends Throwable directlyclass QueueFullException&lt;T&gt; extends Throwable &#123; /** ... **/ // compile-time error 一个方法不能catch类型参数的实例 12345678public static &lt;T extends Exception, J&gt; void execute(List&lt;J&gt; jobs) &#123; try &#123; for (J job : jobs) // ... &#125; catch (T e) &#123; // compile-time error // ... &#125;&#125; 然而，可以在throws子句中使用类型参数 12345class Parser&lt;T extends Exception&gt; &#123; public void parse(File file) throws T &#123; // OK // ... &#125;&#125; 不能拥有在Type Erasure之后签名一样的重载函数 1234public class Example &#123; public void print(Set&lt;String&gt; strSet) &#123; &#125; public void print(Set&lt;Integer&gt; intSet) &#123; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>泛型</tag>
        <tag>Generics</tag>
        <tag>Wildcard</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown-语法说明]]></title>
    <url>%2F2017%2F05%2F30%2FMarkdown-%E8%AF%AD%E6%B3%95%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[斜体和粗体 代码: 1.*斜体* 或者 _斜体_ 2.**粗体** 3.***加粗斜体*** 4.~~删除线~~ 显示效果: 1.斜体 或者 斜体 2.粗体 3.加粗斜体 4.删除线 分级标题 写法1，代码: # 一级标题 ## 二级标题 ### 三级标题 #### 四级标题 ##### 五级标题 ###### 六级标题 效果如下： 一级标题二级标题三级标题四级标题五级标题六级标题 写法2，代码: 一级标题 ============================ 二级标题 ---------------------------- 效果如下： 一级标题二级标题 超链接 Markdown 支持两种形式的链接语法： 行内式和参考式两种形式，行内式一般使用较多。 行内式 语法说明： []里写链接文字，()里写链接地址, ()中的”“中可以为链接指定title属性，title属性可加可不加。title属性的效果是鼠标悬停在链接上会出现指定的 title文字。链接文字’这样的形式。链接地址与链接标题前有一个空格。 代码： 欢迎来到[jet&#39;s blog](http://jethan.bid/) 欢迎来到[jet&#39;s blog](http://jethan.bid/ &quot;jet&#39;s blog&quot;) 显示效果： 欢迎来到jet’s blog 欢迎来到jet’s blog 参考式 参考式超链接一般用在学术论文上面，或者另一种情况，如果某一个链接在文章中多处使用，那么使用引用 的方式创建链接将非常好，它可以让你对链接进行统一的管理。 语法说明：参考式链接分为两部分，文中的写法 [链接文字][链接标记]，在文本的任意位置添加[链接标记]:链接地址 “链接标题”，链接地址与链接标题前有一个空格。 如果链接文字本身可以做为链接标记，你也可以写成[链接文字][][链接文字]：链接地址的形式，见代码的最后一行。 代码： 1.我经常去的几个网站[Google][1]、[印象笔记][2]以及[自己的博客][3] 2.[印象 笔记][2]是一个不错的[网站][]。 3.[1]:http://www.google.com &quot;Google&quot; 4.[2]:https://app.yinxiang.com &quot;印象笔记&quot; 5.[3]:http://jethan.bid &quot;jet&#39;s blog&quot; 6.[网站]:https://app.yinxiang.com 显示效果： 我经常去的几个网站Google、印象笔记以及自己的博客 印象 笔记是一个不错的网站。 自动链接 语法说明：Markdown 支持以比较简短的自动链接形式来处理网址和电子邮件信箱，只要是用&lt;&gt;包起来， Markdown 就会自动把它转成链接。一般网址的链接文字就和链接地址一样，例如： 代码： https://www.baidu.com/ &lt;fajie_han@foxmail.com&gt; 显示效果： https://www.baidu.com/ &#102;&#97;&#x6a;&#x69;&#x65;&#95;&#x68;&#x61;&#110;&#x40;&#102;&#x6f;&#x78;&#109;&#97;&#x69;&#108;&#46;&#99;&#111;&#x6d; 列表无序列表 使用 *，+，- 表示无序列表 代码： - 无序列表项 一 + 无序列表项 二 * 无序列表项 三 显示效果： 无序列表项 一 无序列表项 二 无序列表项 三 有序列表 有序列表则使用数字接着一个英文句点。 代码： 1. 有序列表项 一 2. 有序列表项 二 3. 有序列表项 三 显示效果： 1.有序列表项 一 2.有序列表项 二 3.有序列表项 三 定义型列表 语法说明： 定义型列表由名词和解释组成。一行写上定义，紧跟一行写上解释。解释的写法:紧跟一个缩进(Tab) 代码： Markdown : 轻量级文本标记语言，可以转换成html，pdf等格式（左侧有一个可见的冒号和四个不可见的空格） 代码块 2 : 这是代码块的定义（左侧有一个可见的冒号和四个不可见的空格） 代码块（左侧有八个不可见的空格） 显示效果： Markdown 轻量级文本标记语言，可以转换成html，pdf等格式 代码块 2 这是代码块的定义 代码块（左侧有八个不可见的空格） 列表缩进 语法说明： 列表项目标记通常是放在最左边，但是其实也可以缩进，最多 3 个空格，项目标记后面则一定要接着至少一个空格或制表符。要让列表看起来更漂亮，你可以把内容用固定的缩进整理好（显示效果与代码一致）： 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！ 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩。 但是如果你懒，那也行： 代码： * 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。 那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。 软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！ * 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。 寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。 但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！ 悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩。 显示效果： 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！ 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩。 包含引用的列表 语法说明： 如果要在列表项目内放进引用，那 &gt; 就需要缩进： 代码： * 阅读的方法: &gt; 打开书本。 &gt; 打开电灯。 显示效果： 阅读的方法 打开书本。 打开电灯。 包含代码区块的引用 语法说明： 如果要放代码区块的话，该区块就需要缩进两次，也就是 8 个空格或是 2 个制表符： 一列表项包含一个列表区块： &lt;代码写在这&gt; 一个特殊情况 在特殊情况下，项目列表很可能会不小心产生，像是下面这样的写法： 1986. What a great season. 会显示成： What a great season. 换句话说，也就是在行首出现数字-句点-空白，要避免这样的状况，你可以在句点前面加上反斜杠： 1986\. What a great season. 会显示成： 1986. What a great season. 引用 语法说明： 引用需要在被引用的文本前加上&gt;符号。 代码： &gt; 这是一个有两段文字的引用, &gt; 无意义的占行文字1. &gt; 无意义的占行文字2. &gt; 无意义的占行文字3. &gt; 无意义的占行文字4. 显示效果： 这是一个有两段文字的引用, 无意义的占行文字1. 无意义的占行文字2. 无意义的占行文字3. 无意义的占行文字4. 引用的多层嵌套 区块引用可以嵌套（例如：引用内的引用），只要根据层次加上不同数量的 &gt; ： 代码： &gt;&gt;&gt; 请问 Markdwon 怎么用？ - 小白 &gt;&gt; 自己看教程！ - 愤青 &gt; 教程在哪？ - 小白 显示效果： 请问 Markdwon 怎么用？ - 小白 自己看教程！ - 愤青 教程在哪？ - 小白 引用其它要素 引用的区块内也可以使用其他的 Markdown 语法，包括标题、列表、代码区块等： 代码： &gt; 1. 这是第一行列表项。 &gt; 2. 这是第二行列表项。 &gt; &gt; 给出一些例子代码： &gt; &gt; return shell_exec(&quot;echo $input | $markdown_script&quot;); 显示效果： 这是第一行列表项。 这是第二行列表项。 给出一些例子代码： return shell_exec(“echo $input | $markdown_script”); 插入图像 图片的创建方式与超链接相似，而且和超链接一样也有两种写法，行内式和参考式写法。语法中图片Alt的意思是如果图片因为某些原因不能显示，就用定义的图片Alt文字来代替图片。 图片Title则和 链接中的Title一样，表示鼠标悬停与图片上时出现的文字。 Alt 和 Title 都不是必须的，可以省略，但建议写上。 行内式 语法说明： ![图片Alt](图片地址 “图片Title”) 代码： 阿狸： ![阿狸](http://jethan.bid/img/ali.jpg &quot;阿狸&quot;) 显示效果： 阿狸： 参考式 语法说明： 在文档要插入图片的地方写![图片Alt][标记] 在文档的最后写上[标记]:图片地址 “Title” 代码： 1.阿狸： 2.![阿狸][Ali] 3.[Ali]:http://jet-han.oschina.io/img/ali.jpg &quot;阿狸&quot; 显示效果： 阿狸： 注脚 语法说明： 在需要添加注脚的文字后加上脚注名字注脚名字,称为加注。 然后在文本的任意位置(一般在最后)添加脚注， 脚注前必须有对应的脚注名字。 注意：经测试注脚与注脚之间必须空一行，不然会失效。成功后会发现，即使你没有把注脚写在文末，经Markdown转换后，也会自动归类到文章的最后。 代码： 1.使用 Markdown[^1]可以效率的书写文档, 直接转换成 HTML[^2], 你可以使用 Leanote[^Le] 编辑器进行书写。 2. 3.[^1]:Markdown是一种纯文本标记语言 4. 5.[^2]:HyperText Markup Language 超文本标记语言 #此处有空格会不起作用 6. 7.[^Le]:开源笔记平台，支持Markdown和笔记直接发为博文 显示效果： 使用 Markdown1可以效率的书写文档, 直接转换成 HTML2, 你可以使用 LeanoteLe 编辑器进行书写。 LaTeX 公式渲染MathJax数学公式 在用markdown写技术文档时，免不了会碰到数学公式。常用的Markdown编辑器都会集成Mathjax，用来渲染文档中的类Latex格式书写的数学公式。基于Hexo搭建的个人博客，默认情况下渲染数学公式却会出现各种各样的问题。 原因 Hexo默认使用”hexo-renderer-marked”引擎渲染网页，该引擎会把一些特殊的markdown符号转换为相应的html标签，比如在markdown语法中，下划线’_’代表斜体，会被渲染引擎处理为&lt;\em&gt;标签。 因为类Latex格式书写的数学公式下划线 ‘_’ 表示下标，有特殊的含义，如果被强制转换为&lt;\em&gt;标签，那么 MathJax引擎在渲染数学公式的时候就会出错。例如，$x_i$在开始被渲染的时候，处理为$x&lt;\em&gt;i&lt;\/em&gt;$，这样MathJax引擎就认为该公式有语法错误，因为不会渲染。 类似的语义冲突的符号还包括’*’, ‘{‘, ‘}’, ‘\’等。 解决方法 更换Hexo的markdown渲染引擎，hexo-renderer-kramed引擎是在默认的渲染引擎hexo-renderer-marked的基础上修改了一些bug，两者比较接近，也比较轻量级。 npm uninstall hexo-renderer-marked --save npm install hexo-renderer-kramed --save 执行上面的命令即可，先卸载原来的渲染引擎，再安装新的。 然后，跟换引擎后行间公式可以正确渲染了，但是这样还没有完全解决问题，行内公式的渲染还是有问题，因为hexo-renderer-kramed引擎也有语义冲突的问题。接下来到博客根目录下，找到node_modules\kramed\lib\rules\inline.js，把第11行的escape变量的值做相应的修改： // escape: /^\\([\\`*{}\[\]()#$+\-.!_&gt;])/, escape: /^\\([`*\[\]()#$+\-.!_&gt;])/ 这一步是在原基础上取消了对\,{,}的转义(escape)。同时把第20行的em变量也要做相应的修改。 // em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/, em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/ 重新启动hexo（先clean再generate）,问题完美解决。哦，如果不幸还没解决的话，看看是不是还需要在使用的主题中配置mathjax开关。 在主题中开启mathjax开关 如何使用了主题了，别忘了在主题（Theme）中开启mathjax开关，下面以next主题为例，介绍下如何打开mathjax开关。 进入到主题目录，找到_config.yml配置问题，把mathjax默认的false修改为true，具体如下： # MathJax Support mathjax: enable: true per_page: true 别着急，这样还不够，还需要在文章的Front-matter里打开mathjax开关，如下： --- title: index.html date: 2016-12-28 21:01:30 tags: mathjax: true -- 不要嫌麻烦，之所以要在文章头里设置开关，是因为考虑只有在用到公式的页面才加载 Mathjax，这样不需要渲染数学公式的页面的访问速度就不会受到影响了。 $ 表示行内公式： 代码： 质能守恒方程可以用一个很简洁的方程式 $E=mc^2$ 来表达。 显示效果： 质能守恒方程可以用一个很简洁的方程式 $E=mc^2$ 来表达。 $$ 表示整行公式： 代码： $$\sum_{i=1}^n a_i=0$$ $$f(x_1,x_x,\ldots,x_n) = x_1^2 + x_2^2 + \cdots + x_n^2 $$ $$\sum^{j-1}_{k=0}{\widehat{\gamma}_{kj} z_k}$$ 显示效果： \sum_{i=1}^n a_i=0f(x_1,x_x,\ldots,x_n) = x_1^2 + x_2^2 + \cdots + x_n^2\sum^{j-1}_{k=0}{\widehat{\gamma}_{kj} z_k}访问 MathJax 参考更多使用方法。 流程图 代码： &lt;div id=&quot;flowchart-0&quot; class=&quot;flow-chart&quot;&gt;&lt;/div&gt; 显示效果： Install Generate flowchart diagrams for Hexo. npm install —save hexo-filter-flowchart config In your site’s _config.yml: flowchart: raphael: http://cdnjs.cloudflare.com/ajax/libs/raphael/2.2.7/raphael.min.js flowchart: https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.6.5/flowchart.min.js 表格 语法说明： 不管是哪种方式，第一行为表头，第二行分隔表头和主体部分，第三行开始每一行为一个表格行。 列于列之间用管道符|隔开。原生方式的表格每一行的两边也要有管道符。 第二行还可以为不同的列指定对齐方向。默认为左对齐，在-右边加上:就右对齐。 代码： 为列指定方向写表格： | Item | Value | Qty | | :- | -: | :-: | | Computer | 1600 USD | 5 | | Phone | 12 USD| 12 | | Pipe | 1 USD| 234 | 原生方式写表格： |Item|Value|Qty| |-|-|-| |Computer|1600 USD|5| |Phone|12 USD|12| |Pipe|1 USD|234| 显示效果： 为列指定方向写表格： Item Value Qty Computer 1600 USD 5 Phone 12 USD 12 Pipe 1 USD 234 原生方式写表格： Item Value Qty Computer 1600 USD 5 Phone 12 USD 12 Pipe 1 USD 234 使用Echarts动态图表 在博客页面中引用js文件 在所用主题目录下layout_partial中的head.swig里加入： &lt;script src=&quot;http://echarts.baidu.com/dist/echarts.common.min.js&quot;&gt;&lt;/script&gt; 安装hexo-tag-echarts插件 npm install hexo-tag-echarts --save 使用范例 对于echarts实例，将其提供的option部分复制，形成下述代码即可。 {% echarts 400 '81%' %} { tooltip : { trigger: 'axis', axisPointer : { // 坐标轴指示器，坐标轴触发有效 type : 'shadow' // 默认为直线，可选为：'line' | 'shadow' } }, legend: { data:['利润', '支出', '收入'] }, grid: { left: '3%', right: '4%', bottom: '3%', containLabel: true }, xAxis : [ { type : 'value' } ], yAxis : [ { type : 'category', axisTick : {show: false}, data : ['周一','周二','周三','周四','周五','周六','周日'] } ], series : [ { name:'利润', type:'bar', itemStyle : { normal: { label: {show: true, position: 'inside'} } }, data:[200, 170, 240, 244, 200, 220, 210] }, { name:'收入', type:'bar', stack: '总量', itemStyle: { normal: { label : {show: true} } }, data:[320, 302, 341, 374, 390, 450, 420] }, { name:'支出', type:'bar', stack: '总量', itemStyle: {normal: { label : {show: true, position: 'left'} }}, data:[-120, -132, -101, -134, -190, -230, -210] } ] }; {% endecharts %} 效果显示 // 基于准备好的dom，初始化echarts实例 var myChart = echarts.init(document.getElementById('echarts4156')); // 指定图表的配置项和数据 var option = { tooltip : { trigger: 'axis', axisPointer : { // 坐标轴指示器，坐标轴触发有效 type : 'shadow' // 默认为直线，可选为：'line' | 'shadow' } }, legend: { data:['利润', '支出', '收入'] }, grid: { left: '3%', right: '4%', bottom: '3%', containLabel: true }, xAxis : [ { type : 'value' } ], yAxis : [ { type : 'category', axisTick : {show: false}, data : ['周一','周二','周三','周四','周五','周六','周日'] } ], series : [ { name:'利润', type:'bar', itemStyle : { normal: { label: {show: true, position: 'inside'} } }, data:[200, 170, 240, 244, 200, 220, 210] }, { name:'收入', type:'bar', stack: '总量', itemStyle: { normal: { label : {show: true} } }, data:[320, 302, 341, 374, 390, 450, 420] }, { name:'支出', type:'bar', stack: '总量', itemStyle: {normal: { label : {show: true, position: 'left'} }}, data:[-120, -132, -101, -134, -190, -230, -210] } ] }; // 使用刚指定的配置项和数据显示图表。 myChart.setOption(option); 分隔线 你可以在一行中用三个以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西。你也可以在星号或是减号中间插入空格。下面每种写法都可以建立分隔线： 代码： * * * *** ***** - - - --------------------------------------- 显示效果都一样： 代码 对于程序员来说这个功能是必不可少的，插入程序代码的方式有两种，一种是利用缩进(Tab), 另一种是利用”`”符号（一般在ESC键下方）包裹代码。 语法说明： 插入行内代码，即插入一个单词或者一句代码的情况，使用`code`这样的形式插入。插入多行代码，可以使用缩进或者“` code “`,具体看示例。注意： 缩进式插入前方必须有空行 行内式 代码： C语言里的函数 `scanf()` 怎么使用？ 显示效果： C语言里的函数 scanf() 怎么使用？ 缩进式多行代码 缩进 4 个空格或是 1 个制表符 一个代码区块会一直持续到没有缩进的那一行（或是文件结尾）。 代码： #include &lt;stdio.h&gt; int main(void) { printf(&quot;Hello world\n&quot;); } 显示效果： #include &lt;stdio.h&gt; int main(void) { printf(&quot;Hello world\n&quot;); } 用六个`包裹多行代码 代码： 12345#include &lt;stdio.h&gt;int main(void)&#123; printf(&quot;Hello world\n&quot;);&#125; 显示效果： 12345#include &lt;stdio.h&gt;int main(void)&#123;printf(&quot;Hello world\n&quot;);&#125; HTML 原始码 在代码区块里面， &amp; 、 &lt; 和 &gt; 会自动转成 HTML 实体，这样的方式让你非常容易使用 Markdown 插入范例用的 HTML 原始码，只需要复制贴上，剩下的 Markdown 都会帮你处理，例如： 代码： &lt;table&gt; &lt;tr&gt; &lt;th rowspan=&quot;2&quot;&gt;值班人员&lt;/th&gt; &lt;th&gt;星期一&lt;/th&gt; &lt;th&gt;星期二&lt;/th&gt; &lt;th&gt;星期三&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;李强&lt;/td&gt; &lt;td&gt;张明&lt;/td&gt; &lt;td&gt;王平&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; 显示效果： 值班人员 星期一 星期二 星期三 李强 张明 王平 自定义字体 在 主题配置 - NexT 使用文档 中提及了如何设置字体样式，这里就不再赘述了。如果想自定义字体大小以及颜色，可以直接在 Markdown 文档中使用 html 语法 &lt;font size=4 &gt; 这里输入文字，自定义大小 &lt;/font&gt; &lt;font color=&quot;#FF0000&quot;&gt; 这里输入文字，自定义颜色的字体 &lt;/font&gt; 效果： 这里输入文字，自定义大小 这里输入文字，自定义颜色的字体 st=>start: Start|past:>http://www.google.com[blank] e=>end: End:>http://www.google.com op1=>operation: My Operation|past op2=>operation: Stuff|current sub1=>subroutine: My Subroutine|invalid cond=>condition: Yes or No?|approved:>http://www.google.com c2=>condition: Good idea|rejected io=>inputoutput: catch something...|request st->op1(right)->cond cond(yes, right)->c2 cond(no)->sub1(left)->op1 c2(yes)->io->e c2(no)->op2->e{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);st=>start: Start|past:>http://www.google.com[blank] e=>end: End:>http://www.google.com op1=>operation: My Operation|past op2=>operation: Stuff|current sub1=>subroutine: My Subroutine|invalid cond=>condition: Yes or No?|approved:>http://www.google.com c2=>condition: Good idea|rejected io=>inputoutput: catch something...|request st->op1(right)->cond cond(yes, right)->c2 cond(no)->sub1(left)->op1 c2(yes)->io->e c2(no)->op2->e{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-1-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-1-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-1", options);]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo-NexT主题搭建个人博客]]></title>
    <url>%2F2017%2F05%2F27%2FHexo-NexT%E4%B8%BB%E9%A2%98%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[linux下搭建hexo之next主题个人博客，仅供参考！有问题请留言，谢谢支持！ 所需环境 下载安装nodejs和git(for linux)，声明一下我的搭建环境centos6.8 nodejs安装 准备命令： yum -y install gcc make gcc-c++ openssl-devel wget 载源码及解压： wget http://nodejs.org/dist/v0.10.26/node-v0.10.26.tar.gz tar -zvxf node-v0.10.26.tar.gz 编译及安装： make &amp;&amp; make install 验证是否安装配置成功： node -v 安装Express开发框架 npm install -g express npm install -g express-generator express -t ejs newsproject npm install 新建成功在nodesj目录下会生成newproject目录，其目录下大致有以下文件 bin 相关运行脚本 public 静态资源 routes 路由表 views 试图模板 app.js 视图文件夹 packge.json 项目依赖说明 启动项目 npm start 在浏览器访问http://127.0.0.1:3000/ 测试出现下面图视表示nodejs安装成功，并可以正常部署项目 node -v npm -v git安装 在线源安装 yum install git 安装Hexo命令解释 常用命令: hexo help #查看帮助 hexo init #初始化一个目录 hexo new &quot;postName&quot; #新建文章 hexo new page &quot;pageName&quot; #新建页面 hexo generate #生成网页, 可以在 public 目录查看整个网站的文件 hexo server #本地预览, &#39;Ctrl+C&#39;关闭 hexo deploy #部署.deploy目录 hexo clean #清除缓存, 强烈建议每次执行命令前先清理缓存, 每次部署前先删除 .deploy 文件夹 复合命令: hexo deploy -g #生成加部署 hexo server -g #生成加预览 简写： hexo n == hexo new hexo g == hexo generate hexo s == hexo server hexo d == hexo deploy 安装插件, plugin-name为插件名 npm install plugin-name --save #安装 npm update #升级 npm uninstall plugin-name #卸载 安装主题, repository为主题的 git 仓库, 为要存放在本地的目录名 git clone repository themes/theme-name 修改网站配置文件 theme: theme-name 在线源安装 npm install -g hexo-cli #g代表全局,npm默认为当前项目安装 hexo init #hexo初始化 npm install #安装依赖包 hexo g #生成静态资源生成public文件夹(浏览器访问资源) hexo s #启动服务 在浏览器访问：http://localhost:4000/ 便可查看hexo默认的主题 clone NexT主题,在blog根目录执行命令 git clone https://github.com/iissnan/hexo-theme-next themes/next clone完成后打开blog下的themes文件夹就可以看到有两个主题，一个是默认的，一个是刚刚clone的NexT主题站点配置文件_config.yml主题配置文件themes/next/_config.yml在站点配置文件_config.yml中进行搜索key为’theme’，如果没有theme就添加key为 theme，其值为next #Extensions ##Plugins: https://hexo.io/plugins/ ##Themes: https://hexo.io/themes/ #theme: landscape theme: next 需要注意的是theme: next ，冒号后面有一个空格 hexo clean #清除静态资源 hexo g hexo s 在浏览器中访问http://localhost:4000/ 便可看到效果 打开主题配置文件_config.yml找到Schemes，如下所示有三种方案可选，只需将#去掉就可以了，可以都尝试一下，选择喜欢的风格，修改之后不用重启服务直接刷新浏览器就能看到效果 #切换样式 #Schemes #scheme: Muse #scheme: Mist scheme: Pisces 到此本地资源基本上完成了，下面贴出站点配置_config.yml和主题配置themes/next/_config.yml里面注释了信息仅供参考 全局配置 _config.yml，配置文件的冒号”:”后面有空格 # Site #站点信息 title: Hank subtitle: Hank&#39;s Blog description: 关注WEB前端，前端开发 author: hank author_title: &#39;Web Developer &amp; Designer&#39; avatar: css/img/avatar.png location: &#39;Beijing, China&#39; follow: https://github.com/huangjihua/ language: zh-CN since: 2015 timezone: Asia/Beijing #时区 # URL #链接格式 url: http://blog.huangjihua.com #网址 root: / #根目录 permalink: post/:title.html #文章的链接格式 permalink_defaults: # Directory #目录 source_dir: source #源文件 public_dir: public #生成的网页文件 tag_dir: tags #标签 archive_dir: archives #归档 category_dir: categories #分类 code_dir: downloads/code i18n_dir: :lang #国际化 skip_render: # Writing #写作 new_post_name: :title.md #新文章标题 default_layout: post #默认模板(post page photo draft) titlecase: false #标题转换成大写 external_link: true #新标签页里打开连接 filename_case: 0 render_drafts: false post_asset_folder: false relative_link: false future: true highlight: #语法高亮 enable: true line_number: false #显示行号 auto_detect: true tab_replace: # Category &amp; Tag #分类和标签 default_category: uncategorized #默认分类 category_map: tag_map: # Date / Time format #日期时间格式 ## http://momentjs.com/docs/#/displaying/format/ date_format: YYYY-MM-DD time_format: HH:mm:ss # Pagination #分页 per_page: 20 #每页文章数, 设置成 0 禁用分页 pagination_dir: page # Extensions #插件和主题 ## 插件: http://hexo.io/plugins/ ## 主题: http://hexo.io/themes/ theme: next # Deployment #部署, huangjihua是我的用户名, 同时发布在 GitHub 和 GitCafe 上面 deploy: type: git repository: github: https://github.com/huangjihua/huangjihua.github.io.git,master gitcafe: https://gitcafe.com/huangjihua/huangjihua.git,master # Disqus #Disqus评论系统 disqus_shortname: plugins: #插件，例如生成 RSS 和站点地图的 - hexo-generator-feed - hexo-generator-sitemap # Assets css: css js: js images: images # Theme version version: 5.0.1 # Donate 文章末尾显示打赏按钮 reward_comment: 如果文章对您有用请随意打赏，谢谢支持！ wechatpay: /img/w.png alipay: /img/z.jpg 菜单栏 菜单栏为中文简体字，主题配置文件 language: zh-Hans 这样就引用了themes\next\languages\zh-Hans.yml文件，打开这个文件就可以看每个key对应的都是中文字体 标签和分类 在主题配置文件中找到menu，如果想隐藏菜单栏中的某个选项只要在前面加上 # 即可 menu: home: / categories: /categories #分类 archives: /archives #归档 tags: /tags #标签 message: /message #留言 about: /about #关于 # commonweal: /404.html #公益 我们将categories 和tags 设为显示,再找到menu_icons, 这里是每一个菜单选项前面对应的小图标icon menu_icons: enable: true #KeyMapsToMenuItemKey: NameOfTheIconFromFontAwesome home: home categories: th tags: tags archives: archive commonweal: heartbeat message: external-link about: user 我们将categories 和tags 设为显示,生成categories 和 tags的页面 hexo n page &quot;categories&quot; hexo n page &quot;tags&quot; 会生成source\categories 和 source\tags 两个文件夹，里面都有index.md文件.修改内容为 --- title: categories type: categories --- --- title: tags type: tags --- 再使用命令生成博文文件 hexo n &quot;name&quot; #name 文章名称 生成文章时，在对应的name.md中可以这样添加标签和分类 --- title: Hexo-NexT主题搭建个人博客 date: 2017-05-24 15:39:31 update: 2017-05-24 06:19:11 categories: hexo #分类 tags: [nodejs, hexo, next] #[标签1, 标签2..., 标签n] --- 网易云跟帖评论功能 主题配置文件 menu: home: / categories: /categories archives: /archives tags: /tags message: /message #新增 message about: /about #commonweal: /404.html 配置图标 menu_icons: enable: true home: home categories: th tags: tags archives: archive commonweal: heartbeat message: external-link #新增 message about: user 配置对应的中文名称，在themes/next/languages/zh-Hans.yml文件中修改如下 menu: home: 首页 archives: 归档 categories: 分类 tags: 标签 about: 关于 search: 搜索 message: 留言 #新增 留言 commonweal: 公益404 udpate: 更新 然后执行如下命令 hexo n page &quot;message&quot; 重新清除，生成和启动便可看到效果，只不过留言功能什么也没有 hexo clean hexo g hexo s 进入官网https://manage.gentie.163.com 进行注册、登录（可以用QQ）。登录完成在首页进入后台管理，填写基本信息（站点信息），获取代码找到 productKey的值，写入主题配置文件gentie_productKey处在主题配置文件中修改如下 # Gentie productKey gentie_productKey: your key 留言功能已完成去掉分类和其他的选项的留言功能，只需修改index.md在source/categories/index.md 中修改如下 --- title: categories type: categories comments: false #去掉评论功能 date: 2017-05-24 21:07:35 --- 修改头像 设置菜单栏头像把头像0.jpg图片放在themes/next/source/img中在站点的_config.yml，修改字段 avatar 设置头像 avatar: /img/0.jpg 可以指定网址图片url 侧边栏社交链接 侧栏社交链接的修改包含两个部分，第一是链接，第二是链接图标。 两者配置均在 主题配置文件 中。social 字段下，一行一个链接。其键值格式是 显示文本: 链接地址 ##Social links social: GitHub: https://github.com/your-user-name Twitter: https://twitter.com/your-user-name 微博: http://weibo.com/your-user-name 豆瓣: http://douban.com/people/your-user-name 知乎: http://www.zhihu.com/people/your-user-name #Social Icons 设定链接的图标，对应的字段是 social_icons。其键值格式是 匹配键: Font Awesome 图标名称， 匹配键 与上一步所配置的链接的 显示文本 相同（大小写严格匹配），图标名称 是 Font Awesome 图标的名字（不必带 fa- 前缀）。 enable 选项用于控制是否显示图标，你可以设置成 false 来去掉图标。 social_icons: enable: true #Icon Mappings GitHub: github Twitter: twitter 微博: weibo 友情链接 编辑 主题配置文件 添加： # Blogrolls links_title: 友情链接 links_layout: inline links_icon: link # 设置图标 links: 百度: http://www.baidu.com 文章配置开启阅读全文 修改主题配置文件 auto_excerpt: enable: true # 开启文章阅全文 length: 2000 # 显示长度 新增阅读量 为每一篇文章统计阅读量使用leancloud进行文章变更统计，进入官网https://leancloud.cn/ 注册打开LeanCloud官网，进入注册页面注册。完成邮箱激活后，点击头像，进入控制台页面创建新应用点击应用创建新应用，应用名称随便起创建Class文件进入到应用后点击存储，在左侧点击设置，选择”创建Class”，名称必须为Counter修改主题配置文件 ##文章阅读量 leancloud_visitors: enable: true app_id: **你的app_id** app_key: **你的app_key** 其中，app_id和app_key在你所创建的应用的设置-&gt;应用Key中修改 themes/next/layout_macro/post.swig 文件配置themes/next/layout/_layout.swig文件在最后div标签中查找是否引用了_scripts/third-party/lean-analytics.swig文件，如果没有增加以下代码修改语言配置文件 themes/next/languages/zh-Hans.yml post字段 post: sticky: 置顶 posted: 发表于 updated: 最近 update: 更新于 in: 分类于 visitors: 阅读量 read_more: 阅读全文 untitled: 未命名 toc_empty: 此文章未包含目录 其他语言与之类似，将visitors设置成你希望翻译的字段。最后，重新清除并生成你的网站即可。Web安全性为了保证应用的统计计数功能仅应用于自己的博客系统，你可以在应用-&gt;设置-&gt;安全中心的Web安全域名中加入自己的博客域名，以保证数据的调用安全。直接加上首页地址即可,保存三分之后生效，这时在本地方访问便不会统计。 文章最近更新时间 确保themes/next/layout_scripts/third-party/lean-analytics.swig文件已有update添加文章更新时间scaffolds/post.md 文件 --- title: {{ title }} date: {{ date }} categories: tags: update: {{ date }} # 新增更新时间 --- themes/next/layout_macro/post.swig 文件在每次新建文章时，默认更新时间就是发表时间，更新文章时需要手动修改udpate的值。例如source_posts\hexo之next主题.md --- title: Hexo之NexT主题搭建博客详细过程 date: 2017-05-24 15:39:31 update: 2017-05-24 15:39:31 #每次更新需手动修改成这样的格式时间 categories: hexo tags: [nodejs, hexo] --- 修改themes\next\languages\zh-Hans.yml post: sticky: 置顶 posted: 发表于 updated: 最近 update: 更新于 # 新增 in: 分类于 visitors: 阅读量 read_more: 阅读全文 untitled: 未命名 toc_empty: 此文章未包含目录 为文章增加分享 使用百度分享只修改主题配置文件即可 baidushare: type: button 为文章增加打赏 修改主题配置文件, 收款二维码放在themes/next/source/img 目录下 #Donate 文章末尾显示打赏按钮 reward_comment: 如果文章对您有用请随意打赏，谢谢支持！ wechatpay: /img/w.png alipay: /img/z.jpg 设置代码高亮主题 NexT 使用 Tomorrow Theme 作为代码高亮，共有5款主题供你选择。 NexT 默认使用的是 白色的 normal 主题，可选的值有 normal，night， night blue， night bright， night eighties：在主题配置文件中修改 # Code Highlight theme # Available value: # normal | night | night eighties | night blue | night bright # https://github.com/chriskempson/tomorrow-theme highlight_theme: night eighties # 修改即可 文章添加音乐链接 Hexo支持解析markdown语法，因此每篇博文都是以.md结尾的文件。而markdown又支持如表格、脚注、内嵌HTML等等，所以在.md文件中直接添加html代码！网音乐云音乐，虾米音乐都可以生成内嵌音乐的html代码，复制粘贴到.md文件中即可 &lt;div&gt; &lt;center&gt; &lt;iframe frameborder=&quot;no&quot; border=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; width=330 height=86 src=&quot;https://music.163.com/outchain/player?type=2&amp;id=33856282&amp;auto=0&amp;height=66&quot;&gt; &lt;/iframe&gt; &lt;/center&gt; &lt;/div&gt; 本地站内搜索 以前使用的Swiftype现在不能免费使用了，我这里就是用本地配置进行站内搜索安装 hexo-generator-search，在站点的根目录下执行以下命令: npm install hexo-generator-search --save 编辑 站点配置文件，新增以下内容到任意位置： search: path: search.xml field: post 不蒜子统计站点访次数和访问量 修改themes/next/layout/_partials目录下的footer.swig &lt;div class=&quot;total_count&quot;&gt; 本站共 &lt;span id=&quot;busuanzi_value_site_pv&quot;&gt;&lt;/span&gt;&lt;span id=&quot;site_pv&quot;&gt;次访问&lt;/span&gt; 您是第 &lt;span id=&quot;busuanzi_value_site_uv&quot;&gt;&lt;/span&gt;&lt;span id=&quot;site_uv&quot;&gt;个小伙伴&lt;/span&gt; 本页累计 &lt;span id=&quot;busuanzi_value_page_pv&quot;&gt;&lt;/span&gt;&lt;span id=&quot;page_pv&quot;&gt;次阅读&lt;/span&gt; &lt;span id=&quot;showDays&quot;&gt;&lt;/span&gt; &lt;/div&gt; {% endif %} 百度/google收录你的站点 安装sitemap插件 npm install hexo-generator-sitemap --save #google npm install hexo-generator-baidu-sitemap --save #百度 在站点配置文件_config.yml中添加如下代码： #自动生成sitemap sitemap: path: sitemap.xml baidusitemap: path: baidusitemap.xml 会在public目录下生成baidusitmap.xml 和 sitemap.xml两个文件安装hexo-deployer-git插件 npm install hexo-deployer-git --save #部署到github 在项目根目录下执行命令 hexo clean # 清除资源 hexo g # 生成静态资源 hexo d # 部署 登录在github打开存放博客资源的仓库，就能看到部署的资源文件分别向google,baidu提交站点地图sitemap.xml,baidusitmap.xml百度站长： http://zhanzhang.baidu.com/site/index输入你想添加的网站：你的博客首页地址然后按照提示选择验证方式，点击完成验证。 google站长： https://www.google.com/webmasters/tools/home?hl=zh-CN添加网站后，进行左侧抓取站点地图，添加/测试站点地图，填写sitemap.xml。sitemap.xml就在github存放博客 仓库的根目录下验证完成后大概过一天时间便可google到你的站点了，百度不定。 统计本站运行天数 修改blog/themes/next/layout_partials/footer.swig文件，在后面追加以下代码 &lt;script&gt; var birthDay = new Date(&#39;05/24/2016&#39;); var now = new Date(); var duration = now.getTime() - birthDay.getTime(); var total= Math.floor(duration / (1000 * 60 * 60 * 24)); document.getElementById(&#39;showDays&#39;).innerHTML=&#39;本站已运行&#39; + total + &#39;天&#39;; &lt;/script&gt; 在最后一个div中追加一下代码 &lt;span id=&quot;showDays&quot;&gt;&lt;/span&gt; 腾讯公益404页面 腾讯公益404页面，寻找丢失儿童，让大家一起关注此项公益事业！效果如下 http://www.ixirong.com/404.html 使用方法，新建 404.html 页面，放到主题的 source 目录下，内容如下： &lt;!DOCTYPE HTML&gt; &lt;html&gt; &lt;head&gt; &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html;charset=utf-8;&quot;/&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge,chrome=1&quot; /&gt; &lt;meta name=&quot;robots&quot; content=&quot;all&quot; /&gt; &lt;meta name=&quot;robots&quot; content=&quot;index,follow&quot;/&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://qzone.qq.com/gy/404/style/404style.css&quot;&gt; &lt;/head&gt; &lt;body&gt; &lt;script type=&quot;text/plain&quot; src=&quot;http://www.qq.com/404/search_children.js&quot; charset=&quot;utf-8&quot; homePageUrl=&quot;/&quot; homePageName=&quot;回到我的主页&quot;&gt; &lt;/script&gt; &lt;script src=&quot;https://qzone.qq.com/gy/404/data.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt; &lt;script src=&quot;https://qzone.qq.com/gy/404/page.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt; &lt;/body&gt; &lt;/html&gt; 到此本地资源博客搭建已经完成，有些细微调节可根据浏览器控制台找到对应的模板进行调节，比如站点背景，代码字体字体颜色，页面宽度等等(参考资源： http://gniba.com/2016/07/11/next-custom.html ) 托管到github 修改站点配置文件 # Deployment ## Docs: https://hexo.io/docs/deployment.html deploy: type: git repository: git@github.com:jethan/githug.git branch: master]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>个人博客</tag>
      </tags>
  </entry>
</search>