<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[equals、==和hashCode]]></title>
    <url>%2F2017%2F08%2F01%2Fequals%E3%80%81-%E5%92%8ChashCode%2F</url>
    <content type="text"><![CDATA[引言equals：是否同一个对象实例。注意，是“实例”。比如String s = new String(“test”); s.equals(s), 这就是同一个对象实例的比较； 等号(==)：对比对象实例的内存地址（也即对象实例的ID），来判断是否是同一对象实例；又可以说是判断对象实例是否物理相等； Hashcode：我觉得可以这样理解：并不是对象的内存地址，而是利用hash算法，对对象实例的一种描述符（或者说对象存储位置的hash算法映射）——对象实例的哈希码。 ==比较的是对象的地址String重写的equals比较的是字符串的内容值String重写的hashCode已经不是对象内存地址的hash码，是根据内容产生的，因为a、b是两个完全不同的对象，也满足这条规律“equals相等的两个对象，hashCode也相等”。System.identityHashCode是未被重写的获取对象内存地址hash码的函数，new出来的String对象的内存地址是不一样的，所以hash值也不一样 示例12345678910111213141516171819202122232425public class Test &#123; public static void main(String[] args) &#123; String a=new String(&quot;foo&quot;); String b=new String(&quot;foo&quot;); String c=&quot;hello&quot;; String d=&quot;hello&quot;; System.out.println(&quot;memory address hashcode a:&quot;+System.identityHashCode(a)); System.out.println(&quot;memory address hashcode a:&quot;+System.identityHashCode(b)); System.out.println(&quot;String hashcode a: &quot;+a.hashCode()); System.out.println(&quot;String hashcode a: &quot;+b.hashCode()); System.out.println(&quot;a==b: &quot;+(a==b)); System.out.println(&quot;a.equals(b): &quot;+a.equals(b)); System.out.println(&quot;&quot;); System.out.println(&quot;memory address hashcode c:&quot;+System.identityHashCode(c)); System.out.println(&quot;memory address hashcode d:&quot;+System.identityHashCode(d)); System.out.println(&quot;String hashcode c: &quot;+c.hashCode()); System.out.println(&quot;String hashcode d: &quot;+d.hashCode()); System.out.println(&quot;c==d: &quot;+(c==d)); System.out.println(&quot;c.equals(d): &quot;+c.equals(d)); &#125;&#125; 结果：123456789101112memory address hashcode a:8222510memory address hashcode a:18581223String hashcode a: 101574String hashcode a: 101574a==b: falsea.equals(b): truememory address hashcode c:3526198memory address hashcode d:3526198String hashcode c: 99162322String hashcode d: 99162322c==d: truec.equals(d): true 从Java集合的常用需求为什么需要使用HashcodeJava中的集合（Collection）有两类，一类是List，再有一类是Set。前者集合内的元素是有序的，元素可以重复；后者元素无序，但元素不可重复。那么这里就有一个比较严重的问题了：要想保证元素不重复，可两个元素是否重复应该依据什么来判断呢？这就是 Object.equals方法了。但是，如果每增加一个元素就检查一次，那么当元素很多时，后添加到集合中的元素比较的次数就非常多了。也就是说，如果集合中现在已经有1000个元素，那么第1001个元素加入集合时，它就要调用1000次equals方法。这显然会大大降低效率。 于是，Java采用了哈希表的原理。哈希算法也称为散列算法，是将数据依特定算法直接指定到一个地址上。可以这样简单理解，hashCode方法实际上返回的就是对象存储位置的映像。 这样一来，当集合要添加新的元素时，先调用这个元素的hashCode方法，就能定位到它应该放置的bucket存储位置。如果这个位置上没有元素，它就可以直接存储在这个位置上，不用再进行任何比较了；如果这个位置上已经有元素了，就调用它的equals方法与新元素进行比较，相同的话就不存了，不相同就表示发生冲突了，散列表对于冲突有具体的解决办法，但最终还会将新元素保存在适当的位置。这样一来，实际调用equals方法的次数就大大降低了，几乎只需要一两次。 简单归纳，hashmap的深入理解： HashMap的数据结构是基于数组和链表的。（以数组存储元素，如有hash相同的元素，在数组结构中，创建链表结构，再把hash相同的元素放到链表的下一个节点） hashMap的结构类似这样 元素0—&gt;[hashCode=0, key.value=x1的数据] 元素1—&gt;[hashCode=1, key.value=y1的数据] 。。。。。。 元素n—&gt;[hashCode=n, key.value=z1的数据] 假设没有hashCode=1的元素加入，但是有两个hashCode=0的数据，它的结构就变成这样 元素0—&gt;[hashCode=0, key.value=x1的数据].next—&gt;[hashCode=0, key.value=x2的数据] 元素1—&gt;[null] …… 元素n—&gt;[hashCode=n, key.value=z1的数据] put和get都首先会调用hashcode方法，去查找相关的key，当有冲突时，再调用equals（这也是为什么刚开始就重温hashcode和equals的原因）！HashMap基于hashing原理，我们通过put()和get()方法储存和获取对象。当我们将键值对传递给put()方法时，它调用键对象的hashCode()方法来计算hashcode，让后找到bucket位置来储存值对象。当获取对象时，通过键对象的equals()方法找到正确的键值对，然后返回值对象。HashMap使用链表来解决碰撞问题，当发生碰撞了，对象将会储存在链表的下一个节点中。 HashMap在每个链表节点中储存键值对对象。 当两个不同的键对象的hashcode相同时会发生什么？ 它们会储存在同一个bucket位置的链表中。键对象的equals()方法用来找到键值对。 HashMap的工作原理HashMap基于hashing原理，我们通过put()和get()方法储存和获取对象。当我们将键值对传递给put()方法时，它调用键对象的hashCode()方法来计算hashcode，让后找到bucket位置来储存值对象。当获取对象时，通过键对象的equals()方法找到正确的键值对，然后返回值对象。HashMap使用链表来解决碰撞问题，当发生碰撞了，对象将会储存在链表的下一个节点中。 HashMap在每个链表节点中储存键值对对象。 当两个不同的键对象的hashcode相同时会发生什么？ 它们会储存在同一个bucket位置的链表中。键对象的equals()方法用来找到键值对。 重写 equals 的时候必须重写 hashCodeSUN官方的文档中规定”如果重定义equals方法，就必须重定义hashCode方法,以便用户可以将对象插入到散列(哈希)表中” 那么 SUN 公司是出于什么考虑做了这个规定呢？ 在集合框架中的HashSet，HashTable和HashMap都使用哈希表的形式存储数据，而hashCode计算出来的哈希码便是它们的身份证。哈希码的存在便可以： 快速定位对象，提高哈希表集合的性能。只有当哈希表中对象的索引即hashCode和对象的属性即equals同时相等时，才能够判断两个对象相等。从上面可以看出，哈希码主要是为哈希表服务的，其实如果不需要使用哈希表，也可以不重写hashCode。但是SUN公司应该是出于对程序扩展性的考虑（万一以后需要将对象放入哈希表集合中），才会规定重写equals的同时需要重写hashCode，以避免后续开发不必要的麻烦。 重写equals的注意事项 Java语言规范要求equals需要具有如下的特性： 自反性：对于任何非空引用 x，x.equals() 应该返回 true。对称性：对于任何引用 x 和 y，当且仅当 y.equals(x) 返回 true，x.equals(y) 也应该返回 true。传递性：对于任何引用 x、y 和 z，如果 x.equals(y)返回 true，y.equals(z) 也应返回同样的结果。一致性：如果 x 和 y 引用的对象没有发生变化，反复调用 x.equals(y) 应该返回同样的结果。对于任意非空引用 x，x.equals(null) 应该返回 false。在对象比较时，我们应该如何编写出一个符合特性的 equals 方法呢，《Core Java》中提出了如下建议： 显式参数命名为 otherObject，稍后将它转换成另一个叫做 other 的变量。检测 this 与 otherObject 是否引用同一个对象： if (this == otherObject) return true;计算这个等式可以避免一个个比较类中的域，实现优化。 检测 otherObject 是否为 null，如果为 null，返回 false。进行非空校验是十分重要的。 比较 this 与 otherObject 是否属于同一个类。 如果每个子类都重写了 equals，使用 getClass 检验：12if (getClass() != otherObject.getClass()) return false; 如果所有子类都使用同一个 equals，就用 instanceof 检验：12if (!(otherObject instanceof ClassName)) return false; 将 otherObject 转换为相应的类型变量。1ClassName other = (ClassName) otherObject; 现在可以对所有需要比较的域进行比较了。 基本类型使用 == 比较对象使用 equals 比较数组类型的域可以使用静态方法 Arrays.equals检测相应数组元素是否相等如果所有域匹配，则返回 true注意：子类重写父类 equals 方法时，必须完全覆盖父类方法，不能因为类型错误或者其他原因定义了一个完全无关的方法。可以使用 @Override 注解对覆盖父类的方法进行标记，这样编译器便会检测到覆盖过程中的错误。 重写 hashCode 的注意事项散列码（hash code）是由对象导出的一个整型值。散列码没有规律，在不同的对象中通过不同的算法生成，Java中生成 hashCode 的策略为（以下说明均摘自 Java API 8）： String 类的 hashCode 根据其字符串内容，使用算法计算后返回哈希码。1Returns a hash code for this string. The hash code for a String object is computed as s[0]*31^(n-1) + s[1]*31^(n-2) + ... + s[n-1] Integer 类返回的哈希码为其包含的整数数值。1Returns: a hash code value for this object, equal to the primitive int value represented by this Integer object. Object 类的 hashCode 返回对象的内存地址经过处理后的数值。1Returns a hash code value for the object. This method is supported for the benefit of hash tables such as those provided by HashMap. 在自己的类中想要重写 hashCode 的话一般怎么做呢？建议合理地组合实例域的散列码，让各个不同对象产生的散列码更加均匀。例如我们现在有一个 Cat 对象，它有 name、size 和 color 三个不同域，那么可以重写 hashCode 方法如下： 12345678910class Cat &#123; ...... public int hashCode() &#123; //hashCode是可以返回负值的 return 6 * name.hashCode() + 8 * new Double(size).hashCode() + 10 * color.hashCode(); &#125; ......&#125; 当然还有更好的做法，我们可以直接调用静态方法 Objects.hash 并提供多个参数。这个方法会对各个参数调用 Object.hashCode，并组合返回的散列码。故以上的方法可以缩写为：123public int hashCode() &#123; return Objects.hash(name, size, color);&#125; 【注意】 equals与hashCode的定义必须一致，两个对象equals为true，就必须有相同的hashCode。例如：如果定义的equals比较的是小猫的 name，那么hashCode就需要散列该 name，而不是小猫的 color 或 size。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap工作原理]]></title>
    <url>%2F2017%2F07%2F28%2FHashMap%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[引言HashMap的工作原理是近年来常见的Java面试题。几乎每个Java程序员都知道HashMap，都知道哪里要用HashMap，知道Hashtable和HashMap之间的区别，那么为何这道面试题如此特殊呢？是因为这道题考察的深度很深。这题经常出现在高级或中高级面试中。投资银行更喜欢问这个问题，甚至会要求你实现HashMap来考察你的编程能力。ConcurrentHashMap和其它同步集合的引入让这道题变得更加复杂。让我们开始探索的旅程吧！ HashMap“你用过HashMap吗？” “什么是HashMap？你为什么用到它？” 几乎每个人都会回答“是的”，然后回答HashMap的一些特性，譬如HashMap可以接受null键值和值，而Hashtable则不能；HashMap是非synchronized;HashMap很快；以及HashMap储存的是键值对等等。这显示出你已经用过HashMap，而且对它相当的熟悉。但是面试官来个急转直下，从此刻开始问出一些刁钻的问题，关于HashMap的更多基础的细节。面试官可能会问出下面的问题： “你知道HashMap的工作原理吗？” “你知道HashMap的get()方法的工作原理吗？”你也许会回答“我没有详查标准的Java API，你可以看看Java源代码或者Open JDK。”“我可以用Google找到答案。” 但一些面试者可能可以给出答案，“HashMap是基于hashing的原理，我们使用put(key, value)存储对象到HashMap中，使用get(key)从HashMap中获取对象。当我们给put()方法传递键和值时，我们先对键调用hashCode()方法，返回的hashCode用于找到bucket位置来储存Entry对象。”这里关键点在于指出，HashMap是在bucket中储存键对象和值对象，作为Map.Entry。这一点有助于理解获取对象的逻辑。如果你没有意识到这一点，或者错误的认为仅仅只在bucket中存储值的话，你将不会回答如何从HashMap中获取对象的逻辑。这个答案相当的正确，也显示出面试者确实知道hashing以及HashMap的工作原理。但是这仅仅是故事的开始，当面试官加入一些Java程序员每天要碰到的实际场景的时候，错误的答案频现。下个问题可能是关于HashMap中的碰撞探测(collision detection)以及碰撞的解决方法： “当两个对象的hashcode相同会发生什么？” 从这里开始，真正的困惑开始了，一些面试者会回答因为hashcode相同，所以两个对象是相等的，HashMap将会抛出异常，或者不会存储它们。然后面试官可能会提醒他们有equals()和hashCode()两个方法，并告诉他们两个对象就算hashcode相同，但是它们可能并不相等。一些面试者可能就此放弃，而另外一些还能继续挺进，他们回答“因为hashcode相同，所以它们的bucket位置相同，‘碰撞’会发生。因为HashMap使用链表存储对象，这个Entry(包含有键值对的Map.Entry对象)会存储在链表中。”这个答案非常的合理，虽然有很多种处理碰撞的方法，这种方法是最简单的，也正是HashMap的处理方法。但故事还没有完结，面试官会继续问： “如果两个键的hashcode相同，你如何获取值对象？” 面试者会回答：当我们调用get()方法，HashMap会使用键对象的hashcode找到bucket位置，然后获取值对象。面试官提醒他如果有两个值对象储存在同一个bucket，他给出答案:将会遍历链表直到找到值对象。面试官会问因为你并没有值对象去比较，你是如何确定确定找到值对象的？除非面试者直到HashMap在链表中存储的是键值对，否则他们不可能回答出这一题。 其中一些记得这个重要知识点的面试者会说，找到bucket位置之后，会调用keys.equals()方法去找到链表中正确的节点，最终找到要找的值对象。完美的答案！ 许多情况下，面试者会在这个环节中出错，因为他们混淆了hashCode()和equals()方法。因为在此之前hashCode()屡屡出现，而equals()方法仅仅在获取值对象的时候才出现。一些优秀的开发者会指出使用不可变的、声明作final的对象，并且采用合适的equals()和hashCode()方法的话，将会减少碰撞的发生，提高效率。不可变性使得能够缓存不同键的hashcode，这将提高整个获取对象的速度，使用String，Interger这样的wrapper类作为键是非常好的选择。 如果你认为到这里已经完结了，那么听到下面这个问题的时候，你会大吃一惊。“如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办？”除非你真正知道HashMap的工作原理，否则你将回答不出这道题。默认的负载因子大小为0.75，也就是说，当一个map填满了75%的bucket时候，和其它集合类(如ArrayList等)一样，将会创建原来HashMap大小的两倍的bucket数组，来重新调整map的大小，并将原来的对象放入新的bucket数组中。这个过程叫作rehashing，因为它调用hash方法找到新的bucket位置。 如果你能够回答这道问题，下面的问题来了：“你了解重新调整HashMap大小存在什么问题吗？”你可能回答不上来，这时面试官会提醒你当多线程的情况下，可能产生条件竞争(race condition)。 当重新调整HashMap大小的时候，确实存在条件竞争，因为如果两个线程都发现HashMap需要重新调整大小了，它们会同时试着调整大小。在调整大小的过程中，存储在链表中的元素的次序会反过来，因为移动到新的bucket位置的时候，HashMap并不会将元素放在链表的尾部，而是放在头部，这是为了避免尾部遍历(tail traversing)。如果条件竞争发生了，那么就死循环了。这个时候，你可以质问面试官，为什么这么奇怪，要在多线程的环境下使用HashMap呢？：） 为什么String, Interger这样的wrapper类适合作为键？ String, Interger这样的wrapper类作为HashMap的键是再适合不过了，而且String最为常用。因为String是不可变的，也是final的，而且已经重写了equals()和hashCode()方法了。其他的wrapper类也有这个特点。不可变性是必要的，因为为了要计算hashCode()，就要防止键值改变，如果键值在放入时和获取时返回不同的hashcode的话，那么就不能从HashMap中找到你想要的对象。不可变性还有其他的优点如线程安全。如果你可以仅仅通过将某个field声明成final就能保证hashCode是不变的，那么请这么做吧。因为获取对象的时候要用到equals()和hashCode()方法，那么键对象正确的重写这两个方法是非常重要的。如果两个不相等的对象返回不同的hashcode的话，那么碰撞的几率就会小些，这样就能提高HashMap的性能。我们可以使用自定义的对象作为键吗？ 这是前一个问题的延伸。当然你可能使用任何对象作为键，只要它遵守了equals()和hashCode()方法的定义规则，并且当对象插入到Map中之后将不会再改变了。如果这个自定义对象时不可变的，那么它已经满足了作为键的条件，因为当它创建之后就已经不能改变了。我们可以使用CocurrentHashMap来代替Hashtable吗？这是另外一个很热门的面试题，因为ConcurrentHashMap越来越多人用了。我们知道Hashtable是synchronized的，但是ConcurrentHashMap同步性能更好，因为它仅仅根据同步级别对map的一部分进行上锁。ConcurrentHashMap当然可以代替HashTable，但是HashTable提供更强的线程安全性。看看这篇博客查看Hashtable和ConcurrentHashMap的区别。我个人很喜欢这个问题，因为这个问题的深度和广度，也不直接的涉及到不同的概念。让我们再来看看这些问题设计哪些知识点： hashing的概念HashMap中解决碰撞的方法equals()和hashCode()的应用，以及它们在HashMap中的重要性不可变对象的好处HashMap多线程的条件竞争重新调整HashMap的大小 HashMap的工作原理HashMap基于hashing原理，我们通过put()和get()方法储存和获取对象。当我们将键值对传递给put()方法时，它调用键对象的hashCode()方法来计算hashcode，让后找到bucket位置来储存值对象。当获取对象时，通过键对象的equals()方法找到正确的键值对，然后返回值对象。HashMap使用链表来解决碰撞问题，当发生碰撞了，对象将会储存在链表的下一个节点中。 HashMap在每个链表节点中储存键值对对象。 当两个不同的键对象的hashcode相同时会发生什么？ 它们会储存在同一个bucket位置的链表中。键对象的equals()方法用来找到键值对。 因为HashMap的好处非常多，我曾经在电子商务的应用中使用HashMap作为缓存。因为金融领域非常多的运用Java，也出于性能的考虑，我们会经常用到HashMap和ConcurrentHashMap。 简单归纳，hashmap的深入理解： HashMap的数据结构是基于数组和链表的。（以数组存储元素，如有hash相同的元素，在数组结构中，创建链表结构，再把hash相同的元素放到链表的下一个节点） hashMap的结构类似这样 元素0—&gt;[hashCode=0, key.value=x1的数据] 元素1—&gt;[hashCode=1, key.value=y1的数据] 。。。。。。 元素n—&gt;[hashCode=n, key.value=z1的数据] 假设没有hashCode=1的元素加入，但是有两个hashCode=0的数据，它的结构就变成这样 元素0—&gt;[hashCode=0, key.value=x1的数据].next—&gt;[hashCode=0, key.value=x2的数据] 元素1—&gt;[null] …… 元素n—&gt;[hashCode=n, key.value=z1的数据] put和get都首先会调用hashcode方法，去查找相关的key，当有冲突时，再调用equals（这也是为什么刚开始就重温hashcode和equals的原因）！HashMap基于hashing原理，我们通过put()和get()方法储存和获取对象。当我们将键值对传递给put()方法时，它调用键对象的hashCode()方法来计算hashcode，让后找到bucket位置来储存值对象。当获取对象时，通过键对象的equals()方法找到正确的键值对，然后返回值对象。HashMap使用链表来解决碰撞问题，当发生碰撞了，对象将会储存在链表的下一个节点中。 HashMap在每个链表节点中储存键值对对象。 当两个不同的键对象的hashcode相同时会发生什么？ 它们会储存在同一个bucket位置的链表中。键对象的equals()方法用来找到键值对。 HashMap基于hashing原理，我们通过put()和get()方法储存和获取对象。当我们将键值对传递给put()方法时，它调用键对象的hashCode()方法来计算hashcode，让后找到bucket位置来储存值对象。当获取对象时，通过键对象的equals()方法找到正确的键值对，然后返回值对象。HashMap使用链表来解决碰撞问题，当发生碰撞了，对象将会储存在链表的下一个节点中。 HashMap在每个链表节点中储存键值对对象。 当两个不同的键对象的hashcode相同时会发生什么？ 它们会储存在同一个bucket位置的链表中。键对象的equals()方法用来找到键值对。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>hashmap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[volatile用法]]></title>
    <url>%2F2017%2F07%2F28%2Fvolatile%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[引言在Java中除了long和double类型的基本类型变量的赋值操作外都是原子操作，也就是说，对于变量值的简单读写操作没有必要进行同步。 vilatileJava中的原子操作包括：1）除long和double之外的基本类型的赋值操作2）所有引用reference的赋值操作3）java.concurrent.Atomic.* 包中所有类的一切操作。 long和double占用的字节数都是8，也就是64bits。在32位操作系统上对64位的数据的读写要分两步完成，每一步取32位数据。这样对double和long的赋值操作就会有问题：如果有两个线程同时写一个变量内存，一个进程写低32位，而另一个写高32位，这样将导致获取的64位数据是失效的数据。因此需要使用volatile关键字来防止此类现象。volatile本身不保证获取和设置操作的原子性，仅仅保持修改的可见性。但是java的内存模型保证声明为volatile的long和double变量的get和set操作是原子的。 在当前的Java内存模型下，线程可以把变量保存在本地内存（比如机器的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成数据的不一致。 要解决这个问题，只需要像在本程序中的这样，把该变量声明为volatile（不稳定的）即可，这就指示JVM，这个变量是不稳定的，每次使用它都到主存中进行读取。一般说来，多任务环境下各任务间共享的标志都应该加volatile修饰。 Volatile修饰的成员变量在每次被线程访问时，都强迫从共享内存中重读该成员变量的值。而且，当成员变量发生变化时，强迫线程将变化值回写到共享内存。这样在任何时刻，两个不同的线程总是看到某个成员变量的同一个值。 Java语言规范中指出：为了获得最佳速度，允许线程保存共享成员变量的私有拷贝，而且只当线程进入或者离开同步代码块时才与共享成员变量的原始值对比。 这样当多个线程同时与某个对象交互时，就必须要注意到要让线程及时的得到共享成员变量的变化。 而volatile关键字就是提示VM：对于这个成员变量不能保存它的私有拷贝，而应直接与共享成员变量交互。 使用建议：在两个或者更多的线程访问的成员变量上使用volatile。当要访问的变量已在synchronized代码块中，或者为常量时，不必使用。 由于使用volatile屏蔽掉了VM中必要的代码优化，所以在效率上比较低，因此一定在必要时才使用此关键字。 示例public class UnatomicLong implements Runnable { private static long test = 0; private final long val; public UnatomicLong(long val) { this.val = val; } @Override public void run() { while (!Thread.interrupted()) { test = val; //两个线程都试图将自己的私有变量val赋值给类私有静态变量test } } public static void main(String[] args) { Thread t1 = new Thread(new UnatomicLong(-1)); Thread t2 = new Thread(new UnatomicLong(0)); System.out.println(Long.toBinaryString(-1)); System.out.println(pad(Long.toBinaryString(0), 64)); t1.start(); t2.start(); long val; while ((val = test) == -1 || val == 0) { //如果静态成员test的值是-1或0，说明两个线程操作没有交叉 } System.out.println(pad(Long.toBinaryString(val), 64)); System.out.println(val); t1.interrupt(); t2.interrupt(); } // prepend 0s to the string to make it the target length private static String pad(String s, int targetLength) { int n = targetLength - s.length(); for (int x = 0; x &lt; n; x++) { s = &quot;0&quot; + s; } return s; } } 运行发现程序在while循环时进入了死循环，这是因为使用的JVM是64bits。在64位JVM中double和long的赋值操作是原子操作。在eclipse中修改jre为一个32bit的JVM地址，则会有如下运行结果：111111111111111111111111111111111111111111111111111111111111111100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000011111111111111111111111111111111//很明显test的值被破坏了4294967295]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>volatile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java常量池]]></title>
    <url>%2F2017%2F07%2F28%2Fjava%E5%B8%B8%E9%87%8F%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[引言接上一篇文章继续探索string类牵带出的常量池 jvm程序计数器：1.在IDE上编译的Java代码运行时都会被转译成字节码。程序计数器的就是给编译好的字节码添加行号，这样这些字节码就以程序计数器的编号来作为调度时候的标识了。 2.在程序运行时，诸如循环，跳转，异常处理这些功能都必须依赖于字节码来完。 我的理解：字节码是二进制文件，所以识别起来很难，代表一个功能的字节码数量巨大。如果在编译的时候就将其在程序计数器上进行编号，则后期调用的时候就可以按照程序员在IDE上用高级语言编译时候的顺序进行分条执行了。。栈：栈不灵活，但是很严格，是安全的，易于管理。因为只要上面的引用没有销毁，下面引用就一定还在，在大部分程序中，都是先定义的变量、引用先进栈，后定义的后进栈，同时，区块内部的变量、引用在进入区块时压栈，区块结束时出栈，理解了这种机制，我们就可以很方便地理解各种编程语言的作用域的概念了，同时这也是栈的优点——错误的引用逻辑在编译时就可以被发现，主要存放引用和基本数据类型。包括：&ensp;&ensp;&ensp;1.本地方法栈：是jvm调用操作系统方法所使用的栈。 &ensp;&ensp;&ensp;2.虚拟机栈：是jvm执行java代码所使用的栈。 方法区：存放了一些常量、静态变量、类信息等，可以理解成class文件在内存中的存放位置。 虚拟机堆：堆很灵活，但是不安全。对于对象，我们要动态地创建、销毁，不能说后创建的对象没有销毁，先前创建的对象就不能销毁，那样的话我们的程序就寸步难行，所以Java中用堆来存储对象。而一旦堆中的对象被销毁，我们继续引用这个对象的话，就会出现著名的 NullPointerException，这就是堆的缺点——错误的引用逻辑只有在运行时才会被发现。主要用来存放 new 出来的对象实例。 Java中的常量池：，实际上分为两种形态：静态常量池和运行时常量池。 &ensp;&ensp;&ensp;1.静态常量池：，即*.class文件中的常量池，class文件中的常量池不仅仅包含字符串(数字)字面量，还包含类、方法的信息，占用class文件绝大部分空间。 &ensp;&ensp;&ensp;2.运行时常量池：，则是jvm虚拟机在完成类装载操作后，将class文件中的常量池载入到内存中，并保存在方法区中，我们常说的常量池，就是指方法区中的运行时常量池。 接下来我们引用一些网络上流行的常量池例子，然后借以讲解。12345678910111213141516String s1 = &quot;Hello&quot;; String s2 = &quot;Hello&quot;; String s3 = &quot;Hel&quot; + &quot;lo&quot;; String s4 = &quot;Hel&quot; + new String(&quot;lo&quot;); String s5 = new String(&quot;Hello&quot;); String s6 = s5.intern(); String s7 = &quot;H&quot;; String s8 = &quot;ello&quot;; String s9 = s7 + s8; System.out.println(s1 == s2); // true System.out.println(s1 == s3); // true System.out.println(s1 == s4); // false System.out.println(s1 == s9); // false System.out.println(s4 == s5); // false System.out.println(s1 == s6); // true 在上节中提到，在java 中，直接使用==操作符，比较的是两个字符串的引用地址，并不是比较内容，比较内容请用equals()方法。 s1 == s2这个非常好理解，s1、s2在赋值时，均使用的字符串字面量，说白话点，就是直接把字符串写死，在编译期间，这种字面量会直接放入class文件的常量池中，从而实现复用，载入运行时常量池后，s1、s2指向的是同一个内存地址，所以相等。 s1 == s3这个地方有个坑，s3虽然是动态拼接出来的字符串，但是所有参与拼接的部分都是已知的字面量，在编译期间，这种拼接会被优化，编译器直接帮你拼好，因此String s3 = “Hel” + “lo”;在class文件中被优化成String s3 = “Hello”;，所以s1 == s3成立。 s1 == s4当然不相等，s4虽然也是拼接出来的，但new String(“lo”)这部分不是已知字面量，是一个不可预料的部分，编译器不会优化，必须等到运行时才可以确定结果，结合字符串不变定理，鬼知道s4被分配到哪去了，所以地址肯定不同。配上一张简图理清思路： s1 == s9也不相等，道理差不多，虽然s7、s8在赋值的时候使用的字符串字面量，但是拼接成s9的时候，s7、s8作为两个变量，都是不可预料的，编译器毕竟是编译器，不可能当解释器用，所以不做优化，等到运行时，s7、s8拼接成的新字符串，在堆中地址不确定，不可能与方法区常量池中的s1地址相同。 s4 == s5已经不用解释了，绝对不相等，二者都在堆中，但地址不同。 s1 == s6这两个相等完全归功于intern方法，s5在堆中，内容为Hello ，intern方法会尝试将Hello字符串添加到常量池中，并返回其在常量池中的地址，因为常量池中已经有了Hello字符串，所以intern方法直接返回地址；而s1在编译期就已经指向常量池了，因此s1和s6指向同一地址，相等。 至此，我们可以得出三个非常重要的结论： &ensp;&ensp;&ensp;必须要关注编译期的行为，才能更好的理解常量池。 &ensp;&ensp;&ensp;运行时常量池中的常量，基本来源于各个class文件中的常量池。 &ensp;&ensp;&ensp;程序运行时，除非手动向常量池中添加常量(比如调用intern方法)，否则jvm不会自动添加常量到常量池。 以上所讲仅涉及字符串常量池，实际上还有整型常量池、浮点型常量池等等，但都大同小异，只不过数值类型的常量池不可以手动添加常量，程序启动时常量池中的常量就已经确定了，比如整型常量池中的常量范围：-128~127，只有这个范围的数字可以用到常量池。 说了这么多理论，接下来让我们触摸一下真正的常量池。 前文提到过，class文件中存在一个静态常量池，这个常量池是由编译器生成的，用来存储java源文件中的字面量(本文仅仅关注字面量)，假设我们有如下java代码：1String s = &quot;hi&quot;; 为了方便起见，就这么简单，没错！将代码编译成class文件后，用UE打开二进制格式的class文件。如图： 在命令行我们通过javap工具来查看一个class文件的字节码。1javap -v test 如图所示： 简单讲解一下class文件的结构，开头的4个字节是class文件魔数，用来标识这是一个class文件，说白话点就是文件头，既：CA FE BA BE。 紧接着4个字节是java的版本号，这里的版本号是34，因为笔者是用jdk8编译的，版本号的高低和jdk版本的高低相对应，高版本可以兼容低版本，但低版本无法执行高版本。所以，如果哪天读者想知道别人的class文件是用什么jdk版本编译的，就可以看这4个字节，对应关系如下： jdk1.4 对应48 （00 30）,jdk1.5 对应49,（00 31）,jdk1.6 对应50,（00 32）,jdk1.7 对应51,（00 33）,jdk1.8 对应52,（00 34）, 接下来就是常量池入口，入口处用2个字节标识常量池常量数量，本例中数值为00 13，翻译成十进制是19，也就是有18个常量，其中第0个常量是特殊值，所以只有18个常量。 常量池中存放了各种类型的常量，他们都有自己的类型，并且都有自己的存储规范，本文只关注字符串常量 01 00 02 68 69 ，其中01代表的是“utf-8编码的字符串”，00 02代表的是这个字符串的长度是2个字节，68 69这2个字节代表的就是这个字符串的内容，因为是ascii码，每个字节对应一个字符，翻译过来就是hi 接下来再说说运行时常量池，由于运行时常量池在方法区中，我们可以通过jvm参数：-XX:PermSize、-XX:MaxPermSize来设置方法区大小，从而间接限制常量池大小。 假设jvm启动参数为：-XX:PermSize＝2M -XX:MaxPermSize＝2M，然后运行如下代码：123456789//保持引用，防止自动垃圾回收List&lt;String&gt; list = new ArrayList&lt;String&gt;(); int i = 0; while(true)&#123; //通过intern方法向常量池中手动添加常量 list.add(String.valueOf(i++).intern());&#125; 程序立刻会抛出：Exception in thread “main” java.lang.outOfMemoryError: PermGen space异常。PermGen space正是方法区，足以说明常量池在方法区中。 在jdk8中，移除了方法区，转而用Metaspace区域替代，所以我们需要使用新的jvm参数：-XX:MaxMetaspaceSize=2M，依然运行如上代码，抛出：java.lang.OutOfMemoryError: Metaspace异常。同理说明运行时常量池是划分在Metaspace区域中。具体关于Metaspace区域的知识，请读者自行搜索。 本文所有代码均在jdk7、jdk8下测试通过，其他版本jdk可能会略有差异，请读者自行探索。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>常量池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[string比较之‘’equals‘’和‘’==‘’]]></title>
    <url>%2F2017%2F07%2F28%2Fstring%E6%AF%94%E8%BE%83%E4%B9%8B%E2%80%98%E2%80%99equals%E2%80%98%E2%80%99%E5%92%8C%E2%80%98%E2%80%99%3D%3D%E2%80%98%E2%80%99%2F</url>
    <content type="text"><![CDATA[引言最近我发现了一个事情，那就是在面试笔试中，好多公司都喜欢在String字符串上出问题，涉及到方方面面的知识，包括其中的一些常用方法。在此，我总结下关于String类中的equals方法，以备应对以后的笔试面试。 equals和”==”string是一个final class，两种声明方法 :1.通过new关键字，创建一个新对象，分配一块新的、独立的内存堆String s1 = new String(“Hello”);2.直接赋值，创建一个”Hello”字符串放入字符串常量池里面,s2只是这个字符串的引用.String s2 = “Hello”; 这里s2属于字符串字面量，下一节会详细介绍 在java 中，string重写了equals和hashCode方法，都是以字符串内容复写的，直接使用”==”操作符，比较的是两个字符串的引用是否指向同一个对象，并不是比较内容，”equals”方法比较的是字符串内容，所以如果”==”返回true则”equals”一定为true,反之则不然。 下面来看具体例子：1234567891011121314151617181920212223String s1 = new String(&quot;Hello&quot;);String s2 = new String(&quot;Hello&quot;);System.out.println(s1 == s2);// falseSystem.out.println(s1.equals(s2)); //trueString s3 = new String(&quot;Hello&quot;);String s4 = s3;System.out.println(s3 == s4);// trueSystem.out.println(s3.equals(s4));// trueString s5 = &quot;Hello&quot;;String s6 = &quot;Hello&quot;;System.out.println(s5 == s6);// trueSystem.out.println(s5.equals(s6));// trueString s7 = &quot;Hello&quot;;String s8 = new String(&quot;Hello&quot;);System.out.println(s7 == s8);// false，System.out.println(s7.equals(s8));// trueString s9 = s3.intern();System.out.println(s7 == s9);// true，System.out.println(s7.equals(s9));// true intern方法会尝试将Hello字符串添加到常量池中，并返回其在常量池中的地址，因为常量池中已经有了Hello字符串，所以intern方法直接返回地址；而s7在编译期就已经指向常量池了，因此s7和s9指向同一地址，相等。 扩展假设有一个类，它有一个记录消息的方法，这个方法记录用户传来的消息(假设消息内容可能较大，并且重复率较高)，并且把消息按接收顺序记录在一个列表中。我想有些朋友会这样设计：1234567891011121314import java.util.*;public class Messages &#123;ArrayList messages = new ArrayList();public void record(String msg) &#123;messages.add(msg);&#125;public List getMessages() &#123;return messages;&#125;&#125; 这种设计方案好吗？假设我们重复的发送给record()方法同一个消息(消息来自不同的用户，所以可以视每个消息为一个new String(“…”))，并且消息内容较大，那么这个设计将会大大浪费内存空间，因为消息列表中记录的都是新创建的、独立的String对象，虽然它们的内容都相同。那么怎么样可以对其进行优化呢，其实很简单，请看如下优化后的示例：1234567891011121314import java.util.*;public class Messages &#123;ArrayList messages = new ArrayList();public void record(String msg) &#123;messages.add(msg.intern());&#125;public List getMessages() &#123;return messages;&#125;&#125; 正如你所看到的，原先record()方法中的messages.add(msg);代码段变成了messages.add(msg.intern());，仅仅对msg参数调用了intern()方法，这样将对重复的消息进行共享机制，从而降低了内存消耗，提高了性能。 自己写一个类MyString，里边有一个char[ ] value，实现里边的equalsString方法，要求可以比较两个MyString类的对象。相等返回0，大于返回1，小于返回-1，若比较的不是MyString类型的对象，则返回-100。 代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package cn.ywq.test; class MyString &#123; char[] value; public MyString(char[] value) &#123; this.value=value; //通过构造方法将字符传入 &#125; public int equalsString(Object obj) &#123; if(this==obj)&#123; return 0; &#125; //若该对象是MyString类型的 if(obj instanceof MyString)&#123; MyString string =(MyString) obj; int n=this.value.length; if (n&gt;string.value.length) &#123; //先判断长度的关系 return 1; &#125;else if(n&lt;string.value.length)&#123; return -1; &#125;else&#123; //若长度相等 char v1[] = this.value; char v2[] = string.value; int i = 0; while (n-- != 0) &#123; //按照数组的每一位进行比较 if (v1[i] &gt; v2[i])&#123; return 1; &#125;else if(v1[i] &lt; v2[i])&#123; return -1; &#125; i++; &#125; return 0; //若while循环正常结束，则说明相等，返回0 &#125; &#125; return -100; //若传入的不是MyString类型的对象 &#125; &#125; #测试代码：package cn.ywq.test; public class Test &#123; public static void main(String[] args) &#123; char[] value=&#123;&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;d&apos;&#125;; char[] value2=&#123;&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;d&apos;,&apos;e&apos;&#125;; char[] value3=&#123;&apos;c&apos;,&apos;b&apos;,&apos;c&apos;,&apos;d&apos;&#125;; char[] value4=&#123;&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&#125;; MyString myString = new MyString(value); MyString s=new MyString(value4); int i = myString.equalsString(s); System.out.println(i); &#125; &#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>string</tag>
        <tag>==</tag>
        <tag>equals</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring单例模式与线程安全]]></title>
    <url>%2F2017%2F07%2F26%2FSpring%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%2F</url>
    <content type="text"><![CDATA[引言Spring框架里的bean，或者说组件，获取实例的时候都是默认的单例模式，这是在多线程开发的时候要尤其注意的地方。 单例模式单例模式的意思就是只有一个实例。单例模式确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例。这个类称为单例类。当多用户同时请求一个服务时，容器会给每一个请求分配一个线程，这是多个线程会并发执行该请求多对应的业务逻辑（成员方法），此时就要注意了，如果该处理逻辑中有对该单列状态的修改（体现为该单列的成员属性），则必须考虑线程同步问题同步机制的比较 ThreadLocal和线程同步机制相比有什么优势呢？ThreadLocal和线程同步机制都是为了解决多线程中相同变量的访问冲突问题。 在同步机制中，通过对象的锁机制保证同一时间只有一个线程访问变量。这时该变量是多个线程共享的，使用同步机制要求程序慎密地分析什么时候对变量进行读写，什么时候需要锁定某个对象，什么时候释放对象锁等繁杂的问题，程序设计和编写难度相对较大。 而ThreadLocal则从另一个角度来解决多线程的并发访问。ThreadLocal会为每一个线程提供一个独立的变量副本，从而隔离了多个线程对数据的访问冲突。因为每一个线程都拥有自己的变量副本，从而也就没有必要对该变量进行同步了。ThreadLocal提供了线程安全的共享对象，在编写多线程代码时，可以把不安全的变量封装进ThreadLocal。 由于ThreadLocal中可以持有任何类型的对象，低版本JDK所提供的get()返回的是Object对象，需要强制类型转换。但JDK 5.0通过泛型很好的解决了这个问题，在一定程度地简化ThreadLocal的使用 概括起来说，对于多线程资源共享的问题，同步机制采用了“以时间换空间”的方式，而ThreadLocal采用了“以空间换时间”的方式。前者仅提供一份变量，让不同的线程排队访问，而后者为每一个线程都提供了一份变量，因此可以同时访问而互不影响。 线程安全 Spring使用ThreadLocal解决线程安全问题 我们知道在一般情况下，只有无状态的Bean才可以在多线程环境下共享，在Spring中，绝大部分Bean都可以声明为singleton作用域。就是因为Spring对一些Bean（如RequestContextHolder、TransactionSynchronizationManager、LocaleContextHolder等）中非线程安全状态采用ThreadLocal进行处理，让它们也成为线程安全的状态，因为有状态的Bean就可以在多线程中共享了。 一般的Web应用划分为展现层、服务层和持久层三个层次，在不同的层中编写对应的逻辑，下层通过接口向上层开放功能调用。在一般情况下，从接收请求到返回响应所经过的所有程序调用都同属于一个线程ThreadLocal是解决线程安全问题一个很好的思路，它通过为每个线程提供一个独立的变量副本解决了变量并发访问的冲突问题。在很多情况下，ThreadLocal比直接使用synchronized同步机制解决线程安全问题更简单，更方便，且结果程序拥有更高的并发性。如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。 或者说:一个类或者程序所提供的接口对于线程来说是原子操作或者多个线程之间的切换不会导致该接口的执行结果存在二义性,也就是说我们不用考虑同步的问题。 线程安全问题都是由全局变量及静态变量引起的。若每个线程中对全局变量、静态变量只有读操作，而无写操作，一般来说，这个全局变量是线程安全的；若有多个线程同时执行写操作，一般都需要考虑线程同步，否则就可能影响线程安全。1） 常量始终是线程安全的，因为只存在读操作。2）每次调用方法前都新建一个实例是线程安全的，因为不会访问共享的资源。3）局部变量是线程安全的。因为每执行一个方法，都会在独立的空间创建局部变量，它不是共享的资源。局部变量包括方法的参数变量和方法内变量。有状态就是有数据存储功能。有状态对象(Stateful Bean)，就是有实例变量的对象 ，可以保存数据，是非线程安全的。在不同方法调用间不保留任何状态。无状态就是一次操作，不能保存数据。无状态对象(Stateless Bean)，就是没有实例变量的对象 .不能保存数据，是不变类，是线程安全的。有状态对象:无状态的Bean适合用不变模式，技术就是单例模式，这样可以共享实例，提高性能。有状态的Bean，多线程环境下不安全，那么适合用Prototype原型模式。Prototype: 每次对bean的请求都会创建一个新的bean实例。Struts2默认的实现是Prototype模式。也就是每个请求都新生成一个Action实例，所以不存在线程安全问题。需要注意的是，如果由Spring管理action的生命周期， scope要配成prototype作用域。 线程安全案例：SimpleDateFormat(下面简称sdf)类内部有一个Calendar对象引用,它用来储存和这个sdf相关的日期信息,例如sdf.parse(dateStr), sdf.format(date) 诸如此类的方法参数传入的日期相关String, Date等等, 都是交友Calendar引用来储存的.这样就会导致一个问题,如果你的sdf是个static的, 那么多个thread 之间就会共享这个sdf, 同时也是共享这个Calendar引用, 并且, 观察 sdf.parse() 方法,你会发现有如下的调用: Date parse() { calendar.clear(); // 清理calendar ... // 执行一些操作, 设置 calendar 的日期什么的 calendar.getTime(); // 获取calendar的时间 } 这里会导致的问题就是, 如果 线程A 调用了 sdf.parse(), 并且进行了 calendar.clear()后还未执行calendar.getTime()的时候,线程B又调用了sdf.parse(), 这时候线程B也执行了sdf.clear()方法, 这样就导致线程A的的calendar数据被清空了(实际上A,B的同时被清空了). 又或者当 A 执行了calendar.clear() 后被挂起, 这时候B 开始调用sdf.parse()并顺利i结束, 这样 A 的 calendar内存储的的date 变成了后来B设置的calendar的date这个问题背后隐藏着一个更为重要的问题—无状态：无状态方法的好处之一，就是它在各种环境下，都可以安全的调用。衡量一个方法是否是有状态的，就看它是否改动了其它的东西，比如全局变量，比如实例的字段。format方法在运行过程中改动了SimpleDateFormat的calendar字段，所以，它是有状态的。 这也同时提醒我们在开发和设计系统的时候注意下一下三点: 1.自己写公用类的时候，要对多线程调用情况下的后果在注释里进行明确说明2.对线程环境下，对每一个共享的可变变量都要注意其线程安全性3.我们的类和方法在做设计的时候，要尽量设计成无状态的 解决办法 需要的时候创建新实例： 说明：在需要用到SimpleDateFormat 的地方新建一个实例，不管什么时候，将有线程安全问题的对象由共享变为局部私有都能避免多线程问题，不过也加重了创建对象的负担。在一般情况下，这样其实对性能影响比不是很明显的。 使用同步：同步SimpleDateFormat对象 public class DateSyncUtil { private static SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); public static String formatDate(Date date)throws ParseException{ synchronized(sdf){ return sdf.format(date); } } public static Date parse(String strDate) throws ParseException{ synchronized(sdf){ return sdf.parse(strDate); } } } 说明：当线程较多时，当一个线程调用该方法时，其他想要调用此方法的线程就要block，多线程并发量大的时候会对性能有一定的影响。 使用ThreadLocal： public class ConcurrentDateUtil { private static ThreadLocal&lt;DateFormat&gt; threadLocal = new ThreadLocal&lt;DateFormat&gt;() { @Override protected DateFormat initialValue() { return new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); } }; public static Date parse(String dateStr) throws ParseException { return threadLocal.get().parse(dateStr); } public static String format(Date date) { return threadLocal.get().format(date); } } 或public class ThreadLocalDateUtil { private static final String date_format = &quot;yyyy-MM-dd HH:mm:ss&quot;; private static ThreadLocal&lt;DateFormat&gt; threadLocal = new ThreadLocal&lt;DateFormat&gt;(); public static DateFormat getDateFormat() { DateFormat df = threadLocal.get(); if(df==null){ df = new SimpleDateFormat(date_format); threadLocal.set(df); } return df; } public static String formatDate(Date date) throws ParseException { return getDateFormat().format(date); } public static Date parse(String strDate) throws ParseException { return getDateFormat().parse(strDate); } } 说明：使用ThreadLocal, 也是将共享变量变为独享，线程独享肯定能比方法独享在并发环境中能减少不少创建对象的开销。如果对性能要求比较高的情况下，一般推荐使用这种方法。 抛弃JDK，使用其他类库中的时间格式化类： 1.使用Apache commons 里的FastDateFormat，宣称是既快又线程安全的SimpleDateFormat, 可惜它只能对日期进行format, 不能对日期串进行解析。 2.使用Joda-Time类库来处理时间相关问题 做一个简单的压力测试，方法一最慢，方法三最快，但是就算是最慢的方法一性能也不差，一般系统方法一和方法二就可以满足，所以说在这个点很难成为你系统的瓶颈所在。从简单的角度来说，建议使用方法一或者方法。 如果在必要的时候，追求那么一点性能提升的话，可以考虑用方法三，用ThreadLocal做缓存。Joda-Time类库对时间处理方式比较完美，建议使用。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring scope prototype与singleton]]></title>
    <url>%2F2017%2F07%2F26%2Fspring-scope-prototype%E4%B8%8Esingleton%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[singleton作用域 当一个bean的作用域设置为singleton, 那么Spring IOC容器中只会存在一个共享的bean实例，并且所有对bean的请求，只要id与该bean定义相匹配，则只会返回bean的同一实例。换言之，当把一个bean定义设置为singleton作用域时，Spring IOC容器只会创建该bean定义的唯一实例。这个单一实例会被存储到单例缓存（singleton cache）中，并且所有针对该bean的后续请求和引用都将返回被缓存的对象实例。 这里要注意的是singleton作用域和GOF设计模式中的单例是完全不同的，单例设计模式表示一个ClassLoader中只有一个class存在，而这里的singleton则表示一个容器对应一个bean，也就是说当一个bean被标识为singleton时候，spring的IOC容器中只会存在一个该bean。 prototype prototype作用域部署的bean，每一次请求（将其注入到另一个bean中，或者以程序的方式调用容器的getBean()方法）都会产生一个新的bean实例，相当与一个new的操作，对于prototype作用域的bean，有一点非常重要，那就是Spring不能对一个prototype bean的整个生命周期负责，容器在初始化、配置、装饰或者是装配完一个prototype实例后，将它交给客户端，随后就对该prototype实例不闻不问了。 不管何种作用域，容器都会调用所有对象的初始化生命周期回调方法，而对prototype而言，任何配置好的析构生命周期回调方法都将不会被调用。清除prototype作用域的对象并释放任何prototype bean所持有的昂贵资源，都是客户端代码的职责。（让Spring容器释放被singleton作用域bean占用资源的一种可行方式是，通过使用bean的后置处理器，该处理器持有要被清除的bean的引用。） scope=”prototype”没写的问题,项目中对一个表的增删该操作是用一个action，这个actionadd,update,delete,save这些方法， 添加和修改是共用一个页面，当页面得到id时代表进行的修改操作，反之是添加操作。因为在配置spring的bean是忘了写scope=”prototype” 所以每次添加时都显示最后一次访问过的记录,scope=”prototype” 会在该类型的对象被请求 时创建一个新的action对象。如果没有配置scope=prototype则添加的时候不会新建一个action，他任然会保留上次访问的过记录的信息 webwork的Action不是线程安全的，要求在多线程环境下必须是一个线程对应一个独立的实例，不能使用singleton。所以，我们在Spring配置Webwork Action Bean时，需要加上属性scope=”prototype”或singleton=”false”。 singleton模式指的是对某个对象的完全共享，包括代码空间和数据空间，说白了，如果一个类是singleton的，假如这个类有成员变量，那么这个成员变量的值是各个线程共享的（有点类似于static的样子了），当线程A往给变量赋了一个值以后，线程B就能读出这个值。 因此，对于前台Action，肯定不能使用singleton的模式，必须是一个线程请求对应一个独立的实例。推而广之，只要是带数据成员变量的类，为了防止多个线程混用数据，就不能使用singleton。对于我们用到的Service、Dao，之所以用了singleton，就是因为他们没有用到数据成员变量，如果谁的Service需要数据成员变量，请设置singleton=false。 有状态的bean都使用Prototype作用域，而对无状态的bean则应该使用singleton作用域。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>scope</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm内存模型]]></title>
    <url>%2F2017%2F07%2F20%2Fjvm%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[引言JVM定义了若干个程序执行期间使用的数据区域。这个区域里的一些数据在JVM启动的时候创建，在JVM退出的时候销毁。而其他的数据依赖于每一个线程，在线程创建时创建，在线程退出时销毁。 程序计数器程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。由于Java 虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。如果线程正在执行的是一个Java 方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Natvie 方法，这个计数器值则为空（Undefined）。此内存区域是唯一一个在Java 虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 虚拟机栈线程私有，它的生命周期与线程相同。虚拟机栈描述的是Java 方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。动画是由一帧一帧图片连续切换结果的结果而产生的，其实虚拟机的运行和动画也类似，每个在虚拟机中运行的程序也是由许多的帧的切换产生的结果，只是这些帧里面存放的是方法的局部变量，操作数栈，动态链接，方法返回地址和一些额外的附加信息组成。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 对于执行引擎来说，活动线程中，只有栈顶的栈帧是有效的，称为当前栈帧，这个栈帧所关联的方法称为当前方法。执行引擎所运行的所有字节码指令都只针对当前栈帧进行操作。局部变量表局部变量表是一组变量值存储空间，用于存放方法参数和方法内部定义的局部变量。在Java程序被编译成Class文件时，就在方法的Code属性的max_locals数据项中确定了该方法所需要分配的最大局部变量表的容量。局部变量表的容量以变量槽（Slot）为最小单位，32位虚拟机中一个Slot可以存放一个32位以内的数据类型（boolean、byte、char、short、int、float、reference和returnAddress八种）。reference类型虚拟机规范没有明确说明它的长度，但一般来说，虚拟机实现至少都应当能从此引用中直接或者间接地查找到对象在Java堆中的起始地址索引和方法区中的对象类型数据。returnAddress类型是为字节码指令jsr、jsr_w和ret服务的，它指向了一条字节码指令的地址。虚拟机是使用局部变量表完成参数值到参数变量列表的传递过程的，如果是实例方法（非static），那么局部变量表的第0位索引的Slot默认是用于传递方法所属对象实例的引用，在方法中通过this访问。 Slot是可以重用的，当Slot中的变量超出了作用域，那么下一次分配Slot的时候，将会覆盖原来的数据。Slot对对象的引用会影响GC（要是被引用，将不会被回收）。 系统不会为局部变量赋予初始值（实例变量和类变量都会被赋予初始值）。也就是说不存在类变量那样的准备阶段。 操作数栈和局部变量区一样，操作数栈也是被组织成一个以字长为单位的数组。但是和前者不同的是，它不是通过索引来访问，而是通过标准的栈操作——压栈和出栈—来访问的。比如，如果某个指令把一个值压入到操作数栈中，稍后另一个指令就可以弹出这个值来使用。虚拟机在操作数栈中存储数据的方式和在局部变量区中是一样的：如int、long、float、double、reference和returnType的存储。对于byte、short以及char类型的值在压入到操作数栈之前，也会被转换为int。虚拟机把操作数栈作为它的工作区——大多数指令都要从这里弹出数据，执行运算，然后把结果压回操作数栈。比如，iadd指令就要从操作数栈中弹出两个整数，执行加法运算，其结果又压回到操作数栈中，看看下面的示例，它演示了虚拟机是如何把两个int类型的局部变量相加，再把结果保存到第三个局部变量的：123456begin iload_0 // push the int in local variable 0 ontothe stack iload_1 //push the int in local variable 1 onto the stack iadd // pop two ints, add them, push result istore_2 // pop int, store into local variable 2 end 在这个字节码序列里，前两个指令iload_0和iload_1将存储在局部变量中索引为0和1的整数压入操作数栈中，其后iadd指令从操作数栈中弹出那两个整数相加，再将结果压入操作数栈。第四条指令istore_2则从操作数栈中弹出结果，并把它存储到局部变量区索引为2的位置。下图详细表述了这个过程中局部变量和操作数栈的状态变化，图中没有使用的局部变量区和操作数栈区域以空白表示。 动态连接虚拟机运行的时候,运行时常量池会保存大量的符号引用，这些符号引用可以看成是每个方法的间接引用。如果代表栈帧A的方法想调用代表栈帧B的方法，那么这个虚拟机的方法调用指令就会以B方法的符号引用作为参数，但是因为符号引用并不是直接指向代表B方法的内存位置，所以在调用之前还必须要将符号引用转换为直接引用，然后通过直接引用才可以访问到真正的方法。如果符号引用是在类加载阶段或者第一次使用的时候转化为直接应用，那么这种转换成为静态解析，如果是在运行期间转换为直接引用，那么这种转换就成为动态连接。 返回地址方法的返回分为两种情况，一种是正常退出，退出后会根据方法的定义来决定是否要传返回值给上层的调用者，一种是异常导致的方法结束，这种情况是不会传返回值给上层的调用方法。不过无论是那种方式的方法结束，在退出当前方法时都会跳转到当前方法被调用的位置，如果方法是正常退出的，则调用者的PC计数器的值就可以作为返回地址,，果是因为异常退出的，则是需要通过异常处理表来确定。方法的的一次调用就对应着栈帧在虚拟机栈中的一次入栈出栈操作，因此方法退出时可能做的事情包括：恢复上层方法的局部变量表以及操作数栈，如果有返回值的话，就把返回值压入到调用者栈帧的操作数栈中，还会把PC计数器的值调整为方法调用入口的下一条指令。异常在Java 虚拟机规范中，对虚拟机栈规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError 异常；如果虚拟机栈可以动态扩展（当前大部分的Java 虚拟机都可动态扩展，只不过Java 虚拟机规范中也允许固定长度的虚拟机栈），当扩展时无法申请到足够的内存时会抛出OutOfMemoryError 异常。 本地方法栈本地方法栈（Native MethodStacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java 方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native 方法服务。虚拟机规范中对本地方法栈中的方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。甚至有的虚拟机（譬如Sun HotSpot 虚拟机）直接就把本地方法栈和虚拟机栈合二为一。与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。 堆堆是Java 虚拟机所管理的内存中最大的一块。Java 堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。但是随着JIT 编译器的发展与逃逸分析技术的逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化发生，所有的对象都分配在堆上也渐渐变得不是那么“绝对”了。堆是垃圾收集器管理的主要区域，因此很多时候也被称做“GC 堆”。堆的大小可以通过-Xms(最小值)和-Xmx(最大值)参数设置，-Xms为JVM启动时申请的最小内存，默认为操作系统物理内存的1/64但小于1G，-Xmx为JVM可申请的最大内存，默认为物理内存的1/4但小于1G，默认当空余堆内存小于40%时，JVM会增大Heap到-Xmx指定的大小，可通过-XX:MinHeapFreeRation=来指定这个比列；当空余堆内存大于70%时，JVM会减小heap的大小到-Xms指定的大小，可通过XX:MaxHeapFreeRation=来指定这个比列，对于运行系统，为避免在运行时频繁调整Heap的大小，通常-Xms与-Xmx的值设成一样。 如果从内存回收的角度看，由于现在收集器基本都是采用的分代收集算法，所以Java 堆中还可以细分为：新生代和老年代；新生代：程序新创建的对象都是从新生代分配内存，新生代由Eden Space和两块相同大小的Survivor Space(通常又称S0和S1或From和To)构成，可通过-Xmn参数来指定新生代的大小，也可以通过-XX:SurvivorRation来调整Eden Space及SurvivorSpace的大小。老年代：用于存放经过多次新生代GC仍然存活的对象，例如缓存对象，新建的对象也有可能直接进入老年代，主要有两种情况：1、大对象，可通过启动参数设置-XX:PretenureSizeThreshold=1024(单位为字节，默认为0)来代表超过多大时就不在新生代分配，而是直接在老年代分配。2、大的数组对象，且数组中无引用外部对象。老年代所占的内存大小为-Xmx对应的值减去-Xmn对应的值。 如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError 异常。 方法区方法区在一个jvm实例的内部，类型信息被存储在一个称为方法区的内存逻辑区中。类型信息是由类加载器在类加载时从类文件中提取出来的。类(静态)变量也存储在方法区中。简单说方法区用来存储类型的元数据信息，一个.class文件是类被java虚拟机使用之前的表现形式，一旦这个类要被使用，java虚拟机就会对其进行装载、连接（验证、准备、解析）和初始化。而装载（后的结果就是由.class文件转变为方法区中的一段特定的数据结构。这个数据结构会存储如下信息： 类型信息 这个类型的全限定名 这个类型的直接超类的全限定名 这个类型是类类型还是接口类型 这个类型的访问修饰符 任何直接超接口的全限定名的有序列表 字段信息 字段名 字段类型 字段的修饰符 方法信息 方法名 方法返回类型 方法参数的数量和类型（按照顺序） 方法的修饰符 其他信息 除了常量以外的所有类（静态）变量 一个指向ClassLoader的指针 一个指向Class对象的指针 常量池（常量数据以及对其他类型的符号引用） JVM为每个已加载的类型都维护一个常量池。常量池就是这个类型用到的常量的一个有序集合，包括实际的常量(string,integer,和floating point常量)和对类型，域和方法的符号引用。池中的数据项象数组项一样，是通过索引访问的。 每个类的这些元数据，无论是在构建这个类的实例还是调用这个类某个对象的方法，都会访问方法区的这些元数据。构建一个对象时，JVM会在堆中给对象分配空间，这些空间用来存储当前对象实例属性以及其父类的实例属性（而这些属性信息都是从方法区获得），注意，这里并不是仅仅为当前对象的实例属性分配空间，还需要给父类的实例属性分配，到此其实我们就可以回答第一个问题了，即实例化父类的某个子类时，JVM也会同时构建父类的一个对象。从另外一个角度也可以印证这个问题：调用当前类的构造方法时，首先会调用其父类的构造方法直到Object，而构造方法的调用意味着实例的创建，所以子类实例化时，父类肯定也会被实例化。类变量被类的所有实例共享，即使没有类实例时你也可以访问它。这些变量只与类相关，所以在方法区中，它们成为类数据在逻辑上的一部分。在JVM使用一个类之前，它必须在方法区中为每个non-final类变量分配空间。 方法区主要有以下几个特点：1、方法区是线程安全的。由于所有的线程都共享方法区，所以，方法区里的数据访问必须被设计成线程安全的。例如，假如同时有两个线程都企图访问方法区中的同一个类，而这个类还没有被装入JVM，那么只允许一个线程去装载它，而其它线程必须等待2、方法区的大小不必是固定的，JVM可根据应用需要动态调整。同时，方法区也不一定是连续的，方法区可以在一个堆(甚至是JVM自己的堆)中自由分配。3、方法区也可被垃圾收集，当某个类不在被使用(不可触及)时，JVM将卸载这个类，进行垃圾收集 可以通过-XX:PermSize 和 -XX:MaxPermSize 参数限制方法区的大小。对于习惯在HotSpot 虚拟机上开发和部署程序的开发者来说，很多人愿意把方法区称为“永久代”（PermanentGeneration），本质上两者并不等价，仅仅是因为HotSpot 虚拟机的设计团队选择把GC 分代收集扩展至方法区，或者说使用永久代来实现方法区而已。对于其他虚拟机（如BEA JRockit、IBM J9 等）来说是不存在永久代的概念的。相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入了方法区就如永久代的名字一样“永久”存在了。这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载。当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。 总结 名称 特征 作用 配置参数 异常 程序计数器 占用内存小，线程私有，生命周期与线程相同 大致为字节码行号指示器 - - 虚拟机栈 线程私有，生命周期与线程相同，使用连续的内存空间 Java 方法执行的内存模型，存储局部变量表、操作栈、动态链接、方法出口等信息 -Xss StackOverflowError OutOfMemoryError java堆 线程共享，生命周期与虚拟机相同，可以不使用连续的内存地址 保存对象实例，所有对象实例（包括数组）都要在堆上分配 -Xms-Xsx-Xmn OutOfMemoryError 方法区 线程共享，生命周期与虚拟机相同，可以不使用连续的内存地址 存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据 -XX:PermSize:16M-XX:MaxPermSize64M OutOfMemoryError 运行时常量池 方法区的一部分，具有动态性 存放字面量及符号引用 - - 直接内存直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用，而且也可能导致OutOfMemoryError 异常出现，所以我们放到这里一起讲解。在JDK 1.4 中新加入了NIO（NewInput/Output）类，引入了一种基于通道（Channel）与缓冲区（Buffer）的I/O 方式，它可以使用Native 函数库直接分配堆外内存，然后通过一个存储在Java 堆里面的DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在Java 堆和Native 堆中来回复制数据。 堆与栈的对比经常有人把Java 内存区分为堆内存（Heap）和栈内存（Stack），这种分法比较粗糙，Java内存区域的划分实际上远比这复杂。这种划分方式的流行只能说明大多数程序员最关注的、与对象内存分配关系最密切的内存区域是这两块。堆很灵活，但是不安全。对于对象，我们要动态地创建、销毁，不能说后创建的对象没有销毁，先前创建的对象就不能销毁，那样的话我们的程序就寸步难行，所以Java中用堆来存储对象。而一旦堆中的对象被销毁，我们继续引用这个对象的话，就会出现著名的 NullPointerException，这就是堆的缺点——错误的引用逻辑只有在运行时才会被发现。栈不灵活，但是很严格，是安全的，易于管理。因为只要上面的引用没有销毁，下面引用就一定还在，在大部分程序中，都是先定义的变量、引用先进栈，后定义的后进栈，同时，区块内部的变量、引用在进入区块时压栈，区块结束时出栈，理解了这种机制，我们就可以很方便地理解各种编程语言的作用域的概念了，同时这也是栈的优点——错误的引用逻辑在编译时就可以被发现。 栈—主要存放引用和基本数据类型。 堆—用来存放 new 出来的对象实例。 内存溢出和内存泄漏内存溢出 out of memory，是指程序在申请内存时，没有足够的内存空间供其使用，出现out of memory；比如申请了一个integer，但给它存了long才能存下的数，那就是内存溢出。内存泄露 memory leak，是指程序在申请内存后，无法释放已申请的内存空间，一次内存泄露危害可以忽略，但内存泄露堆积后果很严重，无论多少内存,迟早会被占光。memory leak会最终会导致out ofmemory。 Java 堆内存的OutOfMemoryError异常是实际应用中最常见的内存溢出异常情况。出现Java 堆内存溢出时，异常堆栈信息“java.lang.OutOfMemoryError”会跟着进一步提示“Java heapspace”。要解决这个区域的异常，一般的手段是首先通过内存映像分析工具（如Eclipse Memory Analyzer）对dump 出来的堆转储快照进行分析，重点是确认内存中的对象是否是必要的，也就是要先分清楚到底是出现了内存泄漏（Memory Leak）还是内存溢出（Memory Overflow）。如果是内存泄漏，可进一步通过工具查看泄漏对象到GC Roots 的引用链。于是就能找到泄漏对象是通过怎样的路径与GC Roots 相关联并导致垃圾收集器无法自动回收它们的。掌握了泄漏对象的类型信息，以及GC Roots 引用链的信息，就可以比较准确地定位出泄漏代码的位置。如果不存在泄漏，换句话说就是内存中的对象确实都还必须存活着，那就应当检查虚拟机的堆参数（-Xmx 与-Xms），与机器物理内存对比看是否还可以调大，从代码上检查是否存在某些对象生命周期过长、持有状态时间过长的情况，尝试减少程序运行期的内存消耗。 内存分配过程1、JVM 会试图为相关Java对象在Eden Space中初始化一块内存区域。2、当Eden空间足够时，内存申请结束；否则到下一步。3、JVM 试图释放在Eden中所有不活跃的对象（这属于1或更高级的垃圾回收）。释放后若Eden空间仍然不足以放入新对象，则试图将部分Eden中活跃对象放入Survivor区。4、Survivor区被用来作为Eden及Old的中间交换区域，当Old区空间足够时，Survivor区的对象会被移到Old区，否则会被保留在Survivor区。5、当Old区空间不够时，JVM 会在Old区进行完全的垃圾收集（0级）。6、完全垃圾收集后，若Survivor及Old区仍然无法存放从Eden复制过来的部分对象，导致JVM无法在Eden区为新对象创建内存区域，则出现“outofmemory”错误。 对象访问对象访问在Java 语言中无处不在，是最普通的程序行为，但即使是最简单的访问，也会却涉及Java 栈、Java 堆、方法区这三个最重要内存区域之间的关联关系，如下面的这句代码： Object obj = newObject(); 假设这句代码出现在方法体中，那“Object obj”这部分的语义将会反映到Java 栈的本地变量表中，作为一个reference 类型数据出现。而“new Object()”这部分的语义将会反映到Java 堆中，形成一块存储了Object 类型所有实例数据值（Instance Data，对象中各个实例字段的数据）的结构化内存，根据具体类型以及虚拟机实现的对象内存布局（Object Memory Layout）的不同，这块内存的长度是不固定的。另外，在Java 堆中还必须包含能查找到此对象类型数据（如对象类型、父类、实现的接口、方法等）的地址信息，这些类型数据则存储在方法区中。由于reference 类型在Java 虚拟机规范里面只规定了一个指向对象的引用，并没有定义这个引用应该通过哪种方式去定位，以及访问到Java 堆中的对象的具体位置，因此不同虚拟机实现的对象访问方式会有所不同，主流的访问方式有两种：使用句柄和直接指针。如果使用句柄访问方式，Java 堆中将会划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据和类型数据各自的具体地址信息。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[google-cloud搭建vpn]]></title>
    <url>%2F2017%2F07%2F09%2Fgoogle-cloud%E6%90%AD%E5%BB%BAvpn%2F</url>
    <content type="text"><![CDATA[引言由于公司需要，而老板又不舍得花钱，于是使用google cloud免费vps，搭建vpn。google cloud需要翻墙访问，有gmail账户，单币种美金信用卡(好像有些双币种信用卡也可以，具体没试过)免费试用1年，赠送300$，所以申请vps时，用最低配置，每个月接近5$，300$可以支撑一年，但是流量是收费的，所以流量很大情况下，可能用不到一年。下面就是具体配置了，分两版：centos和ubuntu Google Cloud配置建立好Compute Engine后，申请一个永久静态地址，然后配置SSH登录证书等内容。详情查看Google文档如果实在不想看文档，可以看这里 主要配置是在Google的Firewall rules里，这里决定了什么包可以访问到内部的instance，其后才是instance内部的iptables的配置。 这里我们建立一条新的rule，source filter填写0.0.0.0/0，代表任何地方发出的包，除非你只想在特定IP上访问，否则就填写这个。然后在Allowed protocols and ports里添加udp:500;udp:4500;esp。 这里udp:500是IPSEC协议指定的端口，会通过这个端口来发送Control plane的包 udp:4500是当source或者destination在NAT后时转而使用的端口，另外当NAT被检测到后，Data plane的数据包也会被使用端口，这个时候ESP的数据包会被包含在UDP包中，端口也是这个 最后esp就是允许Data plane的数据包通过 另外需要勾选允许ip forwarding。 安装StrongSwan从源文件编译安装安装PAM库和SSL库，以及make和gcc1234567#ubuntuapt-get updateapt-get install libpam0g-dev libssl-dev make gcc#centosyum -y updateyum -y install pam-devel openssl-devel make gcc 下载StrongSwan的源码并编译12345678910111213141516171819202122232425#下载wget http://download.strongswan.org/strongswan.tar.gztar xzf strongswan.tar.gzcd strongswan-*#生成 Makefile为编译做准备#OpenVZ使用以下参数./configure --enable-eap-identity --enable-eap-md5 \--enable-eap-mschapv2 --enable-eap-tls --enable-eap-ttls --enable-eap-peap \--enable-eap-tnc --enable-eap-dynamic --enable-eap-radius --enable-xauth-eap \--enable-xauth-pam --enable-dhcp --enable-openssl --enable-addrblock --enable-unity \--enable-certexpire --enable-radattr --enable-tools --enable-openssl --disable-gmp --enable-kernel-libipsec#其它服务器执行./configure --prefix=/usr --sysconfdir=/etc/strongswan --enable-eap-identity \--enable-eap-md5 --enable-eap-mschapv2 --enable-eap-tls --enable-eap-ttls \-- enable-eap-peap --enable-eap-tnc --enable-eap-dynamic \--enable-eap-radius --enable-xauth-eap --enable-xauth-pam --enable-dhcp \--enable-addrblock --enable-unity --enable-certexpire --enable-radattr \--enable-openssl --disable-gmp#编译并且安装make&amp;&amp;make install#生成ipsec和strongswan命令mv /usr/sbin/&#123;ipsec,strongswan&#125; 判断VPS是Openvz还是KVM还是Xen1.通过系统上的相关目录或文件判断执行：ls /proc/ ，一般Xen的VPS，/proc目录下面会有xen的目录，openvz的会有vz目录。2.执行：free -m 看内存，openvz的没有swap，当然也有xen的没有swap，但是xen的是可以加的，openvz不行。3.执行：uname -a 有些xen的VPS里面会显示有xen。4.执行：ifconfig 查看网卡，openvz的一般都是venet0: ，xen的一般都是eth。5.通过VPS控制面板查看，像SolusVM、vePortal控制面板上都显示虚拟技术。 完成后执行ipsec version查看是否安装成功。 生成证书生成CA私钥1ipsec pki --gen --outform pem &gt; ca.pem 利用私钥签名CA证书1ipsec pki --self --in ca.pem --dn &quot;C=com, O=myvpn, CN=VPN CA&quot; --ca --outform pem &gt;ca.cert.pem 生成server端私钥1ipsec pki --gen --outform pem &gt; server.pem 用CA证书签发server端证书这里需要将下面的地址更换为google cloud中申请到的静态公网ip地址。 12345SERVER_ADDR=&quot;[REPLACE_WITH_YOUR_OWN_IP_ADDRESS]&quot;ipsec pki --pub --in server.pem | ipsec pki --issue --cacert ca.cert.pem \--cakey ca.pem --dn &quot;C=com, O=myvpn, CN=$SERVER_ADDR&quot; \--san=&quot;$SERVER_ADDR&quot; --flag serverAuth --flag ikeIntermediate \--outform pem &gt; server.cert.pem 生成client端私钥1ipsec pki --gen --outform pem &gt; client.pem 利用CA证书签发client端证书1ipsec pki --pub --in client.pem | ipsec pki --issue --cacert ca.cert.pem --cakey ca.pem --dn &quot;C=com, O=myvpn, CN=VPN Client&quot; --outform pem &gt; client.cert.pem 生成client端p12证书1openssl pkcs12 -export -inkey client.pem -in client.cert.pem -name &quot;client&quot; -certfile ca.cert.pem -caname &quot;VPN CA&quot; -out client.cert.p12 安装证书1234567891011121314# if not root probably you need to prepend sudo in front of the following commands#for ubuntu cp -r ca.cert.pem /usr/local/etc/ipsec.d/cacerts/cp -r server.cert.pem /usr/local/etc/ipsec.d/certs/cp -r server.pem /usr/local/etc/ipsec.d/private/cp -r client.cert.pem /usr/local/etc/ipsec.d/certs/cp -r client.pem /usr/local/etc/ipsec.d/private/#for centoscp -r ca.cert.pem /etc/strongswan/ipsec.d/cacerts/cp -r server.cert.pem /etc/strongswan/ipsec.d/certs/cp -r server.pem /etc/strongswan/ipsec.d/private/cp -r client.cert.pem /etc/strongswan/ipsec.d/certs/cp -r client.pem /etc/strongswan/ipsec.d/private/ 配置StrongSwan配置ipsec.confubuntu:/usr/local/etc/ipsec.confcentos:/etc/strongswan/ipsec.conf替换或新添加为如下内容(rightsourceip为申请的静态公网ip地址)：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455config setup uniqueids=neverconn iOS_cert keyexchange=ikev1 # strongswan version &gt;= 5.0.2, compatible with iOS 6.0,6.0.1 fragmentation=yes left=%defaultroute leftauth=pubkey leftsubnet=0.0.0.0/0 leftcert=server.cert.pem right=%any rightauth=pubkey rightauth2=xauth rightsourceip=10.31.2.0/24 rightcert=client.cert.pem auto=addconn android_xauth_psk keyexchange=ikev1 left=%defaultroute leftauth=psk leftsubnet=0.0.0.0/0 right=%any rightauth=psk rightauth2=xauth rightsourceip=10.31.2.0/24 auto=addconn networkmanager-strongswan keyexchange=ikev2 left=%defaultroute leftauth=pubkey leftsubnet=0.0.0.0/0 leftcert=server.cert.pem right=%any rightauth=pubkey rightsourceip=10.31.2.0/24 rightcert=client.cert.pem auto=addconn windows7 keyexchange=ikev2 ike=aes256-sha1-modp1024! rekey=no left=%defaultroute leftauth=pubkey leftsubnet=0.0.0.0/0 leftcert=server.cert.pem right=%any rightauth=eap-mschapv2 rightsourceip=10.31.2.0/24 rightsendcert=never eap_identity=%any auto=add 配置strongswan.confubuntu:/usr/local/etc/ipsec.confcentos:/etc/strongswan/ipsec.conf替换或新添加为如下内容：12345678910111213charon &#123; load_modular = yes duplicheck.enable = no compress = yes plugins &#123; include strongswan.d/charon/*.conf &#125; dns1 = 8.8.8.8 dns2 = 8.8.4.4 nbns1 = 8.8.8.8 nbns2 = 8.8.4.4 &#125; include strongswan.d/*.conf 配置ipsec.secretsubuntu:/usr/local/etc/ipsec.confcentos:/etc/strongswan/ipsec.conf替换或新添加为如下内容：1234: RSA server.pem: PSK &quot;mykey&quot;: XAUTH &quot;mykey&quot;[用户名] %any : EAP &quot;[密码]&quot; 注意将PSK、XAUTH处的”mykey”编辑为唯一且私密的字符串，并且将[用户名]改为自己想要的登录名，[密码]改为自己想要的密码（[]符号去掉），可以添加多行，得到多个用户。 配置iptables修改系统转发sysctrl.conf打开/etc/sysctl.conf，然后uncomment包含net.ipv4.ip_forward=1的这一行。 保存后，执行sysctl -p。 修改iptables将INF替换为自己的网络接口.12345678910111213INF=&quot;Your own network interface&quot;iptables -A FORWARD -m state --state RELATED,ESTABLISHED -j ACCEPTiptables -A FORWARD -s 10.31.2.0/24 -j ACCEPTiptables -A INPUT -i $INF -p esp -j ACCEPTiptables -A INPUT -i $INF -p udp --dport 500 -j ACCEPTiptables -A INPUT -i $INF -p tcp --dport 500 -j ACCEPTiptables -A INPUT -i $INF -p udp --dport 4500 -j ACCEPT# for l2tpiptables -A INPUT -i $INF -p udp --dport 1701 -j ACCEPT# for pptpiptables -A INPUT -i $INF -p tcp --dport 1723 -j ACCEPTiptables -A FORWARD -j REJECTiptables -t nat -A POSTROUTING -s 10.31.2.0/24 -o $INF -j MASQUERADE 【注意】：1.此处$INF为服务器网卡设备，对于OpenVZ主机请添venet0，其他主机添eth0，具体通过ifconfig查看使用的那个网卡2.此处ip：10.31.2.0/24仅举例，必须与上文ipsec.conf中的设置保持一致，但可是设置多对。 保存iptables且开机自动启动12345678910#for ubuntuiptables-save &gt; /etc/iptables.rulescat &gt; /etc/network/if-up.d/iptables&lt;&lt;EOF#!/bin/shiptables-restore &lt; /etc/iptables.rulesEOFchmod +x /etc/network/if-up.d/iptables#for centosservice iptables save 重启ipsec/iptables/strongswan服务123service iptables restartservice strongswan restartipsec restart 至此分讲完成。 WP8.1手机安装ca.cert.pem，进入设置VPN添加IKEv2连接，地址为证书中的地址或IP，通过用户名-密码连接。Windows连接也是一样，但注意将证书导入本地计算机而不是当前用户的“受信任的证书颁发机构”。iOS/Android/Mac OS X设备添加Cisco IPSec PSK验证方式，预共享密钥是/usr/local/etc/ipsec.secrets或者/etc/strongswan/ipsec.secrets中PSK后的字符串（不含引号），用户名密码同上，可以通过任意域名或IP连接，不需要证书. 自动化安装脚本下面附上自动化安装脚本，点我获取，如若有问题请创建issue沟通。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>vpn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[github搭建个人maven仓库]]></title>
    <url>%2F2017%2F07%2F02%2Fgithub%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BAmaven%E4%BB%93%E5%BA%93%2F</url>
    <content type="text"><![CDATA[引言三步： deploy到本地目录把本地目录提交到gtihub上配置github地址为仓库地址配置local file maven仓库 deploy到本地 maven可以通过http, ftp, ssh等deploy到远程服务器，也可以deploy到本地文件系统里。 例如把项目deploy到/home/jet/workspace/gerrit/maven_xm_repo/目录下： &lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;hengyunabc-mvn-repo&lt;/id&gt; &lt;url&gt;file:/home/hengyunabc/code/maven-repo/repository/&lt;/url&gt; &lt;/repository&gt; &lt;/distributionManagement&gt; 推荐使用命令行来deploy，避免在项目里显式配置: mvn deploy -DaltDeploymentRepository=maven_xm_repo::default::file:/home/jet/workspace/gerrit/maven_xm_repo/repository/ 上面把项目deploy到本地目录/home/jet/workspace/gerrit/maven_xm_repo/repository/里，下面把这个目录提交到github上。 在Github上新建一个项目，然后把/home/jet/workspace/gerrit/maven_xm_repo/下的文件都提交到gtihub上。 cd /home/jet/workspace/gerrit/maven_xm_repo/ git init git add . git commit -m &#39;deploy xxx&#39; git remote add origin git@github.com:jethan/maven_xm_repo.git git push origin master 最终效果可以参考我的个人仓库： maven_xm_repo github maven仓库的使用 因为github使用了raw.githubusercontent.com这个域名用于raw文件下载。所以使用这个maven仓库，只要在pom.xml里增加： &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;hengyunabc-maven-repo&lt;/id&gt; &lt;url&gt;https://raw.githubusercontent.com/jethan/maven_xm_repo/master/repository&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; 目录查看和搜索 值得注意的是，github因为安全原因，把raw文件下载和原来的github域名分开了，而raw.githubusercontent.com这个域名是不支持目录浏览的。所以，想要浏览文件目录，或者搜索的话，可以直接到github域名下的仓库去查看。 比如文件fastjson-1.2.5.jar： 浏览器urlmaven仓库url maven仓库工作的机制 下面介绍一些maven仓库工作的原理。典型的一个maven依赖下会有这三个文件： maven-metadata.xml maven-metadata.xml.md5 maven-metadata.xml.sha1 maven-metadata.xml里面记录了最后deploy的版本和时间。 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;metadata modelVersion=&quot;1.1.0&quot;&gt; &lt;groupId&gt;io.github.hengyunabc&lt;/groupId&gt; &lt;artifactId&gt;mybatis-ehcache-spring&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;versioning&gt; &lt;snapshot&gt; &lt;timestamp&gt;20150804.095005&lt;/timestamp&gt; &lt;buildNumber&gt;1&lt;/buildNumber&gt; &lt;/snapshot&gt; &lt;lastUpdated&gt;20150804095005&lt;/lastUpdated&gt; &lt;/versioning&gt; &lt;/metadata&gt; 其中md5, sha1校验文件是用来保证这个meta文件的完整性。 maven在编绎项目时，会先尝试请求maven-metadata.xml，如果没有找到，则会直接尝试请求到jar文件，在下载jar文件时也会尝试下载jar的md5, sha1文件。 maven-metadata.xml文件很重要，如果没有这个文件来指明最新的jar版本，那么即使远程仓库里的jar更新了版本，本地maven编绎时用上-U参数，也不会拉取到最新的jar！ 所以并不能简单地把jar包放到github上就完事了，一定要先在本地Deploy，生成maven-metadata.xml文件，并上传到github上。 参考 maven的仓库关系 配置使用本地仓库 想要使用本地file仓库里，在项目的pom.xml里配置，如： &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;hengyunabc-maven-repo&lt;/id&gt; &lt;url&gt;file:/home/hengyunabc/code/maven-repo/repository/&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; 注意事项 maven的repository并没有优先级的配置，也不能单独为某些依赖配置repository。所以如果项目配置了多个repository，在首次编绎时，会依次尝试下载依赖。如果没有找到，尝试下一个，整个流程会很长。 所以尽量多个依赖放同一个仓库，不要每个项目都有一个自己的仓库。 参考1参考2]]></content>
      <categories>
        <category>maven</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux常用操作命令(一)]]></title>
    <url>%2F2017%2F06%2F19%2Flinux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[引言 ◆ 安装和登录命令：login、shutdown、halt、reboot、install、mount、umount、chsh、exit、last； ◆ 文件处理命令：file、mkdir、dd、rm、grep、find、mv、cp、ls、diff、cat、ln、tail、head、more、less、cd、管道； ◆ 系统管理相关命令：df、top、free、quota、at、lp、adduser、groupadd、kill、crontab； ◆ 网络操作命令：ifconfig、ip、ping、netstat、telnet、ftp、route、rlogin、rcp、finger、mail、nslookup； ◆ 系统安全相关命令：passwd、su、umask、chgrp、chmod、chown、chattr、sudo ps、who、which、whois； ◆ 其它命令：tar、unzip、gunzip、unarj、mtools、man、unendcode、uudecode。 系统管理命令 stat ＃显示指定文件的详细信息，比ls更详细 who ＃显示在线登陆用户 whoami ＃显示当前操作用户 hostname ＃显示主机名 uname ＃显示系统信息 top ＃动态显示当前耗费资源最多进程信息 ps ＃显示瞬间进程状态 ps -aux du ＃查看目录大小 du -h /home带有单位显示目录信息 df ＃查看磁盘大小 df -h 带有单位显示磁盘信息 ifconfig ＃查看网络情况 ping ＃测试网络连通 netstat ＃显示网络状态信息 man ＃命令不会用了，找男人? 如：man ls clear ＃清屏 alias ＃对命令重命名 如：alias showmeit=”ps -aux” ，另外解除使用unaliax showmeit kill ＃杀死进程，可以先用ps 或 top命令查看进程的id，然后再用kill命令杀死进程。 常用基本指令 ls #显示文件或目录 -l #列出文件详细信息l(list) -a #列出当前目录下所有文件及目录，包括隐藏的a(all) mkdir #创建目录 -p #创建目录，若无父目录，则创建p(parent) cd #切换目录 touch #创建空文件 echo #创建带有内容的文件。 cat #查看文件内容 cp #拷贝 mv #移动或重命名 rm #删除文件 -r #递归删除，可删除子目录及文件 -f #强制删除 find #在文件系统中搜索某文件 wc #统计文本中行数、字数、字符数 grep #在文本文件中查找某个字符串 rmdir #删除空目录 tree #树形结构显示目录，需要安装tree包 pwd #显示当前目录 ln #创建链接文件 more、less #分页显示文本文件内容 head、tail #显示文件头、尾内容 ctrl+alt+F1 #命令行全屏模式 下面只介绍一些常用的基本命令 安装和登录命令shutdown/halt/reboot/exit/logout命令说明 shutdown -r #关机重启 -h #关机不重启 now #立刻关机 halt #关机 reboot #重启 exit #退出当前shell logout #退出登录shell mount/unmount命令说明 fdisk -l #查看磁盘情况 fdisk /dev/sda #为/dev/sda设备分区 m #显示所有命令 n #添加分区 p/e #主分区/逻辑分区 +50G #指定分区大小为50G p #打印分区列表 w #保存 reboot #重启 cat /etc/fstab #查看文件系统 mke2fs -t ext4 /dev/sda4 #格式化文件系统 mount /dev/sda4 /home #挂载到指定目录/home umount #取消挂载 #开机自动挂载 echo &quot;/dev/sda4 /home ext4 defaults 1 1&quot; &gt;&gt; /etc/fstab 文件处理命令awk一种编程语言，用于在linux/unix下对文本和数据进行处理 数据可以来自标准输入(stdin)、一个或多个文件，或其它命令的输出。它支持用户自定义函数和动态正则表达式等先进功能，是linux/unix下的一个强大编程工具。它在命令行中使用，但更多是作为脚本来使用。awk有很多内建的功能，比如数组、函数等，这是它和C语言的相同之处，灵活性是awk最大的优势。 awk [options] &#39;script&#39; var=value file(s) awk [options] -f scriptfile var=value file(s) -F fs fs指定输入分隔符，fs可以是字符串或正则表达式，如-F: -v var=value 赋值一个用户定义变量，将外部变量传递给awk -f scripfile 从脚本文件中读取awk命令 -m[fr] val 对val值设置内在限制，-mf选项限制分配给val的最大块数目；-mr选项限制记录的最大数目。这两个功能是Bell实验室版awk的扩展功能，在标准awk中不适用。 {} 要执行的脚本内容 eg: cat /etc/passwd |awk -F &#39;:&#39; &#39;{print $1&quot;\t&quot;$7}&#39; awk模式和操作 awk脚本是由模式和操作组成的。 模式 模式可以是以下任意一个： /正则表达式/：使用通配符的扩展集。 关系表达式：使用运算符进行操作，可以是字符串或数字的比较测试。 模式匹配表达式：用运算符~（匹配）和~!（不匹配）。 BEGIN语句块、pattern语句块、END语句块：参见awk的工作原理 操作 操作由一个或多个命令、函数、表达式组成，之间由换行符或分号隔开，并位于大括号内，主要部分是： 变量或数组赋值 输出命令 内置函数 控制流语句 awk脚本基本结构 awk &#39;BEGIN{ print &quot;start&quot; } pattern{ commands } END{ print &quot;end&quot; }&#39; file 一个awk脚本通常由：BEGIN语句块、能够使用模式匹配的通用语句块、END语句块3部分组成，这三个部分是可选的。任意一个部分都可以不出现在脚本中，脚本通常是被单引号或双引号中，例如： awk &#39;BEGIN{ i=0 } { i++ } END{ print i }&#39; filename awk &quot;BEGIN{ i=0 } { i++ } END{ print i }&quot; filename awk的工作原理 awk &#39;BEGIN{ commands } pattern{ commands } END{ commands }&#39; 第一步：执行BEGIN{ commands }语句块中的语句； 第二步：从文件或标准输入(stdin)读取一行，然后执行pattern{ commands }语句块，它逐行扫描文件，从第一行到最后一行重复这个过程，直到文件全部被读取完毕。 第三步：当读至输入流末尾时，执行END{ commands }语句块。 BEGIN语句块在awk开始从输入流中读取行之前被执行，这是一个可选的语句块，比如变量初始化、打印输出表格的表头等语句通常可以写在BEGIN语句块中。 END语句块在awk从输入流中读取完所有的行之后即被执行，比如打印所有行的分析结果这类信息汇总都是在END语句块中完成，它也是一个可选语句块。 pattern语句块中的通用命令是最重要的部分，它也是可选的。如果没有提供pattern语句块，则默认执行{ print }，即打印每一个读取到的行，awk读取的每一行都会执行该语句块。 eg： [jet@jet ~]$ echo -e &quot;A line 1\nA line 2&quot; | awk &#39;BEGIN{ print &quot;Start&quot; } { print } END{ print &quot;End&quot; }&#39; Start A line 1 A line 2 End 当使用不带参数的print时，它就打印当前行，当print的参数是以逗号进行分隔时，打印时则以空格作为定界符。在awk的print语句块中双引号是被当作拼接符使用，例如： echo | awk &#39;{ var1=&quot;v1&quot;; var2=&quot;v2&quot;; var3=&quot;v3&quot;; print var1,var2,var3; }&#39; v1 v2 v3 双引号拼接使用： echo | awk &#39;{ var1=&quot;v1&quot;; var2=&quot;v2&quot;; var3=&quot;v3&quot;; print var1&quot;=&quot;var2&quot;=&quot;var3; }&#39; v1=v2=v3 { }类似一个循环体，会对文件中的每一行进行迭代，通常变量初始化语句（如：i=0）以及打印文件头部的语句放入BEGIN语句块中，将打印的结果等语句放在END语句块中。 awk内置变量（预定义变量） 说明：[A][N][P][G]表示第一个支持变量的工具，[A]=awk、[N]=nawk、[P]=POSIXawk、[G]=gawk $n 当前记录的第n个字段，比如n为1表示第一个字段，n为2表示第二个字段。 $0 这个变量包含执行过程中当前行的文本内容。 [N] ARGC 命令行参数的数目。 [G] ARGIND 命令行中当前文件的位置（从0开始算）。 [N] ARGV 包含命令行参数的数组。 [G] CONVFMT 数字转换格式（默认值为%.6g）。 [P] ENVIRON 环境变量关联数组。 [N] ERRNO 最后一个系统错误的描述。 [G] FIELDWIDTHS 字段宽度列表（用空格键分隔）。 [A] FILENAME 当前输入文件的名。 [P] FNR 同NR，但相对于当前文件。 [A] FS 字段分隔符（默认是任何空格）。 [G] IGNORECASE 如果为真，则进行忽略大小写的匹配。 [A] NF 表示字段数，在执行过程中对应于当前的字段数。 [A] NR 表示记录数，在执行过程中对应于当前的行号。 [A] OFMT 数字的输出格式（默认值是%.6g）。 [A] OFS 输出字段分隔符（默认值是一个空格）。 [A] ORS 输出记录分隔符（默认值是一个换行符）。 [A] RS 记录分隔符（默认是一个换行符）。 [N] RSTART 由match函数所匹配的字符串的第一个位置。 [N] RLENGTH 由match函数所匹配的字符串的长度。 [N] SUBSEP 数组下标分隔符（默认值是34）。 eg: echo -e &quot;line1 f2 f3nline2 f4 f5nline3 f6 f7&quot; | awk &#39;{print &quot;Line No:&quot;NR&quot;, No of fields:&quot;NF, &quot;$0=&quot;$0, &quot;$1=&quot;$1, &quot;$2=&quot;$2, &quot;$3=&quot;$3}&#39; Line No:1, No of fields:3 $0=line1 f2 f3 $1=line1 $2=f2 $3=f3 Line No:2, No of fields:3 $0=line2 f4 f5 $1=line2 $2=f4 $3=f5 Line No:3, No of fields:3 $0=line3 f6 f7 $1=line3 $2=f6 $3=f7 使用print $NF可以打印出一行中的最后一个字段，使用$(NF-1)则是打印倒数第二个字段，其他以此类推： echo -e &quot;line1 f2 f3n line2 f4 f5&quot; | awk &#39;{print $NF}&#39; f3 f5 echo -e &quot;line1 f2 f3n line2 f4 f5&quot; | awk &#39;{print $(NF-1)}&#39; f2 f4 打印每一行的第二和第三个字段： awk &#39;{ print $2,$3 }&#39; filename 统计文件中的行数： awk &#39;END{ print NR }&#39; filename 以上命令只使用了END语句块，在读入每一行的时，awk会将NR更新为对应的行号，当到达最后一行NR的值就是最后一行的行号，所以END语句块中的NR就是文件的行数。 一个每一行中第一个字段值累加的例子： seq 5 | awk &#39;BEGIN{ sum=0; print &quot;总和：&quot; } { print $1&quot;+&quot;; sum+=$1 } END{ print &quot;等于&quot;; print sum }&#39; 总和： 1+ 2+ 3+ 4+ 5+ 等于 15 将外部变量值传递给awk 借助-v选项，可以将外部值（并非来自stdin）传递给awk： VAR=10000 echo | awk -v VARIABLE=$VAR &#39;{ print VARIABLE }&#39; 另一种传递外部变量方法： var1=”aaa”var2=”bbb”echo | awk ‘{ print v1,v2 }’ v1=$var1 v2=$var2 当输入来自于文件时使用： awk ‘{ print v1,v2 }’ v1=$var1 v2=$var2 filename 以上方法中，变量之间用空格分隔作为awk的命令行参数跟随在BEGIN、{}和END语句块之后。 awk运算与判断 作为一种程序设计语言所应具有的特点之一，awk支持多种运算，这些运算与C语言提供的基本相同。awk还提供了一系列内置的运算函数（如log、sqr、cos、sin等）和一些用于对字符串进行操作（运算）的函数（如length、substr等等）。这些函数的引用大大的提高了awk的运算功能。作为对条件转移指令的一部分，关系判断是每种程序设计语言都具备的功能，awk也不例外，awk中允许进行多种测试，作为样式匹配，还提供了模式匹配表达式~（匹配）和~!（不匹配）。作为对测试的一种扩充，awk也支持用逻辑运算符。 算术运算符 运算符 描述符 + - 加，减 * / &amp; 乘，除与求余 + - ！ 一元加 ，减和逻辑非 ^ *** 求冥 ++ — 自增,自减 作为前缀或后缀 eg： awk &#39;BEGIN{a=&quot;b&quot;;print a++,++a;}&#39; 0 2 注意：所有用作算术运算符进行操作，操作数自动转为数值，所有非数值都变为0 赋值运算符 运算符 描述符 = += -= *= /= %= ^= **= 赋值语句 eg： a+=5; 等价于：a=a+5; 逻辑运算符 运算符 描述 &#124;&#124; 逻辑或 &amp;&amp; 逻辑与 eg： awk &#39;BEGIN{a=1;b=2;print (a&gt;5 &amp;&amp; b&lt;=2),(a&gt;5 || b&lt;=2);}&#39; 0 1 正则运算符 运算符 描述 ~ ~! 匹配正则表达式和不匹配正则表达式 eg： awk &#39;BEGIN{a=&quot;100testa&quot;;if(a ~ /^100*/){print &quot;ok&quot;;}}&#39; ok 关系运算符 运算符 描述 &lt; &lt;= &gt; &gt;= != == 关系运算符 eg： awk &#39;BEGIN{a=11;if(a &gt;= 9){print &quot;ok&quot;;}}&#39; ok 注意：> < 可以作为字符串比较，也可以用作数值比较，关键看操作数如果是字符串就会转换为字符串比较。两个都为数字才转为数值比较。字符串比较：按照ASCII码顺序比较。 其它运算符 运算符 描述 $ 字段引用 空格 字符串连接符 ?: C条件表达式 in 数组中是否存在某键值 eg： awk &#39;BEGIN{a=&quot;b&quot;;print a==&quot;b&quot;?&quot;ok&quot;:&quot;err&quot;;}&#39; ok awk &#39;BEGIN{a=&quot;b&quot;;arr[0]=&quot;b&quot;;arr[1]=&quot;c&quot;;print (a in arr);}&#39; 0 awk &#39;BEGIN{a=&quot;b&quot;;arr[0]=&quot;b&quot;;arr[&quot;b&quot;]=&quot;c&quot;;print (a in arr);}&#39; 1 运算级优先级表 awk高级输入输出 读取下一条记录 awk中next语句使用：在循环逐行匹配，如果遇到next，就会跳过当前行，直接忽略下面语句。而进行下一行匹配。net语句一般用于多行合并： cat text.txt a b c d e awk &#39;NR%2==1{next}{print NR,$0;}&#39; text.txt 2 b 4 d 当记录行号除以2余1，就跳过当前行。下面的print NR,$0也不会执行。下一行开始，程序有开始判断NR%2值。这个时候记录行号是：2 ，就会执行下面语句块：&#39;print NR,$0&#39; 分析发现需要将包含有“web”行进行跳过，然后需要将内容与下面行合并为一行： [jet@jet oschina_hexo_server]$ cat test.txt web01[192.168.2.100] httpd ok tomcat ok sendmail ok web02[192.168.2.101] httpd ok postfix ok web03[192.168.2.102] mysqld ok httpd ok 0 [jet@jet oschina_hexo_server]$ awk &#39;/^web/{T=$0;next;}{print T&quot;:\t&quot;$0;}&#39; test.txt web01[192.168.2.100] : httpd ok web01[192.168.2.100] : tomcat ok web01[192.168.2.100] : sendmail ok web02[192.168.2.101] : httpd ok web02[192.168.2.101] : postfix ok web03[192.168.2.102] : mysqld ok web03[192.168.2.102] : httpd ok web03[192.168.2.102] : 0 web03[192.168.2.102] : 简单地读取一条记录 awk getline用法：输出重定向需用到getline函数。getline从标准输入、管道或者当前正在处理的文件之外的其他输入文件获得输入。它负责从输入获得下一行的内容，并给NF,NR和FNR等内建变量赋值。如果得到一条记录，getline函数返回1，如果到达文件的末尾就返回0，如果出现错误，例如打开文件失败，就返回-1。 getline语法：getline var，变量var包含了特定行的内容。 awk getline从整体上来说，用法说明： 当其左右无重定向符|或&lt;时：getline作用于当前文件，读入当前文件的第一行给其后跟的变量var或$0（无变量），应该注意到，由于awk在处理getline之前已经读入了一行，所以getline得到的返回结果是隔行的。 当其左右有重定向符|或&lt;时：getline则作用于定向输入文件，由于该文件是刚打开，并没有被awk读入一行，只是getline读入，那么getline返回的是该文件的第一行，而不是隔行。 eg： 执行linux的date命令，并通过管道输出给getline，然后再把输出赋值给自定义变量out，并打印它： awk &#39;BEGIN{ &quot;date&quot; | getline out; print out }&#39; test 执行shell的date命令，并通过管道输出给getline，然后getline从管道中读取并将输入赋值给out，split函数把变量out转化成数组mon，然后打印数组mon的第二个元素： awk &#39;BEGIN{ &quot;date&quot; | getline out; split(out,mon); print mon[2] }&#39; test 命令ls的输出传递给geline作为输入，循环使getline从ls的输出中读取一行，并把它打印到屏幕。这里没有输入文件，因为BEGIN块在打开输入文件前执行，所以可以忽略输入文件。 awk &#39;BEGIN{ while( &quot;ls&quot; | getline) print }&#39; 关闭文件 awk中允许在程序中关闭一个输入或输出文件，方法是使用awk的close语句。 close(&quot;filename&quot;) filename可以是getline打开的文件，也可以是stdin，包含文件名的变量或者getline使用的确切命令。或一个输出文件，可以是stdout，包含文件名的变量或使用管道的确切命令。 输出到一个文件 awk中允许用如下方式将结果输出到一个文件： echo | awk &#39;{printf(&quot;hello word!n&quot;) &gt; &quot;datafile&quot;}&#39; 或 echo | awk &#39;{printf(&quot;hello word!n&quot;) &gt;&gt; &quot;datafile&quot;}&#39; 设置字段定界符 默认的字段定界符是空格，可以使用-F &quot;定界符&quot;明确指定一个定界符： awk -F: &#39;{ print $NF }&#39; /etc/passwd 或 awk &#39;BEGIN{ FS=&quot;:&quot; } { print $NF }&#39; /etc/passwd 在BEGIN语句块中则可以用OFS=“定界符”设置输出字段的定界符。 流程控制语句 在linux awk的while、do-while和for语句中允许使用break,continue语句来控制流程走向，也允许使用exit这样的语句来退出。break中断当前正在执行的循环并跳到循环外执行下一条语句。if 是流程选择用法。awk中，流程控制语句，语法结构，与c语言类型。有了这些语句，其实很多shell程序都可以交给awk，而且性能是非常快的。下面是各个语句用法。 条件判断语句 if(表达式) 语句1 else 语句2 格式中语句1可以是多个语句，为了方便判断和阅读，最好将多个语句用{}括起来。awk分枝结构允许嵌套，其格式为： if(表达式) {语句1} else if(表达式) {语句2} else {语句3} eg： awk &#39;BEGIN{ test=100; if(test&amp;gt;90){ print &quot;very good&quot;; } else if(test&amp;gt;60){ print &quot;good&quot;; } else{ print &quot;no pass&quot;; } }&#39; very good 每条命令语句后面可以用;分号结尾。 循环语句 while语句 while(表达式) {语句} eg： awk &#39;BEGIN{ test=100; total=0; while(i&amp;lt;=test){ total+=i; i++; } print total; }&#39; 5050 for循环 for循环有两种格式： 格式1： for(变量 in 数组) {语句} eg： awk &#39;BEGIN{ for(k in ENVIRON){ print k&quot;=&quot;ENVIRON[k]; } }&#39; TERM=linux G_BROKEN_FILENAMES=1 SHLVL=1 pwd=/root/text ... logname=root HOME=/root SSH_CLIENT=192.168.1.21 53087 22 【注】ENVIRON是awk常量，是子典型数组。 格式2： for(变量;条件;表达式) {语句} eg： awk &#39;BEGIN{ total=0; for(i=0;i&amp;lt;=100;i++){ total+=i; } print total; }&#39; do循环 do {语句} while(条件) eg： awk &#39;BEGIN{ total=0; i=0; do {total+=i;i++;} while(i&amp;lt;=100) print total; }&#39; 5050 其他语句 break 当 break 语句用于 while 或 for 语句时，导致退出程序循环。 continue 当 continue 语句用于 while 或 for 语句时，使程序循环移动到下一个迭代。 next 能能够导致读入下一个输入行，并返回到脚本的顶部。这可以避免对当前输入行执行其他的操作过程。 exit 语句使主输入循环退出并将控制转移到END,如果END存在的话。如果没有定义END规则，或在END中应用exit语句，则终止脚本的执行。 数组应用 数组是awk的灵魂，处理文本中最不能少的就是它的数组处理。因为数组索引（下标）可以是数字和字符串在awk中数组叫做关联数组(associative arrays)。awk 中的数组不必提前声明，也不必声明大小。数组元素用0或空字符串来初始化，这根据上下文而定。 数组的定义 数字做数组索引（下标）： Array[1]=&quot;sun&quot; Array[2]=&quot;kai&quot; 字符串做数组索引（下标）： Array[&quot;first&quot;]=&quot;www&quot; Array[&quot;last&quot;]=&quot;name&quot; Array[&quot;birth&quot;]=&quot;1987&quot; 使用中print Array[1]会打印出sun；使用print Array[2]会打印出kai；使用print[&quot;birth&quot;]会得到1987。 读取数组的值 { for(item in array) {print array[item]}; } #输出的顺序是随机的 { for(i=1;i&lt;=len;i++) {print array[i]}; } #Len是数组的长度 数组相关函数 得到数组长度: awk &#39;BEGIN{info=&quot;it is a test&quot;;lens=split(info,tA,&quot; &quot;);print length(tA),lens;}&#39; 4 4 length返回字符串以及数组长度，split进行分割字符串为数组，也会返回分割得到数组长度。 awk &#39;BEGIN{info=&quot;it is a test&quot;;split(info,tA,&quot; &quot;);print asort(tA);}&#39; 4 asort对数组进行排序，返回数组长度。 输出数组内容（无序，有序输出）： awk ‘BEGIN{info=”it is a test”;split(info,tA,” “);for(k in tA){print k,tA[k];}}’4 test1 it2 is3 a for…in输出，因为数组是关联数组，默认是无序的。所以通过for…in得到是无序的数组。如果需要得到有序数组，需要通过下标获得。 awk &#39;BEGIN{info=&quot;it is a test&quot;;tlen=split(info,tA,&quot; &quot;);for(k=1;k&lt;=tlen;k++){print k,tA[k];}}&#39; 1 it 2 is 3 a 4 test 注意：数组下标是从1开始，与C数组不一样。 判断键值存在以及删除键值： #错误的判断方法： awk &#39;BEGIN{tB[&quot;a&quot;]=&quot;a1&quot;;tB[&quot;b&quot;]=&quot;b1&quot;;if(tB[&quot;c&quot;]!=&quot;1&quot;){print &quot;no found&quot;;};for(k in tB){print k,tB[k];}}&#39; no found a a1 b b1 c 以上出现奇怪问题，tB[“c”]没有定义，但是循环时候，发现已经存在该键值，它的值为空，这里需要注意，awk数组是关联数组，只要通过数组引用它的key，就会自动创建改序列。 #正确判断方法： awk &#39;BEGIN{tB[&quot;a&quot;]=&quot;a1&quot;;tB[&quot;b&quot;]=&quot;b1&quot;;if( &quot;c&quot; in tB){print &quot;ok&quot;;};for(k in tB){print k,tB[k];}}&#39; a a1 b b1 if(key in array)通过这种方法判断数组中是否包含key键值。 #删除键值： [chengmo@localhost ~]$ awk &#39;BEGIN{tB[&quot;a&quot;]=&quot;a1&quot;;tB[&quot;b&quot;]=&quot;b1&quot;;delete tB[&quot;a&quot;];for(k in tB){print k,tB[k];}}&#39; b b1 delete array[key]可以删除，对应数组key的，序列值。 二维、多维数组使用 awk的多维数组在本质上是一维数组，更确切一点，awk在存储上并不支持多维数组。awk提供了逻辑上模拟二维数组的访问方式。例如，array[2,4]=1这样的访问是允许的。awk使用一个特殊的字符串SUBSEP(�34)作为分割字段，在上面的例子中，关联数组array存储的键值实际上是2�344。 类似一维数组的成员测试，多维数组可以使用if ( (i,j) in array)这样的语法，但是下标必须放置在圆括号中。类似一维数组的循环访问，多维数组使用for ( item in array )这样的语法遍历数组。与一维数组不同的是，多维数组必须使用split()函数来访问单独的下标分量。 awk &#39;BEGIN{ for(i=1;i&amp;lt;=9;i++){ for(j=1;j&amp;lt;=9;j++){ tarr[i,j]=i*j; print i,&quot;*&quot;,j,&quot;=&quot;,tarr[i,j]; } } }&#39; 1 * 1 = 1 1 * 2 = 2 1 * 3 = 3 1 * 4 = 4 1 * 5 = 5 1 * 6 = 6 ... 9 * 6 = 54 9 * 7 = 63 9 * 8 = 72 9 * 9 = 81 可以通过array[k,k2]引用获得数组内容。 另一种方法： awk ‘BEGIN{ for(i=1;i&lt;=9;i++){ for(j=1;j&lt;=9;j++){ tarr[i,j]=ij; } } for(m in tarr){ split(m,tarr2,SUBSEP); print tarr2[1],”“,tarr2[2],”=”,tarr[m]; } }’ 内置函数 awk内置函数，主要分以下3种类似：算数函数、字符串函数、其它一般函数、时间函数 算术函数 格式 描述 atan2( y, x ) 返回 y/x 的反正切。 cos( x ) 返回 x 的余弦；x 是弧度。 sin( x ) 返回 x 的正弦；x 是弧度。 exp( x ) 返回 x 幂函数。 log( x ) 返回 x 的自然对数。 sqrt( x ) 返回 x 平方根。 int( x ) 返回 x 的截断至整数的值。 rand( ) 返回任意数字 n，其中 0 &lt;= n &lt; 1。 srand( [expr] ) 将 rand 函数的种子值设置为 Expr 参数的值，或如果省略 Expr 参数则使用某天的时间。返回先前的种子值。 举例说明： awk &#39;BEGIN{OFMT=&quot;%.3f&quot;;fs=sin(1);fe=exp(10);fl=log(10);fi=int(3.1415);print fs,fe,fl,fi;}&#39; 0.841 22026.466 2.303 3 OFMT 设置输出数据格式是保留3位小数。 获得随机数： awk &#39;BEGIN{srand();fr=int(100*rand());print fr;}&#39; 78 awk &#39;BEGIN{srand();fr=int(100*rand());print fr;}&#39; 31 awk &#39;BEGIN{srand();fr=int(100*rand());print fr;}&#39; 41 字符串函数 格式 描述 gsub( Ere, Repl, [ In ] ) 除了正则表达式所有具体值被替代这点，它和 sub 函数完全一样地执行。 sub( Ere, Repl, [ In ] ) 用 Repl 参数指定的字符串替换 In 参数指定的字符串中的由 Ere 参数指定的扩展正则表达式的第一个具体值。sub 函数返回替换的数量。出现在 Repl 参数指定的字符串中的 &amp;（和符号）由 In 参数指定的与 Ere 参数的指定的扩展正则表达式匹配的字符串替换。如果未指定 In 参数，缺省值是整个记录（$0 记录变量）。 index( String1, String2 ) 在由 String1 参数指定的字符串（其中有出现 String2 指定的参数）中，返回位置，从 1 开始编号。如果 String2 参数不在 String1 参数中出现，则返回 0（零）。 length [(String)] 返回 String 参数指定的字符串的长度（字符形式）。如果未给出 String 参数，则返回整个记录的长度（$0 记录变量）。 blength [(String)] 返回 String 参数指定的字符串的长度（以字节为单位）。如果未给出 String 参数，则返回整个记录的长度（$0 记录变量）。 substr( String, M, [ N ] ) 返回具有 N 参数指定的字符数量子串。子串从 String 参数指定的字符串取得，其字符以 M 参数指定的位置开始。M 参数指定为将 String 参数中的第一个字符作为编号 1。如果未指定 N 参数，则子串的长度将是 M 参数指定的位置到 String 参数的末尾 的长度。 match( String, Ere ) 在 String 参数指定的字符串（Ere 参数指定的扩展正则表达式出现在其中）中返回位置（字符形式），从 1 开始编号，或如果 Ere 参数不出现，则返回 0（零）。RSTART 特殊变量设置为返回值。RLENGTH 特殊变量设置为匹配的字符串的长度，或如果未找到任何匹配，则设置为 -1（负一）。 split( String, A, [Ere] ) 将 String 参数指定的参数分割为数组元素 A[1], A[2], . . ., A[n]，并返回 n 变量的值。此分隔可以通过 Ere 参数指定的扩展正则表达式进行，或用当前字段分隔符（FS 特殊变量）来进行（如果没有给出 Ere 参数）。除非上下文指明特定的元素还应具有一个数字值，否则 A 数组中的元素用字符串值来创建。 tolower( String ) 返回 String 参数指定的字符串，字符串中每个大写字符将更改为小写。大写和小写的映射由当前语言环境的 LC_CTYPE 范畴定义。 toupper( String ) 返回 String 参数指定的字符串，字符串中每个小写字符将更改为大写。大写和小写的映射由当前语言环境的 LC_CTYPE 范畴定义。 sprintf(Format, Expr, Expr, . . . ) 根据 Format 参数指定的 printf 子例程格式字符串来格式化 Expr 参数指定的表达式并返回最后生成的字符串。 注：Ere都可以是正则表达式。 gsub,sub使用 awk &#39;BEGIN{info=&quot;this is a test2010test!&quot;;gsub(/[0-9]+/,&quot;!&quot;,info);print info}&#39; this is a test!test! 在 info中查找满足正则表达式，/[0-9]+/用””替换，并且替换后的值，赋值给info 未给info值，默认是$0 查找字符串（index使用） awk &#39;BEGIN{info=&quot;this is a test2010test!&quot;;print index(info,&quot;test&quot;)?&quot;ok&quot;:&quot;no found&quot;;}&#39; ok 未找到，返回0 正则表达式匹配查找(match使用） awk &#39;BEGIN{info=&quot;this is a test2010test!&quot;;print match(info,/[0-9]+/)?&quot;ok&quot;:&quot;no found&quot;;}&#39; ok 截取字符串(substr使用） [wangsl@centos5 ~]$ awk &#39;BEGIN{info=&quot;this is a test2010test!&quot;;print substr(info,4,10);}&#39; s is a tes 从第 4个 字符开始，截取10个长度字符串 字符串分割（split使用） awk &#39;BEGIN{info=&quot;this is a test&quot;;split(info,tA,&quot; &quot;);print length(tA);for(k in tA){print k,tA[k];}}&#39; 4 4 test 1 this 2 is 3 a 分割info，动态创建数组tA，这里比较有意思，awk for …in循环，是一个无序的循环。 并不是从数组下标1…n ，因此使用时候需要注意。 格式化字符串输出（sprintf使用） 格式化字符串格式： 其中格式化字符串包括两部分内容：一部分是正常字符，这些字符将按原样输出; 另一部分是格式化规定字符，以”%”开始，后跟一个或几个规定字符,用来确定输出内容格式。 格式 描述 %d 十进制有符号整数 %u 十进制无符号整数 %f 浮点数 %s 字符串 %c 单个字符 %p 指针的值 %e 指数形式的浮点数 %x %X无符号以十六进制表示的整数 %o 无符号以八进制表示的整数 %g 自动选择合适的表示法 awk &#39;BEGIN{n1=124.113;n2=-1.224;n3=1.2345; printf(&quot;%.2f,%.2u,%.2g,%X,%on&quot;,n1,n2,n3,n1,n1);}&#39; 124.11,18446744073709551615,1.2,7C,174 一般函数 格式 描述 close( Expression ) 用同一个带字符串值的 Expression 参数来关闭由 print 或 printf 语句打开的或调用 getline 函数打开的文件或管道。如果文件或管道成功关闭，则返回 0；其它情况下返回非零值。如果打算写一个文件，并稍后在同一个程序中读取文件，则 close 语句是必需的。 system(command ) 执行 Command 参数指定的命令，并返回退出状态。等同于 system 子例程。 Expression&#124;getline [ Variable ] 从来自 Expression 参数指定的命令的输出中通过管道传送的流中读取一个输入记录，并将该记录的值指定给 Variable 参数指定的变量。如果当前未打开将 Expression 参数的值作为其命令名称的流，则创建流。创建的流等同于调用 popen 子例程，此时 Command 参数取 Expression 参数的值且 Mode 参数设置为一个是 r 的值。只要流保留打开且 Expression 参数求得同一个字符串，则对 getline 函数的每次后续调用读取另一个记录。如果未指定 Variable 参数，则 $0 记录变量和 NF 特殊变量设置为从流读取的记录。 getline [ Variable ] &lt; Expression 从 Expression 参数指定的文件读取输入的下一个记录，并将 Variable 参数指定的变量设置为该记录的值。只要流保留打开且 Expression 参数对同一个字符串求值，则对 getline 函数的每次后续调用读取另一个记录。如果未指定 Variable 参数，则 $0 记录变量和 NF 特殊变量设置为从流读取的记录。 getline [ Variable ] 将 Variable 参数指定的变量设置为从当前输入文件读取的下一个输入记录。如果未指定 Variable 参数，则 $0 记录变量设置为该记录的值，还将设置 NF、NR 和 FNR 特殊变量。 打开外部文件（close用法） awk &#39;BEGIN{while(&quot;cat /etc/passwd&quot;|getline){print $0;};close(&quot;/etc/passwd&quot;);}&#39; root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin 逐行读取外部文件(getline使用方法） awk &#39;BEGIN{while(getline &lt; &quot;/etc/passwd&quot;){print $0;};close(&quot;/etc/passwd&quot;);}&#39; root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin awk &#39;BEGIN{print &quot;Enter your name:&quot;;getline name;print name;}&#39; Enter your name: chengmo chengmo 调用外部应用程序(system使用方法） awk &#39;BEGIN{b=system(&quot;ls -al&quot;);print b;}&#39; total 42092 drwxr-xr-x 14 chengmo chengmo 4096 09-30 17:47 . drwxr-xr-x 95 root root 4096 10-08 14:01 .. b返回值，是执行结果。 时间函数 格式 描述 函数名 说明 mktime( YYYY MM dd HH MM ss[ DST]) 生成时间格式 strftime([format [, timestamp]]) 格式化时间输出，将时间戳转为时间字符串 具体格式，见下表. systime() 得到时间戳,返回从1970年1月1日开始到当前时间(不计闰年)的整秒数 建指定时间(mktime使用） awk &#39;BEGIN{tstamp=mktime(&quot;2001 01 01 12 12 12&quot;);print strftime(&quot;%c&quot;,tstamp);}&#39; 2001年01月01日 星期一 12时12分12秒 awk &#39;BEGIN{tstamp1=mktime(&quot;2001 01 01 12 12 12&quot;);tstamp2=mktime(&quot;2001 02 01 0 0 0&quot;);print tstamp2-tstamp1;}&#39; 2634468 求2个时间段中间时间差，介绍了strftime使用方法 awk &#39;BEGIN{tstamp1=mktime(&quot;2001 01 01 12 12 12&quot;);tstamp2=systime();print tstamp2-tstamp1;}&#39; 308201392 strftime日期和时间格式说明符 格式 描述 %a 星期几的缩写(Sun) %A 星期几的完整写法(Sunday) %b 月名的缩写(Oct) %B 月名的完整写法(October) %c 本地日期和时间 %d 十进制日期 %D 日期 08/20/99 %e 日期，如果只有一位会补上一个空格 %H 用十进制表示24小时格式的小时 %I 用十进制表示12小时格式的小时 %j 从1月1日起一年中的第几天 %m 十进制表示的月份 %M 十进制表示的分钟 %p 12小时表示法(AM/PM) %S 十进制表示的秒 %U 十进制表示的一年中的第几个星期(星期天作为一个星期的开始) %w 十进制表示的星期几(星期天是0) %W 十进制表示的一年中的第几个星期(星期一作为一个星期的开始) %x 重新设置本地日期(08/20/99) %X 重新设置本地时间(12：00：00) %y 两位数字表示的年(99) %Y 当前月份 %Z 时区(PDT) %% 百分号(%) sed 对数据行进行替换、删除、新增、选取等操作 a 新增，在新的下一行出现 c 取代，取代 n1,n2 之间的行 eg: sed &#39;1,2c Hi&#39; ab d 删除 i 插入，在新的上一行出现 eg: #指定时间段查看日志 sed -n &#39;/2016-10-21 14:18:29/,/2016-10-21 18:18:29/p&#39; catalina.out #替换当前目录下所有文件中的 /usr/local为/data/dshp sed -i &quot;s/\/usr\/local/\/data\/dshp/g&quot; . paste 合并文件，需确保合并的两文件行数相同 -d 指定不同于空格或tab键的域分隔符 -s 按行合并，单独一个文件为一行 wc wc 计算数字 利用wc指令我们可以计算文件的Byte数、字数或是列数，若不指定文件名称，或是所给予的文件名为“-”，则wc指令会从标准输入设备读取数据 wc(选项)(参数) #(选项) -c或--bytes或——chars：只显示Bytes数； -l或——lines：只显示列数； -w或——words：只显示字数。 #(参数) 文件：需要统计的文件列表。 统计当前文件夹下文件的个数 ls -l |grep &quot;^-&quot;|wc -l 统计当前文件夹下目录的个数 ls -l |grep &quot;^d&quot;|wc -l 统计当前文件夹下文件的个数，包括子文件夹里的 ls -lR|grep &quot;^-&quot;|wc -l 统计文件夹下目录的个数，包括子文件夹里的 ls -lR|grep &quot;^d&quot;|wc -l ls -l #长列表输出当前文件夹下文件信息(注意这里的文件，不同于一般的文件，可能是目录、链接、设备文件等) grep &quot;^-&quot; #这里将长列表输出信息过滤一部分，只保留一般文件，如果只保留目录就是 ^d wc -l #统计当前目录下指定文件后缀的行数，既可以统计项目的代码量 find . -name &quot;*.java&quot; -or -name &quot;*.jsp&quot; -or -name &quot;*.xml&quot; -or -name &quot;*.c&quot; |xargs grep -v &quot;^$&quot;|wc -l #统计输出信息的行数，因为已经过滤得只剩一般文件了，所以统计结果就是一般文件信息的行数，又由于一行信息对应一个文件，所以也就是文件的个数 uniq uniq 去除文件中相邻的重复行 清空/新建文件，将内容重定向输入进去 &amp;&gt; 正确、错误都重定向过去 后面追加 file 该命令用于判断接在file命令后的文件的基本数据，因为在Linux下文件的类型并不是以后缀为分的，所以这个命令对我们来说就很有用了，它的用法非常简单，基本语法如下： [plain] view plain copy print? file filename #例如： file ./test mkdir 创建新目录 mkdir [选项] 目录… -p #递归创建目录，若父目录不存在则依次创建 eg: mkdir -p ~/temp/test -m #自定义创建目录的权限 eg:mkdir -m 777 temp -v #显示创建目录的详细信息 eg:mkdir -m 662 -pv ~/temp/test grep 用正则表达式搜索文本，并把匹配的行打印出来 grep ‘正则表达式’ 文件名 | -c 只输出匹配行的计数。 -I 不区分大小写(只适用于单字符)。 -l 只显示文件名 -v 显示不包含匹配文本的所有行。 -n 显示匹配行数据及其行号 eg: # 取出文件urls.txt中包含mysql的行，并把找到的关键字加上颜色 grep --color=auto &#39;mysql&#39; urls.txt # 把ls -l的输出中包含字母file（不区分大小写）的内容输出 ls -l | grep -i file # 查找当前目录下所有包含mysql的文件并逐行显示,文件路径+行号+匹配内容 grep -rn &quot;mysql&quot; ./* find 在文件树种查找文件，并作出相应的处理 find [PATH] [option] [action] 选项与参数： 与时间有关的选项：共有 -atime, -ctime 与 -mtime 和-amin,-cmin与-mmin，以 -mtime 说明 -mtime n ：n 为数字，意义为在 n 天之前的『一天之内』被更动过内容的档案； -mtime +n ：列出在 n 天之前(不含 n 天本身)被更动过内容的档案档名； -mtime -n ：列出在 n 天之内(含 n 天本身)被更动过内容的档案档名。 -newer file ：file 为一个存在的档案，列出比 file 还要新的档案档名 eg： find ./ -mtime 0 # 在当前目录下查找今天之内有改动的文件 与使用者或组名有关的参数： -uid n ：n 为数字，这个数字是用户的账号 ID，亦即 UID -gid n ：n 为数字，这个数字是组名的 ID，亦即 GID -user name ：name 为使用者账号名称！例如 dmtsai -group name：name 为组名，例如 users ； -nouser ：寻找档案的拥有者不存在 /etc/passwd 的人！ -nogroup ：寻找档案的拥有群组不存在于 /etc/group 的档案！ eg： find /home/jet -user jet # 在目录/home/jet中找出所有者为jet的文件 与档案权限及名称有关的参数： -name filename #搜寻文件名为 filename 的档案（可使用通配符） -size [+-]SIZE #搜寻比 SIZE 还要大(+)或小(-)的档案。这个 SIZE 的规格有： c: 代表 byte k: 代表 1024bytes。所以，要找比 50KB还要大的档案，就是『 -size +50k 』 -type TYPE #搜寻档案的类型为 TYPE 的，类型主要有： 一般正规档案 (f) 装置档案 (b, c) 目录 (d) 连结档 (l) socket (s) FIFO (p) -perm mode #搜寻档案权限『刚好等于』 mode的档案，这个mode为类似chmod的属性值 举例来说，-rwsr-xr-x 的属性为4755！ -perm -mode #搜寻档案权限『必须要全部囊括 mode 的权限』的档案 举例来说，我们要搜寻-rwxr--r-- 亦即 0744 的档案，使用-perm -0744，当一个档案的权限为 -rwsr-xr-x ，亦即 4755 时，也会被列出来，因为 -rwsr-xr-x 的属性已经囊括了 -rwxr--r-- 的属性了。 -perm +mode #搜寻档案权限『包含任一 mode 的权限』的档案 举例来说，我们搜寻-rwxr-xr-x ，亦即 -perm +755 时，但一个文件属性为 -rw-------也会被列出来，因为他有 -rw.... 的属性存在！ eg： find / -name passwd # 查找文件名为passwd的文件 find . -perm 0755 # 查找当前目录中文件权限的0755的文件 find . -size +12k # 查找当前目录中大于12KB的文件，注意c表示byte 额外可进行的动作： -exec command #command 为其他指令，-exec 后面可再接额外的指令来处理搜寻到的结果。 -print ：将结果打印到屏幕上，这个动作是预设动作！ eg: find / -perm +7000 -exec ls -l {} \; #额外指令以-exec开头，以\;结尾{}代替前面找到的内容 | xargs -i 默认的前面输出用{}代替 eg: find . -name &quot;*.log&quot; | xargs -i mv {} test4 # 查找当前目录下所有log结尾的文件并删除 find . -name *.log | xargs rm dd 用指定大小的块拷贝一个文件，并在拷贝的同时进行指定的转换(convert and copy a file ) 语法：dd [选项] if =输入文件（或设备名称）。 of =输出文件（或设备名称）。 ibs = bytes 一次读取bytes字节，即读入缓冲区的字节数。 skip = blocks 跳过读入缓冲区开头的ibs*blocks块。 obs = bytes 一次写入bytes字节，即写入缓冲区的字节数。 bs = bytes 同时设置读/写缓冲区的字节数（等于设置ibs和obs）。 cbs = byte 一次转换bytes字节。 count=blocks 只拷贝输入的blocks块。 conv = ASCII 把EBCDIC码转换为ASCIl码。 conv = ebcdic 把ASCIl码转换为EBCDIC码。 conv = ibm 把ASCIl码转换为alternate EBCDIC码。 conv = block 把变动位转换成固定字符。 conv = ublock 把固定位转换成变动位。 conv = ucase 把字母由小写转换为大写。 conv = lcase 把字母由大写转换为小写。 conv = notrunc 不截短输出文件。 conv = swab 交换每一对输入字节。 conv = noerror 出错时不停止处理。 conv = sync 把每个输入记录的大小都调到ibs的大小（用NUL填充）。 例1：要把一张软盘的内容拷贝到另一张软盘上，利用/tmp作为临时存储区。把源盘插入驱动器中，输入下述命令： $ dd if =/dev/fd0 of = /tmp/tmpfile 拷贝完成后，将源盘从驱动器中取出，把目标盘插入，输入命令： $ dd if = /tmp/tmpfile of =/dev/fd0 软盘拷贝完成后，应该将临时文件删除： $ rm /tmp/tmpfile 例2：把net.i这个文件写入软盘中，并设定读/写缓冲区的数目。 （注意：软盘中的内容会被完全覆盖掉） $ dd if = net.i of = /dev/fd0 bs = 16384 例3：将文件sfile拷贝到文件 dfile中。 $ dd if=sfile of=dfile 例4：创建一个100M的空文件 $ dd if=/dev/zero of=hello.txt bs=100M count=1 # 创建一个大小为1k的空文件 $ dd if=/dev/zero of=./test.txt bs=1k count=1 $ ls -l total 4 -rw-rw-r--. 1 jet jet 1024 Jun 20 16:36 test.txt # 将access_log中错误信息丢弃 $ find / -name access_log 2&gt;/dev/null &gt;-&gt;&gt;-/dev/null-/dev/zero /dev/null: 它是空设备，也称为位桶（bit bucket），外号叫无底洞，任何写入它的输出都会被抛弃。如果不想让消息以标准输出显示或写入文件，那么可以将消息重定向到位桶。 /dev/zero: 是一个输入设备，该设备无穷尽地提供0，可以使用任何你需要的数目，用于向设备或文件写入字符串0，你可你用它来初始化文件。 &lt; ：由 &lt; 的右边读入参数档案； &gt; ：将原本由屏幕输出的正确数据输出到 &gt; 右边的 file ( 文件名称 ) 或 device ( 装置，如 printer )去； &gt;&gt; ：将原本由屏幕输出的正确数据输出到 &gt;&gt; 右边，与 &gt; 不同的是，该档案将不会被覆盖，而新的数据将以『增加的方式』增加到该档案的最后面； 2&gt; ：将原本应该由屏幕输出的错误数据输出到 2&gt; 的右边去。 说明 [jet @jet oschina_hexo_server]# ls -al &gt; test.txt # 将显示的结果输出到 test.txt 档案中，若该档案以存在则覆盖！ [jet @jet oschina_hexo_server]# ls -al &gt;&gt; test.txt # 将显示的结果追加到 test.txt 档案中，该档案为累加的，旧数据保留！ [jet @jet oschina_hexo_server]# ls -al 1&gt; test.txt 2&gt; test.err # 将显示的数据，正确的输出到 test.txt 错误的数据输出到 test.err [jet @jet oschina_hexo_server]# ls -al 1&gt; test.txt 2&gt;&amp;1 # 将显示的数据，不论正确或错误均输出到 test.txt 当中！ [jet @jet oschina_hexo_server]# ls -al 1&gt; test.txt 2&gt; /dev/null # 将显示的数据，正确的输出到 test.txt 错误的数据则予以丢弃！ 【注意】错误与正确档案输出到同一个档案中，则必须以上面的方法来写！ 不能写成其它格式！这个观念相当的重要，尤其是在 /etc/crontab 当中执行的时候，如果我们已经知道错误的讯息为何，又不想要让错误的讯息一直填满 root 的信箱，就必须以 2&gt; 搭配 /dev/null 这个垃圾桶黑洞装置，来将数据丢弃！这个相当的重要！ rm 删除文件 rm [选项] 文件 -r 【--recursive】删除文件夹即递归的删除目录下面文件以及子目录下文件。 -f 【--force】强制删除不提示，忽略不存在的文件。 -i 【--interactive】交互模式删除文件，删除文件前给出提示 -v 【-verbose】详细显示进行步骤 cd 切换工作目录 cd . #返回上层目录 cd .. #返回上层目录 cd 回车 #返回主目录同cd ~ cd / #根目录 cd ~/git/ #主目录下的git目录 cd - #回到之前的目录 ls 列出相关目录下的所有目录和文件 ls [选项] [目录名] -a 列出包括.a开头的隐藏文件的所有文件 -A 通-a，但不列出&quot;.&quot;和&quot;..&quot; -l 列出文件的详细信息 -c 根据ctime排序显示 -t 根据文件修改时间排序 ---color[=WHEN] 用色彩辨别文件类型 WHEN 可以是’never’、’always’或’auto’其中之一 白色：表示普通文件 蓝色：表示目录 绿色：表示可执行文件 红色：表示压缩文件 浅蓝色：链接文件 红色闪烁：表示链接的文件有问题 黄色：表示设备文件 灰色：表示其它文件 mv 移动或重命名文件 mv [选项] 源文件或目录 目录或多个源文件 -b 覆盖前做备份 -f 如存在不询问而强制覆盖 -i 如存在则询问是否覆盖 -u 较新才覆盖 -t 将多个源文件移动到统一目录下，目录参数在前，文件参数在后 eg: mv a /tmp/ 将文件a移动到 /tmp目录下 mv a b 将a命名为b mv /home/zenghao test1.txt test2.txt test3.txt cp 将源文件复制至目标文件，或将多个源文件复制至目标目录。 cp [选项] 源文件或目录 目录或多个源文件 -r -R #递归复制该目录及其子目录内容 -p #连同档案属性一起复制过去 -f #不询问而强制复制 -s #生成快捷方式 -a #将档案的所有特性都一起复制 eg: cp -a file1 file2 #连同文件的所有特性把文件file1复制成文件file2 cp file1 file2 file3 dir #把文件file1、file2、file3复制到目录dir中 touch 创建空文件或更新文件时间 touch [选项] 文件 -a #只修改存取时间 -m #值修改变动时间 -r #eg:touch -r a b ,使b的时间和a相同 -t #指定特定的时间 eg:touch -t 201211142234.50 log.log #-t time [[CC]YY]MMDDhhmm[.SS],C:年前两位 pwd 查看当前所在路径 rmdir 删除空目录 -v 显示执行过程 -p 若自父母删除后父目录为空则一并删除 rm 删除一个或多个文件或目录 rm [选项].. 文件 -f 忽略不存在的文件，不给出提示 -i 交互式删除 -r 将列出的目录及其子目录递归删除 -v 列出详细信息 echo 显示内容到屏幕 -n 输出后不换行 -e 遇到转义字符特殊处理 eg: echo &quot;hello\nworld&quot; 显示hello\nworld ehco -e &quot;hello\nworld&quot; 显示hello(换行了)world cat 一次显示整个文件或从键盘创建一个文件或将几个文件合并成一个文件 cat [选项] [文件].. -n 编号文件内容再输出 -E 在结束行提示$ tac cat的反向显示 more 按页查看文章内容，从前向后读取文件，因此在启动时就加载整个文件 +n 从第n行开始显示 -n 每次查看n行数据 +/String 搜寻String字符串位置，从其前两行开始查看 -c 清屏再显示 -p 换页时清屏 less 可前后移动地逐屏查看文章内容，在查看前不会加载整个文件 -m 显示类似于more命令的百分比 -N 显示行号 / 字符串：向下搜索“字符串”的功能 ? 字符串：向上搜索“字符串”的功能 n 重复前一个搜索（与 / 或 ? 有关） N 反向重复前一个搜索（与 / 或 ? 有关） b 向后翻一页 d 向后翻半页 nl 将输出内容自动加上行号 nl [选项]… [文件]… -b -b a 不论是否有空行，都列出行号（类似 cat -n) -b t 空行则不列行号（默认） -n 有ln rn rz三个参数，分别为再最左方显示，最右方显示不加0，最右方显示加0 head 显示档案开头，默认开头10行 head [参数]… [文件]… -v 显示文件名 -c number 显示前number个字符,若number为负数,则显示除最后number个字符的所有内容 -number/n (+)number 显示前number行内容， -n number 若number为负数，则显示除最后number行数据的所有内容 tail 显示文件结尾内容 tail [必要参数] [选择参数] [文件] -v #显示详细的处理信息 -q #不显示处理信息 -num/-n (-)num #显示最后num行内容 -n +num #从第num行开始显示后面的数据 -c #显示最后c个字符 -f #循环读取 # 实时查看日志，从文件最后50行开始 tail -fn 50 ExecuteConfig.log vi 编辑文件 :w filename #将文章以指定的文件名保存起来 :q #退出 :q! #强制退出 :wq #保存并退出 :set nu #显示行号 :set nonu #隐藏行号 /git #在文档中查找git 按n跳到下一个，shift+n上一个 yyp #复制光标所在行，并粘贴 h(左移一个字符←)、j(下一行↓)、k(上一行↑)、l(右移一个字符→) 命令行模式功能键 1. 插入模式 按「i」切换进入插入模式「insert mode」，按&quot;i&quot;进入插入模式后是从光标当前位置开始输入文件； 按「a」进入插入模式后，是从目前光标所在位置的下一个位置开始输入文字； 按「o」进入插入模式后，是插入新的一行，从行首开始输入文字。 2. 从插入模式切换为命令行模式 按「ESC」键。 3. 移动光标 vi可以直接用键盘上的光标来上下左右移动，但正规的vi是用小写英文字母「h」、「j」、「k」、「l」，分别控制光标左、下、上、右移一格。 按「ctrl」+「b」#屏幕往&quot;后&quot;移动一页。 按「ctrl」+「f」#屏幕往&quot;前&quot;移动一页。 按「ctrl」+「u」#屏幕往&quot;后&quot;移动半页。 按「ctrl」+「d」#屏幕往&quot;前&quot;移动半页。 按数字「0」#移到文章的开头。 按「G」#移动到文章的最后。 按「$」#移动到光标所在行的&quot;行尾&quot;。 按「^」#移动到光标所在行的&quot;行首&quot; 按「w」#光标跳到下个字的开头 按「e」#光标跳到下个字的字尾 按「b」#光标回到上个字的开头 按「#l」#光标移到该行的第#个位置，如：5l,56l。 4. 删除文字 「x」#每按一次，删除光标所在位置的&quot;后面&quot;一个字符。 「#x」#例如，「6x」表示删除光标所在位置的&quot;后面&quot;6个字符。 「X」#大写的X，每按一次，删除光标所在位置的&quot;前面&quot;一个字符。 「#X」#例如，「20X」表示删除光标所在位置的&quot;前面&quot;20个字符。 「dd」#删除光标所在行。 「#dd」#从光标所在行开始删除#行 5. 复制 「yw」#将光标所在之处到字尾的字符复制到缓冲区中。 「#yw」#复制#个字到缓冲区 「yy」#复制光标所在行到缓冲区。 「#yy」#例如，「6yy」表示拷贝从光标所在的该行&quot;往下数&quot;6行文字。 「p」#将缓冲区内的字符贴到光标所在位置。注意：所有与&quot;y&quot;有关的复制命令都必须与&quot;p&quot;配合才能完成复制与粘贴功能。 6. 替换 「r」#替换光标所在处的字符。 「R」#替换光标所到之处的字符，直到按下「ESC」键为止。 7. 恢复上一次操作 「u」#如果您误执行一个命令，可以马上按下「u」，回到上一个操作。按多次&quot;u&quot;可以执行多次回复。 8. 更改 「cw」#更改光标所在处的字到字尾处 「c#w」#例如，「c3w」表示更改3个字 9. 跳至指定的行 「ctrl」+「g」 #列出光标所在行的行号。 「#G」：例如，「15G」，表示移动光标至文章的第15行行首。 10.视图模式 「ctrl」+「v」#进入视图模式，可以移动方向键选中多行，按d键可以删除 11.清空文件 :.,$d 回车 #命令模式输入 .,$d 后回车 12.替换文本内容 #可以替换当前行的所有/usr/local为/data/dshp，命令模式输入s/old\new/g :s/\/usr\/local/\/data\/dshp/g 管道 将一个命令的标准输出作为另一个命令的标准输入。也就是把几个命令组合起来使用，后一个命令除以前一个命令的结果。 grep -r “close” /home/* | more 在home目录下所有文件中查找，包括close的文件，并分页输出。 diff 以逐行的方式，比较文本文件的异同处。指定要比较目录，则diff会比较目录中相同文件名的文件，但不会比较其中子目录。 diff [参数] [文件1或目录1] [文件2或目录2] -&lt;行数&gt; 指定要显示多少行的文本。此参数必须与-c或-u参数一并使用。 -a或--text diff预设只会逐行比较文本文件。 -b或--ignore-space-change 不检查空格字符的不同。 -B或--ignore-blank-lines 不检查空白行。 -c 显示全部内文，并标出不同之处。 -C&lt;行数&gt;或--context&lt;行数&gt; 与执行&quot;-c-&lt;行数&gt;&quot;指令相同。 -d或--minimal 使用不同的演算法，以较小的单位来做比较。 -D&lt;巨集名称&gt;或ifdef&lt;巨集名称&gt; 此参数的输出格式可用于前置处理器巨集。 -e或--ed 此参数的输出格式可用于ed的script文件。 -f或-forward-ed 输出的格式类似ed的script文件，但按照原来文件的顺序来显示不同处。 -H或--speed-large-files 比较大文件时，可加快速度。 -l&lt;字符或字符串&gt;或--ignore-matching-lines&lt;字符或字符串&gt; 若两个文件在某几行有所不同，而这几行同时都包含了选项中指定的字符或字符串，则不显示这两个文件的差异。 -i或--ignore-case 不检查大小写的不同。 -l或--paginate 将结果交由pr程序来分页。 -n或--rcs 将比较结果以RCS的格式来显示。 -N或--new-file 在比较目录时，若文件A仅出现在某个目录中，预设会显示： Only in目录：文件A若使用-N参数，则diff会将文件A与一个空白的文件比较。 -p 若比较的文件为C语言的程序码文件时，显示差异所在的函数名称。 -P或--unidirectional-new-file 与-N类似，但只有当第二个目录包含了一个第一个目录所没有的文件时，才会将这个文件与空白的文件做比较。 -q或--brief 仅显示有无差异，不显示详细的信息。 -r或--recursive 比较子目录中的文件。 -s或--report-identical-files 若没有发现任何差异，仍然显示信息。 -S&lt;文件&gt;或--starting-file&lt;文件&gt; 在比较目录时，从指定的文件开始比较。 -t或--expand-tabs 在输出时，将tab字符展开。 -T或--initial-tab 在每行前面加上tab字符以便对齐。 -u,-U&lt;列数&gt;或--unified=&lt;列数&gt; 以合并的方式来显示文件内容的不同。 -v或--version 显示版本信息。 -w或--ignore-all-space 忽略全部的空格字符。 -W&lt;宽度&gt;或--width&lt;宽度&gt; 在使用-y参数时，指定栏宽。 -x&lt;文件名或目录&gt;或--exclude&lt;文件名或目录&gt; 不比较选项中所指定的文件或目录。 -X&lt;文件&gt;或--exclude-from&lt;文件&gt; 您可以将文件或目录类型存成文本文件，然后在=&lt;文件&gt;中指定此文本文件。 -y或--side-by-side 以并列的方式显示文件的异同之处。 --help 显示帮助。 --left-column 在使用-y参数时，若两个文件某一行内容相同，则仅在左侧的栏位显示该行内容。 --suppress-common-lines 在使用-y参数时，仅显示不同之处 示例： 比较两个文件 [root@localhost test3]# diff log2014.log log2013.log 3c3 &lt; 2014-03 --- &gt; 2013-03 8c8 &lt; 2013-07 --- &gt; 2013-08 11,12d10 &lt; 2013-11 &lt; 2013-12 【注】 上面的”3c3”和”8c8”表示log2014.log和log20143log文件在3行和第8行内容有所不同；”11,12d10”表示第一个文件比第二个文件多了第11和12行。 并排格式输出 [root@localhost test3]# diff log2014.log log2013.log -y -W 50 2013-01 2013-01 2013-02 2013-02 2014-03 | 2013-03 2013-04 2013-04 2013-05 2013-05 2013-06 2013-06 2013-07 2013-07 2013-07 | 2013-08 2013-09 2013-09 2013-10 2013-10 2013-11 &lt; 2013-12 &lt; [root@localhost test3]# diff log2013.log log2014.log -y -W 50 2013-01 2013-01 2013-02 2013-02 2013-03 | 2014-03 2013-04 2013-04 2013-05 2013-05 2013-06 2013-06 2013-07 2013-07 2013-08 | 2013-07 2013-09 2013-09 2013-10 2013-10 &gt; 2013-11 &gt; 2013-12 【注】 “|”表示前后2个文件内容有不同 “&lt;”表示后面文件比前面文件少了1行内容 “&gt;”表示后面文件比前面文件多了1行内容 ln 某一个文件在另外一个位置建立一个同步的链接，通常给/usr/bin/下建立软连接，相当于给某个应用程序配置环境变量一样，可以不带路径直接运行命令 ln [参数] [源文件或目录] [目标文件或目录] -s 建立软连接 -v 显示详细的处理过程 which 查看可执行文件的位置，在PATH变量指定的路径中查看系统命令是否存在及其位置 which 可执行文件名称 whereis 定位可执行文件、源代码文件、帮助文件在文件系统中的位置 whereis [-bmsu] [BMS 目录名 -f ] 文件名 -b 定位可执行文件。 -m 定位帮助文件。 -s 定位源代码文件。 -u 搜索默认路径下除可执行文件、源代码文件、帮助文件以外的其它文件。 -B 指定搜索可执行文件的路径。 -M 指定搜索帮助文件的路径。 -S 指定搜索源代码文件的路径。 locate 通过搜寻数据库快速搜寻档案 -r 使用正规运算式做寻找的条件 系统管理相关命令ps 列出当前进程的快照 a 显示所有的进程 -a 显示同一终端下的所有程序 e 显示环境变量 f 显示进程间的关系 -H 显示树状结构 r 显示当前终端的程序 T 显示当前终端的所有程序 -au 显示更详细的信息 -aux 显示所有包含其他使用者的行程 -u 指定用户的所有进程 eg: ps aux # 查看系统所有的进程数据 ps ax # 查看不与terminal有关的所有进程 ps -lA # 查看系统所有的进程数据 ps axjf # 查看连同一部分进程树状态 ps aux | grep tomcat ps -ef | grep tomcat df 显示指定磁盘文件的可用空间,如果没有文件名被指定，则所有当前被挂载的文件系统的可用空间将被显示 df [选项] [文件] -a 显示全部文件系统 -h 文件大小友好显示，即会显示单位 -l 只显示本地文件系统 -i 显示inode信息 -T 显示文件系统类型 du 显示每个文件和目录的磁盘使用空间 du [选项] [文件] -h 方便阅读的方式，会带单位 -s 只显示总和的大小 top 显示当前系统正在执行的进程的相关信息，包括进程ID、内存占用率、CPU占用率等 top [参数] free 显示Linux系统中空闲的、已用的物理内存及swap内存,及被内核使用的buffer free [参数] quota 显示用户或者工作组的磁盘配额信息。输出信息包括磁盘使用和配额限制 quota(选项)(参数) -g：列出群组的磁盘空间限制； -q：简明列表，只列出超过限制的部分； -u：列出用户的磁盘空间限制； -v：显示该用户或群组，在所有挂入系统的存储设备的空间限制； -V：显示版本信息。 我们可以限制某一群组所能使用的最大磁盘配额，而且可以再限制某一使用者的最大磁盘配额 ，好比做一个收费的应用，vip可以得到空间更大一些。另外，以 Link 的方式，来使邮件可以作为限制的配额（更改/var/spool/mail 这个路径），不2，需要重新再规划一个硬盘！直接使用 Link 的方式指向 /home （或者其它已经做好的 quota 磁盘）就可以！这通常是用在原本规划不好，但是却又不想要更动原有主机架构的情况中！ 要求：Linux 主机里面主要针对 quser1 及 quser2 两个使用者来进行磁盘配额， 且这两个使用者都是挂在 qgroup 组里面的。每个使用者总共有 50MB 的磁盘空间 (不考虑 inode) 限制！并且 soft limit 为 45 MB；而宽限时间设定为 1 天， 但是在一天之内必须要将多余的文件删除掉，否则将无法使用剩下的空间 ；gquota 这个组考虑最大限额，所以设定为 90 MB！（注意，这样设置的好处是富有弹性，好比现在的邮件服务，那么多用户，承诺给用户每人最大空间为数GB，然而人们不可能每人都会使用那么大的空间，所以邮件服务的总空间，实际上肯定不是注册客户数乘以数GB，否则这样得多大啊。） [root@jet ~]# groupadd qgroup [root@jet ~]# useradd -m -g qgroup quser1 [root@jet ~]# useradd -m -g qgroup quser2 [root@jet ~]# passwd quser1 [root@jet ~]# passwd quser2 [root@jet ~]# df #用/disk2测试 Filesystem 1K-blocks Used Available Use% Mounted on /dev/hda1 5952252 3193292 2451720 57% / /dev/hdb1 28267608 77904 26730604 1% /disk2 /dev/hda5 9492644 227252 8775412 3% /disk1 [root@jet ~]# vi /etc/fstab LABEL=/ / ext3 defaults 1 1 LABEL=/disk1 /disk1 ext3 defaults 1 2 LABEL=/disk2 /disk2 ext3 defaults,usrquota,grpquota 1 2 /dev/hda3 swap swap defaults 0 0 注意多了usrquota,grpquota，在defaults,usrquota,grpquota之间都没有空格，务必正确书写。这样就算加入了 quota 的磁盘格式了！不过，由于真正的 quota 在读取的时候是读取/etc/mtab这个文件的，而该文件需要重新开机之后才能够以/etc/fstab 的新数据进行改写！所以这个时候可以选择：重新开机 (reboot)。 重新remount filesystem来驱动设定值。 [root@jet ~]# umount /dev/hdb1 [root@jet ~]# mount -a [root@jet ~]# grep &#39;/disk2&#39; /etc/mtab /dev/hdb1 /disk2 ext3 rw,usrquota,grpquota 0 0 事实上，也可以利用 mount 的 remount 功能。 [root@jet ~]# mount -o remount /disk2 这样就已经成功的将 filesystem 的 quota 功能加入。 扫瞄磁盘的使用者使用状况，并产生重要的 aquota.group 与 aquota.user： [root@jet ~]# quotacheck -avug quotacheck: Scanning /dev/hdb1 [/disk2] done quotacheck: Checked 3 directories and 4 files [root@localhost ~]# ll /disk2 -rw------- 1 root root 6144 Sep 6 11:44 aquota.group -rw------- 1 root root 6144 Sep 6 11:44 aquota.user 使用 quotacheck 就可以轻易的将所需要的数据给他输出了！但奇怪的是，在某些 Linux 版本中，不能够以 aquota.user(group) 来启动quota ，可能是因为旧版 quota 的关系， 所以就另外做了一个 link 文件按来欺骗 quota，这个动作非必要。（主要是学习这个思维很重要） [root@localhost ~]# cd /disk2 [root@localhost ~]# ln -s aquota.user quota.user [root@localhost ~]# ln -s aquota.group quota.group 启动 quota 的限额： [root@localhost ~]# quotaon -avug /dev/hdb1 [/disk2]: group quotas turned on /dev/hdb1 [/disk2]: user quotas turned on ===&gt; 看到turned on，才是真的成功！ 编辑使用者的可使用空间： [root@localhost ~]# edquota -u quser1 Disk quotas for user quser1 (uid 502): Filesystem blocks soft hard inodes soft hard /dev/hdb1 0 45000 50000 0 0 0 [root@localhost ~]# edquota -p quser1 quser2 ===&gt; 直接复制给quser2 接下来要来设定宽限时间，还是使用 edquota [root@localhost ~]# edquota -t Grace period before enforcing soft limits for users: time units may be: days, hours, minutes, or seconds Filesystem Block grace period Inode grace period /dev/hdb1 1days 7days 使用quota -v来查询： [root@localhost ~]# quota -vu quser1 quser2 Disk quotas for user quser1 (uid 502): Filesystem blocks quota limit grace files quota limit grace /dev/hdb1 0 45000 50000 0 0 0 Disk quotas for user quser2 (uid 503): Filesystem blocks quota limit grace files quota limit grace /dev/hdb1 0 45000 50000 0 0 0 注意，由于使用者尚未超过45 MB，所以 grace ( 宽限时间 ) 就不会出现。 编辑群组可使用的空间： [root@localhost ~]# edquota -g qgroup Disk quotas for group qgroup (gid 502): Filesystem blocks soft hard inodes soft hard /dev/hdb1 0 80000 90000 0 0 0 [root@localhost ~]# quota -vg qgroup Disk quotas for group qgroup (gid 502): Filesystem blocks quota limit grace files quota limit grace /dev/hdb1 0 80000 90000 0 0 0 kill 用于向某个工作（%jobnumber）或者是某个PID（数字）传送一个信号，它通常与ps和jobs命令一起使用 kill [参数] [进程号] 1：SIGHUP，启动被终止的进程 2：SIGINT，相当于输入ctrl+c，中断一个程序的进行 9：SIGKILL，强制中断一个进程的进行 15：SIGTERM，以正常的结束进程方式来终止进程 17：SIGSTOP，相当于输入ctrl+z，暂停一个进程的进行 eg: kill -9 19785 killall 杀死同一进程组内的所有进程。其允许指定要终止的进程的名称，而非PID -i ：交互式的意思，若需要删除时，会询问用户 -e ：表示后面接的command name要一致，但command name不能超过15个字符 -I ：命令名称忽略大小写 eg: killall -SIGHUP syslogd # 重新启动syslogd useradd 创建的新的系统用户 帐号建好之后，再用passwd设定帐号的密码．而可用userdel删除帐号。使用useradd指令所建立的帐号，实际上是保存在/etc/passwd文本文件中。 在Slackware中，adduser指令是个script程序，利用交谈的方式取得输入的用户帐号资料，然后再交由真正建立帐号的useradd命令建立新用户，如此可方便管理员建立用户帐号。在Red Hat Linux中，adduser命令则是useradd命令的符号连接，两者实际上是同一个指令 useradd(选项)(参数) -c&lt;备注&gt;：加上备注文字。备注文字会保存在passwd的备注栏位中； -d&lt;登入目录&gt;：指定用户登入时的启始目录； -D：变更预设值； -e&lt;有效期限&gt;：指定帐号的有效期限； -f&lt;缓冲天数&gt;：指定在密码过期后多少天即关闭该帐号； -g&lt;群组&gt;：指定用户所属的群组； -G&lt;群组&gt;：指定用户所属的附加群组； -m：自动建立用户的登入目录； -M：不要自动建立用户的登入目录； -n：取消建立以用户名称为名的群组； -r：建立系统帐号； -s：指定用户登入后所使用的shell； -u：指定用户id。 新建用户加入组： useradd –g sales jack –G company,employees //-g：加入主要组、-G：加入次要组 建立一个新用户账户，并设置ID： useradd caojh -u 544 需要说明的是，设定ID值时尽量要大于500，以免冲突。因为Linux安装后会建立一些特殊用户，一般0到499之间的值留给bin、mail这样的系统账号 groupadd 创建一个新的工作组，新工作组的信息将被添加到系统文件中 groupadd(选项)(参数) -g：指定新建工作组的id； -r：创建系统工作组，系统工作组的组ID小于500； -K：覆盖配置文件“/ect/login.defs”； -o：允许添加组ID号不唯一的工作组。 实例 建立一个新组，并设置组ID加入系统： groupadd -g 344 linuxde 此时在/etc/passwd文件中产生一个组ID（GID）是344的项目 groupdel 删除指定的工作组 要修改的系统文件包括/ect/group和/ect/gshadow。若该群组中仍包括某些用户，则必须先删除这些用户后，方能删除群组 groupdel(参数) eg: groupadd damon //创建damon工作组 groupdel damon //删除这个工作组 crontab 提交和管理用户的需要周期性执行的任务 与windows下的计划任务类似，当安装完成操作系统后，默认会安装此服务工具，并且会自动启动crond进程，crond进程每分钟会定期检查是否有要执行的任务，如果有要执行的任务，则自动执行该任务。 crontab(选项)(参数) -e：编辑该用户的计时器设置； -l：列出该用户的计时器设置； -r：删除该用户的计时器设置； -u&lt;用户名称&gt;：指定要设定计时器的用户名称。 Linux下的任务调度分为两类：系统任务调度和用户任务调度。 系统任务调度：系统周期性所要执行的工作，比如写缓存数据到硬盘、日志清理等。在/etc目录下有一个crontab文件，这个就是系统任务调度的配置文件。 /etc/crontab文件包括下面几行： SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=&quot;&quot;HOME=/ # run-parts 51 * * * * root run-parts /etc/cron.hourly 24 7 * * * root run-parts /etc/cron.daily 22 4 * * 0 root run-parts /etc/cron.weekly 42 4 1 * * root run-parts /etc/cron.monthly 【注】 前四行是用来配置crond任务运行的环境变量，第一行SHELL变量指定了系统要使用哪个shell，这里是bash，第二行PATH变量指定了系统执行命令的路径，第三行MAILTO变量指定了crond的任务执行信息将通过电子邮件发送给root用户，如果MAILTO变量的值为空，则表示不发送任务执行信息给用户，第四行的HOME变量指定了在执行命令或者脚本时使用的主目录。 用户任务调度：用户定期要执行的工作，比如用户数据备份、定时邮件提醒等。用户可以使用 crontab 工具来定制自己的计划任务。所有用户定义的crontab文件都被保存在/var/spool/cron目录中。其文件名与用户名一致，使用者权限文件如下： /etc/cron.deny 该文件中所列用户不允许使用crontab命令 /etc/cron.allow 该文件中所列用户允许使用crontab命令 /var/spool/cron/ 所有用户crontab文件存放的目录,以用户名命名 crontab文件的含义：用户所建立的crontab文件中，每一行都代表一项任务，每行的每个字段代表一项设置，它的格式共分为六个字段，前五段是时间设定段，第六段是要执行的命令段，格式如下： minute hour day month week command 顺序：分 时 日 月 周 minute： 表示分钟，可以是从0到59之间的任何整数。 hour：表示小时，可以是从0到23之间的任何整数。 day：表示日期，可以是从1到31之间的任何整数。 month：表示月份，可以是从1到12之间的任何整数。 week：表示星期几，可以是从0到7之间的任何整数，这里的0或7代表星期日。 command：要执行的命令，可以是系统命令，也可以是自己编写的脚本文件。 在以上各个字段中，还可以使用以下特殊字符： 星号（*）：代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。 逗号（,）：可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9” 中杠（-）：可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6” 正 斜线（/）：可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如*/10，如果用在minute字段，表示每十分钟执行一次。 service crond start #启动服务 service crond stop #关闭服务 service crond restart #重启服务 service crond reload #重新载入配置 service crond status #查看crontab服务状态 ntsysv #查看crontab服务是否已设置为开机启动 chkconfig –level 35 crond on #开机启动 eg: * * * * * command #每1分钟执行一次command 3,15 * * * * command #每小时的第3和第15分钟执行 3,15 8-11 * * * command #在上午8点到11点的第3和第15分钟执行 3,15 8-11 */2 * * command #每隔两天的上午8点到11点的第3和第15分钟执行 3,15 8-11 * * 1 command #每个星期一的上午8点到11点的第3和第15分钟执行 30 21 * * * /etc/init.d/smb restart #每晚的21:30重启smb 45 4 1,10,22 * * /etc/init.d/smb restart #每月1、10、22日的4 : 45重启smb 10 1 * * 6,0 /etc/init.d/smb restart #每周六、周日的1:10重启smb 0,30 18-23 * * * /etc/init.d/smb restart #每天18 : 00至23 : 00之间每隔30分钟重启smb 0 23 * * 6 /etc/init.d/smb restart #每星期六的晚上11:00 pm重启smb * */1 * * * /etc/init.d/smb restart #每一小时重启smb * 23-7/1 * * * /etc/init.d/smb restart #晚上11点到早上7点之间，每隔一小时重启smb 0 11 4 * mon-wed /etc/init.d/smb restart #每月的4号与每周一到周三的11点重启smb 0 4 1 jan * /etc/init.d/smb restart #一月一号的4点重启smb 01 * * * * root run-parts /etc/cron.hourly #每小时执行/etc/cron.hourly目录内的脚本 网络操作命令ifconfig 配置和显示Linux内核中网络接口的网络参数 用ifconfig命令配置的网卡信息，在网卡重启后机器重启后，配置就不存在。要想将上述的配置信息永远的存的电脑里，那就要修改网卡的配置文件了。 ifconfig(参数) add&lt;地址&gt;：设置网络设备IPv6的ip地址； del&amp;lt;地址&amp;gt;：删除网络设备IPv6的IP地址； down：关闭指定的网络设备； &amp;lt;hw&amp;lt;网络设备类型&amp;gt;&amp;lt;硬件地址&amp;gt;：设置网络设备的类型与硬件地址； io_addr&amp;lt;I/O地址&amp;gt;：设置网络设备的I/O地址； irq&amp;lt;IRQ地址&amp;gt;：设置网络设备的IRQ； media&amp;lt;网络媒介类型&amp;gt;：设置网络设备的媒介类型； mem_start&amp;lt;内存地址&amp;gt;：设置网络设备在主内存所占用的起始地址； metric&amp;lt;数目&amp;gt;：指定在计算数据包的转送次数时，所要加上的数目； mtu&amp;lt;字节&amp;gt;：设置网络设备的MTU； netmask&amp;lt;子网掩码&amp;gt;：设置网络设备的子网掩码； tunnel&amp;lt;地址&amp;gt;：建立IPv4与IPv6之间的隧道通信地址； up：启动指定的网络设备； -broadcast&amp;lt;地址&amp;gt;：将要送往指定地址的数据包当成广播数据包来处理； -pointopoint&amp;lt;地址&amp;gt;：与指定地址的网络设备建立直接连线，此模式具有保密功能； -promisc：关闭或启动指定网络设备的promiscuous模式； IP地址：指定网络设备的IP地址； 网络设备：指定网络设备的名称。 显示网络设备信息（激活状态的）： [root@jet ~]# ifconfig eth0 Link encap:Ethernet HWaddr 00:16:3E:00:1E:51 inet addr:10.160.7.81 Bcast:10.160.15.255 Mask:255.255.240.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:61430830 errors:0 dropped:0 overruns:0 frame:0 TX packets:88534 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:3607197869 (3.3 GiB) TX bytes:6115042 (5.8 MiB) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:56103 errors:0 dropped:0 overruns:0 frame:0 TX packets:56103 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:5079451 (4.8 MiB) TX bytes:5079451 (4.8 MiB) 【注】eth0表示第一块网卡，其中HWaddr表示网卡的物理地址，可以看到目前这个网卡的物理地址(MAC地址）是00:16:3E:00:1E:51。 inet addr**用来表示网卡的IP地址，此网卡的IP地址是10.160.7.81，广播地址Bcast:10.160.15.255，掩码地址Mask:255.255.240.0。 lo是表示主机的回坏地址，这个一般是用来测试一个网络程序，但又不想让局域网或外网的用户能够查看，只能在此台主机上运行和查看所用的网络接口。比如把 httpd服务器的指定到回坏地址，在浏览器输入127.0.0.1就能看到你所架WEB网站了。但只是您能看得到，局域网的其它主机或用户无从知道。 第一行：连接类型：Ethernet（以太网）HWaddr（硬件mac地址）。第二行：网卡的IP地址、子网、掩码。第三行：UP（代表网卡开启状态）RUNNING（代表网卡的网线被接上）MULTICAST（支持组播）MTU:1500（最大传输单元）：1500字节。第四、五行：接收、发送数据包情况统计。第七行：接收、发送数据字节数统计信息。 启动关闭指定网卡： ifconfig eth0 up ifconfig eth0 down ifconfig eth0 up为启动网卡eth0，ifconfig eth0 down为关闭网卡eth0。ssh登陆linux服务器操作要小心，关闭了就不能开启了，除非你有多网卡。 为网卡配置和删除IPv6地址： ifconfig eth0 add 33ffe:3240:800:1005::2/64 #为网卡eth0配置IPv6地址 ifconfig eth0 del 33ffe:3240:800:1005::2/64 #为网卡eth0删除IPv6地址 用ifconfig修改MAC地址： ifconfig eth0 hw ether 00:AA:BB:CC:dd:EE 配置IP地址： [root@localhost ~]# ifconfig eth0 192.168.2.10 [root@localhost ~]# ifconfig eth0 192.168.2.10 netmask 255.255.255.0 [root@localhost ~]# ifconfig eth0 192.168.2.10 netmask 255.255.255.0 broadcast 192.168.2.255 启用和关闭arp协议： ifconfig eth0 arp #开启网卡eth0 的arp协议 ifconfig eth0 -arp #关闭网卡eth0 的arp协议 设置最大传输单元： ifconfig eth0 mtu 1500 #设置能通过的最大数据包大小为 1500 bytes netstat 打印Linux中网络系统的状态信息，可让你得知整个Linux系统的网络情况 netstat(选项) -a或--all：显示所有连线中的Socket； -A&amp;lt;网络类型&amp;gt;或--&amp;lt;网络类型&amp;gt;：列出该网络类型连线中的相关地址； -c或--continuous：持续列出网络状态； -C或--cache：显示路由器配置的快取信息； -e或--extend：显示网络其他相关信息； -F或--fib：显示FIB； -g或--groups：显示多重广播功能群组组员名单； -h或--help：在线帮助； -i或--interfaces：显示网络界面信息表单； -l或--listening：显示监控中的服务器的Socket； -M或--masquerade：显示伪装的网络连线； -n或--numeric：直接使用ip地址，而不通过域名服务器； -N或--netlink或--symbolic：显示网络硬件外围设备的符号连接名称； -o或--timers：显示计时器； -p或--programs：显示正在使用Socket的程序识别码和程序名称； -r或--route：显示Routing Table； -s或--statistice：显示网络工作信息统计表； -t或--tcp：显示TCP传输协议的连线状况； -u或--udp：显示UDP传输协议的连线状况； -v或--verbose：显示指令执行过程； -V或--version：显示版本信息； -w或--raw：显示RAW传输协议的连线状况； -x或--unix：此参数的效果和指定&quot;-A unix&quot;参数相同； --ip或--inet：此参数的效果和指定&quot;-A inet&quot;参数相同。 eg: netstat -a #列出所有端口 netstat -at #列出所有tcp端口 netstat -au #列出所有udp端口 netstat -l #只显示监听端口 netstat -lt #只列出所有监听 tcp 端口 netstat -lu #只列出所有监听 udp 端口 netstat -lx #只列出所有监听 UNIX 端口 netstat -s #显示所有端口的统计信息 netstat -st #显示TCP端口的统计信息 netstat -su #显示UDP端口的统计信息 netstat -pt #在netstat输出中显示 PID 和进程名称 netstat -p可以与其它开关一起使用，就可以添加“PID/进程名称”到netstat输出中，这样debugging的时候可以很方便的发现特定端口运行的程序。 在netstat输出中不显示主机，端口和用户名(host, port or user) 当你不想让主机，端口和用户名显示，使用netstat -n。将会使用数字代替那些名称。同样可以加速输出，因为不用进行比对查询。 netstat -an 如果只是不想让这三个名称中的一个被显示，使用以下命令: netsat -a --numeric-ports netsat -a --numeric-hosts netsat -a --numeric-users 持续输出netstat信息 netstat -c #每隔一秒输出网络信息 显示系统不支持的地址族(Address Families) netstat --verbose 在输出的末尾，会有如下的信息： netstat: no support for `AF IPX&#39; on this system. netstat: no support for `AF AX25&#39; on this system. netstat: no support for `AF X25&#39; on this system. netstat: no support for `AF NETROM&#39; on this system. 显示核心路由信息 netstat -r 使用netstat -rn显示数字格式，不查询主机名称。 找出程序运行的端口 并不是所有的进程都能找到，没有权限的会不显示，使用 root 权限查看所有的信息。 netstat -ap | grep ssh 找出运行在指定端口的进程： netstat -an | grep &#39;:80&#39; 显示网络接口列表 netstat -i 显示详细信息，像是ifconfig使用 netstat -ie。 IP和TCP分析 查看连接某服务端口最多的的IP地址： netstat -ntu | grep :80 | awk &#39;{print $5}&#39; | cut -d: -f1 | awk &#39;{++ip[$1]} END {for(i in ip) print ip[i],&quot;\t&quot;,i}&#39; | sort -nr TCP各种状态列表： netstat -nt | grep -e 127.0.0.1 -e 0.0.0.0 -e ::: -v | awk &#39;/^tcp/ {++state[$NF]} END {for(i in state) print i,&quot;\t&quot;,state[i]}&#39; 查看phpcgi进程数，如果接近预设值，说明不够用，需要增加： netstat -anpo | grep &quot;php-cgi&quot; | wc -l telnet 登录远程主机，对远程主机进行管理 telnet因为采用明文传送报文，安全性不好，很多Linux服务器都不开放telnet服务，而改用更安全的ssh方式了。但仍然有很多别的系统可能采用了telnet方式来提供远程登录，因此弄清楚telnet客户端的使用方式仍是很有必要的。 telnet(选项)(参数) -8：允许使用8位字符资料，包括输入与输出； -a：尝试自动登入远端系统； -b&lt;主机别名&gt;：使用别名指定远端主机名称； -c：不读取用户专属目录里的.telnetrc文件； -d：启动排错模式； -e&lt;脱离字符&gt;：设置脱离字符； -E：滤除脱离字符； -f：此参数的效果和指定&quot;-F&quot;参数相同； -F：使用Kerberos V5认证时，加上此参数可把本地主机的认证数据上传到远端主机； -k&lt;域名&gt;：使用Kerberos认证时，加上此参数让远端主机采用指定的领域名，而非该主机的域名； -K：不自动登入远端主机； -l&lt;用户名称&gt;：指定要登入远端主机的用户名称； -L：允许输出8位字符资料； -n&lt;记录文件&gt;：指定文件记录相关信息； -r：使用类似rlogin指令的用户界面； -S&lt;服务类型&gt;：设置telnet连线所需的ip TOS信息； -x：假设主机有支持数据加密的功能，就使用它； -X&lt;认证形态&gt;：关闭指定的认证形态。 eg: [root@jet oschina_hexo_server]# telnet 124.251.54.61 5001 Trying 124.251.54.61... Connected to 124.251.54.61. Escape character is &#39;^]&#39;. SSH-2.0-OpenSSH_6.7 ping 测试主机之间网络的连通性 执行ping指令会使用ICMP传输协议，发出要求回应的信息，若远端主机的网络功能没有问题，就会回应该信息，因而得知该主机运作正常。 ping(选项)(参数) -d：使用Socket的SO_DEBUG功能； -c&lt;完成次数&gt;：设置完成要求回应的次数； -f：极限检测； -i&lt;间隔秒数&gt;：指定收发信息的间隔时间； -I&lt;网络界面&gt;：使用指定的网络界面送出数据包； -l&lt;前置载入&gt;：设置在送出要求信息之前，先行发出的数据包； -n：只输出数值； -p&lt;范本样式&gt;：设置填满数据包的范本样式； -q：不显示指令执行过程，开头和结尾的相关信息除外； -r：忽略普通的Routing Table，直接将数据包送到远端主机上； -R：记录路由过程； -s&lt;数据包大小&gt;：设置数据包的大小； -t&lt;存活数值&gt;：设置存活数值TTL的大小； -v：详细显示指令的执行过程。 eg: [root@jet oschina_hexo_server]# ping www.baidu.com PING www.a.shifen.com (220.181.112.244) 56(84) bytes of data. 64 bytes from 220.181.112.244: icmp_seq=1 ttl=45 time=13.9 ms 64 bytes from 220.181.112.244: icmp_seq=2 ttl=45 time=3.27 ms 64 bytes from 220.181.112.244: icmp_seq=3 ttl=45 time=2.46 ms 64 bytes from 220.181.112.244: icmp_seq=4 ttl=45 time=3.39 ms 64 bytes from 220.181.112.244: icmp_seq=5 ttl=45 time=2.42 ms 64 bytes from 220.181.112.244: icmp_seq=6 ttl=45 time=2.70 ms 64 bytes from 220.181.112.244: icmp_seq=7 ttl=45 time=2.54 ms 64 bytes from 220.181.112.244: icmp_seq=8 ttl=45 time=3.78 ms 64 bytes from 220.181.112.244: icmp_seq=9 ttl=45 time=3.20 ms 64 bytes from 220.181.112.244: icmp_seq=10 ttl=45 time=2.46 ms 64 bytes from 220.181.112.244: icmp_seq=11 ttl=45 time=2.56 ms 64 bytes from 220.181.112.244: icmp_seq=12 ttl=45 time=2.74 ms 64 bytes from 220.181.112.244: icmp_seq=13 ttl=45 time=2.42 ms 64 bytes from 220.181.112.244: icmp_seq=14 ttl=45 time=2.46 ms #ctrl + c 结束 --- www.a.shifen.com ping statistics --- 14 packets transmitted, 14 received, 0% packet loss, time 13555ms rtt min/avg/max/mdev = 2.420/3.596/13.902/2.889 ms ftp 用来设置文件系统相关功能 ftp服务器在网上较为常见，Linux ftp命令的功能是用命令的方式来控制在本地机和远程机之间传送文件，这里详细介绍Linux ftp命令的一些经常使用的命令，相信掌握了这些使用Linux进行ftp操作将会非常容易。 ftp(选项)(参数) -d：详细显示指令执行过程，便于排错或分析程序执行的情况； -i：关闭互动模式，不询问任何问题； -g：关闭本地主机文件名称支持特殊字符的扩充特性； -n：不使用自动登录； -v：显示指令执行过程。 FTP&gt;ascii: 设定以ASCII方式传送文件(缺省值) FTP&gt;bell: 每完成一次文件传送,报警提示. FTP&gt;binary: 设定以二进制方式传送文件. FTP&gt;bye: 终止主机FTP进程,并退出FTP管理方式. FTP&gt;case: 当为ON时,用MGET命令拷贝的文件名到本地机器中,全部转换为小写字母. FTP&gt;cd: 同UNIX的CD命令. FTP&gt;cdup: 返回上一级目录. FTP&gt;chmod: 改变远端主机的文件权限. FTP&gt;close: 终止远端的FTP进程,返回到FTP命令状态, 所有的宏定义都被删除. FTP&gt;delete: 删除远端主机中的文件. FTP&gt;dir [remote-directory] [local-file] 列出当前远端主机目录中的文件.如果有本地文件,就将结果写至本地文件. FTP&gt;get [remote-file] [local-file] 从远端主机中传送至本地主机中. FTP&gt;help [command] 输出命令的解释. FTP&gt;lcd: 改变当前本地主机的工作目录,如果缺省,就转到当前用户的HOME目录. FTP&gt;ls [remote-directory] [local-file] 同DIR. FTP&gt;macdef: 定义宏命令. FTP&gt;mdelete [remote-files] 删除一批文件. FTP&gt;mget [remote-files] 从远端主机接收一批文件至本地主机. FTP&gt;mkdir directory-name 在远端主机中建立目录. FTP&gt;mput local-files 将本地主机中一批文件传送至远端主机. FTP&gt;open host [port] 重新建立一个新的连接. FTP&gt;prompt: 交互提示模式. FTP&gt;put local-file [remote-file] 将本地一个文件传送至远端主机中. FTP&gt;pwd: 列出当前远端主机目录. FTP&gt;quit: 同BYE. FTP&gt;recv remote-file [local-file] 同GET. FTP&gt;rename [from] [to] 改变远端主机中的文件名. FTP&gt;rmdir directory-name 删除远端主机中的目录. FTP&gt;send local-file [remote-file] 同PUT. FTP&gt;status: 显示当前FTP的状态. FTP&gt;system: 显示远端主机系统类型. FTP&gt;user user-name [password] [account] 重新以别的用户名登录远端主机. FTP&gt;? [command]: 同HELP. [command]指定需要帮助的命令名称。如果没有指定 command，ftp 将显示全部命令的列表。 FTP&gt;! 从 ftp 子系统退出到外壳。 sftp 交互式的文件传输程序 命令的运行和使用方式与ftp命令相似，但是，sftp命令对传输的所有信息使用ssh加密，它还支持公钥认证和压缩等功能 -B：指定传输文件时缓冲区的大小； -l：使用ssh协议版本1； -b：指定批处理文件； -C：使用压缩； -o：指定ssh选项； -F：指定ssh配置文件； -R：指定一次可以容忍多少请求数； -v：升高日志等级。 推荐一款sftp连接工具 FlashFXP iptables Linux上常用的防火墙软件 是netfilter项目的一部分。可以直接配置，也可以通过许多前端和图形界面配置。 iptables(选项)(参数) -t&lt;表&gt;：指定要操纵的表； -A：向规则链中添加条目； -D：从规则链中删除条目； -i：向规则链中插入条目； -R：替换规则链中的条目； -L：显示规则链中已有的条目； -F：清楚规则链中已有的条目； -Z：清空规则链中的数据包计算器和字节计数器； -N：创建新的用户自定义规则链； -P：定义规则链中的默认目标； -h：显示帮助信息； -p：指定要匹配的数据包协议类型； -s：指定要匹配的数据包源ip地址； -j&lt;目标&gt;：指定要跳转的目标； -i&lt;网络接口&gt;：指定数据包进入本机的网络接口； -o&lt;网络接口&gt;：指定数据包要离开本机所使用的网络接口。 iptables命令选项输入顺序： iptables -t 表名 &lt;-A/I/D/R&gt; 规则链名 [规则号] &lt;-i/o 网卡名&gt; -p 协议名 &lt;-s 源IP/源子网&gt; --sport 源端口 &lt;-d 目标IP/目标子网&gt; --dport 目标端口 -j 动作 表名包括： raw：高级功能，如：网址过滤。 mangle：数据包修改（QOS），用于实现服务质量。 net：地址转换，用于网关路由器。 filter：包过滤，用于防火墙规则。 规则链名包括： I NPUT链：处理输入数据包。 OUTPUT链：处理输出数据包。 PORWARD链：处理转发数据包。 PREROUTING链：用于目标地址转换（DNAT）。 POSTOUTING链：用于源地址转换（SNAT）。 动作包括： accept：接收数据包。 DROP：丢弃数据包。 REDIRECT：重定向、映射、透明代理。 SNAT：源地址转换。 DNAT：目标地址转换。 MASQUERADE：IP伪装（NAT），用于ADSL。 LOG：日志记录。 清除已有iptables规则 iptables -F iptables -X iptables -Z 开放指定的端口 iptables -A INPUT -s 127.0.0.1 -d 127.0.0.1 -j ACCEPT #允许本地回环接口(即运行本机访问本机) iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT #允许已建立的或相关连的通行 iptables -A OUTPUT -j ACCEPT #允许所有本机向外的访问 iptables -A INPUT -p tcp --dport 22 -j ACCEPT #允许访问22端口 iptables -A INPUT -p tcp --dport 80 -j ACCEPT #允许访问80端口 iptables -A INPUT -p tcp --dport 21 -j ACCEPT #允许ftp服务的21端口 iptables -A INPUT -p tcp --dport 20 -j ACCEPT #允许FTP服务的20端口 iptables -A INPUT -j reject #禁止其他未允许的规则访问 iptables -A FORWARD -j REJECT #禁止其他未允许的规则访问 屏蔽IP iptables -I INPUT -s 123.45.6.7 -j DROP #屏蔽单个IP的命令 iptables -I INPUT -s 123.0.0.0/8 -j DROP #封整个段即从123.0.0.1到123.255.255.254的命令 iptables -I INPUT -s 124.45.0.0/16 -j DROP #封IP段即从123.45.0.1到123.45.255.254的命令 iptables -I INPUT -s 123.45.6.0/24 -j DROP #封IP段即从123.45.6.1到123.45.6.254的命令是 查看已添加的 iptables规则 iptables -L -n -v Chain INPUT (policy DROP 48106 packets, 2690K bytes) pkts bytes target prot opt in out source destination 5075 589K ACCEPT all -- lo * 0.0.0.0/0 0.0.0.0/0 191K 90M ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:22 1499K 133M ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:80 4364K 6351M ACCEPT all -- * * 0.0.0.0/0 0.0.0.0/0 state RELATED,ESTABLISHED 6256 327K ACCEPT icmp -- * * 0.0.0.0/0 0.0.0.0/0 Chain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 3382K packets, 1819M bytes) pkts bytes target prot opt in out source destination 5075 589K ACCEPT all -- * lo 0.0.0.0/0 0.0.0.0/0 删除已添加的iptables规则 将所有iptables以序号标记显示，执行： iptables -L -n --line-numbers 比如要删除INPUT里序号为8的规则，执行： iptables -D INPUT 8 mail 命令行的电子邮件发送和接收工具 操作的界面不像elm或pine那么容易使用，但功能非常完整。 mail(选项)(参数) -b&lt;地址&gt;：指定密件副本的收信人地址； -c&lt;地址&gt;：指定副本的收信人地址； -f&lt;邮件文件&gt;：读取指定邮件文件中的邮件； -i：不显示终端发出的信息； -I：使用互动模式； -n：程序使用时，不使用mail.rc文件中的设置； -N：阅读邮件时，不显示邮件的标题； -s&lt;邮件主题&gt;：指定邮件的主题； -u&lt;用户帐号&gt;：读取指定用户的邮件； -v：执行时，显示详细的信息。 mail -s &quot;Hello from jet-han.oschina.io by shell&quot; admin@oschina.io hello,this is the content of mail. welcome to jet-han.oschina.io 【注】 第一行是输入的命令，-s表示邮件的主题，后面的admin@oschina.io则是邮件的接收人，输入完这行命令后回车，会进入邮件正文的编写，我们可以输入任何文字，比如上面的两行。当邮件正文输入完成后，需要按CTRL+D结束输入，此时会提示你输入Cc地址，即邮件抄送地址，没有直接回车就完成了邮件的发送 使用管道进行邮件发送 echo &quot;hello,this is the content of mail.welcome to jet-han.oschina.io&quot; | mail -s &quot;Hello from jet-han.oschina.io by pipe&quot; admin@oschina.io 【注】 使用管道直接敲入这行命令即可完成邮件的发送，其中echo后的是邮件正文。 使用文件进行邮件发送 mail -s &quot;Hello from jet-han.oschina.io by file&quot; admin@oschina.io &lt; mail.txt 使用上面的命令后，我们就可以把mail.txt文件的内容作为邮件的内容发送给admin@oschina.io了。 使用上述三种方式都可以给外部邮箱进行邮件发送，但因为前面2种都是直接在shell中敲入邮件内容，因此无法输入中文，即使我们使用粘贴的方式输入了中文，那么收到的邮件也是乱码的。但第3种方式，我们可以在window下编辑好邮件内容后，放到linux下，再进行发送，这样就可以正常发送中文了。不过目前邮件的中文标题暂时没有找到解决办法。 因为mail程序本身就是调用sendmail来进行邮件发送的，因此我们可以在mail命令中使用sendmail的参数进行配置，比如我想使用特定的发件人发送邮件，可以使用如下命令： mail -s &quot;Hello from linuxde.net with sender&quot; admin@oschina.io -- -f jet@oschina.io&lt; mail.txt 【注】 上面的命令中，我们使用了– -f jet@oschina.io这样的参数，这是sendmail的选项，其中-f表示邮件的发送人邮件地址 很多情况下，我们也需要使用邮件来发送附件，在linux下使用mail命令发送附件也很简单，不过首先需要安装uuencode软件包，这个程序是对二进制文件进行编码使其适合通过邮件进行发送，在CentOS上安装该软件包如下： yum install sharutils 安装完成后我们就可以来进行附件的发送了，使用如下命令： uuencode test.txt test | mail -s &quot;hello,see the attachement&quot; admin@oschina.io 完成后就可以把text.txt文件作为邮件的附件发送出去了。uuencode有两个参数，第一个是要发送的文件，第二个是显示的文件名称。 这里我主要介绍的是在CentOS下使用mail发送电子邮件的一些使用方法，需要的要求是你的linux必须安装了sendmail并开启了，同时保证可以连接外网。另外，文章中提到的命令本人都经过亲自测试，保证完全可用，不过你需要将命令中的电子邮件地址换成自己的电子邮件地址 如果出现错误[Postfix] – warning: mail_queue_enter: create file maildrop Permission denied [jet@jet oschina_hexo_server]$ lpostdrop: warning: mail_queue_enter: create file maildrop/820792.3848: Permission denied postdrop: warning: mail_queue_enter: create file maildrop/821453.3848: Permission denied postdrop: warning: mail_queue_enter: create file maildrop/821762.3848: Permission denied postdrop: warning: mail_queue_enter: create file maildrop/822488.3848: Permission denied postdrop: warning: mail_queue_enter: create file maildrop/822928.3848: Permission denied postdrop: warning: mail_queue_enter: create file maildrop/823425.3848: Permission denied postdrop: warning: mail_queue_enter: create file maildrop/823907.3848: Permission denied postdrop: warning: mail_queue_enter: create file maildrop/824427.3848: Permission denied postdrop: warning: mail_queue_enter: create file maildrop/824928.3848: Permission denied postdrop: warning: mail_queue_enter: create file maildrop/825368.3848: Permission denied postdrop: warning: mail_queue_enter: create file maildrop/825899.3848: Permission denied postdrop: warning: mail_queue_enter: create file maildrop/826355.3848: Permission denied root@jet:/var/spool/postfix# postfix check postfix/postfix-script: warning: not owned by group postdrop: /var/spool/postfix/public postfix/postfix-script: warning: not owned by group postdrop: /var/spool/postfix/maildrop root@jet:/var/spool/postfix# /etc/init.d/postfix stop root@jet:/var/spool/postfix# killall -9 postdrop root@jet:/var/spool/postfix# chgrp -R postdrop /var/spool/postfix/public root@jet:/var/spool/postfix# chgrp -R postdrop /var/spool/postfix/maildrop/ root@jet:/var/spool/postfix# postfix check root@jet:/var/spool/postfix# postfix start root@jet:/var/spool/postfix# postfix reload chmod g+s /usr/sbin/postqueue chmod g+s /usr/sbin/postdrop root@gandalf:/var/spool/postfix# postfix check #此时没有警告了 nslookup 命令是常用域名查询工具，就是查DNS信息用的命令 nslookup4有两种工作模式，即“交互模式”和“非交互模式”。在“交互模式”下，用户可以向域名服务器查询各类主机、域名的信息，或者输出域名中的主机列表。而在“非交互模式”下，用户可以针对一个主机或域名仅仅获取特定的名称或所需信息。 进入交互模式，直接输入nslookup命令，不加任何参数，则直接进入交互模式，此时nslookup会连接到默认的域名服务器（即/etc/resolv.conf 的第一个dns地址）。或者输入nslookup -nameserver/ip。进入非交互模式，就直接输入nslookup 域名就可以了。 nslookup(选项)(参数) -sil：不显示任何警告信息。 eg: [jet@jet oschina_hexo_server]$ nslookup jet-han.oschina.io Server: 114.114.114.114 Address: 114.114.114.114#53 Non-authoritative answer: Name: jet-han.oschina.io Address: 103.21.119.115 ip 显示或操纵Linux主机的路由、网络设备、策略路由和隧道，是Linux下较新的功能强大的网络配置工具 ip(选项)(参数) #(参数) 网络对象：指定要管理的网络对象； 具体操作：对指定的网络对象完成具体操作； help：显示网络对象支持的操作命令的帮助信息。 #(选项) -V：显示指令版本信息； -s：输出更详细的信息； -f：强制使用指定的协议族； -4：指定使用的网络层协议是IPv4协议； -6：指定使用的网络层协议是IPv6协议； -0：输出信息每条记录输出一行，即使内容较多也不换行显示； -r：显示主机时，不使用IP地址，而使用主机的域名。 用ip命令显示网络设备的运行状态 [jet@jet oschina_hexo_server]$ ip -s link list 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 RX: bytes packets errors dropped overrun mcast 830 14 0 0 0 0 TX: bytes packets errors dropped carrier collsns 830 14 0 0 0 0 2: eth3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:8b:22:5e brd ff:ff:ff:ff:ff:ff RX: bytes packets errors dropped overrun mcast 121209665 198774 0 0 0 0 TX: bytes packets errors dropped carrier collsns 227857521 157867 0 0 0 0 显示核心路由表 [jet@jet oschina_hexo_server]$ ip route list 10.111.24.0/24 dev eth3 proto kernel scope link src 10.111.24.222 metric 1 default via 10.111.24.1 dev eth3 proto static 显示邻居表 [jet@jet oschina_hexo_server]$ ip neigh list fe80::ac9e:6493:cb07:4add dev eth3 lladdr 54:ee:75:03:60:e7 STALE fe80::1870:3ef3:ba4f:e55b dev eth3 lladdr bc:9f:ef:8e:d3:13 STALE fe80::a28d:16ff:fe84:ac43 dev eth3 lladdr a0:8d:16:84:ac:43 STALE fe80::ca6:b92b:4736:a95a dev eth3 lladdr 24:a2:e1:39:ba:21 STALE fe80::83c:b2a6:cc95:fae7 dev eth3 lladdr 54:4e:90:7a:6b:e3 STALE fe80::8486:b8c:5150:15c1 dev eth3 lladdr 28:d2:44:74:a0:d4 STALE fe80::1c2f:e7e6:82ee:17f0 dev eth3 lladdr 20:3c:ae:b0:87:88 STALE fe80::78d2:a70e:cba3:5373 dev eth3 lladdr 28:d2:44:68:36:3c STALE fe80::9c19:a5e5:918b:b069 dev eth3 lladdr 50:7b:9d:e6:7c:ac STALE fe80::1c12:cb63:3897:fcb0 dev eth3 lladdr fc:d8:48:92:44:c9 STALE fe80::184c:1bc1:a201:2fa7 dev eth3 lladdr 90:b0:ed:77:94:4a STALE fe80::792a:9e54:8679:cb84 dev eth3 lladdr b8:ee:65:04:81:89 STALE fe80::1098:1ed2:b23a:4ef dev eth3 lladdr 5c:ad:cf:6e:11:6a STALE fe80::28bc:6b21:4fce:f51a dev eth3 lladdr 28:d2:44:c9:c0:ed STALE fe80::1895:8cec:208d:5eec dev eth3 lladdr f4:5c:89:8e:ad:a5 STALE fe80::1c44:bede:96a5:499a dev eth3 lladdr 20:ab:37:93:1f:43 STALE fe80::5a:d7d:e3f6:6f9f dev eth3 lladdr 14:2d:27:f8:4b:79 STALE fe80::61e9:b002:68c1:7ba dev eth3 lladdr 28:d2:44:6e:11:d7 STALE fe80::1cbe:22d4:b466:d564 dev eth3 lladdr 40:33:1a:ad:1b:8c STALE fe80::1863:6370:356f:c6ec dev eth3 lladdr 24:24:0e:de:6c:86 STALE fe80::426c:8fff:fe3f:304e dev eth3 lladdr 40:6c:8f:3f:30:4e STALE fe80::1824:b631:d44a:5bf3 dev eth3 lladdr 9c:fc:01:e7:c8:21 STALE fe80::1038:72ee:9f9e:51ea dev eth3 lladdr 70:48:0f:60:e7:0d STALE fe80::a069:d8a9:5fc0:219d dev eth3 lladdr ac:22:0b:c9:bb:6c STALE fe80::8e4:27f0:1ac7:97cc dev eth3 lladdr 28:d2:44:6d:fb:6f STALE fe80::59a0:8d02:8cb7:430c dev eth3 lladdr 28:d2:44:68:74:80 STALE fe80::3884:7711:39ce:2b96 dev eth3 lladdr 48:5a:b6:df:8f:8d STALE fe80::f8c1:52f5:5286:9bae dev eth3 lladdr 28:d2:44:75:5d:ec STALE fe80::c9c:69:70b5:2796 dev eth3 lladdr 2c:20:0b:bf:2d:16 STALE fe80::ee01:eeff:fe0a:fe55 dev eth3 lladdr ec:01:ee:0a:fe:55 STALE fe80::3ea3:48ff:fe99:5bf6 dev eth3 lladdr 3c:a3:48:99:5b:f6 STALE fe80::1092:6d00:3bfa:ad5f dev eth3 lladdr 7c:04:d0:32:44:24 STALE fe80::c3e:8ab7:92f8:d0f6 dev eth3 lladdr 64:b0:a6:26:a5:f0 STALE fe80::ca6:3dd9:1fe:f6a0 dev eth3 lladdr 24:24:0e:be:1a:57 STALE fe80::d265:caff:fece:62c9 dev eth3 lladdr d0:65:ca:ce:62:c9 STALE fe80::163e:bfff:fefc:ac78 dev eth3 lladdr 14:3e:bf:fc:ac:78 STALE fe80::9ef3:87ff:fec0:c6fa dev eth3 lladdr 9c:f3:87:c0:c6:fa STALE fe80::1415:65e3:71b0:4c9e dev eth3 lladdr d8:1d:72:52:6f:84 STALE 10.111.24.248 dev eth3 lladdr bc:75:74:5e:fb:2e STALE 10.111.24.220 dev eth3 lladdr 14:3e:bf:fc:ac:78 STALE 10.111.24.1 dev eth3 lladdr 10:47:80:28:02:e0 STALE 10.111.24.227 dev eth3 lladdr f4:8e:38:ba:47:3f REACHABLE scp 远程拷贝文件的命令 和它类似的命令有cp，不过cp只是在本机进行拷贝不能跨服务器，而且scp传输是加密的。可能会稍微影响一下速度。当你服务器硬盘变为只读read only system时，用scp可以帮你把文件移出来。另外，scp还非常不占资源，不会提高多少系统负荷，在这一点上，rsync就远远不及它了。虽然 rsync比scp会快一点，但当小文件众多的情况下，rsync会导致硬盘I/O非常高，而scp基本不影响系统正常使用。 scp(选项)(参数) #(选项) -1：使用ssh协议版本1； -2：使用ssh协议版本2； -4：使用ipv4； -6：使用ipv6； -B：以批处理模式运行； -C：使用压缩； -F：指定ssh配置文件； -l：指定宽带限制； -o：指定使用的ssh选项； -P：指定远程主机的端口号； -p：保留文件的最后修改时间，最后访问时间和权限模式； -q：不显示复制进度； -r：以递归方式复制； -v 详细显示输出的具体情况。 #(参数) 源文件：指定要复制的源文件。 目标文件：目标文件。格式为user@host：filename（文件名为目标文件的名称）。 (1) 复制文件： 命令格式： scp local_file remote_username@remote_ip:remote_folder 或者 scp local_file remote_username@remote_ip:remote_file 或者 scp local_file remote_ip:remote_folder 或者 scp local_file remote_ip:remote_file 第1,2个指定了用户名，命令执行后需要输入用户密码，第1个仅指定了远程的目录，文件名字不变，第2个指定了文件名 第3,4个没有指定用户名，命令执行后需要输入用户名和密码，第3个仅指定了远程的目录，文件名字不变，第4个指定了文件名 (2) 复制目录： 命令格式： scp -r local_folder remote_username@remote_ip:remote_folder 或者 scp -r local_folder remote_ip:remote_folder 第1个指定了用户名，命令执行后需要输入用户密码； 第2个没有指定用户名，命令执行后需要输入用户名和密码； eg: #从 本地 上传到 远程 scp /home/daisy/full.tar.gz root@172.19.2.75:/home/root #从 远程 下载到 本地 scp root@172.19.2.75:/home/root/full.tar.gz /home/daisy/ wget 直接从网络上下载文件 wget [参数] [URL地址] -o FILE 把记录写到FILE文件中 eg : wget -O a.txt URL wget --limit-rate=300k URL 限速下载 系统安全相关命令vmstat 对操作系统的虚拟内存、进程、CPU活动进行监控 iostat 对系统的磁盘操作活动进行监视,汇报磁盘活动统计情况，同时也会汇报出CPU使用情况 -p[磁盘] 显示磁盘和分区的情况 watch 重复执行某一命令以观察变化 watch [参数] [命令] -n 时隔多少秒刷新 -d 高亮显示动态变化 at 在一个指定的时间执行一个指定任务，只能执行一次 at [参数] [时间] HH:MM[am|pm] + number [minutes|hours|days|weeks] 强制在某年某月某日的某时刻进行该项任务 atq 查看系统未执行的任务 atrm n 删除编号为n的任务 at -c n 显示编号为n的任务的内容 passwd 用于设置用户的认证信息，包括用户密码、密码过期时间等 系统管理者则能用它管理系统用户的密码。只有管理者可以指定用户名称，一般用户只能变更自己的密码。 passwd(选项)(参数) #(选项) -l 使密码失效 -u 与-l相对，用户解锁 -S 列出登陆用户passwd文件内的相关参数 -n 后面接天数，shadow 的第 4 字段，多久不可修改密码天数 -x 后面接天数，shadow 的第 5 字段，多久内必须要更动密码 -w 后面接天数，shadow 的第 6 字段，密码过期前的警告天数 -i 后面接『日期』，shadow 的第 7 字段，密码失效日期 使用管道刘设置密码：echo &quot;zeng&quot; | passwd --stdin zenghao #(参数) 用户名：需要设置密码的用户名。 与用户、组账户信息相关的文件 存放用户信息： /etc/passwd /etc/shadow 存放组信息： /etc/group /etc/gshadow 用户信息文件分析（每项用:隔开） 例如：jack:X:503:504:::/home/jack/:/bin/bash jack //用户名 X //口令、密码 503 //用户 （0代表root、普通新建用户从500开始） 504 //所在组 : //描述 /home/jack/ //用户主目录 /bin/bash //用户缺省Shell 组信息文件分析 例如：jack:$!$:???:13801:0:99999:7:*:*: jack //组名 $!$ //被加密的口令 13801 //创建日期与今天相隔的天数 0 //口令最短位数 99999 //用户口令 7 //到7天时提醒 * //禁用天数 * //过期天数 如果是普通用户执行passwd只能修改自己的密码。如果新建用户后，要为新用户创建密码，则用passwd用户名，注意要以root用户的权限来创建 [root@jet ~]# passwd linuxde //更改或创建linuxde用户的密码； Changing password for user linuxde. New UNIX password: //请输入新密码； Retype new UNIX password: //再输入一次； passwd: all authentication tokens updated successfully. //成功； 普通用户如果想更改自己的密码，直接运行passwd即可，比如当前操作的用户是jet [jet@jet ~]$ passwd Changing password for user linuxde. //更改jet用户的密码； (current) UNIX password: //请输入当前密码； New UNIX password: //请输入新密码； Retype new UNIX password: //确认新密码； passwd: all authentication tokens updated successfully. //更改成功； 比如我们让某个用户不能修改密码，可以用-l选项来锁定： [root@localhost ~]# passwd -l linuxde //锁定用户jet不能更改密码； Locking password for user linuxde. passwd: Success //锁定成功； [jet@jet ~]# su linuxde //通过su切换到jet用户； [jet@jet ~]$ passwd //jet来更改密码； Changing password for user jet. Changing password for linuxde (current) UNIX password: //输入jet的当前密码； passwd: Authentication token manipulation error //失败，不能更改密码； 清除密码 [root@jet ~]# passwd -d jet //清除jet用户密码； Removing password for user jet. passwd: Success //清除成功； [root@jet ~]# passwd -S jet //查询jet用户密码状态； Empty password. //空密码，也就是没有密码； 【注】 当我们清除一个用户的密码时，登录时就无需密码，这一点要加以注意。 su 切换当前用户身份到其他用户身份，变更时须输入所要变更的用户帐号与密码 su [参数] user -c&lt;指令&gt;或--command=&lt;指令&gt;：执行完指定的指令后，即恢复原来的身份； -f或——fast：适用于csh与tsch，使shell不用去读取启动文件； -l或——login：改变身份时，也同时变更工作目录，以及HOME,SHELL,USER,logname。此外，也会变更PATH变量； -m,-p或--preserve-environment：变更身份时，不要变更环境变量； -s或--shell=：指定要执行的shell； --help：显示帮助； --version；显示版本信息。 eg: #变更帐号为root并在执行ls指令后退出变回原使用者： su -c ls root #变更帐号为root并传入-f选项给新执行的shell： su root -f #变更帐号为test并改变工作目录至test的家目录： su -test sudo 以其他身份来执行命令，预设的身份为root 在/etc/sudoers中设置了可执行sudo指令的用户。若其未经授权的用户企图使用sudo，则会发出警告的邮件给管理员。用户使用sudo时，必须先输入密码，之后有5分钟的有效期限，超过期限则必须重新输入密码。 sudo(选项)(参数) -b：在后台执行指令； -h：显示帮助； -H：将HOME环境变量设为新身份的HOME环境变量； -k：结束密码的有效期限，也就是下次再执行sudo时便需要输入密码；。 -l：列出目前用户可执行与无法执行的指令； -p：改变询问密码的提示符号； -s：执行指定的shell； -u&lt;用户&gt;：以指定的用户作为新的身份。若不加上此参数，则预设以root作为新的身份； -v：延长密码有效期限5分钟； -V ：显示版本信息。 配置sudo必须通过编辑/etc/sudoers文件，而且只有超级用户才可以修改它，还必须使用visudo编辑。之所以使用visudo有两个原因，一是它能够防止两个用户同时修改它；二是它也能进行有限的语法检查。所以，即使只有你一个超级用户，你也最好用visudo来检查一下语法。 visudo默认的是在vi里打开配置文件，用vi来修改文件。我们可以在编译时修改这个默认项。visudo不会擅自保存带有语法错误的配置文件，它会提示你出现的问题，并询问该如何处理，就像： &gt;&gt;&gt; sudoers file: syntax error, line 22 &lt;&lt; 此时我们有三种选择：键入“e”是重新编辑，键入“x”是不保存退出，键入“Q”是退出并保存。如果真选择Q，那么sudo将不会再运行，直到错误被纠正。 现在，我们一起来看一下神秘的配置文件，学一下如何编写它。让我们从一个简单的例子开始：让用户Foobar可以通过sudo执行所有root可执行的命令。以root身份用visudo打开配置文件，可以看到类似下面几行： # Runas alias specification # User privilege specificationroot ALL=(ALL)ALL 我们一看就明白个差不多了，root有所有权限，只要仿照现有root的例子就行，我们在下面加一行（最好用tab作为空白）： foobar ALL=(ALL) ALL 保存退出后，切换到foobar用户，我们用它的身份执行命令： [foobar@localhost ~]$ ls /root ls: /root: 权限不够 [foobar@localhost ~]$ sudo ls /root PassWord: anaconda-ks.cfg Desktop install.log install.log.syslog 好了，我们限制一下foobar的权利，不让他为所欲为。比如我们只想让他像root那样使用ls和ifconfig，把那一行改为： foobar localhost= /sbin/ifconfig, /bin/ls 再来执行命令： [foobar@localhost ~]$ sudo head -5 /etc/shadow Password: Sorry, user foobar is not allowed to execute &#39;/usr/bin/head -5 /etc/shadow&#39; as root on localhost.localdomain. [foobar@localhost ~]$ sudo /sbin/ifconfigeth0 Linkencap:Ethernet HWaddr 00:14:85:EC:E9:9B... 现在让我们来看一下那三个ALL到底是什么意思。第一个ALL是指网络中的主机，我们后面把它改成了主机名，它指明foobar可以在此主机上执行后面的命令。第二个括号里的ALL是指目标用户，也就是以谁的身份去执行命令。最后一个ALL当然就是指命令名了。例如，我们想让foobar用户在linux主机上以jimmy或rene的身份执行kill命令，这样编写配置文件： foobar linux=(jimmy,rene) /bin/kill 但这还有个问题，foobar到底以jimmy还是rene的身份执行？这时我们应该想到了sudo -u了，它正是用在这种时候。 foobar可以使用sudo -u jimmy kill PID或者sudo -u rene kill PID，但这样挺麻烦，其实我们可以不必每次加-u，把rene或jimmy设为默认的目标用户即可。再在上面加一行： Defaults:foobar runas_default=rene Defaults后面如果有冒号，是对后面用户的默认，如果没有，则是对所有用户的默认。就像配置文件中自带的一行： Defaults env_reset 另一个问题是，很多时候，我们本来就登录了，每次使用sudo还要输入密码就显得烦琐了。我们可不可以不再输入密码呢？当然可以，我们这样修改配置文件： foobar localhost=NOPASSWD: /bin/cat, /bin/ls 再来sudo一下： [foobar@localhost ~]$ sudo ls /rootanaconda-ks.cfg Desktop install.log install.log.syslog 当然，你也可以说“某些命令用户foobar不可以运行”，通过使用!操作符，但这不是一个好主意。因为，用!操作符来从ALL中“剔出”一些命令一般是没什么效果的，一个用户完全可以把那个命令拷贝到别的地方，换一个名字后再来运行。 日志与安全 sudo为安全考虑得很周到，不仅可以记录日志，还能在有必要时向系统管理员报告。但是，sudo的日志功能不是自动的，必须由管理员开启。这样来做： touch /var/log/sudo vi /etc/syslog.conf 在syslog.conf最后面加一行（必须用tab分割开）并保存： local2.debug /var/log/sudo 重启日志守候进程， ps aux grep syslogd 把得到的syslogd进程的PID（输出的第二列是PID）填入下面： kill –HUP PID 这样，sudo就可以写日志了： [foobar@localhost ~]$ sudo ls /rootanaconda-ks.cfg Desktop install.log install.log.syslog $cat /var/log/sudoJul 28 22:52:54 localhost sudo: foobar : TTY=pts/1 ; pwd=/home/foobar ; USER=root ; command=/bin/ls /root 不过，有一个小小的“缺陷”，sudo记录日志并不是很忠实： [foobar@localhost ~]$ sudo cat /etc/shadow &gt; /dev/null cat /var/log/sudo...Jul 28 23:10:24 localhost sudo: foobar : TTY=pts/1 ; PWD=/home/foobar ; USER=root ; COMMAND=/bin/cat /etc/shadow 重定向没有被记录在案！为什么？因为在命令运行之前，shell把重定向的工作做完了，sudo根本就没看到重定向。这也有个好处，下面的手段不会得逞： [foobar@localhost ~]$ sudo ls /root &gt; /etc/shadowbash: /etc/shadow: 权限不够 sudo 有自己的方式来保护安全。以root的身份执行sudo-V，查看一下sudo的设置。因为考虑到安全问题，一部分环境变量并没有传递给sudo后面的命令，或者被检查后再传递的，比如：PATH，HOME，SHELL等。当然，你也可以通过sudoers来配置这些环境变量。 chgrp 改变文件或目录所属的用户组 该命令用来改变指定文件所属的用户组。其中，组名可以是用户组的id，也可以是用户组的组名。文件名可以 是由空格分开的要改变属组的文件列表，也可以是由通配符描述的文件集合。如果用户不是该文件的文件主或超级用户(root)，则不能改变该文件的组 chgrp(选项)(参数) #(选项) -c或——changes：效果类似“-v”参数，但仅回报更改的部分； -f或--quiet或——silent：不显示错误信息； -h或--no-dereference：只对符号连接的文件作修改，而不是该其他任何相关文件； -R或——recursive：递归处理，将指令目录下的所有文件及子目录一并处理； -v或——verbose：显示指令执行过程； --reference=&lt;参考文件或目录&gt;：把指定文件或目录的所属群组全部设成和参考文件或目录的所属群组相同； #(参数) 组：指定新工作名称； 文件：指定要改变所属组的文件列表。多个文件或者目录之间使用空格隔开。 eg： chgrp users -R ./dir #递归地把dir目录下中的所有文件和子目录下所有文件的用户组修改为users chown 改变某个文件或目录的所有者和所属的组 该命令可以向某个用户授权，使该用户变成指定文件的所有者或者改变文件所属的组。用户可以是用户或者是用户D，用户组可以是组名或组id。文件名可以使由空格分开的文件列表，在文件名中可以包含通配符。 chown(选项)(参数) #(选项) -c或——changes：效果类似“-v”参数，但仅回报更改的部分； -f或--quite或——silent：不显示错误信息； -h或--no-dereference：只对符号连接的文件作修改，而不更改其他任何相关文件； -R或——recursive：递归处理，将指定目录下的所有文件及子目录一并处理； -v或——version：显示指令执行过程； --dereference：效果和“-h”参数相同； --help：在线帮助； --reference=&lt;参考文件或目录&gt;：把指定文件或目录的拥有者与所属群组全部设成和参考文件或目录的拥有者与所属群组相同； --version：显示版本信息。 #(参数) 用户：组：指定所有者和所属工作组。当省略“：组”，仅改变文件所有者； 文件：指定要改变所有者和工作组的文件列表。支持多个文件和目标，支持shell通配符。 #将目录/usr/meng及其下面的所有文件、子目录的文件主改成 liu： chown -R liu /usr/meng #文件的属主和属组属性设置 chown user:market f01 //把文件f01给uesr，添加到market组 ll -d f1 查看目录f1的属性 chmod 变更文件或目录的权限 在UNIX系统家族里，文件或目录权限的控制分别以读取、写入、执行3种一般权限来区分，另有3种特殊权限可供运用。用户可以使用chmod指令去变更文件与目录的权限，设置方式采用文字或数字代号皆可。符号连接的权限无法变更，如果用户对符号连接修改权限，其改变会作用在被连接的原始文件。 权限范围的表示法如下：u User，即文件或目录的拥有者；g Group，即文件或目录的所属群组；o Other，除了文件或目录拥有者或所属群组之外，其他用户皆属于这个范围；a All，即全部的用户，包含拥有者，所属群组以及其他用户 ；r 读取权限，数字代号为“4”;w 写入权限，数字代号为“2”；x 执行或切换权限，数字代号为“1”； - 不具任何权限，数字代号为“0”；s 特殊功能说明：变更文件或目录的权限。 chmod(选项)(参数) #(选项) -c或——changes：效果类似“-v”参数，但仅回报更改的部分； -f或--quiet或——silent：不显示错误信息； -R或——recursive：递归处理，将指令目录下的所有文件及子目录一并处理； -v或——verbose：显示指令执行过程； --reference=&lt;参考文件或目录&gt;：把指定文件或目录的所属群组全部设成和参考文件或目录的所属群组相同； &lt;权限范围&gt;+&lt;权限设置&gt;：开启权限范围的文件或目录的该选项权限设置； &lt;权限范围&gt;-&lt;权限设置&gt;：关闭权限范围的文件或目录的该选项权限设置； &lt;权限范围&gt;=&lt;权限设置&gt;：指定权限范围的文件或目录的该选项权限设置； #(参数) 权限模式：指定文件的权限模式； 文件：要改变权限的文件。 eg： chmod 0755 file # 把file的文件权限改变为-rxwr-xr-x chmod g+w file # 向file的文件权限中加入用户组可写权限 Linux用 户分为：拥有者、组群(Group)、其他（other），Linux系统中，预设的情況下，系统中所有的帐号与一般身份使用者，以及root的相关信 息， 都是记录在/etc/passwd文件中。每个人的密码则是记录在/etc/shadow文件下。 此外，所有的组群名称记录在/etc/group內！ linux文件的用户权限的分析图 文件权限管理 三种基本权限 R 读 数值表示为4 W 写 数值表示为2 X 可执行 数值表示为1 如图所示，copyright.html文件的权限为-rw-rw-r— -rw-rw-r-- 一共十个字符，分成四段。 第一个字符“-”表示普通文件；这个位置还可能会出现“l”链接；“d”表示目录 第二三四个字符“rw-”表示当前所属用户的权限。 所以用数值表示为4+2=6 第五六七个字符“rw-”表示当前所属组的权限。 所以用数值表示为4+2=6 第八九十个字符“r-–”表示其他用户权限。 所以用数值表示为4 所以操作此文件的权限用数值表示为664 用户及用户组管理 /etc/passwd 存储用户账号 /etc/group 存储组账号 /etc/shadow 存储用户账号的密码 /etc/gshadow 存储用户组账号的密码 useradd 添加用户名 userdel 删除用户名 adduser 添加用户名 groupadd 添加组名 groupdel 删除组名 passwd root 给root设置密码 su root su – root /etc/profile 系统环境变量 bash_profile 用户环境变量 .bashrc 用户环境变量 su user 切换用户，加载配置文件.bashrc su – user 切换用户，加载配置文件/etc/profile ，加载bash_profile who 显示目前登录系统的用户信息 执行who命令可得知目前有那些用户登入系统，单独执行who命令会列出登入帐号，使用的终端机，登入时间以及从何处登入或正在使用哪个X显示器。 who(选项)(参数) #(选项) -H或--heading：显示各栏位的标题信息列； -i或-u或--idle：显示闲置时间，若该用户在前一分钟之内有进行任何动作，将标示成&quot;.&quot;号，如果该用户已超过24小时没有任何动作，则标示出&quot;old&quot;字符串； -m：此参数的效果和指定&quot;am i&quot;字符串相同； -q或--count：只显示登入系统的帐号名称和总人数； -s：此参数将忽略不予处理，仅负责解决who指令其他版本的兼容性问题； -w或-T或--mesg或--message或--writable：显示用户的信息状态栏； --help：在线帮助； --version：显示版本信息。 #(参数) 文件：指定查询文件。 whoami 打印当前有效的用户名称，相当于执行id -un命令 whoami(选项) (选项) --help：在线帮助； --version：显示版本信息。 which 查找并显示给定命令的绝对路径 环境变量PATH中保存了查找命令时需要遍历的目录。which指令会在环境变量$PATH设置的目录里查找符合条件的文件。也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。 which(选项)(参数) #(选项) -n&lt;文件名长度&gt;：制定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名； -p&lt;文件名长度&gt;：与-n参数相同，但此处的&lt;文件名长度&gt;包含了文件的路径； -w：指定输出时栏位的宽度； -V：显示版本信息。 #(参数) 指令名：指令名列表。 查找文件、显示命令路径： [root@jet ~]# which pwd /bin/pwd [root@jet ~]# which adduser /usr/sbin/adduser 【注】 which是根据使用者所配置的 PATH 变量内的目录去搜寻可运行档的！所以，不同的 PATH 配置内容所找到的命令当然不一样的！ ntpdate设置本地日期和时间 服务器的时间不对的时候，可以使用ntpdate工具来校正时间。 ntpdate ip/site eg: /usr/sbin/ntpdate time.windows.com 以下是一些可用的NTP服务器地址： Name IP Location 210.72.145.44 210.72.145.44 中国（国家授时中心） 133.100.11.8 133.100.11.8 日本（福冈大学） time-a.nist.gov 129.6.15.28 NIST,Gaithersburg,Maryland time-b.nist.gov 129.6.15.29 NIST,Gaithersburg,Maryland time-a.timefreq.bldrdoc.gov 132.163.4.101 NIST,Boulder,Colorado time-b.timefreq.bldrdoc.gov 132.163.4.102 NIST,Boulder,Colorado time-c.timefreq.bldrdoc.gov 132.163.4.103 NIST,Boulder,Colorado utcnist.colorado.edu 128.138.140.44 UniversityofColorado,Boulder time.nist.gov 192.43.244.18 NCAR,Boulder,Colorado time-nw.nist.gov 131.107.1.10 Microsoft,Redmond,Washington nist1.symmetricom.com 69.25.96.13 Symmetricom,SanJose,California nist1-dc.glassey.com 216.200.93.8 Abovenet,Virginia nist1-ny.glassey.com 208.184.49.9 Abovenet,NewYorkCity nist1-sj.glassey.com 207.126.98.204 Abovenet,SanJose,California nist1.aol-ca.truetime.com 207.200.81.113 TrueTime,AOLfacility,Sunnyvale,California nist1.aol-va.truetime.com 64.236.96.53 TrueTime,AOLfacility,Virginia 其它命令gzip 压缩文件 gzip是在Linux系统中经常使用的一个对文件进行压缩和解压缩的命令，文件经它压缩过后，其名称后面会多处“.gz”扩展名，既方便又好用。gzip不仅可以用来压缩大的、较少使用的文件以节省磁盘空间，还可以和tar命令一起构成Linux操作系统中比较流行的压缩文件格式。据统计，gzip命令对文本文件有60%～70%的压缩率。减少文件大小有两个明显的好处，一是可以减少存储空间，二是通过网络传输文件时，可以减少传输的时间。 gzip(选项)(参数) #(选项) -a或——ascii：使用ASCII文字模式； -d或--decompress或----uncompress：解开压缩文件； -f或——force：强行压缩文件。不理会文件名称或硬连接是否存在以及该文件是否为符号连接； -h或——help：在线帮助； -l或——list：列出压缩文件的相关信息； -L或——license：显示版本与版权信息； -n或--no-name：压缩文件时，不保存原来的文件名称及时间戳记； -N或——name：压缩文件时，保存原来的文件名称及时间戳记； -q或——quiet：不显示警告信息； -r或——recursive：递归处理，将指定目录下的所有文件及子目录一并处理； -S或&lt;压缩字尾字符串&gt;或----suffix&lt;压缩字尾字符串&gt;：更改压缩字尾字符串； -t或——test：测试压缩文件是否正确无误； -v或——verbose：显示指令执行过程； -V或——version：显示版本信息； -&lt;压缩效率&gt;：压缩效率是一个介于1~9的数值，预设值为“6”，指定愈大的数值，压缩效率就会愈高； --best：此参数的效果和指定“-9”参数相同； --fast：此参数的效果和指定“-1”参数相同。 #(参数) 文件列表：指定要压缩的文件列表。 把test6目录下的每个文件压缩成.gz文件 gzip * 把上例中每个压缩的文件解压，并列出详细的信息 gzip -dv * 详细显示例1中每个压缩的文件的信息，并不解压 gzip -l * 压缩一个tar备份文件，此时压缩文件的扩展名为.tar.gz gzip -r log.tar 递归的压缩目录 gzip -rv test6 这样，所有test下面的文件都变成了.gz，目录依然存在只是目录里面的文件相应变成了.gz.这就是压缩，和打包不同。因为是对目录操作，所以需要加上-r选项，这样也可以对子目录进行递归了。 递归地解压目录 gzip -dr test6 gunzip 解压缩文件 gunzip是个使用广泛的解压缩程序，它用于解开被gzip压缩过的文件，这些压缩文件预设最后的扩展名为.gz。事实上gunzip就是gzip的硬连接，因此不论是压缩或解压缩，都可通过gzip指令单独完成。 gunzip(选项)(参数) #(选项) -a或——ascii：使用ASCII文字模式； -c或--stdout或--to-stdout：把解压后的文件输出到标准输出设备； -f或-force：强行解开压缩文件，不理会文件名称或硬连接是否存在以及该文件是否为符号连接； -h或——help：在线帮助； -l或——list：列出压缩文件的相关信息； -L或——license：显示版本与版权信息； -n或--no-name：解压缩时，若压缩文件内含有原来的文件名称及时间戳记，则将其忽略不予处理； -N或——name：解压缩时，若压缩文件内含有原来的文件名称及时间戳记，则将其回存到解开的文件上； -q或——quiet：不显示警告信息； -r或——recursive：递归处理，将指定目录下的所有文件及子目录一并处理； -S或&lt;压缩字尾字符串&gt;或----suffix&lt;压缩字尾字符串&gt;：更改压缩字尾字符串； -t或——test：测试压缩文件是否正确无误； -v或——verbose：显示指令执行过程； -V或——version：显示版本信息； #(参数) 文件列表：指定要解压缩的压缩包。 首先将/etc目录下的所有文件以及子目录进行压缩，备份压缩包etc.zip到/opt目录，然后对etc.zip文件进行gzip压缩，设置gzip的压缩级别为9。 zip –r /opt/etc.zip /etc gzip -9v /opt/etc.zip 查看上述etc.zip.gz文件的压缩信息。 gzip -l /opt/etc.zip.gz compressed uncompressed ratio uncompressed_name 11938745 12767265 6.5% /opt/etc.zip 解压上述etc.zip.gz文件到当前目录。 [root@mylinux ~]#gzip –d /opt/etc.zip.gz 或者执行 [root@mylinux ~]#gunzip /opt/etc.zip.gz 通过上面的示例可以知道gzip –d等价于gunzip命令。 bzip2 创建和管理（包括解压缩）“.bz2”格式的压缩包 我们遇见Linux压缩打包方法有很多种，以下讲解了Linux压缩打包方法中的Linux bzip2命令的多种范例供大家查看，相信大家看完后会有很多收获。 bzip2(选项)(参数) #(选项) -c或——stdout：将压缩与解压缩的结果送到标准输出； -d或——decompress：执行解压缩； -f或-force：bzip2在压缩或解压缩时，若输出文件与现有文件同名，预设不会覆盖现有文件。若要覆盖。请使用此参数； -h或——help：在线帮助； -k或——keep：bzip2在压缩或解压缩后，会删除原始文件。若要保留原始文件，请使用此参数； -s或——small：降低程序执行时内存的使用量； -t或——test：测试.bz2压缩文件的完整性； -v或——verbose：压缩或解压缩文件时，显示详细的信息； -z或——compress：强制执行压缩； -V或——version：显示版本信息； --repetitive-best：若文件中有重复出现的资料时，可利用此参数提高压缩效果； --repetitive-fast：若文件中有重复出现的资料时，可利用此参数加快执行效果。 #(参数) 文件：指定要压缩的文件。 压缩指定文件filename: bzip2 filename 或 bzip2 -z filename 这里，压缩的时候不会输出，会将原来的文件filename给删除，替换成filename.bz2.如果以前有filename.bz2则不会替换并提示错误（如果想要替换则指定-f选项，例如bzip2 -f filename；如果filename是目录则也提醒错误不做任何操作；如果filename已经是压过的了有bz2后缀就提醒一下，不再压缩，没有bz2后缀会再次压缩。 解压指定的文件filename.bz2: bzip2 -d filename.bz2 或 bunzip2 filename.bz2 这里，解压的时候没标准输出，会将原来的文件filename.bz2给替换成filename。如果以前有filename则不会替换并提示错误（如果想要替换则指定-f选项，例如bzip2 -df filename.bz2。 压缩解压的时候将结果也输出： $bzip2 -v filename 输入之后，输出如下： filename: 0.119:1, 67.200 bits/byte, -740.00% saved, 5 in, 42 out. 这里，加上-v选项就会输出了,只用压缩举例了，解压的时候同理bzip2 -dv filename.bz2不再举例了。 模拟解压实际并不解压： bzip2 -tv filename.bz2 输入之后，输出如下： filename.bz2: ok 这里，-t指定要进行模拟解压，不实际生成结果，也就是说类似检查文件,当然就算目录下面有filename也不会有什么错误输出了，因为它根本不会真的解压文件。为了在屏幕上输出，这里加上-v选项了,如果是真的解压bzip2 -dv filename.bz2则输出的是把”ok”替换成了”done”。 压缩解压的时候，除了生成结果文件，将原来的文件也保存: bzip2 -k filename 这里，加上-k就保存原始的文件了，否则原始文件会被结果文件替代。只用压缩举例了，解压的时候同理$bzip2 -dk filename.bz2不再举例了。 解压到标准输出： bzip2 -dc filename.bz2 输入之后，输出如下： hahahhaahahha 这里，使用-c指定到标准输出，输出的是文件filename的内容，不会将filename.bz2删除。 压缩到标准输出： bzip2 -c filename bzip2: I won&#39;t write compressed data to a terminal. bzip2: For help, type: `bzip2 --help&#39;. 这里，使用-c指定压缩到标准输出不删除原有文件，不同的是，压缩后的文件无法输出到标准输出。 使用bzip2的时候将所有后面的看作文件(即使文件名以’-‘开头)： bzip2 -- -myfilename 这里主要是为了防止文件名中-产生以为是选项的歧义。 bzcat 读取数据而无需解压 解压缩指定的.bz2文件，并显示解压缩后的文件内容。保留原压缩文件，并且不生成解压缩后的文件 bzcat(参数) #(参数) .bz2压缩文件：指定要显示内容的.bz2压缩文件。 将/tmp/man.config以bzip2格式压缩： bzip2 -z man.config 此时man.config会变成man.config.bz2 将上面的压缩文件内容读出来： bzcat man.config.bz2 此时屏幕上会显示 man.config.bz2 解压缩之后的文件内容。 tar 为linux的文件和目录创建档案 利用tar，可以为某一特定文件创建档案（备份文件），也可以在档案中改变文件，或者向档案中加入新的文件。tar最初被用来在磁带上创建档案，现在，用户可以在任何设备上创建档案。利用tar命令，可以把一大堆的文件和目录全部打包成一个文件，这对于备份文件或将几个文件组合成为一个文件以便于网络传输是非常有用的。 首先要弄清两个概念：打包和压缩。打包是指将一大堆文件或目录变成一个总的文件；压缩则是将一个大的文件通过一些压缩算法变成一个小文件。 为什么要区分这两个概念呢？这源于Linux中很多压缩程序只能针对一个文件进行压缩，这样当你想要压缩一大堆文件时，你得先将这一大堆文件先打成一个包（tar命令），然后再用压缩程序进行压缩（gzip bzip2命令）。 tar(选项)(参数) #(选项) -A或--catenate：新增文件到以存在的备份文件； -B：设置区块大小； -c或--create：建立新的备份文件； -C &lt;目录&gt;：这个选项用在解压缩，若要在特定目录解压缩，可以使用这个选项。 -d：记录文件的差别； -x或--extract或--get：从备份文件中还原文件； -t或--list：列出备份文件的内容； -z或--gzip或--ungzip：通过gzip指令处理备份文件； -Z或--compress或--uncompress：通过compress指令处理备份文件； -f&lt;备份文件&gt;或--file=&lt;备份文件&gt;：指定备份文件； -v或--verbose：显示指令执行过程； -r：添加文件到已经压缩的文件； -u：添加改变了和现有的文件到已经存在的压缩文件； -j：支持bzip2解压文件； -v：显示操作过程； -l：文件系统边界设置； -k：保留原有文件不覆盖； -m：保留文件不被覆盖； -w：确认压缩文件的正确性； -p或--same-permissions：用原来的文件权限还原文件； -P或--absolute-names：文件名使用绝对名称，不移除文件名称前的“/”号； -N &lt;日期格式&gt; 或 --newer=&lt;日期时间&gt;：只将较指定日期更新的文件保存到备份文件里； --exclude=&lt;范本样式&gt;：排除符合范本样式的文件。 #(参数) 文件或目录：指定要打包的文件或目录列表。 将文件全部打包成tar包： tar -jcvf filename.tar.bz2 要被压缩的档案或目录名称 #压 缩 tar -jtvf filename.tar.bz2 #查 询 tar -jxvf filename.tar.bz2 -C 欲解压缩的目录 #解压缩 tar -cvf log.tar log2012.log #仅打包，不压缩！ tar -zcvf log.tar.gz log2012.log #打包后，以 gzip 压缩 tar -jcvf log.tar.bz2 log2012.log #打包后，以 bzip2 压缩 在选项f之后的文件档名是自己取的，我们习惯上都用 .tar 来作为辨识。 如果加z选项，则以.tar.gz或.tgz来代表gzip压缩过的tar包；如果加j选项，则以.tar.bz2来作为tar包名。 查阅上述tar包内有哪些文件： tar -ztvf log.tar.gz 由于我们使用 gzip 压缩的log.tar.gz，所以要查阅log.tar.gz包内的文件时，就得要加上z这个选项了。 将tar包解压缩： tar -zxvf /opt/soft/test/log.tar.gz 在预设的情况下，我们可以将压缩档在任何地方解开的 只将tar内的部分文件解压出来： tar -zxvf /opt/soft/test/log30.tar.gz log2013.log 我可以透过tar -ztvf来查阅 tar 包内的文件名称，如果单只要一个文件，就可以透过这个方式来解压部分文件！ 文件备份下来，并且保存其权限： tar -zcvpf log31.tar.gz log2014.log log2015.log log2016.log 这个-p的属性是很重要的，尤其是当您要保留原本文件的属性时。 在文件夹当中，比某个日期新的文件才备份： tar -N “2012/11/13” -zcvf log17.tar.gz test 备份文件夹内容是排除部分文件： tar —exclude scf/service -zcvf scf.tar.gz scf/* 其实最简单的使用 tar 就只要记忆底下的方式即可： 压 缩：tar -jcv -f filename.tar.bz2 要被压缩的文件或目录名称 查 询：tar -jtv -f filename.tar.bz2 解压缩：tar -jxv -f filename.tar.bz2 -C 欲解压缩的目录 users 显示当前登录系统地用户 who 登录在本机的用户与来源 -H或--heading 显示各栏位的标题信息列。 w 登录在本机的用户及其运行的程序 -s 使用简洁格式列表，不显示用户登入时间，终端机阶段作业和程序所耗费的CPU时间。 -h 不显示各栏位的标题信息列。 write 给当前联机的用户发消息 wall 给所有登录再本机的用户发消息 last 查看用户的登陆日志 lastlog 查看每个用户最后的登陆时间 finger 查看用户信息 -s 显示用户的注册名、实际姓名、终端名称、写状态、停滞时间、登录时间等信息 -l 除了用-s选项显示的信息外，还显示用户主目录、登录shell、邮件状态等信息，以及用户主目录下的.plan、.project和.forward文件的内容。 -p 除了不显示.plan文件和.project文件以外，与-l选项相同 hostname 查看主机名 alias 添加别名 unalias 清除别名 chage **修改用户密码的相关属性 -l 列出该账号的详细密码参数； -d 后面接日期，修改 shadow 第三字段(最近一次更改密码的日期)，格式YYYY-MM-DD -E 后面接日期，修改 shadow 第八字段(账号失效日)，格式 YYYY-MM-DD -I 后面接天数，修改 shadow 第七字段(密码失效日期) -m 后面接天数，修改 shadow 第四字段(密码最短保留天数) -M 后面接天数，修改 shadow 第五字段(密码多久需要进行变更) -W 后面接天数，修改 shadow 第六字段(密码过期前警告日期) usermod 修改用户的相关属性 -c 后面接账号的说明，即 /etc/passwd 第五栏的说明栏，可以加入一些账号的说明。 -d 后面接账号的家目录，即修改 /etc/passwd 的第六栏； -e 后面接日期，格式是 YYYY-MM-DD 也就是在 /etc/shadow 内的第八个字段数据啦！ -f 后面接天数为 shadow 的第七字段。 -g 后面接初始群组，修改 /etc/passwd 的第四个字段，亦即是GID的字段！ -G 后面接次要群组，修改这个使用者能够支持的群组 -l 后面接账号名称。亦即是修改账号名称， /etc/passwd 的第一栏！ -s 后面接 Shell 的实际档案，例如 /bin/bash 或 /bin/csh 等等。 -u 后面接 UID 数字啦！即 /etc/passwd 第三栏的资料； -L 冻结密码 -U 解冻密码 id 查看用户相关的id信息，还可以用来判断用户是否存在 groups 查看登陆用户支持的群组， 第一个输出的群组为有效群组 newgrp 切换有效群组 groupmod 修改组信息 -g 修改既有的 GID 数字 -n 修改既有的组名 groupdel 删除群组 gpasswd 群组管理员功能 root管理员动作： -gpasswd groupname 设定密码 -gpasswd [-A user1,...] [-M user3,...] groupname -A 将 groupname 的主控权交由后面的使用者管理(该群组的管理员) -M 将某些账号加入这个群组当中 -gpasswd [-r] groupname -r 将 groupname 的密码移除 群组管理员动作： - gpasswd [-ad] user groupname -a 将某位使用者加入到 groupname 这个群组当中 -d 将某位使用者移除出 groupname 这个群组当中 chfn 修改个人信息 cut Print selected parts of lines from each FILE to standard output -b ：以字节为单位进行分割。这些字节位置将忽略多字节字符边界，除非也指定了 -n 标志。 -c ：以字符为单位进行分割。 -d ：自定义分隔符，默认为制表符。 -f ：与-d一起使用，指定显示哪个区域。 sort sort -n 依照数值的大小排序。 -o&lt;输出文件&gt; 将排序后的结果存入指定的文件。 -r 以相反的顺序来排序。 -t&lt;分隔字符&gt; 指定排序时所用的栏位分隔字符。 -k 选择以哪个区间进行排序。 set 显示环境变量和普通变量 env 显示环境变量 export 把普通变量变成环境变量 unset 删除一个环境变量 aaa(){} 定义函数 read read -p 接提示字符 -t 接等待的秒数 declare/typeset declare、typeset -i 声明为整数 -a 声明为数组 -f 声明为函数 -r 声明为只读 ulimit 限制使用者的某些系统资源 -f 此 shell 可以建立的最大档案容量 (一般可能设定为 2GB)单位为 Kbytes eg: ulimit -f 1024 限制使用者仅能建立 1MBytes 以下的容量的档案 date 显示或设定系统的日期与时间 date [参数]… [+格式] %H 小时(以00-23来表示)。 %M 分钟(以00-59来表示)。 %P AM或PM。 %D 日期(含年月日) %U 该年中的周数。 date -s “2015-10-17 01:01:01″ //时间设定 date +%Y%m%d //显示前天年月日 date +%Y%m%d --date=&quot;+1 day/month/year&quot; //显示前一天/月/年的日期 date +%Y%m%d --date=&quot;-1 day/month/year&quot; //显示后一天/月/年的日期 date -d &#39;2 weeks&#39; 2周后的日期 cal 查看日历 -1 显示当月的月历 -3 显示前、当、后一个月的日历 -m 显示星期一为一个星期的第一天 -s （默认）星期天为第一天 -j 显示当月是一年中的第几天的日历 -y 显示当前年份的日历 gcc 命令 对于一个用Linux开发C程序的人来说，这个命令就非常重要了，它用于把C语言的源程序文件，编译成可执行程序，由于g++的很多参数跟它非常相似，所以这里只介绍gcc的参数，它的常用参数如下： [plain] view plain copy print? -o ：output之意，用于指定生成一个可执行文件的文件名 -c ：用于把源文件生成目标文件（.o)，并阻止编译器创建一个完整的程序 -I ：增加编译时搜索头文件的路径 -L ：增加编译时搜索静态连接库的路径 -S ：把源文件生成汇编代码文件 -lm：表示标准库的目录中名为libm.a的函数库 -lpthread ：连接NPTL实现的线程库 -std= ：用于指定把使用的C语言的版本 # 例如： # 把源文件test.c按照c99标准编译成可执行程序test gcc -o test test.c -lm -std=c99 #把源文件test.c转换为相应的汇编程序源文件test.s gcc -S test.c time 测算一个命令（即程序）的执行时间 它的使用非常简单，就像平时输入命令一样，不过在命令的前面加入一个time即可，例如： [plain] view plain copy print? time ./process time ps aux 在程序或命令运行结束后，在最后输出了三个时间，它们分别是：user：用户CPU时间，命令执行完成花费的用户CPU时间，即命令在用户态中执行时间总和；system：系统CPU时间，命令执行完成花费的系统CPU时间，即命令在核心态中执行时间总和；real：实际时间，从command命令行开始执行到运行终止的消逝时间； 注：用户CPU时间和系统CPU时间之和为CPU时间，即命令占用CPU执行的时间总和。实际时间要大于CPU时间，因为Linux是多任务操作系统，往往在执行一条命令时，系统还要处理其它任务。另一个需要注意的问题是即使每次执行相同命令，但所花费的时间也是不一样，其花费时间是与系统运行相关的。 查看内存溢出 查看内存溢出 jmap -heap pid #打印heap的概要信息 jmap -histo pid #打印每个class的实例数目，内存占用，类全名信息 jmap -dump:format=b,file=heap.bin pid #输出heap信息到heap.bin文件 jhat -J-mx768m heap.bin #分析heap.bin文件 jstack -l pid &gt; deadlock.jstack #输出stack信息到deadlock.jstack vi deadlock.jstack #使用vi查看]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库之mysql(一)]]></title>
    <url>%2F2017%2F06%2F10%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B9%8Bmysql-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[忘记mysql root密码 本站所有环境都是linux下 service mysqld stop #停止mysql服务，注意权限 mysqld_safe --skip-grant-tables&amp; #也可以在配置文件中添加--skip-grant-tables mysql -u root mysql #这里就不用指定-p了，直接登录 use mysql #选择使用mysql数据库 UPDATE user SET Password = PASSWORD(&#39;new password&#39;) WHERE user = &#39;root&#39;; #修改密码 FLUSH PRIVILEGES; #刷新，生效 mysql配置文件my.cnf详解1 mysqld程序：基本配置 basedir = path #使用给定目录作为根目录(安装目录)。 character-sets-dir = path #给出存放着字符集的目录。 datadir = path #从给定目录读取数据库文件。 pid-file = filename #为mysqld程序指定一个存放进程ID的文件(仅适用于UNIX/Linux系统); Init-V脚本需要使用这个文件里的进程ID结束mysqld进程。 socket = filename #为MySQL客户程序与服务器之间的本地通信指定一个套接字文件(仅适用于UNIX/Linux系统; 默认设置一般是/var/lib/mysql/mysql.sock文件)。在Windows环境下，如果MySQL客户与服务器是通过命名管道进行通信 的，–sock选项给出的将是该命名管道的名字(默认设置是MySQL)。 lower_case_table_name = 1/0 #新目录和数据表的名字是否只允许使用小写字母; 这个选项在Windows环境下的默认设置是1(只允许使用小写字母)。 mysqld程序：语言设置 character-sets-server = name #新数据库或数据表的默认字符集。为了与MySQL的早期版本保持兼容，这个字符集也可以用–default-character-set选项给出; 但这个选项已经显得有点过时了。 collation-server = name #新数据库或数据表的默认排序方式。 language = name #用指定的语言显示出错信息。 mysqld程序：通信、网络、信息安全 enable-named-pipes #允许Windows 2000/XP环境下的客户和服务器使用命名管道(named pipe)进行通信。这个命名管道的默认名字是MySQL，但可以用–socket选项来改变。 local-infile [=0] #允许/禁止使用LOAD DATA LOCAL语句来处理本地文件。 myisam-recover [=opt1, opt2, ...] 在启动时自动修复所有受损的MyISAM数据表。这个选项的可取值有4种:DEFAULT、BACKUP、QUICK和FORCE; 它们与myisamchk程序的同名选项作用相同。 old-passwords #使用MySQL 3.23和4.0版本中的老算法来加密mysql数据库里的密码(默认使用MySQL 4.1版本开始引入的新加密算法)。 port = n #为MySQL程序指定一个TCP/IP通信端口(通常是3306端口)。 safe-user-create #只有在mysql.user数据库表上拥有INSERT权限的用户才能使用GRANT命令; 这是一种双保险机制(此用户还必须具备GRANT权限才能执行GRANT命令)。 shared-memory #允许使用内存(shared memory)进行通信(仅适用于Windows)。 shared-memory-base-name = name #给共享内存块起一个名字(默认的名字是MySQL)。 skip-grant-tables #不使用mysql数据库里的信息来进行访问控制(警告:这将允许用户任何用户去修改任何数据库)。 skip-host-cache #不使用高速缓存区来存放主机名和IP地址的对应关系。 skip-name-resovle #不把IP地址解析为主机名; 与访问控制(mysql.user数据表)有关的检查全部通过IP地址行进。 skip-networking #只允许通过一个套接字文件(Unix/Linux系统)或通过命名管道(Windows系统)进行本地连接，不允许ICP/IP连接; 这提高了安全性，但阻断了来自网络的外部连接和所有的Java客户程序(Java客户即使在本地连接里也使用TCP/IP)。 user = name #mysqld程序在启动后将在给定UNIX/Linux账户下执行; mysqld必须从root账户启动才能在启动后切换到另一个账户下执行; mysqld_safe脚本将默认使用–user=mysql选项来启动mysqld程序。 mysqld程序：内存管理、优化、查询缓存区 bulk_insert_buffer_size = n #为一次插入多条新记录的INSERT命令分配的缓存区长度(默认设置是8M)。 key_buffer_size = n #用来存放索引区块的RMA值(默认设置是8M)。 join_buffer_size = n #在参加JOIN操作的数据列没有索引时为JOIN操作分配的缓存区长度(默认设置是128K)。 max_heap_table_size = n #HEAP数据表的最大长度(默认设置是16M); 超过这个长度的HEAP数据表将被存入一个临时文件而不是驻留在内存里。 max_connections = n #MySQL服务器同时处理的数据库连接的最大数量(默认设置是100)。 query_cache_limit = n #允许临时存放在查询缓存区里的查询结果的最大长度(默认设置是1M)。 query_cache_size = n #查询缓存区的最大长度(默认设置是0，不开辟查询缓存区)。 query_cache_type = 0/1/2 #查询缓存区的工作模式:0, 禁用查询缓存区; 1，启用查询缓存区(默认设置); 2，”按需分配”模式，只响应SELECT SQL_CACHE命令。 read_buffer_size = n #为从数据表顺序读取数据的读操作保留的缓存区的长度(默认设置是128KB); 这个选项的设置值在必要时可以用SQL命令SET SESSION read_buffer_size = n命令加以改变。 read_rnd_buffer_size = n #类似于read_buffer_size选项，但针对的是按某种特定顺序(比如使用了ORDER BY子句的查询)输出的查询结果(默认设置是256K)。 sore_buffer = n #为排序操作分配的缓存区的长度(默认设置是2M); 如果这个缓存区太小，则必须创建一个临时文件来进行排序。 table_cache = n #同时打开的数据表的数量(默认设置是64)。 tmp_table_size = n #临时HEAP数据表的最大长度(默认设置是32M); 超过这个长度的临时数据表将被转换为MyISAM数据表并存入一个临时文件。 mysqld程序：日志 log [= file] #把所有的连接以及所有的SQL命令记入日志(通用查询日志); 如果没有给出file参数，MySQL将在数据库目录里创建一个hostname.log文件作为这种日志文件(hostname是服务器的主机名)。 log-slow-queries [= file] #把执行用时超过long_query_time变量值的查询命令记入日志(慢查询日志); 如果没有给出file参数，MySQL将在数据库目录里创建一个hostname-slow.log文件作为这种日志文件(hostname是服务器主机 名)。 long_query_time = n #慢查询的执行用时上限(默认设置是10s)。 long_queries_not_using_indexs #把慢查询以及执行时没有使用索引的查询命令全都记入日志(其余同–log-slow-queries选项)。 log-bin [= filename] #把对数据进行修改的所有SQL命令(也就是INSERT、UPDATE和DELETE命令)以二进制格式记入日志(二进制变更日志，binary update log)。这种日志的文件名是filename.n或默认的hostname.n，其中n是一个6位数字的整数(日志文件按顺序编号)。 log-bin-index = filename #二进制日志功能的索引文件名。在默认情况下，这个索引文件与二进制日志文件的名字相同，但后缀名是.index而不是.nnnnnn。 max_binlog_size = n #二进制日志文件的最大长度(默认设置是1GB)。在前一个二进制日志文件里的信息量超过这个最大长度之前，MySQL服务器会自动提供一个新的二进制日志文件接续上。 binlog-do-db = dbname #只把给定数 据库里的变化情况记入二进制日志文件，其他数据库里的变化情况不记载。如果需要记载多个数据库里的变化情况，就必须在配置文件使用多个本选项来设置，每个数据库一行。 binlog-ignore-db = dbname #不把给定数据库里的变化情况记入二进制日志文件。 sync_binlog = n #每经过n次日志写操作就把日志文件写入硬盘一次(对日志信息进行一次同步)。n=1是最安全的做法，但效率最低。默认设置是n=0，意思是由操作系统来负责二进制日志文件的同步工作。 log-update [= file] #记载出错情况的日志文件名(出错日志)。这种日志功能无法禁用。如果没有给出file参数，MySQL会使用hostname.err作为种日志文件的名字。 mysqld程序：镜像(主控镜像服务器) server-id = n #给服务器分配一个独一无二的ID编号; n的取值范围是1~2的32次方启用二进制日志功能。 log-bin = name #启用二进制日志功能。这种日志的文件名是filename.n或默认的hostname.n，其中的n是一个6位数字的整数(日志文件顺序编号)。 binlog-do/ignore-db = dbname #只把给定数据库里的变化情况记入二进制日志文件/不把给定的数据库里的变化记入二进制日志文件。 mysqld程序：镜像(从属镜像服务器) server-id = n #给服务器分配一个唯一的ID编号 log-slave-updates #启用从属服务器上的日志功能，使这台计算机可以用来构成一个镜像链(A-&gt;B-&gt;C)。 master-host = hostname #主控服务器的主机名或IP地址。如果从属服务器上存在mater.info文件(镜像关系定义文件)，它将忽略此选项。 master-user = replicusername #从属服务器用来连接主控服务器的用户名。如果从属服务器上存在mater.info文件，它将忽略此选项。 master-password = passwd #从属服务器用来连接主控服务器的密码。如果从属服务器上存在mater.info文件，它将忽略此选项。 master-port = n #从属服务器用来连接主控服务器的TCP/IP端口(默认设置是3306端口)。 master-connect-retry = n #如果与主控服务器的连接没有成功，则等待n秒(s)后再进行管理方式(默认设置是60s)。如果从属服务器存在mater.info文件，它将忽略此选项。 master-ssl-xxx = xxx #对主、从服务器之间的SSL通信进行配置。 read-only = 0/1 #0: 允许从属服务器独立地执行SQL命令(默认设置); 1: 从属服务器只能执行来自主控服务器的SQL命令。 read-log-purge = 0/1 #1: 把处理完的SQL命令立刻从中继日志文件里删除(默认设置); 0: 不把处理完的SQL命令立刻从中继日志文件里删除。 replicate-do-table = dbname.tablename 与–replicate-do-table选项的含义和用法相同，但数据库和数据库表名字里允许出现通配符”%” (例如: test%.%–对名字以”test”开头的所有数据库里的所以数据库表进行镜像处理)。 replicate-do-db = name #只对这个数据库进行镜像处理。 replicate-ignore-table = dbname.tablename #不对这个数据表进行镜像处理。 replicate-wild-ignore-table = dbn.tablen #不对这些数据表进行镜像处理。 replicate-ignore-db = dbname #不对这个数据库进行镜像处理。 replicate-rewrite-db = db1name &gt; db2name #把主控数据库上的db1name数据库镜像处理为从属服务器上的db2name数据库。 report-host = hostname #从属服务器的主机名; 这项信息只与SHOW SLAVE HOSTS命令有关–主控服务器可以用这条命令生成一份从属服务器的名单。 slave-compressed-protocol = 1 #主、从服务器使用压缩格式进行通信–如果它们都支持这么做的话。 slave-skip-errors = n1, n2, …或all #即使发生出错代码为n1、n2等的错误，镜像处理工作也继续进行(即不管发生什么错误，镜像处理工作也继续进行)。如果配置得当，从属服务器不应该在执行 SQL命令时发生错误(在主控服务器上执行出错的SQL命令不会被发送到从属服务器上做镜像处理); 如果不使用slave-skip-errors选项，从属服务器上的镜像工作就可能因为发生错误而中断，中断后需要有人工参与才能继续进行。 mysqld–InnoDB：基本设置、表空间文件 skip-innodb #不加载InnoDB数据表驱动程序–如果用不着InnoDB数据表，可以用这个选项节省一些内存。 innodb-file-per-table #为每一个新数据表创建一个表空间文件而不是把数据表都集中保存在中央表空间里(后者是默认设置)。该选项始见于MySQL 4.1。 innodb-open-file = n #InnoDB数据表驱动程序最多可以同时打开的文件数(默认设置是300)。如果使用了innodb-file-per-table选项并且需要同时打开很多数据表的话，这个数字很可能需要加大。 innodb_data_home_dir = p #InnoDB主目录，所有与InnoDB数据表有关的目录或文件路径都相对于这个路径。在默认的情况下，这个主目录就是MySQL的数据目录。 innodb_data_file_path = ts #用来容纳InnoDB为数据表的表空间: 可能涉及一个以上的文件; 每一个表空间文件的最大长度都必须以字节(B)、兆字节(MB)或千兆字节(GB)为单位给出; 表空间文件的名字必须以分号隔开; 最后一个表空间文件还可以带一个autoextend属性和一个最大长度(max:n)。例如，ibdata1:1G; ibdata2:1G:autoextend:max:2G的意思是: 表空间文件ibdata1的最大长度是1GB，ibdata2的最大长度也是1G，但允许它扩充到2GB。除文件名外，还可以用硬盘分区的设置名来定义表 空间，此时必须给表空间的最大初始长度值加上newraw关键字做后缀，给表空间的最大扩充长度值加上raw关键字做后缀(例如/dev/hdb1: 20Gnewraw或/dev/hdb1:20Graw); MySQL 4.0及更高版本的默认设置是ibdata1:10M:autoextend。 innodb_autoextend_increment = n #带有autoextend属性的表空间文件每次加大多少兆字节(默认设置是8MB)。这个属性不涉及具体的数据表文件，那些文件的增大速度相对是比较小的。 innodb_lock_wait_timeout = n #如果某个事务在等待n秒(s)后还没有获得所需要的资源，就使用ROLLBACK命令放弃这个事务。这项设置对于发现和处理未能被InnoDB数据表驱动 程序识别出来的死锁条件有着重要的意义。这个选项的默认设置是50s。 innodb_fast_shutdown 0/1 #是否以最快的速度关闭InnoDB，默认设置是1，意思是不把缓存在INSERT缓存区的数据写入数据表，那些数据将在MySQL服务器下次启动时再写入 (这么做没有什么风险，因为INSERT缓存区是表空间的一个组成部分，数据不会丢失)。把这个选项设置为0反面危险，因为在计算机关闭时，InnoDB 驱动程序很可能没有足够的时间完成它的数据同步工作，操作系统也许会在它完成数据同步工作之前强行结束InnoDB，而这会导致数据不完整。 mysqld程序：InnoDB–日志 innodb_log_group_home_dir = p #用来存放InnoDB日志文件的目录路径(如ib_logfile0、ib_logfile1等)。在默认的情况下，InnoDB驱动程序将使用 MySQL数据目录作为自己保存日志文件的位置。 innodb_log_files_in_group = n #使用多少个日志文件(默认设置是2)。InnoDB数据表驱动程序将以轮转方式依次填写这些文件; 当所有的日志文件都写满以后，之后的日志信息将写入第一个日志文件的最大长度(默认设置是5MB)。这个长度必须以MB(兆字节)或GB(千兆字节)为单 位进行设置。 innodb_flush_log_at_trx_commit = 0/1/2 #这个选项决定着什么时候把日志信息写入日志文件以及什么时候把这些文件物理地写(术语称为”同步”)到硬盘上。设置值0的意思是每隔一秒写一次日志并进行 同步，这可以减少硬盘写操作次数，但可能造成数据丢失; 设置值1(设置设置)的意思是在每执行完一条COMMIT命令就写一次日志并进行同步，这可以防止数据丢失，但硬盘写操作可能会很频繁; 设置值2是一般折衷的办法，即每执行完一条COMMIT命令写一次日志，每隔一秒进行一次同步。 innodb_flush_method = x #InnoDB日志文件的同步办法(仅适用于UNIX/Linux系统)。这个选项的可取值有两种: fdatasync，用fsync()函数进行同步; O_DSYNC，用O_SYNC()函数进行同步。 innodb_log_archive = 1 #启用InnoDB驱动程序的archive(档案)日志功能，把日志信息写入ib_arch_log_n文件。启用这种日志功能在InnoDB与 MySQL一起使用时没有多大意义(启用MySQL服务器的二进制日志功能就足够用了)。 mysqld程序–InnoDB：缓存区的设置和优化 innodb_log_buffer_pool_size = n #为InnoDB数据表及其索引而保留的RAM内存量(默认设置是8MB)。这个参数对速度有着相当大的影响，如果计算机上只运行有 MySQL/InnoDB数据库服务器，就应该把全部内存的80%用于这个用途。 innodb_log_buffer_size = n #事务日志文件写操作缓存区的最大长度(默认设置是1MB)。 innodb_additional_men_pool_size = n #为用于内部管理的各种数据结构分配的缓存区最大长度(默认设置是1MB)。 innodb_file_io_threads = n #I/O操作(硬盘写操作)的最大线程个数(默认设置是4)。 innodb_thread_concurrency = n #InnoDB驱动程序能够同时使用的最大线程个数(默认设置是8)。 mysqld程序：其它选项 bind-address = ipaddr #MySQL服务器的IP地址。如果MySQL服务器所在的计算机有多个IP地址，这个选项将非常重要。 default-storage-engine = type #新数据表的默认数据表类型(默认设置是MyISAM)。这项设置还可以通过–default-table-type选项来设置。 default-timezone = name #为MySQL服务器设置一个地理时区(如果它与本地计算机的地理时区不一样)。 ft_min_word_len = n #全文索引的最小单词长度工。这个选项的默认设置是4，意思是在创建全文索引时不考虑那些由3个或更少的字符构建单词。 Max-allowed-packet = n #客户与服务器之间交换的数据包的最大长度，这个数字至少应该大于客户程序将要处理的最大BLOB块的长度。这个选项的默认设置是1MB。 Sql-mode = model1, mode2, … #MySQL将运行在哪一种SQL模式下。这个选项的作用是让MySQL与其他的数据库系统保持最大程度的兼容。这个选项的可取值包括ansi、db2、 oracle、no_zero_date、pipes_as_concat。 mysql配置文件my.cnf详解2 配置MySQL服务器是一个丰富而复杂的工作。在本文中，我只能肤浅的说一下各种选项。可以使用的mysql配置文件共有５个。·/etc/my.cnf是默认的MySQL配置文件。应该对这个文件配置修改。它是为学习目的而设计的。·my-small.cnf是为了小型数据库而设计的。不应该把这个模型用于含有一些常用项目的数据库。·my-medium.cnf是为中等规模的数据库而设计的。如果你正在企业中使用RHEL,可能会比这个操作系统的最小RAM需求(256MB)明显多得多的物理内存。由此可见，如果有那么多RAM内存可以使用，自然可以在同一台机器上运行其它服务。·my-large.cnf是为专用于一个SQL数据库的计算机而设计的。由于它可以为该数据库使用多达512MB的内存，所以在这种类型的系统上将需要至少1GB的RAM,以便它能够同时处理操作系统与数据库应用程序。·my-huge.cnf是为企业中的数据库而设计的。这样的数据库要求专用服务器和1GB或1GB以上的RAM。这些选择高度依赖于内存的数量、计算机的运算速度、数据库的细节大小、访问数据库的用户数量以及在数据库中装入并访问数据的用户数量。随着数据库和用户的不断增加，数据库的性能可能会发生变化。我将逐个的说明这些配置文件。如果用户决定使用my-.cnf文件之一，将首先需要把这个文件复制到/etc/my.cnf文件上。由于这些原因，用户应该仔细观察数据库系统的性能。如果发现问题，可能需要增加更多的RAM，或者把数据库迁移到一个含有附加资源(比如多个CPU)的系统上。提示：数据库变得非常大。把一个SQL数据库目录配置在一个专用分区上可能更有道理。虽然一个不断增长的数据库可能会占满整个分区，但它至少不会吞掉RHEL运行所必需的磁盘空间。/etc/my.cnf文件默认是/etc/my.cnf文件。它包含6条命令，并且这6条命令被组织在3个配置段中。这些配置段与Samba配置文件中的配置段相似，并且含有功能组名称和相关的命令。本文将逐行的说明这个文件的默认版本。如果用户进行了任何修改，将需要确保MySQL启动脚本(即/etc/rc.d /init.d/mysqld)中的命令一致。[mysqld]在这个配置段之内，将会看到与MySQL守护进程相关的命令。datadir=/var/lib/mysqlMySQL服务器把数据库存储在由datadir变量所定义的目录中。Socket=/var/lib/mysql/mysql.sockMySQL套接字把数据库程序局部的或通过网络连接到MySQL客户。提示：MySQL被配置成使用InnoDB存储器引擎。如果用户在自己的系统上还没有一个InnoDB数据库，将需要给[mysqld]配置段添加skip-innodb语句。[mysql.server]在这个配置段之内，将会看到MySQL服务器守护进程有关的命令。这个配置段的较早期版本被命名为[mysql_server]。如果使用 MySQL4.X或MySQL4.X以上版本，将必须把这个配置段标题改成[mysql_server]。当启动MySQL服务时，它使用这个配置段中的选项。user=mysql与MySQL服务相关联的标准用户名是mysql。它应该是/etc/passwd文件的一部分；如果在这个文件中没有发现它，用户可能还没有安装Red Hat Enterprise Linux mysql-server RPM程序包。basedir=/var/lib这表示MySQL数据库的顶级目录。它充当MySQL系统上的一个根目录；这个数据库中的其它目录都是相对于这个目录。[safe_mysqld]这个配置段包含MySQL启动脚本所引用的命令。如果使用MySQL4.X或4.X以上版本，必须把这个配置段改成[mysqld_safe]。err-log=/var/log/mysqld.log这是MySQL所关联的错误被发送到的这个文件。如果使用MySQL4.X或4.X以上版本，必须使用log-error指令替换这条命令。pid-file=/var/run/mysqld/mysqld.pid最后，pid-file指令定义MySQL服务器在运作期间的进程标识符(PID)。如果MySQL服务器当前没有运行，这个文件应该不存在。提示：用户可以配置与用户特定相关的MySQL配置文件；为此，只需给指定用户主目录中的.my.cnf隐含文件添加所选的配置命令即可。my-samll-cnf在本文中，将说明my-small-cnf配置文本中的所有命令。当回顾其它MySQL样本配置文件时，将参考本文所解释的各条命令和指令的含义。先从下面这个配置段开始分析该文件中的有效命令和指令：[client]这个配置把指令传递给与MySQL服务器相关的客户。port＝3306MySQL所相关的标准TCP/IP端口是3306。如果需要修改这个端口号(可以增强安全)，必须确保用于MySQL客户与服务器的所有相应配置文件中均修改这个号。socket=/var/lib/mysql/mysql.sock正像默认的/etc/my.cnf文件中所定义的那样，这是控制MySQL客户与服务器间通信的标准套接字文件。[mysqld]当启动MySQL服务器时，它由[mysqld]配置段中所定义的命令来控制。port=3306socket=/var/lib/mysql/mysql.sock当然，与同一个MySQL数据库相关的客户与服务器需要使用相同的TCP/IP端口和套接字。skip-locking多个客户可能会访问同一个数据库，因此这防止外部客户锁定MySQL服务器。这个skip-locking命令是MySQL4.X或4.X以上版本中的skip-external-locking命令。一般来说，如果正在使用MySQL4.X或4.X上以版本，这个set-variable指令没有必要带有这个列表中的这些命令。set-variable=key_buffer=16k这个缓冲区确实很小；如果一个数据库在一个文本文件中包含不止几百行数据，它将会超载这个缓冲区的容量。这个数据库可能不会超载一个文本文件地址簿的容量。如果这不只是一个供个人使用的数据库，这个限额很快就会被达到。假使那样的话，可能需要考虑与其它配置文件之一相关的那些限额。set-variable=max_allowed_packet=1M当然，与一个数据库相关的信息会增加到超出实际数据。在默认的情况下，如果该信息在一个服务器上超过1MB以上，MySQL将会产生一条错误信息。set-variable=thread_stack=64k这条指令限定用于每个数据库线程的栈大小。默认设置足以满足大多数应用。set-variable=table_cache=4用户可以限定一个数据库中打开表的数量；越小的限额(默认值是64)适合越小规模的数据库。set-variable=sort_buffer=64k在处理一个数据库时，用户可能需要内存中附加的缓冲区空间。set-variable=net_buffer_length=2k正如net_buffer_length指令所定义的，MySQL服务器还给传入的请求保留了空间。server-id=1一般来说，如果有一个MySQL主服务器，应该把它的server-id设置成１；应该把MySQL从属服务器的server-id设置成２；[mysqldump]用户可以在不同类型的SQL数据库之间传输数据，这由[mysqldump]配置段中的命令来控制。quickquick选项支持较大数据库的转储。set-variable=max_allowed_packet=16M当然，用来传输数据库表到其它数据库的max_allowed_packet大于客户与服务器之间的简单通信所使用的信息包。[mysql]no-auto-rehash这个配置段设置启动MySQL服务的条件；在这种情况下，no-auto-rehash确保这个服务启动得比较快。[isamchk][myisamchk]像SQL这样的关系数据库用所谓的Indexed Sequential Access Method(索引顺序存取方法，简称ISAM)来处理。这两个配置段中的命令是相同的；这些命令与检查并修复数据库表的同名命令有关。set-variable=key_buffer=8Mset-variable=sort_buffer=8M在前面谈及MySQL服务器时，用户己经见过这些变量。它们在这里都比较大，以便支持数据库的较快速检查与修复。[mysqlhotcopy]interactive-timeout正如[mysqlhotcopy]配置段所指定的，在一个数据库复制操作期间，连接会挂起。在默认情况下，interactive-timeout变量把一个数据传输的最大时间量设置为28800秒(8个小时)。my-medium.cnf文件与中等数据库相关的MySQL配置文件含有和my-small-cnf配置文件中一样的有效配置段。在[mysqld]配置段中，下面这些命令支持较大规模的服务器数据库：set-variable=key_buffer=16Mset-variable=table_cache=64set-variable=sort_buffer=512Kset-variable=net_buffer_length=8Klog-bin一般来说，这个配置段中的命令支持服务器上的较大高速缓存与缓冲区长度。应该看到两条新命令。set-variable=myisam_sort_buffer_size=8Mlog-binmyisam_sort_buffer_size命令允许MySQL索引数据库，第二条命令支持二进制日志记录方法。[isamchk][myisamchk]当然，这两个配置段中的缓冲区比用于数据库传输的缓冲区大，这个文件包含下面这些命令；它们发送消息到服务器和接收来自服务器的消息。set-variable=read_buffer=2Mset-variable=write_buffer=2Mmy-large.cnf文件与较大型数据库相关的MySQL配置文件含有和my-samll-cnf配置文件中一样的有效配置段。在本文中，将比较my-large-cnf与my-medium-cnf样本文件中的各条命令。在[mysqld]配置段中，下面这些命令支持较大型的服务器数据库：set-variable=key_buffer=256Mset-variable=table_cache=256set-variable=sort_buffer=1Mset-variable=myisam_sort_buffer_size=64Mset-variable=net_buffer_length=8K这个配置段中有３条附加的命令。record_buffer命令保存对一个数据库中不同表的扫描结果。thread_cache命令对多请求有用；空闲线程被高速缓存起来，进而允许新的搜索操作采用己有的线程。只要这防止搜索操作启动新的服务器进程，这就能减轻系统上的负荷。set-variable=record_buffer=1Mset-variable=thread_cache=8set-variable=thread_concurrency=8thread_concurrency变量限定同时运行的线程数量。my-large.cnf样本文件建议用户应该把这个数量限定于本计算机上CPU数量的两倍；这个特定设置相当于４个CPU。*my-huge.cnf文件my-huge.cnf文件含有和my-large.cnf配置文件中一样的命令。当然，分配给大多数指令的值比较大并适合较大型的数据库。 mysql备份和恢复数据库 mysqldump默认是锁表进行备份的 注意，如果你运行mysqldump没有—quick或—opt选项，mysqldump将在导出结果前装载整个结果集到内存中，如果你正在导出一个大的数据库，这将可能是一个问题。锁表进行备份时可能会影响业务操作，根据自身情况选择即可 打包成gz到当前目录 mysqldump -h 192.168.167.55 -utest1 -ptest2 --opt --compress --single-transaction test3 | gzip &gt; test3.sql.gz 恢复备份数据库 gunzip test3.sql.gz #解压 mysql&gt;source test3.sql #恢复 直接备份恢复到本地数据库 mysqldump -h 192.168.167.55 -utest1 -ptest2 --opt --compress --skip-lock-tables | mysql -h localhost -uroot -proot database 解释：192.168.167.55 远程服务器名称test1 远程数据库登录名test2 远程数据库登录密码test3 远程数据库名（即：复制的源localhost 本地数据库名称（一般情况下都是这个）root 本地数据库登录名（一般情况下都是这个）root 本地数据库登录密码（一般情况下都是这个）database 本地（即：复制的目标数据库）sql解释：&lt;/br&gt;mysqldump 是mysql的一个专门用于拷贝操作的命令—single-transaction 不锁表进行备份—opt 操作的意思—compress 压缩要传输的数据—skip-lock 忽略锁住的表（加上这句能防止当表有外键时的报错）-tables 某数据库所有表-h 服务器名称-u 用户名（后面无空格，直接加用户名）-p 密码（后面无空格，直接加密码）注意：-u、-p的后面没有空格，直接加用户名和密码！！！]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown-语法说明]]></title>
    <url>%2F2017%2F05%2F30%2FMarkdown-%E8%AF%AD%E6%B3%95%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[斜体和粗体 代码: 1.*斜体* 或者 _斜体_ 2.**粗体** 3.***加粗斜体*** 4.~~删除线~~ 显示效果: 1.斜体 或者 斜体 2.粗体 3.加粗斜体 4.删除线 分级标题 写法1，代码: # 一级标题 ## 二级标题 ### 三级标题 #### 四级标题 ##### 五级标题 ###### 六级标题 效果如下： 一级标题二级标题三级标题四级标题五级标题六级标题 写法2，代码: 一级标题 ============================ 二级标题 ---------------------------- 效果如下： 一级标题二级标题 超链接 Markdown 支持两种形式的链接语法： 行内式和参考式两种形式，行内式一般使用较多。 行内式 语法说明： []里写链接文字，()里写链接地址, ()中的”“中可以为链接指定title属性，title属性可加可不加。title属性的效果是鼠标悬停在链接上会出现指定的 title文字。链接文字’这样的形式。链接地址与链接标题前有一个空格。 代码： 欢迎来到[jet&#39;s blog](http://jethan.bid/) 欢迎来到[jet&#39;s blog](http://jethan.bid/ &quot;jet&#39;s blog&quot;) 显示效果： 欢迎来到jet’s blog 欢迎来到jet’s blog 参考式 参考式超链接一般用在学术论文上面，或者另一种情况，如果某一个链接在文章中多处使用，那么使用引用 的方式创建链接将非常好，它可以让你对链接进行统一的管理。 语法说明：参考式链接分为两部分，文中的写法 [链接文字][链接标记]，在文本的任意位置添加[链接标记]:链接地址 “链接标题”，链接地址与链接标题前有一个空格。 如果链接文字本身可以做为链接标记，你也可以写成[链接文字][][链接文字]：链接地址的形式，见代码的最后一行。 代码： 1.我经常去的几个网站[Google][1]、[印象笔记][2]以及[自己的博客][3] 2.[印象 笔记][2]是一个不错的[网站][]。 3.[1]:http://www.google.com &quot;Google&quot; 4.[2]:https://app.yinxiang.com &quot;印象笔记&quot; 5.[3]:http://jethan.bid &quot;jet&#39;s blog&quot; 6.[网站]:https://app.yinxiang.com 显示效果： 我经常去的几个网站Google、印象笔记以及自己的博客 印象 笔记是一个不错的网站。 自动链接 语法说明：Markdown 支持以比较简短的自动链接形式来处理网址和电子邮件信箱，只要是用&lt;&gt;包起来， Markdown 就会自动把它转成链接。一般网址的链接文字就和链接地址一样，例如： 代码： https://www.baidu.com/ &lt;fajie_han@foxmail.com&gt; 显示效果： https://www.baidu.com/ &#102;&#x61;&#x6a;&#105;&#x65;&#x5f;&#104;&#x61;&#x6e;&#x40;&#x66;&#x6f;&#x78;&#109;&#x61;&#x69;&#x6c;&#46;&#99;&#111;&#x6d; 列表无序列表 使用 *，+，- 表示无序列表 代码： - 无序列表项 一 + 无序列表项 二 * 无序列表项 三 显示效果： 无序列表项 一 无序列表项 二 无序列表项 三 有序列表 有序列表则使用数字接着一个英文句点。 代码： 1. 有序列表项 一 2. 有序列表项 二 3. 有序列表项 三 显示效果： 1.有序列表项 一 2.有序列表项 二 3.有序列表项 三 定义型列表 语法说明： 定义型列表由名词和解释组成。一行写上定义，紧跟一行写上解释。解释的写法:紧跟一个缩进(Tab) 代码： Markdown : 轻量级文本标记语言，可以转换成html，pdf等格式（左侧有一个可见的冒号和四个不可见的空格） 代码块 2 : 这是代码块的定义（左侧有一个可见的冒号和四个不可见的空格） 代码块（左侧有八个不可见的空格） 显示效果： Markdown 轻量级文本标记语言，可以转换成html，pdf等格式 代码块 2 这是代码块的定义 代码块（左侧有八个不可见的空格） 列表缩进 语法说明： 列表项目标记通常是放在最左边，但是其实也可以缩进，最多 3 个空格，项目标记后面则一定要接着至少一个空格或制表符。要让列表看起来更漂亮，你可以把内容用固定的缩进整理好（显示效果与代码一致）： 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！ 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩。 但是如果你懒，那也行： 代码： * 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。 那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。 软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！ * 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。 寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。 但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！ 悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩。 显示效果： 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！ 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩。 包含引用的列表 语法说明： 如果要在列表项目内放进引用，那 &gt; 就需要缩进： 代码： * 阅读的方法: &gt; 打开书本。 &gt; 打开电灯。 显示效果： 阅读的方法 打开书本。 打开电灯。 包含代码区块的引用 语法说明： 如果要放代码区块的话，该区块就需要缩进两次，也就是 8 个空格或是 2 个制表符： 一列表项包含一个列表区块： &lt;代码写在这&gt; 一个特殊情况 在特殊情况下，项目列表很可能会不小心产生，像是下面这样的写法： 1986. What a great season. 会显示成： What a great season. 换句话说，也就是在行首出现数字-句点-空白，要避免这样的状况，你可以在句点前面加上反斜杠： 1986\. What a great season. 会显示成： 1986. What a great season. 引用 语法说明： 引用需要在被引用的文本前加上&gt;符号。 代码： &gt; 这是一个有两段文字的引用, &gt; 无意义的占行文字1. &gt; 无意义的占行文字2. &gt; 无意义的占行文字3. &gt; 无意义的占行文字4. 显示效果： 这是一个有两段文字的引用, 无意义的占行文字1. 无意义的占行文字2. 无意义的占行文字3. 无意义的占行文字4. 引用的多层嵌套 区块引用可以嵌套（例如：引用内的引用），只要根据层次加上不同数量的 &gt; ： 代码： &gt;&gt;&gt; 请问 Markdwon 怎么用？ - 小白 &gt;&gt; 自己看教程！ - 愤青 &gt; 教程在哪？ - 小白 显示效果： 请问 Markdwon 怎么用？ - 小白 自己看教程！ - 愤青 教程在哪？ - 小白 引用其它要素 引用的区块内也可以使用其他的 Markdown 语法，包括标题、列表、代码区块等： 代码： &gt; 1. 这是第一行列表项。 &gt; 2. 这是第二行列表项。 &gt; &gt; 给出一些例子代码： &gt; &gt; return shell_exec(&quot;echo $input | $markdown_script&quot;); 显示效果： 这是第一行列表项。 这是第二行列表项。 给出一些例子代码： return shell_exec(“echo $input | $markdown_script”); 插入图像 图片的创建方式与超链接相似，而且和超链接一样也有两种写法，行内式和参考式写法。语法中图片Alt的意思是如果图片因为某些原因不能显示，就用定义的图片Alt文字来代替图片。 图片Title则和 链接中的Title一样，表示鼠标悬停与图片上时出现的文字。 Alt 和 Title 都不是必须的，可以省略，但建议写上。 行内式 语法说明： ![图片Alt](图片地址 “图片Title”) 代码： 阿狸： ![阿狸](http://jethan.bid/img/ali.jpg &quot;阿狸&quot;) 显示效果： 阿狸： 参考式 语法说明： 在文档要插入图片的地方写![图片Alt][标记] 在文档的最后写上[标记]:图片地址 “Title” 代码： 1.阿狸： 2.![阿狸][Ali] 3.[Ali]:http://jet-han.oschina.io/img/ali.jpg &quot;阿狸&quot; 显示效果： 阿狸： 注脚 语法说明： 在需要添加注脚的文字后加上脚注名字注脚名字,称为加注。 然后在文本的任意位置(一般在最后)添加脚注， 脚注前必须有对应的脚注名字。 注意：经测试注脚与注脚之间必须空一行，不然会失效。成功后会发现，即使你没有把注脚写在文末，经Markdown转换后，也会自动归类到文章的最后。 代码： 1.使用 Markdown[^1]可以效率的书写文档, 直接转换成 HTML[^2], 你可以使用 Leanote[^Le] 编辑器进行书写。 2. 3.[^1]:Markdown是一种纯文本标记语言 4. 5.[^2]:HyperText Markup Language 超文本标记语言 #此处有空格会不起作用 6. 7.[^Le]:开源笔记平台，支持Markdown和笔记直接发为博文 显示效果： 使用 Markdown1可以效率的书写文档, 直接转换成 HTML2, 你可以使用 LeanoteLe 编辑器进行书写。 LaTeX 公式渲染MathJax数学公式 在用markdown写技术文档时，免不了会碰到数学公式。常用的Markdown编辑器都会集成Mathjax，用来渲染文档中的类Latex格式书写的数学公式。基于Hexo搭建的个人博客，默认情况下渲染数学公式却会出现各种各样的问题。 原因 Hexo默认使用”hexo-renderer-marked”引擎渲染网页，该引擎会把一些特殊的markdown符号转换为相应的html标签，比如在markdown语法中，下划线’_’代表斜体，会被渲染引擎处理为&lt;\em&gt;标签。 因为类Latex格式书写的数学公式下划线 ‘_’ 表示下标，有特殊的含义，如果被强制转换为&lt;\em&gt;标签，那么 MathJax引擎在渲染数学公式的时候就会出错。例如，$x_i$在开始被渲染的时候，处理为$x&lt;\em&gt;i&lt;\/em&gt;$，这样MathJax引擎就认为该公式有语法错误，因为不会渲染。 类似的语义冲突的符号还包括’*’, ‘{‘, ‘}’, ‘\’等。 解决方法 更换Hexo的markdown渲染引擎，hexo-renderer-kramed引擎是在默认的渲染引擎hexo-renderer-marked的基础上修改了一些bug，两者比较接近，也比较轻量级。 npm uninstall hexo-renderer-marked --save npm install hexo-renderer-kramed --save 执行上面的命令即可，先卸载原来的渲染引擎，再安装新的。 然后，跟换引擎后行间公式可以正确渲染了，但是这样还没有完全解决问题，行内公式的渲染还是有问题，因为hexo-renderer-kramed引擎也有语义冲突的问题。接下来到博客根目录下，找到node_modules\kramed\lib\rules\inline.js，把第11行的escape变量的值做相应的修改： // escape: /^\\([\\`*{}\[\]()#$+\-.!_&gt;])/, escape: /^\\([`*\[\]()#$+\-.!_&gt;])/ 这一步是在原基础上取消了对\,{,}的转义(escape)。同时把第20行的em变量也要做相应的修改。 // em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/, em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/ 重新启动hexo（先clean再generate）,问题完美解决。哦，如果不幸还没解决的话，看看是不是还需要在使用的主题中配置mathjax开关。 在主题中开启mathjax开关 如何使用了主题了，别忘了在主题（Theme）中开启mathjax开关，下面以next主题为例，介绍下如何打开mathjax开关。 进入到主题目录，找到_config.yml配置问题，把mathjax默认的false修改为true，具体如下： # MathJax Support mathjax: enable: true per_page: true 别着急，这样还不够，还需要在文章的Front-matter里打开mathjax开关，如下： --- title: index.html date: 2016-12-28 21:01:30 tags: mathjax: true -- 不要嫌麻烦，之所以要在文章头里设置开关，是因为考虑只有在用到公式的页面才加载 Mathjax，这样不需要渲染数学公式的页面的访问速度就不会受到影响了。 $ 表示行内公式： 代码： 质能守恒方程可以用一个很简洁的方程式 $E=mc^2$ 来表达。 显示效果： 质能守恒方程可以用一个很简洁的方程式 $E=mc^2$ 来表达。 $$ 表示整行公式： 代码： $$\sum_{i=1}^n a_i=0$$ $$f(x_1,x_x,\ldots,x_n) = x_1^2 + x_2^2 + \cdots + x_n^2 $$ $$\sum^{j-1}_{k=0}{\widehat{\gamma}_{kj} z_k}$$ 显示效果： \sum_{i=1}^n a_i=0f(x_1,x_x,\ldots,x_n) = x_1^2 + x_2^2 + \cdots + x_n^2\sum^{j-1}_{k=0}{\widehat{\gamma}_{kj} z_k}访问 MathJax 参考更多使用方法。 流程图 代码： &lt;div id=&quot;flowchart-0&quot; class=&quot;flow-chart&quot;&gt;&lt;/div&gt; 显示效果： Install Generate flowchart diagrams for Hexo. npm install —save hexo-filter-flowchart config In your site’s _config.yml: flowchart: raphael: http://cdnjs.cloudflare.com/ajax/libs/raphael/2.2.7/raphael.min.js flowchart: https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.6.5/flowchart.min.js 表格 语法说明： 不管是哪种方式，第一行为表头，第二行分隔表头和主体部分，第三行开始每一行为一个表格行。 列于列之间用管道符|隔开。原生方式的表格每一行的两边也要有管道符。 第二行还可以为不同的列指定对齐方向。默认为左对齐，在-右边加上:就右对齐。 代码： 为列指定方向写表格： | Item | Value | Qty | | :- | -: | :-: | | Computer | 1600 USD | 5 | | Phone | 12 USD| 12 | | Pipe | 1 USD| 234 | 原生方式写表格： |Item|Value|Qty| |-|-|-| |Computer|1600 USD|5| |Phone|12 USD|12| |Pipe|1 USD|234| 显示效果： 为列指定方向写表格： Item Value Qty Computer 1600 USD 5 Phone 12 USD 12 Pipe 1 USD 234 原生方式写表格： Item Value Qty Computer 1600 USD 5 Phone 12 USD 12 Pipe 1 USD 234 使用Echarts动态图表 在博客页面中引用js文件 在所用主题目录下layout_partial中的head.swig里加入： &lt;script src=&quot;http://echarts.baidu.com/dist/echarts.common.min.js&quot;&gt;&lt;/script&gt; 安装hexo-tag-echarts插件 npm install hexo-tag-echarts --save 使用范例 对于echarts实例，将其提供的option部分复制，形成下述代码即可。 {% echarts 400 '81%' %} { tooltip : { trigger: 'axis', axisPointer : { // 坐标轴指示器，坐标轴触发有效 type : 'shadow' // 默认为直线，可选为：'line' | 'shadow' } }, legend: { data:['利润', '支出', '收入'] }, grid: { left: '3%', right: '4%', bottom: '3%', containLabel: true }, xAxis : [ { type : 'value' } ], yAxis : [ { type : 'category', axisTick : {show: false}, data : ['周一','周二','周三','周四','周五','周六','周日'] } ], series : [ { name:'利润', type:'bar', itemStyle : { normal: { label: {show: true, position: 'inside'} } }, data:[200, 170, 240, 244, 200, 220, 210] }, { name:'收入', type:'bar', stack: '总量', itemStyle: { normal: { label : {show: true} } }, data:[320, 302, 341, 374, 390, 450, 420] }, { name:'支出', type:'bar', stack: '总量', itemStyle: {normal: { label : {show: true, position: 'left'} }}, data:[-120, -132, -101, -134, -190, -230, -210] } ] }; {% endecharts %} 效果显示 // 基于准备好的dom，初始化echarts实例 var myChart = echarts.init(document.getElementById('echarts6557')); // 指定图表的配置项和数据 var option = { tooltip : { trigger: 'axis', axisPointer : { // 坐标轴指示器，坐标轴触发有效 type : 'shadow' // 默认为直线，可选为：'line' | 'shadow' } }, legend: { data:['利润', '支出', '收入'] }, grid: { left: '3%', right: '4%', bottom: '3%', containLabel: true }, xAxis : [ { type : 'value' } ], yAxis : [ { type : 'category', axisTick : {show: false}, data : ['周一','周二','周三','周四','周五','周六','周日'] } ], series : [ { name:'利润', type:'bar', itemStyle : { normal: { label: {show: true, position: 'inside'} } }, data:[200, 170, 240, 244, 200, 220, 210] }, { name:'收入', type:'bar', stack: '总量', itemStyle: { normal: { label : {show: true} } }, data:[320, 302, 341, 374, 390, 450, 420] }, { name:'支出', type:'bar', stack: '总量', itemStyle: {normal: { label : {show: true, position: 'left'} }}, data:[-120, -132, -101, -134, -190, -230, -210] } ] }; // 使用刚指定的配置项和数据显示图表。 myChart.setOption(option); 分隔线 你可以在一行中用三个以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西。你也可以在星号或是减号中间插入空格。下面每种写法都可以建立分隔线： 代码： * * * *** ***** - - - --------------------------------------- 显示效果都一样： 代码 对于程序员来说这个功能是必不可少的，插入程序代码的方式有两种，一种是利用缩进(Tab), 另一种是利用”`”符号（一般在ESC键下方）包裹代码。 语法说明： 插入行内代码，即插入一个单词或者一句代码的情况，使用`code`这样的形式插入。插入多行代码，可以使用缩进或者“` code “`,具体看示例。注意： 缩进式插入前方必须有空行 行内式 代码： C语言里的函数 `scanf()` 怎么使用？ 显示效果： C语言里的函数 scanf() 怎么使用？ 缩进式多行代码 缩进 4 个空格或是 1 个制表符 一个代码区块会一直持续到没有缩进的那一行（或是文件结尾）。 代码： #include &lt;stdio.h&gt; int main(void) { printf(&quot;Hello world\n&quot;); } 显示效果： #include &lt;stdio.h&gt; int main(void) { printf(&quot;Hello world\n&quot;); } 用六个`包裹多行代码 代码： 12345#include &lt;stdio.h&gt;int main(void)&#123; printf(&quot;Hello world\n&quot;);&#125; 显示效果： 12345#include &lt;stdio.h&gt;int main(void)&#123;printf(&quot;Hello world\n&quot;);&#125; HTML 原始码 在代码区块里面， &amp; 、 &lt; 和 &gt; 会自动转成 HTML 实体，这样的方式让你非常容易使用 Markdown 插入范例用的 HTML 原始码，只需要复制贴上，剩下的 Markdown 都会帮你处理，例如： 代码： &lt;table&gt; &lt;tr&gt; &lt;th rowspan=&quot;2&quot;&gt;值班人员&lt;/th&gt; &lt;th&gt;星期一&lt;/th&gt; &lt;th&gt;星期二&lt;/th&gt; &lt;th&gt;星期三&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;李强&lt;/td&gt; &lt;td&gt;张明&lt;/td&gt; &lt;td&gt;王平&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; 显示效果： 值班人员 星期一 星期二 星期三 李强 张明 王平 自定义字体 在 主题配置 - NexT 使用文档 中提及了如何设置字体样式，这里就不再赘述了。如果想自定义字体大小以及颜色，可以直接在 Markdown 文档中使用 html 语法 &lt;font size=4 &gt; 这里输入文字，自定义大小 &lt;/font&gt; &lt;font color=&quot;#FF0000&quot;&gt; 这里输入文字，自定义颜色的字体 &lt;/font&gt; 效果： 这里输入文字，自定义大小 这里输入文字，自定义颜色的字体 st=>start: Start|past:>http://www.google.com[blank] e=>end: End:>http://www.google.com op1=>operation: My Operation|past op2=>operation: Stuff|current sub1=>subroutine: My Subroutine|invalid cond=>condition: Yes or No?|approved:>http://www.google.com c2=>condition: Good idea|rejected io=>inputoutput: catch something...|request st->op1(right)->cond cond(yes, right)->c2 cond(no)->sub1(left)->op1 c2(yes)->io->e c2(no)->op2->e{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);st=>start: Start|past:>http://www.google.com[blank] e=>end: End:>http://www.google.com op1=>operation: My Operation|past op2=>operation: Stuff|current sub1=>subroutine: My Subroutine|invalid cond=>condition: Yes or No?|approved:>http://www.google.com c2=>condition: Good idea|rejected io=>inputoutput: catch something...|request st->op1(right)->cond cond(yes, right)->c2 cond(no)->sub1(left)->op1 c2(yes)->io->e c2(no)->op2->e{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-1-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-1-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-1", options);]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo-NexT主题搭建个人博客]]></title>
    <url>%2F2017%2F05%2F27%2FHexo-NexT%E4%B8%BB%E9%A2%98%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[linux下搭建hexo之next主题个人博客，仅供参考！有问题请留言，谢谢支持！ 所需环境 下载安装nodejs和git(for linux)，声明一下我的搭建环境centos6.8 nodejs安装 准备命令： yum -y install gcc make gcc-c++ openssl-devel wget 载源码及解压： wget http://nodejs.org/dist/v0.10.26/node-v0.10.26.tar.gz tar -zvxf node-v0.10.26.tar.gz 编译及安装： make &amp;&amp; make install 验证是否安装配置成功： node -v 安装Express开发框架 npm install -g express npm install -g express-generator express -t ejs newsproject npm install 新建成功在nodesj目录下会生成newproject目录，其目录下大致有以下文件 bin 相关运行脚本 public 静态资源 routes 路由表 views 试图模板 app.js 视图文件夹 packge.json 项目依赖说明 启动项目 npm start 在浏览器访问http://127.0.0.1:3000/ 测试出现下面图视表示nodejs安装成功，并可以正常部署项目 node -v npm -v git安装 在线源安装 yum install git 安装Hexo命令解释 常用命令: hexo help #查看帮助 hexo init #初始化一个目录 hexo new &quot;postName&quot; #新建文章 hexo new page &quot;pageName&quot; #新建页面 hexo generate #生成网页, 可以在 public 目录查看整个网站的文件 hexo server #本地预览, &#39;Ctrl+C&#39;关闭 hexo deploy #部署.deploy目录 hexo clean #清除缓存, 强烈建议每次执行命令前先清理缓存, 每次部署前先删除 .deploy 文件夹 复合命令: hexo deploy -g #生成加部署 hexo server -g #生成加预览 简写： hexo n == hexo new hexo g == hexo generate hexo s == hexo server hexo d == hexo deploy 安装插件, plugin-name为插件名 npm install plugin-name --save #安装 npm update #升级 npm uninstall plugin-name #卸载 安装主题, repository为主题的 git 仓库, 为要存放在本地的目录名 git clone repository themes/theme-name 修改网站配置文件 theme: theme-name 在线源安装 npm install -g hexo-cli #g代表全局,npm默认为当前项目安装 hexo init #hexo初始化 npm install #安装依赖包 hexo g #生成静态资源生成public文件夹(浏览器访问资源) hexo s #启动服务 在浏览器访问：http://localhost:4000/ 便可查看hexo默认的主题 clone NexT主题,在blog根目录执行命令 git clone https://github.com/iissnan/hexo-theme-next themes/next clone完成后打开blog下的themes文件夹就可以看到有两个主题，一个是默认的，一个是刚刚clone的NexT主题站点配置文件_config.yml主题配置文件themes/next/_config.yml在站点配置文件_config.yml中进行搜索key为’theme’，如果没有theme就添加key为 theme，其值为next #Extensions ##Plugins: https://hexo.io/plugins/ ##Themes: https://hexo.io/themes/ #theme: landscape theme: next 需要注意的是theme: next ，冒号后面有一个空格 hexo clean #清除静态资源 hexo g hexo s 在浏览器中访问http://localhost:4000/ 便可看到效果 打开主题配置文件_config.yml找到Schemes，如下所示有三种方案可选，只需将#去掉就可以了，可以都尝试一下，选择喜欢的风格，修改之后不用重启服务直接刷新浏览器就能看到效果 #切换样式 #Schemes #scheme: Muse #scheme: Mist scheme: Pisces 到此本地资源基本上完成了，下面贴出站点配置_config.yml和主题配置themes/next/_config.yml里面注释了信息仅供参考 全局配置 _config.yml，配置文件的冒号”:”后面有空格 # Site #站点信息 title: Hank subtitle: Hank&#39;s Blog description: 关注WEB前端，前端开发 author: hank author_title: &#39;Web Developer &amp; Designer&#39; avatar: css/img/avatar.png location: &#39;Beijing, China&#39; follow: https://github.com/huangjihua/ language: zh-CN since: 2015 timezone: Asia/Beijing #时区 # URL #链接格式 url: http://blog.huangjihua.com #网址 root: / #根目录 permalink: post/:title.html #文章的链接格式 permalink_defaults: # Directory #目录 source_dir: source #源文件 public_dir: public #生成的网页文件 tag_dir: tags #标签 archive_dir: archives #归档 category_dir: categories #分类 code_dir: downloads/code i18n_dir: :lang #国际化 skip_render: # Writing #写作 new_post_name: :title.md #新文章标题 default_layout: post #默认模板(post page photo draft) titlecase: false #标题转换成大写 external_link: true #新标签页里打开连接 filename_case: 0 render_drafts: false post_asset_folder: false relative_link: false future: true highlight: #语法高亮 enable: true line_number: false #显示行号 auto_detect: true tab_replace: # Category &amp; Tag #分类和标签 default_category: uncategorized #默认分类 category_map: tag_map: # Date / Time format #日期时间格式 ## http://momentjs.com/docs/#/displaying/format/ date_format: YYYY-MM-DD time_format: HH:mm:ss # Pagination #分页 per_page: 20 #每页文章数, 设置成 0 禁用分页 pagination_dir: page # Extensions #插件和主题 ## 插件: http://hexo.io/plugins/ ## 主题: http://hexo.io/themes/ theme: next # Deployment #部署, huangjihua是我的用户名, 同时发布在 GitHub 和 GitCafe 上面 deploy: type: git repository: github: https://github.com/huangjihua/huangjihua.github.io.git,master gitcafe: https://gitcafe.com/huangjihua/huangjihua.git,master # Disqus #Disqus评论系统 disqus_shortname: plugins: #插件，例如生成 RSS 和站点地图的 - hexo-generator-feed - hexo-generator-sitemap # Assets css: css js: js images: images # Theme version version: 5.0.1 # Donate 文章末尾显示打赏按钮 reward_comment: 如果文章对您有用请随意打赏，谢谢支持！ wechatpay: /img/w.png alipay: /img/z.jpg 菜单栏 菜单栏为中文简体字，主题配置文件 language: zh-Hans 这样就引用了themes\next\languages\zh-Hans.yml文件，打开这个文件就可以看每个key对应的都是中文字体 标签和分类 在主题配置文件中找到menu，如果想隐藏菜单栏中的某个选项只要在前面加上 # 即可 menu: home: / categories: /categories #分类 archives: /archives #归档 tags: /tags #标签 message: /message #留言 about: /about #关于 # commonweal: /404.html #公益 我们将categories 和tags 设为显示,再找到menu_icons, 这里是每一个菜单选项前面对应的小图标icon menu_icons: enable: true #KeyMapsToMenuItemKey: NameOfTheIconFromFontAwesome home: home categories: th tags: tags archives: archive commonweal: heartbeat message: external-link about: user 我们将categories 和tags 设为显示,生成categories 和 tags的页面 hexo n page &quot;categories&quot; hexo n page &quot;tags&quot; 会生成source\categories 和 source\tags 两个文件夹，里面都有index.md文件.修改内容为 --- title: categories type: categories --- --- title: tags type: tags --- 再使用命令生成博文文件 hexo n &quot;name&quot; #name 文章名称 生成文章时，在对应的name.md中可以这样添加标签和分类 --- title: Hexo-NexT主题搭建个人博客 date: 2017-05-24 15:39:31 update: 2017-05-24 06:19:11 categories: hexo #分类 tags: [nodejs, hexo, next] #[标签1, 标签2..., 标签n] --- 网易云跟帖评论功能 主题配置文件 menu: home: / categories: /categories archives: /archives tags: /tags message: /message #新增 message about: /about #commonweal: /404.html 配置图标 menu_icons: enable: true home: home categories: th tags: tags archives: archive commonweal: heartbeat message: external-link #新增 message about: user 配置对应的中文名称，在themes/next/languages/zh-Hans.yml文件中修改如下 menu: home: 首页 archives: 归档 categories: 分类 tags: 标签 about: 关于 search: 搜索 message: 留言 #新增 留言 commonweal: 公益404 udpate: 更新 然后执行如下命令 hexo n page &quot;message&quot; 重新清除，生成和启动便可看到效果，只不过留言功能什么也没有 hexo clean hexo g hexo s 进入官网https://manage.gentie.163.com 进行注册、登录（可以用QQ）。登录完成在首页进入后台管理，填写基本信息（站点信息），获取代码找到 productKey的值，写入主题配置文件gentie_productKey处在主题配置文件中修改如下 # Gentie productKey gentie_productKey: your key 留言功能已完成去掉分类和其他的选项的留言功能，只需修改index.md在source/categories/index.md 中修改如下 --- title: categories type: categories comments: false #去掉评论功能 date: 2017-05-24 21:07:35 --- 修改头像 设置菜单栏头像把头像0.jpg图片放在themes/next/source/img中在站点的_config.yml，修改字段 avatar 设置头像 avatar: /img/0.jpg 可以指定网址图片url 侧边栏社交链接 侧栏社交链接的修改包含两个部分，第一是链接，第二是链接图标。 两者配置均在 主题配置文件 中。social 字段下，一行一个链接。其键值格式是 显示文本: 链接地址 ##Social links social: GitHub: https://github.com/your-user-name Twitter: https://twitter.com/your-user-name 微博: http://weibo.com/your-user-name 豆瓣: http://douban.com/people/your-user-name 知乎: http://www.zhihu.com/people/your-user-name #Social Icons 设定链接的图标，对应的字段是 social_icons。其键值格式是 匹配键: Font Awesome 图标名称， 匹配键 与上一步所配置的链接的 显示文本 相同（大小写严格匹配），图标名称 是 Font Awesome 图标的名字（不必带 fa- 前缀）。 enable 选项用于控制是否显示图标，你可以设置成 false 来去掉图标。 social_icons: enable: true #Icon Mappings GitHub: github Twitter: twitter 微博: weibo 友情链接 编辑 主题配置文件 添加： # Blogrolls links_title: 友情链接 links_layout: inline links_icon: link # 设置图标 links: 百度: http://www.baidu.com 文章配置开启阅读全文 修改主题配置文件 auto_excerpt: enable: true # 开启文章阅全文 length: 2000 # 显示长度 新增阅读量 为每一篇文章统计阅读量使用leancloud进行文章变更统计，进入官网https://leancloud.cn/ 注册打开LeanCloud官网，进入注册页面注册。完成邮箱激活后，点击头像，进入控制台页面创建新应用点击应用创建新应用，应用名称随便起创建Class文件进入到应用后点击存储，在左侧点击设置，选择”创建Class”，名称必须为Counter修改主题配置文件 ##文章阅读量 leancloud_visitors: enable: true app_id: **你的app_id** app_key: **你的app_key** 其中，app_id和app_key在你所创建的应用的设置-&gt;应用Key中修改 themes/next/layout_macro/post.swig 文件配置themes/next/layout/_layout.swig文件在最后div标签中查找是否引用了_scripts/third-party/lean-analytics.swig文件，如果没有增加以下代码修改语言配置文件 themes/next/languages/zh-Hans.yml post字段 post: sticky: 置顶 posted: 发表于 updated: 最近 update: 更新于 in: 分类于 visitors: 阅读量 read_more: 阅读全文 untitled: 未命名 toc_empty: 此文章未包含目录 其他语言与之类似，将visitors设置成你希望翻译的字段。最后，重新清除并生成你的网站即可。Web安全性为了保证应用的统计计数功能仅应用于自己的博客系统，你可以在应用-&gt;设置-&gt;安全中心的Web安全域名中加入自己的博客域名，以保证数据的调用安全。直接加上首页地址即可,保存三分之后生效，这时在本地方访问便不会统计。 文章最近更新时间 确保themes/next/layout_scripts/third-party/lean-analytics.swig文件已有update添加文章更新时间scaffolds/post.md 文件 --- title: {{ title }} date: {{ date }} categories: tags: update: {{ date }} # 新增更新时间 --- themes/next/layout_macro/post.swig 文件在每次新建文章时，默认更新时间就是发表时间，更新文章时需要手动修改udpate的值。例如source_posts\hexo之next主题.md --- title: Hexo之NexT主题搭建博客详细过程 date: 2017-05-24 15:39:31 update: 2017-05-24 15:39:31 #每次更新需手动修改成这样的格式时间 categories: hexo tags: [nodejs, hexo] --- 修改themes\next\languages\zh-Hans.yml post: sticky: 置顶 posted: 发表于 updated: 最近 update: 更新于 # 新增 in: 分类于 visitors: 阅读量 read_more: 阅读全文 untitled: 未命名 toc_empty: 此文章未包含目录 为文章增加分享 使用百度分享只修改主题配置文件即可 baidushare: type: button 为文章增加打赏 修改主题配置文件, 收款二维码放在themes/next/source/img 目录下 #Donate 文章末尾显示打赏按钮 reward_comment: 如果文章对您有用请随意打赏，谢谢支持！ wechatpay: /img/w.png alipay: /img/z.jpg 设置代码高亮主题 NexT 使用 Tomorrow Theme 作为代码高亮，共有5款主题供你选择。 NexT 默认使用的是 白色的 normal 主题，可选的值有 normal，night， night blue， night bright， night eighties：在主题配置文件中修改 # Code Highlight theme # Available value: # normal | night | night eighties | night blue | night bright # https://github.com/chriskempson/tomorrow-theme highlight_theme: night eighties # 修改即可 文章添加音乐链接 Hexo支持解析markdown语法，因此每篇博文都是以.md结尾的文件。而markdown又支持如表格、脚注、内嵌HTML等等，所以在.md文件中直接添加html代码！网音乐云音乐，虾米音乐都可以生成内嵌音乐的html代码，复制粘贴到.md文件中即可 &lt;div&gt; &lt;center&gt; &lt;iframe frameborder=&quot;no&quot; border=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; width=330 height=86 src=&quot;https://music.163.com/outchain/player?type=2&amp;id=33856282&amp;auto=0&amp;height=66&quot;&gt; &lt;/iframe&gt; &lt;/center&gt; &lt;/div&gt; 本地站内搜索 以前使用的Swiftype现在不能免费使用了，我这里就是用本地配置进行站内搜索安装 hexo-generator-search，在站点的根目录下执行以下命令: npm install hexo-generator-search --save 编辑 站点配置文件，新增以下内容到任意位置： search: path: search.xml field: post 不蒜子统计站点访次数和访问量 修改themes/next/layout/_partials目录下的footer.swig &lt;div class=&quot;total_count&quot;&gt; 本站共 &lt;span id=&quot;busuanzi_value_site_pv&quot;&gt;&lt;/span&gt;&lt;span id=&quot;site_pv&quot;&gt;次访问&lt;/span&gt; 您是第 &lt;span id=&quot;busuanzi_value_site_uv&quot;&gt;&lt;/span&gt;&lt;span id=&quot;site_uv&quot;&gt;个小伙伴&lt;/span&gt; 本页累计 &lt;span id=&quot;busuanzi_value_page_pv&quot;&gt;&lt;/span&gt;&lt;span id=&quot;page_pv&quot;&gt;次阅读&lt;/span&gt; &lt;span id=&quot;showDays&quot;&gt;&lt;/span&gt; &lt;/div&gt; {% endif %} 百度/google收录你的站点 安装sitemap插件 npm install hexo-generator-sitemap --save #google npm install hexo-generator-baidu-sitemap --save #百度 在站点配置文件_config.yml中添加如下代码： #自动生成sitemap sitemap: path: sitemap.xml baidusitemap: path: baidusitemap.xml 会在public目录下生成baidusitmap.xml 和 sitemap.xml两个文件安装hexo-deployer-git插件 npm install hexo-deployer-git --save #部署到github 在项目根目录下执行命令 hexo clean # 清除资源 hexo g # 生成静态资源 hexo d # 部署 登录在github打开存放博客资源的仓库，就能看到部署的资源文件分别向google,baidu提交站点地图sitemap.xml,baidusitmap.xml百度站长： http://zhanzhang.baidu.com/site/index输入你想添加的网站：你的博客首页地址然后按照提示选择验证方式，点击完成验证。 google站长： https://www.google.com/webmasters/tools/home?hl=zh-CN添加网站后，进行左侧抓取站点地图，添加/测试站点地图，填写sitemap.xml。sitemap.xml就在github存放博客 仓库的根目录下验证完成后大概过一天时间便可google到你的站点了，百度不定。 统计本站运行天数 修改blog/themes/next/layout_partials/footer.swig文件，在后面追加以下代码 &lt;script&gt; var birthDay = new Date(&#39;05/24/2016&#39;); var now = new Date(); var duration = now.getTime() - birthDay.getTime(); var total= Math.floor(duration / (1000 * 60 * 60 * 24)); document.getElementById(&#39;showDays&#39;).innerHTML=&#39;本站已运行&#39; + total + &#39;天&#39;; &lt;/script&gt; 在最后一个div中追加一下代码 &lt;span id=&quot;showDays&quot;&gt;&lt;/span&gt; 腾讯公益404页面 腾讯公益404页面，寻找丢失儿童，让大家一起关注此项公益事业！效果如下 http://www.ixirong.com/404.html 使用方法，新建 404.html 页面，放到主题的 source 目录下，内容如下： &lt;!DOCTYPE HTML&gt; &lt;html&gt; &lt;head&gt; &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html;charset=utf-8;&quot;/&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge,chrome=1&quot; /&gt; &lt;meta name=&quot;robots&quot; content=&quot;all&quot; /&gt; &lt;meta name=&quot;robots&quot; content=&quot;index,follow&quot;/&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://qzone.qq.com/gy/404/style/404style.css&quot;&gt; &lt;/head&gt; &lt;body&gt; &lt;script type=&quot;text/plain&quot; src=&quot;http://www.qq.com/404/search_children.js&quot; charset=&quot;utf-8&quot; homePageUrl=&quot;/&quot; homePageName=&quot;回到我的主页&quot;&gt; &lt;/script&gt; &lt;script src=&quot;https://qzone.qq.com/gy/404/data.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt; &lt;script src=&quot;https://qzone.qq.com/gy/404/page.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt; &lt;/body&gt; &lt;/html&gt; 到此本地资源博客搭建已经完成，有些细微调节可根据浏览器控制台找到对应的模板进行调节，比如站点背景，代码字体字体颜色，页面宽度等等(参考资源： http://gniba.com/2016/07/11/next-custom.html ) 托管到github 修改站点配置文件 # Deployment ## Docs: https://hexo.io/docs/deployment.html deploy: type: git repository: git@github.com:jethan/githug.git branch: master]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>个人博客</tag>
      </tags>
  </entry>
</search>